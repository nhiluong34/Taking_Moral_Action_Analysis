---
title: "TMA analysis"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# Load in libraries

```{r}
library(tidyverse)
library(tm)
library(tidytext)
library(ggplot2)
library(dplyr)
library(pdftools)
library(stringr)
```

# Scrape book pdf

```{r}
text <- pdf_text("TakingMoralActionFinal-3.pdf")
```

## Basic info

```{r}
# Author, version, etc
pdf_info("TakingMoralActionFinal-3.pdf")

# Table of contents
toc <- pdf_toc("TakingMoralActionFinal-3.pdf") # doesn't work well here

# Fonts
pdf_fonts("TakingMoralActionFinal-3.pdf")

```


## Look at some pages

```{r}
# Preface first page, index [11]
text[11]

# Chapter 1: Evolution (first page)
cat(text[57])
```

## Basic text cleaning

```{r}
text_trim <- str_squish(text)
# Total of 370

text_trim[55]
```

# Divide into Part then Chapter

```{r}
str_view(text_trim, "^Part") # detects string that starts with the word "Part"

str_view(text_trim, "References")

str_extract(text_trim[55], "\\d+")
```

- Using str_view, we see Part I is from [55] to [140], Part II [141] to [230], Part III [231] to end (including Index). We could use this to combine text into 3 Parts first.
- Part I: Contexts
- Part II: Influences
- Part III: Processes

```{r}
part1 <- text_trim[55:140]
part2 <- text_trim[141:230]
part3 <- text_trim[231:370]
```

- Now, within each part, we can combine the chapters together. Using the table of contents, we know the starting page of each chapter, so repeat the same process above.

```{r}
# p1c1 stands for part 1 chapter 1 and so on
p1c1 <- part1[3:28]
p1c2 <- part1[29:56]
p1c3 <- part1[57:86]
p2c4 <- part2[3:28]
p2c5 <- part2[29:58]
p2c6 <- part2[59:90]
p3c7 <- part3[3:38]
p3c8 <- part3[39:69]
p3c9 <- part3[70:114]
coda <- part3[115:122]
index <- part3[123:140]

```

## Turn into clean tibble

```{r}
# Odd pages have the word "Evolution" first then the page, so we'll switch that using str_replace

p1c1 <- str_replace(p1c1, "(^Evolution) (\\d)", "\\2 \\1")
```

```{r}
# Test manually first
p1c1_collapse <- str_c(p1c1, collapse = " ")
```

### Make a function to repeat the process

```{r}
# Function takes in 3 parameters: the text, part number, and chapter number
collapse_func <- function(text, part, chapter) {
  text <- str_c(text, collapse = " ")
  text <- str_trim(str_remove(text, "^\\d"))
  tibble(part = part, chapter = chapter, text)
}
```

```{r}
# Individual chapters in tibble
p1c1_tbl <- collapse_func(p1c1, 1, 1)
p1c2_tbl <- collapse_func(p1c2, 1, 2)
p1c3_tbl <- collapse_func(p1c3, 1, 3)
p2c4_tbl <- collapse_func(p2c4, 2, 4)
p2c5_tbl <- collapse_func(p2c5, 2, 5)
p2c6_tbl <- collapse_func(p2c6, 2, 6)
p3c7_tbl <- collapse_func(p3c7, 3, 7)
p3c8_tbl <- collapse_func(p3c8, 3, 8)
p3c9_tbl <- collapse_func(p3c9, 3, 9)

# Part I tibble
part1_tbl <- rbind(p1c1_tbl, p1c2_tbl, p1c3_tbl)

# Part 2
part2_tbl <- rbind(p2c4_tbl, p2c5_tbl, p2c6_tbl)

# Part 3
part3_tbl <- rbind(p3c7_tbl, p3c8_tbl, p3c9_tbl)

# All 3 parts, so the most of the book except Preface, Coda and Index
all_parts <- rbind(part1_tbl, part2_tbl, part3_tbl)

```

# Text analysis

```{r}
# Load in stopwords
smart_stopwords <- get_stopwords(source = "smart")
```

```{r}
# Unnest to words
chap1_words <- p1c1_tbl |>
  unnest_tokens(word, text)

# Filter out stop words
chap1_words |>
  anti_join(smart_stopwords) |>
  count(word, sort = TRUE)
```

```{r}
# Make some plots

# Chapter 1
chap1_words |>
  anti_join(smart_stopwords) |>
  count(word, sort = TRUE) |>
  filter(word != "NA") |>
  slice_max(n, n = 20) |>
  ggplot(aes(fct_reorder(word, n), n)) +
  geom_col() +
  coord_flip()

# Chapter 2
p1c2_tbl |>
  unnest_tokens(word, text) |>
  anti_join(smart_stopwords) |>
  count(word, sort = TRUE) |>
  filter(word != "NA") |>
  slice_max(n, n = 20) |>
  ggplot(aes(fct_reorder(word, n), n)) +
  geom_col() +
  coord_flip()

# Chapter 3
p1c3_tbl |>
  unnest_tokens(word, text) |>
  anti_join(smart_stopwords) |>
  count(word, sort = TRUE) |>
  filter(word != "NA") |>
  slice_max(n, n = 20) |>
  ggplot(aes(fct_reorder(word, n), n)) +
  geom_col() +
  coord_flip()
```

# IGNORE: Test area (where I test different codes)

```{r}
str_view(text_trim, "^Part") #comment
str_view(part3, "^Index")

# Table will look something like this
tibble(part = 1, text = part1)

str_view(part1, "References")
test <- str_c(p1c1, collapse = " ")
str_trim(str_remove(test, "^\\d"))
```

