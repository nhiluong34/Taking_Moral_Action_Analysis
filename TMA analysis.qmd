---
title: "TMA analysis"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

# Load in libraries

```{r}
library(tidyverse)
library(tm)
library(tidytext)
library(ggplot2)
library(dplyr)
library(pdftools)
library(stringr)
library(readr)
library(tidyr)
```

```{r}
references <- read_csv("references.csv")
book <- read_csv("book.csv")
three_parts <- read_csv("three_parts.csv")

#Sentiments
ncr <- get_sentiments("nrc")
bing <- get_sentiments("bing")
afinn <- get_sentiments("afinn")

stop_words <- stop_words |> filter(lexicon == "SMART")
```

# Chapter Analysis

```{r}
book_sentiment <- book |>
  unnest_tokens(sentences, text, token = "lines") |>
  group_by(chapter) |>
  mutate(linenumber = row_number()) |>
  ungroup() |>
  unnest_tokens(word, sentences) |>
  inner_join(bing) |>
  count(chapter, linenumber, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative) |>
  ggplot(aes(linenumber, sentiment, fill = chapter)) +
  geom_col(show.legend = F) +
  facet_wrap(~chapter, ncol = 2, scales = "free_x")
```

# Count references

## Chapter
```{r}
book |> 
  mutate(text = str_to_lower(text),
         ref_extract = str_extract_all(text, "chapter \\d")) |>
  select(sections, ref_extract) |>
  unnest(ref_extract) |>
  group_by(sections, ref_extract) |>
  count()
```

## Sections
```{r}
book |>
  mutate(text = str_to_lower(text),
         ref_extract = str_extract_all(text, "section \\d+(?:\\.\\d+)+")) |>
  select(sections, ref_extract) |>
  unnest(ref_extract) |>
  group_by(sections, ref_extract) |>
  count()

str_view(book$text, "Section \\d+(?:\\.\\d+)+")
```


# !Test Area

```{r}
test <- book |> filter(book == 1.1) |> pull(text)

str_view(test, "Chapter \\d")
str_extract_all(test, "Chapter \\d")
str_extract_all(test, "Section \\d")
```

