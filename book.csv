chapter,sections,text
1,1.1,"The Social Brain of The human brain is among the largest relative to body size in mammals ­(Herculano-­Houzel, 2009), but more surprising is that in the evolutionary time scale, the brain has recently (in the last million years or so) shown rapid increases in size (Adolphs, 2009). This poses a puzzle: Why such a massive increase in such a relaro tively short time? One widely accepted answer to this puzzle is the social brain hypothesis (Adolphs, 2009; Byrne & Whiten, 1988; Whiten & van Schaik, 2007). This is the idea that the rapid development of the brain was in response to1 increases in the complexity of the social problems that were necessary for early hominids to lP solve. These problems include many of those we will review in this chapter: various forms of cooperation, deception, status hierarchy negotiation, altruistic punishment, and anticipatory fear of punishment. It is during this rapid spate of development that humans became a species able to enact a complex (im)morality. Philosophers as early as Aristotle (1941) recognized the importance of the social na nature of humans. His discussion of humans as zōon politikon2 in the early chapters of the Politics makes it clear that our social nature (as opposed to that of bees or cranes) is intimately related to our concern for justice. For Aristotle and many thinkers that followed, the connection between our social nature and our moral nature is intimate and inextricable. We will find this to be true in our evolutionary history as well. We know today that moral judgment and action involve a rich, complex interaction Fi of emotion, inference, automatic and controlled processing, strategic planning, etc. A core assumption of evolutionary psychology is that the capacities for these activities evolved under the pressure of selection from the social environment and together constitute our distinct form of moral/social organization as the human species (Krebs, 2008). 1 Or at least in coevolutionary tandem with, see Section 2.4. 2 Perhaps best translated as political beings. Aristotle’s Politics is about the role that the community and its lawgivers should play in bringing about the virtuous life in the citizens. Thus, morality is closely linked to our social nature. Taking Moral Action, First Edition. Chuck Huff and Almut Furchert. © 2023 John Wiley & Sons Ltd. Published 2023 by John Wiley & Sons Ltd. Taking Moral Action To understand how these capacities might have evolved, we first need to ­understand some basic concepts and terminology in evolution. That will give us the vocabulary to describe how difficult it is to build a strong case that some particular psychological characteristic has been evolutionarily selected. After we see what a good evolutionary argument looks like, we will then review a set of six basic building blocks out of which our complex moral nature might be constructed, and review the evidence for them. Finally, we will look at a set of eleven ways that human morality is distinct from the proto-­morality of other species, and ask how one might build an evolutionary argument for these aspects. We conclude that there is strong evidence that much of human morality has evolved and a long (but possible) way to go to build evidence for how a uniquely human morality might have evolved. One offshoot of this grounding of morality in evolution is that it highlights the intimate links between the development and expression of morality and immorality, a theme that will be woven throughout s the book. of 1.2 Basic Evolutionary Processes (With an Eye Toward Morality) ro “Survival of the fittest” is a phrase that Darwin first uses in his fifth edition of The Origin of Species (Darwin, 1869 p. 92). He uses it as a synonym for natural selection. The many misunderstandings of this phrase over time have come to haunt those who would talk about evolution, and particularly evolution and morality. Herbert Spencer lP originated the “survival of the fittest” phrase (Spencer, 1866, pp. 444–445) and, among other burdens the phrase carries, it has come to be associated with Social Darwinism, a much maligned attempt to derive a kind of “might makes right” ethical principle.3 The phrase has also been misunderstood to suggest that it is the most physically fit, or aggressive, or selfishly competitive individual who survives. This is a na mistake on multiple fronts. Natural selection is not about individual survival, but about the ability to reproduce (and thus propagate one’s genome). And since it is about reproduction, it need not be about physical fitness or aggressiveness, but also about cooperation or camouflage or cleverness or compassion that allows the production and continuation of the genome. As we will see later, it is also a mistake in terms Fi of the level at which one can speak of selfishness. Genes may metaphorically be selfish (Dawkins, 1976), but individuals do not have to be (de Waal, 2006). However, to understand Darwin’s approach to “natural” selection, one must first understand the material on which it works. Darwin begins his Origin of Species (Darwin, 1859) not by talking about natural selection but about variation. Any population (of sheep, pigeons, or insect-­eating plants) has some natural variation in the characteristics of individuals in that population. Darwin begins his argument by noting that breeders (of pigeons or of strawberries, etc.) take advantage of this variation and selectively breed individuals with characteristics they desire. Darwin calls this “selection by man.” Natural selection is a similar process operating without (usually) human intervention. Some individuals with particular characteristics survive long 3 See Weinstein (2009) for a balanced discussion of Spencer’s role in Social Darwinism. Evolution 5 enough to pass on those characteristics to their offspring. To the extent that those characteristics have played a role in the propagation of characteristics in further individuals, then one can say those characteristics have been “naturally” selected or that they are evolutionary “adaptations.” This, then, is the basic idea of selection. Scholars of evolution list many and various varieties of selection (see Sober, 2006 for an overview of these and other issues). Because the moral is so closely associated with the social, the kind of selection that will particularly concern us here is social selection. This is natural selection driven by social interaction within a species, selection of the sort that may have resulted in the rapid increases in brain size mentioned earlier. There are four versions of social selection we will deal with here: sexual, kin, and group selection and gene–culture coevolution. s 1.2.1 Sexual Selection Though it may certainly have other functions, a primary evolutionary function of sexof ual interaction is the continuation of the species and the genome. In animals, sexual selection occurs during mating choice, with the choice based on some c­ haracteristic among the available partners (Krebs, 2008). The classic example in the literature is the mating selection among peacocks, with the female basing her choice in part on ro the characteristics of the splendid tail of the male.4 Can we construct a story of how this might account for moral characteristics among humans? It is at least the case that, across many cultures, moral qualities are preferred in mates (Buss et al., 1990), with dependability and kindness/­understanding lP appearing near the top in lists of preferences for both sexes from thirty-­three different countries. In addition, there is evidence that humans can reliably identify moral dispositions in others based on short observations (Fetchenhauer, Groothuis, & Pradel, 2010), making it possible that selection could be based on this identification. Miller (2007) has marshaled the evidence for a theoretical account of sexual ­selection na of virtues and suggested a set of testable theses based on this account. Others (Goetz, Keltner, & Simon-­Thomas, 2010) have included sexual selection among the kinds of selection pressure that can support an evolutionary account of the virtue of compassion in both sexes. Thus, one can construct a case for the evolutionary sexual selection of virtues. We Fi expect this is often overlooked because of the unfortunate connotations of “survival of the fittest.” 1.2.2 Kin (Family) Selection The idea of kin selection is implicit in the phrase inclusive fitness (Krebs, 2008). Inclusive fitness is based on the number of genes an individual can contribute to succeeding generations both directly (by producing offspring) and indirectly ­ (by ­supporting family relatives who share genetic material). This concept makes it 4 The empirical story is somewhat more complicated by the search to determine just what it is about the splendid tale that the peahen responds to (Loyau, Petrie, Saint Jalme, & Sorci, 2008). This cannot, of course, be immediately applied to the human species. Taking Moral Action possible to understand how compassion toward one’s immediate and extended ­relatives might evolve (Goetz et al., 2010) since care for relatives increases one’s inclusive fitness. This pattern of closer care for closer relatives has been documented in a wide variety of cultures (Essock-­Vitale & McGuire, 1980). If compassion for kin already exists it can be adapted or generalized to compassion for a wider group (Goetz et al., 2010).5 1.2.3 Group Selection One can extend the idea of selection based on one’s relatives to selection based on one’s group. Wilson and Sober (1994, 1998) revived the idea of group selection and embedded it in a model of multi-­level selection. One can think of selection occurring at the level of the gene, the cell, the individual, the kin group, or of larger, arbitrary s groups. Group selection was originally proposed by Darwin (1859). It seemed to later researchers (see Richerson & Boyd, 2005 for a review) that selfish individuals in of an arbitrary group would take advantage of cooperation, without themselves helping, increasing their fitness with no cost to themselves. It was thought that mathematical models easily predicted that in this case, the selfish defectors would eventually take over in any group (see Thompson, 1998 for some of the complexities in this claim). ro This “free riding” seemed to make it impossible for cooperative behavior to evolve based on its adaptive value for a group of unrelated individuals. In response to these concerns, Sober and Wilson (1999) identified the conditions that must obtain for group selection to work. lP To make group selection viable, variation on the characteristic (e.g. compassion) between competing groups would need to be larger than variation within each group. Simply put, the groups must differ on the characteristic. Equally important is that selection pressure between the groups would also need to be greater than any within group selection that might be caused by free riding. Sufficient selection presna sure between groups could be produced by things like intergroup conflict, foraging for a common but scarce resource, or the founding of new groups (Sober & Wilson, 1999). If group selection is going to work to increase some moral attribute that is favorable to the group, it needs to be the case that individuals can recognize the group and Fi establish an attraction to it. This makes immediate sense in terms of kin groups, and such attraction can develop from already existing attractions associated with parenting (Goetz et al., 2010). But how might this attraction establish itself with arbitrary groups? Lewis and Bates (2010) used a twin study and mathematical modeling to provide evidence for genetically based preferences for particular groups (in this case, ethnicity, religion, and race). In addition to these basic preferences for each of the groupings, they also found evidence for a central affiliation mechanism (CAM) that 5 The technical term for this is exapted, the selection of an already existing characteristic to serve another purpose. The existing characteristic need not have been naturally selected before, but it might simply have been a necessary byproduct of an already selected characteristic (e.g. a biologically affective experience like compassion for kin that is available to be exapted for non-­kin). It might then play a role in group selection to produce a broader characteristic (Goetz et al., 2010). Evolution 7 allows for affiliation or attachment to arbitrary groupings (like a sports team). This preference to be loyal to groups that develop out of local culture might be naturally selected (in a similar way that sexual selection might select virtues). Thus, there is some support for the idea that loyalty to groups of individuals is a characteristic that might be selected for by evolutionary processes (see also Krebs, 2008). 1.2.4 Gene–Culture Coevolution One more complication must be added to the ways that evolution is socially shaped. Human culture can itself create new selection pressures on individuals in a population, and thus influence genetic characteristics of the population over time. Culture creates an environment that produces selection pressure on the individuals in that culture. One example of this is the widespread change to agriculture. Richerson and s Boyd (2010) provide examples of this sort of coevolution with the change in the enzymes that allow adults to digest milk occurring among those populations that had of adopted herding of livestock and also the coevolution of enzymes that help with the digestion of plant starch among those adopting agriculture. Gene–culture coevolution is at the center of debates about the evolution of cooperation and altruism,6 since this process involves cultural processes like altruistic punishment7 that would ro ­“deselect” individuals who violate group norms (Boyd et al., 2003; Boyd, Richerson, & Henrich, 2011). We are only beginning to understand the complexity of the pathways that might lead to the current variety in human culture and genome. Genes do not code for lP specific behaviors, but they can influence systems that make some behaviors more likely to be expressed or some things easier or harder to learn (see Schmitt & Pilcher, 2004 for examples). The processes of development in the organism that move from a genetic encoding to a phenotypic (body, behavior, etc.) outcome of that encoding (a process called expression) can interact with an organism’s experience in na the world. For instance, careful maternal care can support the expression of genes that make the giving of maternal care more likely when the offspring grows up (Goetz et al., 2010). 1.2.5 Evolution vs. Culture Fi One of the standard critiques of evolutionary accounts of morality (and indeed one of the standard critiques of evolutionary psychology) is that these accounts ignore the overwhelming influence of culture on the complexity of human behavior (McKinnon, 2005). The dichotomous structure of this argument should immediately make one suspicious, since it mirrors many other sometimes overzealous debates in the social sciences like that between nature or nurture, personality or situation, reason or emotion, altruism or selfishness, etc. 6 See the section on Selfishness for selection for altruism. 7 This is punishment of an offender of a norm that is costly to the punisher (thus altruistic). Taking Moral Action But before looking at an integrative response to this dichotomy, we should note the difficulties that the “culture alone” camp has with explaining some aspects of morality. Two of the most well-­documented psychological accounts of moral judgment and action are the social learning (Bandura & Walters, 1963) and cognitive developmental ones (Boyd et al., 2011; Kohlberg, 1963; Turiel, 2006). Both have difficulties explaining some aspects of morality in comparison to evolutionary accounts. Social learning accounts have trouble explaining how moral rules emerged in culture, why people are motivated to preach them, and why children resist induction of moral rules. Cognitive developmental accounts struggle to explain the centrality of affect in moral judgment, the continuing presence of “childish” moral thinking in adults, and the connection (or lack thereof) between moral reasoning and behavior (Krebs, 2008). In addition, both approaches have difficulty in explaining the pattern of data that surround some effects (such as the incest taboo) that have been extens sively investigated from an evolutionary perspective (Schmitt & Pilcher, 2004). Finally, both cultural approaches find it hard to explain (or even finding relevant) the of extensive list of cultural universals that have moral content (Brown, 1991; Curry, Mullins, & Whitehouse, 2019). This is not an argument that cultural or purely ­psychological approaches are wrong but simply that they are incomplete, as the evolutionary approach itself is incomplete. This is the reason we try to bring together ro multiple narratives of moral behavior in this text. In Section 1.2.4, we covered the process of coevolution. This is the idea that culturally valued, socialized, and transmitted behaviors can influence the ­evolutionary path of groups, making things like cooperation an evolutionary advantage for a lP group. This suggests that culture may influence evolutionary paths more than evolutionary paths may influence the expression of culture. The idea of coevolution has emerged from decades of theoretical and empirical confrontation in the evolution– culture debate (Durham, 1991; McElreath, 2010; Richerson et al., 2010). This understanding of culture–evolution interaction helps to bring some resoluna tion to the voluminous literature on altruism (de Waal, 2008) as we will see in the A Note on Selfishness and Altruism section. And it also helps us understand the many different ways one might find culture–evolution interaction underlying moral judgment and behavior. Some authors (e.g. Mikhail, 2007) have proposed that much of our moral judgment is innate and pre-­packaged into independently operating modFi ules.8 But it is more likely that the wide range of moral things in our lives is, from the perspective of evolution, a kludge (Stich, 2006) and is constructed from a range of abilities and predispositions (Cushman & Young, 2011; Cushman, Young, & Hauser, 2006; Heyes, 2020). For instance, moral emotions can channel our reactions (e.g. anger against defectors can provoke us to punish them) in ways that help to enforce group norms and make the group more successful (and in ways that pass on this capacity for altruistic punishment). This is an approach adopted by Haidt and Joseph (2004, 2007), who propose sets of moral emotions linked to dimensions of how actions are morally judged. 8 See Chapter 7 for more detail. Evolution 9 1.2.6 A Note on Selfishness and Altruism One of the conceptual oddities of the debate in evolution for the past thirty years has been confusion about the word “selfish.” This is in part because Dawkins (1976) published a book using the “selfish gene” as a metaphor for evolution at about the same time that economic models of the rational and self-­ interested “Homo ­economicus” were widely discussed. Dawkins’s argument was that natural selection occurs at the level of the gene, and that genes were metaphorically “selfish” when their ­“strategies” to replicate themselves were analyzed at this level. The idea received wide acceptance in biology and for some time formed the orthodox view of the level at which selection was operating: the level of the gene. More recently, multi-­level approaches to selection (see the discussion in Section 1.2.3) have been proposed and favorably evaluated (Wilson & Sober, 1994, 1998). s However, the confluence of Homo economicus and the selfish gene in the 1970s, along with some unfortunate language that Dawkins used toward the end of his influof ential book, have served to support the idea that because genes are metaphorically “selfish,” then human psychological motivations must be selfish too. There are a variety of problems here. First, the idea simply assumes an identity across these levels of explanation. The word selfish is rooted in a description of one kind of human motiro vation and action, and it works as a metaphor for the point Dawkins wants to make about genes. But to then take that metaphorical use and deduce a psychological motivation or even a pattern of behavior is at best a stretch requiring good evidence. Genetically selfish is simply different from psychologically selfish. And the case for the lP psychologically selfish Homo economicus is not as strong as it used to be, and may well be suffering the death of a thousand limiting factors (Aktipis & Kurzban, 2004). An additional difficulty is that a simple “always be selfish” strategy is an implausible one in a shifting environment and may be less successful across different environments (Krebs, 2008). na There is clear evidence for a wide range of cooperative, non-­prototypically selfish activities in humans and other animals including: mutualism (e.g. group hunting), simple reciprocity (e.g. exchanging meals), cooperation with cooperators (requiring keeping track of “defectors”), “community concern” (de Waal, 2006), and long-­term social investment (e.g. care for infants, family, friends). Work in the laboratory (Aktipis Fi & Kurzban, 2004; Van de Vondervoort & Hamlin, 2018) and in the field across many societies (Curry et al., 2019; Henrich et al., 2005) supports these sorts of cooperative motivations in human action against the simple self-­interest model. And work by de Waal and colleagues (2006, 2008) shows similar behavior among other species. The renewal of research on cooperative and compassionate behavior across cultures and species seems to be leading to the “extinction” of the selfish Homo economicus model (Aktipis & Kurzban, 2004). Even though cooperation, nurturance, and compassion are important and natural human motivations, we should not assume a uniformly bright picture. There is a range of motivations and behavioral strategies in our moral interaction that involves selfishness, deception, taking advantage of others, and outright aggression. Indeed, a profound irony is likely built into the group selection mechanism that may be operating to produce cooperation and caretaking. Effective group selection for cooperation within the group requires some level of competition between groups Taking Moral Action (Sober & Wilson, 1999; Wilson & Sober, 1994, 1998). This competition can be created by warfare, but also other more peaceful means, like competition for a scarce resource. In addition, most models of group selection to produce cooperation assume what is called vicarious punishment for in-­group members, that is, aggression against those who deviate from the cooperative norm of the group. Both of these mechanisms underpin what has been called the dark side of altruism (Graham & Haidt, 2012; Skitka & Mullen, 2002). Now that we have a sense of the basic terms of how evolutionary processes might work, we will look into ways they might be combined together to produce evidence for how some aspect of morality might have evolved. 1.3 How to Argue That Behavior Was Selected Because s It Was Adaptive of Evolutionary psychology has frequently been accused of consisting of too many “just so” stories9 about how some psychological characteristic might have been selected in a hypothetical past (Gould & Lewontin, 1979) – but having only that hypothetical possibility and little evidence. Having a “just so” story is a fine place to begin when ro that story points to where one might collect evidence. Given the relatively recent state of evolutionary psychology, we might expect for evidence about most proposed psychological adaptations to be fairly sparse, but these networks should become denser as more work is done. How might this happen? lP Much of evolutionary psychology is an argument for how some trait, or constellation of traits, might have been selected 100,000–300,000 or more years ago. How does one collect evidence and make an empirical argument for something that ­happened this long ago? In part, one does it by changing the question. For example, if in fact incest avoidance, a common ethical norm, is an evolutionary adaptation, what na pattern of evidence would we expect to find today in incest avoidance’s ­distribution across cultures, its relationship with genetics, its physiology, etc.? To answer this question requires several different kinds of evidence. Schmitt and Pilcher (2004) provide us with a useful map of eight different areas of evidence that are needed to give a convincing, valid case that some item of interest is an evolutionary adaptation: Fi 1. Theoretical coherence: The extent to which the adaptation connects to one or more theories or theoretical networks about evolution. This can involve some of the classical theoretical accounts in biology or psychology or game-­theoretic or mathematical modeling theory. This is a central piece of evidence in the network: lacking a coherent theoretical explanation means we would not have information about why or how the item is related to an evolutionary history or even the pattern of data we should expect in the other seven categories. In the case of incest, this consists of evidence that genetic problems arise in offspring of incest (Schmitt & Pilcher, 2004). 9 This is a reference to Rudyard Kipling’s Just So Stories (1912) for children. These are fantastic stories of how, for instance, the camel got its hump or the whale got its throat. The narrative logic in the stories is that it is a pleasing tale, and therefore must be true, just so. Evolution 11 2. Cross-­cultural evidence: If an adaptation occurs with regularity across cultures, or interacts across cultures in interesting ways (e.g. being less prevalent when cultural norms are strong, or occurring in reaction to specified cultural stimuli), then one may have evidence that the characteristic is influenced, at least in part, by some factor in common across all the cultures. There are almost universal prohibitions against incest across cultures (though what counts as incest varies), and there is cross-­cultural evidence that being raised with other-­sex peers before age six produces a diminishment of attraction to those peers (Schmitt & Pilcher, 2004). 3. Hunter-­gatherer evidence: There are still cultures today that inhabit environments much like that of our pre-­agricultural forebears. This gives us (somewhat tenuous, but nevertheless helpful) evidence of the likely environmental and cultural pressures for selection that may have been operating at the time the theory says the s adaptation should have been adaptive. Ethnographies of these cultures show, again, almost universal absence of incest (Schmitt & Pilcher, 2004). of 4. Psychological evidence: A particular attribute like incest avoidance may follow a developmental path that seems linked with the function our theory says it should have. Or it might relate to other psychological characteristics (or not correlate with them), or serve similar functions in modern societies. All these are part of ro the network of evidence that the characteristic is playing the adaptive role the theory says it should. Being raised with other-­sex peers before age six reduces attraction, and this provides developmental psychological evidence (Schmitt & Pilcher, 2004). lP 5. Physiological evidence: If one can find a physiological substrate for the characteristic in question (e.g. oxytocin and empathy: Rodrigues, Saslow, Garcia, John, & Keltner, 2009), then one has established a physical mechanism by which a characteristic might be heritable. The interaction of this physical mechanism with culture and situational stimuli can enrich the evidence network to provide more detail na about how the adapted characteristic functions in society. There is evidence for the sense of smell as a mechanism that produces sexual aversion to close kin, thus incest avoidance (Weisfeld, Czilli, Phillips, Gall, & Lichtman, 2003) 6. Medical evidence: This is similar to the physiological evidence but based in medical cases of the supposed physiological mechanism going wrong. When the physiology Fi is upset, are the functional relationships of the characteristics also upset (see e.g. the use of brain damage cases in Chapter 2)? Schmitt and Pilcher (2004) do not list any medical evidence for incest avoidance. 7. Phylogenetic evidence: Finding similar patterns in other species, where the theory leads one to expect the patterns, is another set of nodes in the network of evidence. For some characteristics (e.g. the effects of oxytocin on social behavior) one might expect to see a range of species across all mammals (Rodrigues et al., 2009), while for other characteristics (like a sense of fairness) one may expect only similarities among other primates (de Waal, 2006; Preston & de Waal, 2002). In terms of incest, animals rarely mate with parents or siblings (Schmitt & Pilcher, 2004). 8. Genetic evidence: We are increasingly able to use genomic evidence to trace the timing of events in human evolution (Richerson et al., 2010) and this will become a rich source of data that can connect with the others in this list. Schmitt and Pilcher (2004) do not list any genetic evidence for incest avoidance. Taking Moral Action Schmitt and Pilcher (2004) use this framework to survey the evidence for four psychologically relevant characteristics as evolutionary adaptations. Profet (1988) has followed the possibility that pregnancy sickness and its associated food aversions are an adaptation that allows for the fetus to be protected against toxins in plants that would cause birth defects. This story suggests that pregnancy sickness will follow a particular pattern (certain food avoidances, a particular timeline, the relationship of sickness to miscarriage, similarity across cultures, etc.) and there is much evidence for this rich network of relationships (Schmitt & Pilcher, 2004). Schmitt and Pilcher (2004) find less extensive, but still “exemplary,” evidence for incest avoidance. They find only “extensive” evidence for men’s greater desire for short-­term sexual variety than that of women, and “moderate” levels of evidence that we have evolved a mechanism that makes it easier to learn fear of snakes. s 1.4 Evolutionary Building Blocks for a Robust Morality of So, what can we learn about our moral nature by seeing it through the lens of ­evolutionary adaptation? At the most complex level, this might mean we have inherited a distinct and structured universal moral grammar, much like what has been ro claimed for the deep structure of a universal linguistic grammar (Huebner, Dwyer, & Hauser, 2009; Mikhail, 2007). We will evaluate this claim in a moment, but the picture of morality we provide in this book attempts a much wider claim. Moral action certainly involves a kind of structure of moral intuition, but the full picture includes lP far more: emotional intuitions, strategic planning, self-­regulation, self-­concept and group identity, and much more. Each of these might have an evolutionary underpinning. But it seems unlikely that they would have all evolved together as one piece. The usual pattern of evolutionary adaptation that moves toward complexity is more one of building that complexity slowly based on some existing variation.10 Given that na many of these aspects, such as opposing values, are often at odds with one another (and that self-­regulation is, in one sense, a mechanism to help adjudicate these conflicts), an evolutionary story would expect the complexity of moral action in humans to have been built up slowly across many species and a great deal of time. For instance, maternal care for the young is common to all mammals, but it plays an important part Fi in human morality (Preston & de Waal, 2002). For an overview of how these building blocks might come together, we will follow the proposal by Krebs (2008) of the various psychological building blocks that likely came together to constitute what we now call morality. This overview itself will suggest additional pieces that remain to be covered, and we address them in Section 1.5. 1.4.1 Adaptive Sociality The first and fundamental building block that Krebs lists is that of sociality – or living in groups. Group living is built out of interdependence among animals and the 10 Evolution does not always build toward complexity. Even “build” is a metaphor that contains intention. “Natural” selection has no intention. An organism may evolve toward less complexity if that makes it fit better in an environment. Evolution 13 complexities of how that interdependence is negotiated. This sociality is the basic ­background for the development of all the other building blocks. One thing to note: in Krebs’s phrase, social life is built of both confluence and conflict of interest. For organisms to work in a group there must be some attachment to the group, some confluence of interest, and this attachment can be elaborated in many directions. As de Waal (2002) and Goetz et al. (2010) have documented, one origin (at least in mammals) of this social attraction must have been the giving and receiving of care between parents and offspring, which became more crucial as the time for complete maturation of offspring increased. And there is of course conflict of interest that must also be managed. This conflict and confluence is the arena in which moral action and judgment evolved. 1.4.2 Pro-­social Behavior Strategies Based in Social Emotions s Emotions are not simply “feelings” but are instead a complexity of: (1) cognitive appraisal (that arouses and shapes the emotion); (2) directed arousal (that provides of the “feel” of the emotion and signals its urgency); and (3) action tendency (that links action to the reaction of the emotion). (See Oatley, Keltner, & Jenkins, 2006 or Chapter 8 for an overview). How this complex itself has evolved is a fine puzzle; but for social animals, it certainly evolved in connection with socially relevant behavior. ro Krebs (2008) lists three relevant sets of emotions tied to pro-­ social behaviors: (1) ­deference in dominance hierarchies based in fear and respect; (2) cooperation among individuals based in gratitude, anger, and indignation; and (3) altruism based in love, sympathy, and empathy. We suggest some more in Chapter 8. lP 1.4.3 Strategic Interaction Simply having social emotions and reacting based on them produces a sort of mechanical social order. But, once sociality is established, cheating is possible when one can na take the other’s perspective in order to deceive. A basic requirement for strategic social interaction is theory of mind, recognizing and ascribing mental states to ourselves and others (Wellman, 2018). There is evidence that even infants have basic aspects of theory of mind (Hudac & Sommerville, 2020) though its developmental trajectory looks similar to that of reading (Heyes, 2020), suggesting that the full Fi capacity is some mix of built-­in capability and cultural shaping. The capacity to take perspective can then produce an “arms race” (Krebs, 2008) when it makes it possible to detect cheating and punish free riders. It can become even more complex when we keep track not only of cheaters but also those among us who do not punish the cheaters. (Boyd, Gintis, & Bowles, 2010; Boyd et al., 2003). This strategic level of interaction can apply to areas as abstract as what de Waal has called “community concern,” the strategic intervention in group processes to produce desired outcomes at the group level (de Waal, 2006). 1.4.4 Conscience Krebs (2008), citing Darwin (1859), lists the linking of emotional responses with anticipatory fear of punishment from others (and later the internalized other) as a potential origin for what we call conscience. There is some evidence for this linkage. Taking Moral Action For instance, physical responses associated with negative self-­emotions (like shame and guilt) mirror behavior shown in appeasement displays in humans and other primates (Keltner & Buswell, 1997; Leary, 2007). Leary (2007) provides an overview of the research that makes this link between what we might call conscience and anticipatory reactions of real or imagined others. But one need not assume that this effect runs on anticipatory punishment alone. One can find evidence of an evolved capacity for compassion that can motivate behavior, not merely of avoiding the bad but also approaching the good (Goetz et al., 2010). 1.4.5 Moral Judgment and Reasoning Krebs (2008) proposes that the origin of moral reasoning lies in moral c­ ommunication – in verbal influence attempts to get others to behave in morally prescribed ways. But s this is surely starting too late in the process. Tse (2008) looks back even further to a proposed delinking of attention from concrete objects in the world that allows arbiof trary symbols to be associated with each other.11 This is likely a basis for the flexibility of human reasoning, and the basis of things like metaphor, allowing for the association of arbitrary symbols and ideas in metaphor (a poem as lovely as a tree) but also the association of actions with abstract classes of good and bad. There is currently a ro vigorous debate about whether something as structured as a moral “grammar” is an evolutionary heritage of humans. This idea is an analogy from what seems to be an evolved grammar in language. There is currently only suggestive evidence for this hypothesis (Beller, 2010) and nothing like the strong networks of evidence we have lP reviewed for other adaptations (see Greene, 2008; Mikhail, 2007 for some idea of the controversy). 1.4.6 Moral Norms na Earlier we reviewed at least one moral norm (the incest taboo) that seems to have an evolutionary basis (Schmitt & Pilcher, 2004). But we clearly have a large store of moral norms that are in regular use, and that vary widely from culture to culture. In Chapters 7 and 8, we review the evidence that there is a structure to these norms that is cross-­culturally consistent, with the same value sets showing up across all cultures Fi but differently emphasized by each culture (Haidt & Joseph, 2004; Haidt, Koller, & Dias, 1993; Schwartz, 2006). This cross-­cultural evidence of a universal structure might argue for an evolutionary origin (see Haidt & Joseph, 2007 for an evolutionary argument). Managing these norms involves a complex cultural process of protecting against deviance while promoting diversity (Wright, 2021). We already have a long list of building blocks, and Krebs (2008) provides some idea of how these might come together to support what we call moral judgment and action. However, the chapters in this text suggest we need to add even more complexity to this picture. There must be some accounting of the development and 11 There is currently little evidence for this interesting proposal. Whether one calls this an interesting theoretical proposal or a “just so story” depends on one’s attitude toward the likelihood that such evidence will turn up (Dietrich, 2008). Evolution 15 integration of short-­and long-­term self-­regulation. How and why might willpower (and variations in willpower) have evolved (Heatherton, 2011)? While it is merely difficult to assemble the network of evidence for short-­term self-­regulation as an ­evolutionary adaptation, work on the evolutionary underpinnings of longer-­term self-­ regulation seems quite thin (Heatherton, 2011); though Miller (2007) suggests the sexual selection of moral virtues like dependability might play a role. We know that storytelling (McAdams, 2009) and religion (Graham & Haidt, 2010; Kirkpatrick, 1999) play a role in moral judgment and action. For many of these more complex and higher-­level aspects of morality it may well be that the relatively new approaches to culture and coevolution (Wilson & Sober, 1998) will provide us with a way to understand their construction. We will now look at a list of many of these additional aspects of morality that may (or may not) find some evolutionary underpinning. s of 1.5 Human Distinctiveness: How Large is the Gap? We have spent most of this chapter looking at the processes of evolution and the building blocks of human morality. The goal has been to see how we can ground ro human morality in, or derive it from, various aspects of the capacities and behavior of our ancestors. An older version of this approach, disparagingly called “veneer theory” by de Waal (2006), proposes that humans have only a veneer of politeness and hypocrisy overlaying the motivation of brute selfishness. Higgins and Pittman (2008) lP ­suggest that this version of human moral evolution is mirrored in the historical split in evolutionary approaches in different sub-­fields of psychology. In cognition, we are said to have “developed from” prior species, while in motivation, we have been presented as merely “deriving” our animal motivations from prior species. This results in an image, they claim, of “humans as having the mind of a god and the motives of a na brute” (Higgins & Pittman, 2008, p. 363). In the realm of morality, this image of the supremacy of reason is aided and abetted by philosophical approaches to ethics (e.g. Kant, 1999; Rawls, 1971/1999) that portray reason as both the foundation and the limit of real (that is, human) morality. But current approaches to human morality that we review in this book suggest Fi that: (1) human morality is constituted of more complex stuff than pure reason; and (2) the differences with other animals and our primate ancestors lie in a range of ­distinctly human abilities and motivations (Higgins & Pittman, 2008) and not just differences in reason alone. There is unanimity in recognizing that there are deep differences between humans and other animals in morality but the nature, structure, and meaning of those differences is still in dispute.12 12 Some claims might underestimate these differences (Adolphs, 2009) in the way veneer theory does. Other claims may underestimate the unique abilities of other animals by making human morality the criterion, and missing uniquely adapted, species-­specific capacities of other animals (Emery & Clayton, 2009). Crows, for example, do not have a full-­blown theory of mind like humans, but they are remarkably good at hiding food from other crows (Emery & Clayton, 2009). De Waal (2006, 2009), Emery and Clayton (2009), and Adolphs (2009) provide some insight into the debates about these differences. Taking Moral Action The dimensions associated with morality on which humans differ from other ­animals include at least the eleven categories noted in Sections 1.5.1–1.5.11. We have constructed this incomplete list from the literature in evolutionary psychology. The effort to build coherent networks of evidence for the origins of human ability in each of these categories may, of course, suggest additional categories or the merging of some. The list makes it clear that we are, indeed, at the very beginning of an evolutionary understanding of the structure and development of a truly human morality. 1.5.1 Symbolizing and Reasoning The beginning of the ability to reason lies, perhaps, in the ability to take any particular representation of an object and link it arbitrarily to some other mental representation, e.g. a poem is like a tree (Tse, 2008). This may provide the basis for human ability to s represent things symbolically (think of early cave paintings and whether any animal other than humans would “get” them). The empirical evidence for an evolutionary of basis for moral reasoning and judgment remains unclear (Beller, 2010). Some researchers claim that regularities in the way people ignore logical structure and reason in specific content areas (e.g. cheating, incest) show the primacy of evolutionary modules for content-­ specific reasoning (Cosmides & Tooby, 2008; Cushman ro et al., 2006).13 But this claim is disputed by both philosophers (Prinz, 2008) and psychologists (Chater & Oaksford, 1996; Pietraszewski & Wertz, 2021). This is a disagreement about how ought-­based (or deontic) reasoning might have evolved in humans. But it is also a dispute anchored in an agreement that human capabilities for lP deontic reasoning are vastly more complex than that of other animals. 1.5.2 Time Perspective Time perspective underlies the ability to think about the moral consequences of an na action or to make plans to achieve moral goals. In order to support some conception of a past or a future time, or of an alternative present, one must construct a mental representation and distinguish it from one’s own current experience (Higgins & Pittman, 2008). Thus, a conception of time requires the symbolizing abilities ­mentioned in Section 1.5.1. It remains unclear whether any animals other than Fi humans can experience an imagined point of view (Adolphs, 2009) and thus have some sense of time. The sense of the future and past allows humans to construct moral stories about the past and about the future, and compare the self to them (Higgins & Pittman, 2008). This adoption of another point of view than that of immediate consciousness is likely one that underlies the ability to recognize other minds (Adolphs, 2009). 13 For an example of this content-­specific reasoning, see the discussion on moral dumbfounding in Chapter 7. In short, careful experimentation can find instances where people will simply say “I know it is wrong, but I do not know why.” Such moral intuition suggests that these particular moral judgments do not derive from a general reasoning mechanism. But this does not mean that no moral judgments derive from a general reasoning mechanism. Evolution 17 1.5.3 Cognitive Control and Self-­Regulation As we argue in Chapters 6 and 9, self-­regulation is central to moral action. It is ­certainly the case that other animals can exert cognitive control over immediate desire, both to deceive other animals (de Waal, 2006) and in response to training by humans (H. C. Miller et al., 2010). This sort of immediate willpower of response suppression seems to share similar biological substrates in humans and other mammals (e.g. it uses glucose-­based energy: Baumeister, Bratslavsky, Muraven, & Tice, 1998; H. C. Miller et al., 2010). But the extent, complexity, and flexibility of human self-­control mechanisms far outpaces those of other animals (Heatherton, 2011). It extends to what the philosopher Frankfurt (1971) has called “second order desires,” or the desire to have a particular desire and to the planning of outside influences that will help one attain future states (for example, by going to school: Cohen, 2005). It s also requires directed planning and practice to achieve long-­term goals (Baumeister, Masicampo, & Vohs, 2011; Cervone, Shadel, Smith, & Fiori, 2006; Lord, Diefendorff, of Schmidt, & Hall, 2009; McRae, Ochsner, & Gross, 2011). 1.5.4 Extensive Integration of Reason and Emotion ro Moll and colleagues (de Oliveira-­Souza, Zahn, & Moll, 2016; Moll, de ­Oliveira-­Souza, & Eslinger, 2003; Moll, De Oliveira-­Souza, & Zahn, 2009) have hypothesized that the most important thing about human reason may well be its integration with rather than its opposition to emotion.14 Even philosophical champions of reason as a marker lP of human morality (Korsgaard, 2006) have suggested that the integration of reason and emotion is a central puzzle in the evolution of morality (Korsgaard, 2010). It is not simply the addition of rationality to an “emotional animal” that makes humans special and human morality possible. It is the extensive integration of that rationality with emotion that allows them to influence and “tune” each other. Emotions influna ence our implicit and explicit moral reasoning by guiding intuition (Haidt, 2001) and reasoning (Goldin et al., 2008; McRae et al., 2011). And rationality influences emotion through the multifaceted self-­regulation processes mentioned in Section 1.5.3, through the appraisal and re-­appraisal process (Lazarus, 1991; Ochsner et al., 2010), and through the planned construction of culture (Cohen, 2005). Fi 1.5.5 Extensive Culture Humans have complex, stable, and constantly adapting cultural systems with ­enduring artifacts, language, artistic expression, economies, ritual, values, social structures, and extensive bodies of knowledge and practice (McElreath, 2010; Richerson & Boyd, 2005). These cultural achievements are clearly one of the major differences between humans and other animals. There is some evidence for social transmission of information among other primates (Adolphs, 2009) and thus some rudimentary socially shared culture. Understanding the linkages among evolution, neuroscience, and cultural processes will be a crucial undertaking for a complete understanding of moral action (Kitayama, Varnum, & Salvador, 2019; Wright, 2021). 14 We review evidence for this integration in Chapters 2 and 8. Taking Moral Action 1.5.6 Self-­Consciousness and Self-­Awareness The classic experimental demonstration of self-­ consciousness in children and in ­non-­humans is the body awareness test. This involves placing some marker on the body in a place that is difficult to see without a mirror and then measuring the attempts to examine the new decoration. Evidence for such awareness has been found in chimpanzees, bonobos, dolphins, elephants, and monkeys (Adolphs, 2009). This seems adequate to demonstrate body awareness but its evidential status for awareness of one’s own mind is unclear (Adolphs, 2009; Gallup & Anderson, 2020). For ­normally functioning adolescent and adult humans, there is unanimity that a comawareness is present (Byrne & plex, multidimensional, and morally relevant self-­ Whiten, 1988; Robins, 2021). s 1.5.7 Social Consciousness of Dogs and some other domesticated animals, perhaps because they have been shaped by human intervention over many generations, are skilled at interpreting gestures (e.g. pointing) and in responding correctly in the guesser–knower paradigm (in which they must choose a person based on that person’s knowledge of ro where some food is hidden) (Emery & Clayton, 2009). But dogs do not appear to have some basic t­ heory of mind characteristics that human infants share, like preferring helpers over hinderers in an attention task (Hamlin, 2013,; McAuliffe et al., 2019; Van de Vondervoort & Hamlin, 2018). Primates are particularly lP skilled at tracking kinship and dominance relationships over time (Adolphs, 2009). However, if one asks for a full-­fledged human theory of mind in other primates, it appears to be lacking (Emery & Clayton, 2009) – although one can likely find components of it. For example, there is evidence that other primates know that others know something but probably cannot grasp the complexity that the other’s na knowledge may be false (Emery & Clayton, 2009). Waytz and colleagues (Waytz, Cacioppo, & Epley, 2010; Waytz et al., 2010) have shown that humans’ perception of agency (even the anthropomorphic perception of agency in inanimate objects) includes a moral dimension allowing for blame and suggesting that the roots of moral perception go quite deep into basic perception. And though other Fi primates form coalitions (de Waal, 2007) the complexity of human tribalism is much greater (Clark et al., 2019). 1.5.8 Manipulation of Others’ Perception There is evidence that other primates understand and practice deception (Adolphs, 2009; Emery & Clayton, 2009). There is even evidence that crows and other corvids cache food in ways that make it difficult for other crows to find it, but only if other crows who might take it are present (Emery & Clayton, 2009). But again, even in young children, human manipulation of others’ perception is vastly more complex, multidimensional, and subtle (Higgins & Pittman, 2008). Humans are deeply concerned about what others think (Higgins & Pittman, 2008) and particularly what others think about them (Leary, 2007). Evolution 19 1.5.9 Sharing Reality With Other People Humans have a deep need to share their understanding of the world with others (Higgins & Pittman, 2008). All mammals have some abilities at social coordination and signaling (Goetz et al., 2010) and some have components of a theory of mind (Emery & Clayton, 2009). But even human children are competent in communicating shared social knowledge, sharing joint attention, and explicit teaching. Language is a primary achievement of this need (Byrne & Whiten, 1988). 1.5.10 Universalized Normative Evaluations People’s concern about what others think of them has been included in models of the “generalized other” (Heatherton, 2011; Mead & Morris, 1934) as one source of s how humans universalize normative evaluations. The philosopher Korsgaard (2006) argues that this concern is more than simply worrying about how others might think of of us, it involves seeing a moral reason as a reason for behavior, and using that reason to guide planning and action. In short, it involves some version of moral autonomy where the desires associated with moral reason become dominant over other desires or appetites.15 Managing these norms in a society involves a complex cultural process ro of protecting against deviance while promoting diversity (Wright, 2021). Psychologically, these reasons are experienced as “natural law,” as a moral imperative that trumps any social convention or personal preference (Shweder, 2012; Shweder, Mahapatra, & Miller, 1987); and this experience is one of the aspects of human morallP ity that is a cultural universal. Despite clear evidence that other primates have some expectation about the nature of their social world, and show clear distress and attempts at punishment or repair when they are violated, it seems unlikely that one would find evidence for this aspect of moral expectation in non-­human primates (Kitcher, 2006; Korsgaard, 2006). Indeed, it is unclear how one could even collect such evidence. na 1.5.11 Self-­Actualization, Religious Experience, and Self-­Transcendence Although some evolutionary theorists would prefer to dismiss self-­actualization since Fi it is not “clearly linked to reproductive fitness” (Schaller et al., 2010, p. 336), others find it both compatible with evolutionary theory and essential in understanding human experience (Peterson & Park, 2010). Both sides in the controversy agree that they do not expect to find it in other animals. A similar pattern emerges with another human universal: religion (Brown, 1991). Though there is disagreement about the status of religion and its relationship to evolutionary theory (Dawkins, 2006; Kirkpatrick, 1999), any suggestion that one might find something like human religion in other animals is conspicuous by its absence. Self-­transcendence goes beyond the fulfillment of the self, and invests the self in some purpose beyond the self (Maslow, 1969). It seems to be both a natural product of adult development and a 15 Note how desire and reason are integrated in this account. Taking Moral Action process that can lead to extraordinary moral commitment (Walker & Frimer, 2015). This commitment has a dark side, depending in part on the cause one chooses (Koltko-­Rivera, 2006; Skitka & Mullen, 2002). 1.6 Discussion 1.6.1 Conclusion An evolutionary understanding of morality can primarily help us in understanding our capacities for taking moral action. How those capacities are shaped, influenced, and directed is the subject of the other chapters of this book. However, an ­understanding of capacity, its structures, and its limitations can help to articulate the s structure and limits of our morality, help us see how good and evil are linked, and allow us to grasp the precarious human condition that is balanced in the gray zone of between those two: 1. Moral action is deeply tied to the social nature of being human. Much philosophy and psychology have presented morality as the achievement of ro reason and will alone. Evolutionary theory confronts us with how our human morality is deeply rooted in the social nature of our species. The need to negotiate a complex social hierarchy within groups and to compete between groups has produced a set of capacities that we list in Section 1.4. These capacities are densely lP interwoven and help us to see how moral action results from the complex interplay among social emotions, planning, and rationality. Any understanding of morality that does not take this interplay into account will be inadequate. 2. The dark side of morality is, ironically, enabled by our desire to do good. An evolutionary approach to morality also helps us to understand the peculiar dual-­ na sided interaction of morality with social motives and structures. Social status in social hierarchies and in between groups is based in respect but also anger and fear. Cooperation among individuals and groups is based in gratitude and respect but also vicarious anger and indignation. Compassion for others is based in love and empathy but also vicarious anger and revenge against those who hurt loved ones. Fi This complex set of social emotions can be harnessed by our rationality and culture in the service of a range of goals, producing both international aid organizations and organized ethnic cleansing and self-­giving care for a partner and abuse for a partner. In this way, the psychology of being moral is also the psychology of evil. 1.6.2 Application In the Introduction, we presented the story of Rick Munson and his wife.16 The Munsons began by hosting foster children, then went on to host disabled foster children. Eventually, they founded a charitable organization and a facility that provided 16 Rick Munson is a pseudonym for a participant in a study of volunteerism (Hart & Atkins, 2006). The report of the study does not give a pseudonym for his wife, though it makes it clear they made decisions together. Evolution 21 integrated services to children with physical challenges. One can chart this as a move from the pro-­social integration of the two individuals into a committed couple, ­followed by the expression of their concern for others in caring for children, followed by the extension of that concern to community action. Their taking in of foster children already stretches our conception of a narrow evolutionary basis for pro-­social action, as it was likely an extension of the desire to have children to those who were clearly outside their genetic family. But their actions were surely due to a capacity for compassion that is a part of their evolutionary heritage and was shaped and supported by their religious culture. It was also made possible by an organized cultural practice of finding homes for children without any. The empathy the Munsons had for other disabled children and their parents and the couple’s capacity for planning and ­rationality led them to a more general community concern, which was expressed by volunteering in charitable organizations. This in turn lead to their founding of organs izations to meet community needs. One can see in this example the integration of evolutionarily shaped emotional and of rational capacities with culturally constructed social structures to produce good. This provides an example of the fit of these capacities (rationality, planning, compassion, empathy) to the local ecology in which the Munsons were embedded. But it is also an example of the shaping of those capacities by the wider moral ecology (e.g. religious ro practice) and the local ecology (the lack of integrated service for disabled children and the practice of founding organizations to meet needs). An understanding of the evolutionary basis of morality will require this sort of complexity. lP 1.6.3 Open Questions 1. We have an excellent beginning of a model of the evolution of morality and a long way to go in developing it. The review of building blocks (Section 1.4) suggests that we are beginning to na accumulate an evidential network of the underpinning of the moral ability in humans. But a comparison of the standards for making an evolutionary argument (Section 1.3) with the evidence for each building block suggests we still have a long way to go to fill in the argument. 2. There is a significant collection of capacities that underlie moral action for which we Fi so far have no viable evolutionary explanations. Section 1.5 gives a list of eleven areas in which there is an easily discernable distinction between the moral capacities of humans and other animals. There is clearly a vast field of opportunity for good research and theory here. But doing this work will require changing the way the question is asked. Instead of asking whether humans are different from other animals in their morality, we should begin asking how they are different, and how those differences have come about. It is some combination of these morally relevant differences in how that differentiates human morality from what might be called the proto-­morality of other species. 3. Exploring the fit of the evolved moral capacities of humans with their social and physical ecology will provide for a more complete evolutionary understanding of human morality. A central mistake in work on theory of mind is the tendency to measure other animals by their differences from human theory of mind, rather than by the Taking Moral Action ecologically valid fit of the abilities of the particular species with that species’ social and physical ecology. The field of moral psychology should take a clue from this ­mistake and insist on an ecologically valid explanation of human morality. Thus, rather than simply looking for universals, we should look for a more complete understanding of human morality in the fit of the moral capacities of humans with their varied social and physical ecologies. This will necessarily include an evolutionary perspective, but is unlikely to be reducible to only that perspective. 4. The evolution of morality and immorality are closely linked and interdependent. Neither morality nor immorality is more “basic.” Aggression against outsiders and norm-­violators is integral to our understanding of how moral commitment to a group evolved. We can regulate this, and even balance it with compassion, but altruistic punishment based in revenge motives will likely remain central to doing so. Empirical and theoretical work might help us find ways to motivate pro-­social s behavior and discourage anti-­social behavior that work within the limits of our evolutionary heritage and are still acceptable to ethical norms. 1.7 Further Readings of ro These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. lP • Aktipis and Kurzban (2004). “Is Homo economicus extinct? Vernon Smith, Daniel Kahneman and the Evolutionary Perspective.” An historical overview of the idea of the selfish “economic human” and its diminishing psychological appeal in the face of a wave of research suggesting its falsity (or at least incompleteness). • Curry et al. (2019). “Is it good to cooperate?” An excellent example of cross-­ na cultural work to establish an evolutionary basis for morality. • de Waal (2008). “Putting the altruism back into altruism: The evolution of empathy.” Primatologist Franz de Waal provides a useful presentation of the evidence for the evolution of empathy and its role in altruism. • Gallup and Anderson (2020). “Self-­Recognition in animals.” A review of a half-­ Fi century of research on animal consciousness that argues that the gap between great apes/humans and other species is larger than usually acknowledged. • Krebs (2008). “Morality: An evolutionary account.” A thoughtful presentation of the main issues in an evolutionary account of human morality. • Schmitt and Pilcher (2004). “Evaluating evidence of psychological adaptation: How do we know one when we see one?” A readable and systematic overview of what it means to say that some psychological characteristic is an evolutionary adaptation. • Sober (2006) Conceptual Issues in Evolutionary Biology (3rd ed.). Excellent volume edited by a philosopher deeply involved in the evolutionary debates within the biological disciplines. Every chapter is an example of how to think carefully about evolution. Essays on what fitness means, levels of selection, race, culture, ethics, etc. Evolution 23"
1,1.2,"Basic Evolutionary Processes (With an Eye Toward Morality) ro “Survival of the fittest” is a phrase that Darwin first uses in his fifth edition of The Origin of Species (Darwin, 1869 p. 92). He uses it as a synonym for natural selection. The many misunderstandings of this phrase over time have come to haunt those who would talk about evolution, and particularly evolution and morality. Herbert Spencer lP originated the “survival of the fittest” phrase (Spencer, 1866, pp. 444–445) and, among other burdens the phrase carries, it has come to be associated with Social Darwinism, a much maligned attempt to derive a kind of “might makes right” ethical principle.3 The phrase has also been misunderstood to suggest that it is the most physically fit, or aggressive, or selfishly competitive individual who survives. This is a na mistake on multiple fronts. Natural selection is not about individual survival, but about the ability to reproduce (and thus propagate one’s genome). And since it is about reproduction, it need not be about physical fitness or aggressiveness, but also about cooperation or camouflage or cleverness or compassion that allows the production and continuation of the genome. As we will see later, it is also a mistake in terms Fi of the level at which one can speak of selfishness. Genes may metaphorically be selfish (Dawkins, 1976), but individuals do not have to be (de Waal, 2006). However, to understand Darwin’s approach to “natural” selection, one must first understand the material on which it works. Darwin begins his Origin of Species (Darwin, 1859) not by talking about natural selection but about variation. Any population (of sheep, pigeons, or insect-­eating plants) has some natural variation in the characteristics of individuals in that population. Darwin begins his argument by noting that breeders (of pigeons or of strawberries, etc.) take advantage of this variation and selectively breed individuals with characteristics they desire. Darwin calls this “selection by man.” Natural selection is a similar process operating without (usually) human intervention. Some individuals with particular characteristics survive long 3 See Weinstein (2009) for a balanced discussion of Spencer’s role in Social Darwinism. Evolution 5 enough to pass on those characteristics to their offspring. To the extent that those characteristics have played a role in the propagation of characteristics in further individuals, then one can say those characteristics have been “naturally” selected or that they are evolutionary “adaptations.” This, then, is the basic idea of selection. Scholars of evolution list many and various varieties of selection (see Sober, 2006 for an overview of these and other issues). Because the moral is so closely associated with the social, the kind of selection that will particularly concern us here is social selection. This is natural selection driven by social interaction within a species, selection of the sort that may have resulted in the rapid increases in brain size mentioned earlier. There are four versions of social selection we will deal with here: sexual, kin, and group selection and gene–culture coevolution. s 1.2.1 Sexual Selection Though it may certainly have other functions, a primary evolutionary function of sexof ual interaction is the continuation of the species and the genome. In animals, sexual selection occurs during mating choice, with the choice based on some c­ haracteristic among the available partners (Krebs, 2008). The classic example in the literature is the mating selection among peacocks, with the female basing her choice in part on ro the characteristics of the splendid tail of the male.4 Can we construct a story of how this might account for moral characteristics among humans? It is at least the case that, across many cultures, moral qualities are preferred in mates (Buss et al., 1990), with dependability and kindness/­understanding lP appearing near the top in lists of preferences for both sexes from thirty-­three different countries. In addition, there is evidence that humans can reliably identify moral dispositions in others based on short observations (Fetchenhauer, Groothuis, & Pradel, 2010), making it possible that selection could be based on this identification. Miller (2007) has marshaled the evidence for a theoretical account of sexual ­selection na of virtues and suggested a set of testable theses based on this account. Others (Goetz, Keltner, & Simon-­Thomas, 2010) have included sexual selection among the kinds of selection pressure that can support an evolutionary account of the virtue of compassion in both sexes. Thus, one can construct a case for the evolutionary sexual selection of virtues. We Fi expect this is often overlooked because of the unfortunate connotations of “survival of the fittest.” 1.2.2 Kin (Family) Selection The idea of kin selection is implicit in the phrase inclusive fitness (Krebs, 2008). Inclusive fitness is based on the number of genes an individual can contribute to succeeding generations both directly (by producing offspring) and indirectly ­ (by ­supporting family relatives who share genetic material). This concept makes it 4 The empirical story is somewhat more complicated by the search to determine just what it is about the splendid tale that the peahen responds to (Loyau, Petrie, Saint Jalme, & Sorci, 2008). This cannot, of course, be immediately applied to the human species. Taking Moral Action possible to understand how compassion toward one’s immediate and extended ­relatives might evolve (Goetz et al., 2010) since care for relatives increases one’s inclusive fitness. This pattern of closer care for closer relatives has been documented in a wide variety of cultures (Essock-­Vitale & McGuire, 1980). If compassion for kin already exists it can be adapted or generalized to compassion for a wider group (Goetz et al., 2010).5 1.2.3 Group Selection One can extend the idea of selection based on one’s relatives to selection based on one’s group. Wilson and Sober (1994, 1998) revived the idea of group selection and embedded it in a model of multi-­level selection. One can think of selection occurring at the level of the gene, the cell, the individual, the kin group, or of larger, arbitrary s groups. Group selection was originally proposed by Darwin (1859). It seemed to later researchers (see Richerson & Boyd, 2005 for a review) that selfish individuals in of an arbitrary group would take advantage of cooperation, without themselves helping, increasing their fitness with no cost to themselves. It was thought that mathematical models easily predicted that in this case, the selfish defectors would eventually take over in any group (see Thompson, 1998 for some of the complexities in this claim). ro This “free riding” seemed to make it impossible for cooperative behavior to evolve based on its adaptive value for a group of unrelated individuals. In response to these concerns, Sober and Wilson (1999) identified the conditions that must obtain for group selection to work. lP To make group selection viable, variation on the characteristic (e.g. compassion) between competing groups would need to be larger than variation within each group. Simply put, the groups must differ on the characteristic. Equally important is that selection pressure between the groups would also need to be greater than any within group selection that might be caused by free riding. Sufficient selection presna sure between groups could be produced by things like intergroup conflict, foraging for a common but scarce resource, or the founding of new groups (Sober & Wilson, 1999). If group selection is going to work to increase some moral attribute that is favorable to the group, it needs to be the case that individuals can recognize the group and Fi establish an attraction to it. This makes immediate sense in terms of kin groups, and such attraction can develop from already existing attractions associated with parenting (Goetz et al., 2010). But how might this attraction establish itself with arbitrary groups? Lewis and Bates (2010) used a twin study and mathematical modeling to provide evidence for genetically based preferences for particular groups (in this case, ethnicity, religion, and race). In addition to these basic preferences for each of the groupings, they also found evidence for a central affiliation mechanism (CAM) that 5 The technical term for this is exapted, the selection of an already existing characteristic to serve another purpose. The existing characteristic need not have been naturally selected before, but it might simply have been a necessary byproduct of an already selected characteristic (e.g. a biologically affective experience like compassion for kin that is available to be exapted for non-­kin). It might then play a role in group selection to produce a broader characteristic (Goetz et al., 2010). Evolution 7 allows for affiliation or attachment to arbitrary groupings (like a sports team). This preference to be loyal to groups that develop out of local culture might be naturally selected (in a similar way that sexual selection might select virtues). Thus, there is some support for the idea that loyalty to groups of individuals is a characteristic that might be selected for by evolutionary processes (see also Krebs, 2008). 1.2.4 Gene–Culture Coevolution One more complication must be added to the ways that evolution is socially shaped. Human culture can itself create new selection pressures on individuals in a population, and thus influence genetic characteristics of the population over time. Culture creates an environment that produces selection pressure on the individuals in that culture. One example of this is the widespread change to agriculture. Richerson and s Boyd (2010) provide examples of this sort of coevolution with the change in the enzymes that allow adults to digest milk occurring among those populations that had of adopted herding of livestock and also the coevolution of enzymes that help with the digestion of plant starch among those adopting agriculture. Gene–culture coevolution is at the center of debates about the evolution of cooperation and altruism,6 since this process involves cultural processes like altruistic punishment7 that would ro ­“deselect” individuals who violate group norms (Boyd et al., 2003; Boyd, Richerson, & Henrich, 2011). We are only beginning to understand the complexity of the pathways that might lead to the current variety in human culture and genome. Genes do not code for lP specific behaviors, but they can influence systems that make some behaviors more likely to be expressed or some things easier or harder to learn (see Schmitt & Pilcher, 2004 for examples). The processes of development in the organism that move from a genetic encoding to a phenotypic (body, behavior, etc.) outcome of that encoding (a process called expression) can interact with an organism’s experience in na the world. For instance, careful maternal care can support the expression of genes that make the giving of maternal care more likely when the offspring grows up (Goetz et al., 2010). 1.2.5 Evolution vs. Culture Fi One of the standard critiques of evolutionary accounts of morality (and indeed one of the standard critiques of evolutionary psychology) is that these accounts ignore the overwhelming influence of culture on the complexity of human behavior (McKinnon, 2005). The dichotomous structure of this argument should immediately make one suspicious, since it mirrors many other sometimes overzealous debates in the social sciences like that between nature or nurture, personality or situation, reason or emotion, altruism or selfishness, etc. 6 See the section on Selfishness for selection for altruism. 7 This is punishment of an offender of a norm that is costly to the punisher (thus altruistic). Taking Moral Action But before looking at an integrative response to this dichotomy, we should note the difficulties that the “culture alone” camp has with explaining some aspects of morality. Two of the most well-­documented psychological accounts of moral judgment and action are the social learning (Bandura & Walters, 1963) and cognitive developmental ones (Boyd et al., 2011; Kohlberg, 1963; Turiel, 2006). Both have difficulties explaining some aspects of morality in comparison to evolutionary accounts. Social learning accounts have trouble explaining how moral rules emerged in culture, why people are motivated to preach them, and why children resist induction of moral rules. Cognitive developmental accounts struggle to explain the centrality of affect in moral judgment, the continuing presence of “childish” moral thinking in adults, and the connection (or lack thereof) between moral reasoning and behavior (Krebs, 2008). In addition, both approaches have difficulty in explaining the pattern of data that surround some effects (such as the incest taboo) that have been extens sively investigated from an evolutionary perspective (Schmitt & Pilcher, 2004). Finally, both cultural approaches find it hard to explain (or even finding relevant) the of extensive list of cultural universals that have moral content (Brown, 1991; Curry, Mullins, & Whitehouse, 2019). This is not an argument that cultural or purely ­psychological approaches are wrong but simply that they are incomplete, as the evolutionary approach itself is incomplete. This is the reason we try to bring together ro multiple narratives of moral behavior in this text. In Section 1.2.4, we covered the process of coevolution. This is the idea that culturally valued, socialized, and transmitted behaviors can influence the ­evolutionary path of groups, making things like cooperation an evolutionary advantage for a lP group. This suggests that culture may influence evolutionary paths more than evolutionary paths may influence the expression of culture. The idea of coevolution has emerged from decades of theoretical and empirical confrontation in the evolution– culture debate (Durham, 1991; McElreath, 2010; Richerson et al., 2010). This understanding of culture–evolution interaction helps to bring some resoluna tion to the voluminous literature on altruism (de Waal, 2008) as we will see in the A Note on Selfishness and Altruism section. And it also helps us understand the many different ways one might find culture–evolution interaction underlying moral judgment and behavior. Some authors (e.g. Mikhail, 2007) have proposed that much of our moral judgment is innate and pre-­packaged into independently operating modFi ules.8 But it is more likely that the wide range of moral things in our lives is, from the perspective of evolution, a kludge (Stich, 2006) and is constructed from a range of abilities and predispositions (Cushman & Young, 2011; Cushman, Young, & Hauser, 2006; Heyes, 2020). For instance, moral emotions can channel our reactions (e.g. anger against defectors can provoke us to punish them) in ways that help to enforce group norms and make the group more successful (and in ways that pass on this capacity for altruistic punishment). This is an approach adopted by Haidt and Joseph (2004, 2007), who propose sets of moral emotions linked to dimensions of how actions are morally judged. 8 See Chapter 7 for more detail. Evolution 9 1.2.6 A Note on Selfishness and Altruism One of the conceptual oddities of the debate in evolution for the past thirty years has been confusion about the word “selfish.” This is in part because Dawkins (1976) published a book using the “selfish gene” as a metaphor for evolution at about the same time that economic models of the rational and self-­ interested “Homo ­economicus” were widely discussed. Dawkins’s argument was that natural selection occurs at the level of the gene, and that genes were metaphorically “selfish” when their ­“strategies” to replicate themselves were analyzed at this level. The idea received wide acceptance in biology and for some time formed the orthodox view of the level at which selection was operating: the level of the gene. More recently, multi-­level approaches to selection (see the discussion in Section 1.2.3) have been proposed and favorably evaluated (Wilson & Sober, 1994, 1998). s However, the confluence of Homo economicus and the selfish gene in the 1970s, along with some unfortunate language that Dawkins used toward the end of his influof ential book, have served to support the idea that because genes are metaphorically “selfish,” then human psychological motivations must be selfish too. There are a variety of problems here. First, the idea simply assumes an identity across these levels of explanation. The word selfish is rooted in a description of one kind of human motiro vation and action, and it works as a metaphor for the point Dawkins wants to make about genes. But to then take that metaphorical use and deduce a psychological motivation or even a pattern of behavior is at best a stretch requiring good evidence. Genetically selfish is simply different from psychologically selfish. And the case for the lP psychologically selfish Homo economicus is not as strong as it used to be, and may well be suffering the death of a thousand limiting factors (Aktipis & Kurzban, 2004). An additional difficulty is that a simple “always be selfish” strategy is an implausible one in a shifting environment and may be less successful across different environments (Krebs, 2008). na There is clear evidence for a wide range of cooperative, non-­prototypically selfish activities in humans and other animals including: mutualism (e.g. group hunting), simple reciprocity (e.g. exchanging meals), cooperation with cooperators (requiring keeping track of “defectors”), “community concern” (de Waal, 2006), and long-­term social investment (e.g. care for infants, family, friends). Work in the laboratory (Aktipis Fi & Kurzban, 2004; Van de Vondervoort & Hamlin, 2018) and in the field across many societies (Curry et al., 2019; Henrich et al., 2005) supports these sorts of cooperative motivations in human action against the simple self-­interest model. And work by de Waal and colleagues (2006, 2008) shows similar behavior among other species. The renewal of research on cooperative and compassionate behavior across cultures and species seems to be leading to the “extinction” of the selfish Homo economicus model (Aktipis & Kurzban, 2004). Even though cooperation, nurturance, and compassion are important and natural human motivations, we should not assume a uniformly bright picture. There is a range of motivations and behavioral strategies in our moral interaction that involves selfishness, deception, taking advantage of others, and outright aggression. Indeed, a profound irony is likely built into the group selection mechanism that may be operating to produce cooperation and caretaking. Effective group selection for cooperation within the group requires some level of competition between groups Taking Moral Action (Sober & Wilson, 1999; Wilson & Sober, 1994, 1998). This competition can be created by warfare, but also other more peaceful means, like competition for a scarce resource. In addition, most models of group selection to produce cooperation assume what is called vicarious punishment for in-­group members, that is, aggression against those who deviate from the cooperative norm of the group. Both of these mechanisms underpin what has been called the dark side of altruism (Graham & Haidt, 2012; Skitka & Mullen, 2002). Now that we have a sense of the basic terms of how evolutionary processes might work, we will look into ways they might be combined together to produce evidence for how some aspect of morality might have evolved."
1,1.3,"How to Argue That Behavior Was Selected Because s It Was Adaptive of Evolutionary psychology has frequently been accused of consisting of too many “just so” stories9 about how some psychological characteristic might have been selected in a hypothetical past (Gould & Lewontin, 1979) – but having only that hypothetical possibility and little evidence. Having a “just so” story is a fine place to begin when ro that story points to where one might collect evidence. Given the relatively recent state of evolutionary psychology, we might expect for evidence about most proposed psychological adaptations to be fairly sparse, but these networks should become denser as more work is done. How might this happen? lP Much of evolutionary psychology is an argument for how some trait, or constellation of traits, might have been selected 100,000–300,000 or more years ago. How does one collect evidence and make an empirical argument for something that ­happened this long ago? In part, one does it by changing the question. For example, if in fact incest avoidance, a common ethical norm, is an evolutionary adaptation, what na pattern of evidence would we expect to find today in incest avoidance’s ­distribution across cultures, its relationship with genetics, its physiology, etc.? To answer this question requires several different kinds of evidence. Schmitt and Pilcher (2004) provide us with a useful map of eight different areas of evidence that are needed to give a convincing, valid case that some item of interest is an evolutionary adaptation: Fi 1. Theoretical coherence: The extent to which the adaptation connects to one or more theories or theoretical networks about evolution. This can involve some of the classical theoretical accounts in biology or psychology or game-­theoretic or mathematical modeling theory. This is a central piece of evidence in the network: lacking a coherent theoretical explanation means we would not have information about why or how the item is related to an evolutionary history or even the pattern of data we should expect in the other seven categories. In the case of incest, this consists of evidence that genetic problems arise in offspring of incest (Schmitt & Pilcher, 2004). 9 This is a reference to Rudyard Kipling’s Just So Stories (1912) for children. These are fantastic stories of how, for instance, the camel got its hump or the whale got its throat. The narrative logic in the stories is that it is a pleasing tale, and therefore must be true, just so. Evolution 11 2. Cross-­cultural evidence: If an adaptation occurs with regularity across cultures, or interacts across cultures in interesting ways (e.g. being less prevalent when cultural norms are strong, or occurring in reaction to specified cultural stimuli), then one may have evidence that the characteristic is influenced, at least in part, by some factor in common across all the cultures. There are almost universal prohibitions against incest across cultures (though what counts as incest varies), and there is cross-­cultural evidence that being raised with other-­sex peers before age six produces a diminishment of attraction to those peers (Schmitt & Pilcher, 2004). 3. Hunter-­gatherer evidence: There are still cultures today that inhabit environments much like that of our pre-­agricultural forebears. This gives us (somewhat tenuous, but nevertheless helpful) evidence of the likely environmental and cultural pressures for selection that may have been operating at the time the theory says the s adaptation should have been adaptive. Ethnographies of these cultures show, again, almost universal absence of incest (Schmitt & Pilcher, 2004). of 4. Psychological evidence: A particular attribute like incest avoidance may follow a developmental path that seems linked with the function our theory says it should have. Or it might relate to other psychological characteristics (or not correlate with them), or serve similar functions in modern societies. All these are part of ro the network of evidence that the characteristic is playing the adaptive role the theory says it should. Being raised with other-­sex peers before age six reduces attraction, and this provides developmental psychological evidence (Schmitt & Pilcher, 2004). lP 5. Physiological evidence: If one can find a physiological substrate for the characteristic in question (e.g. oxytocin and empathy: Rodrigues, Saslow, Garcia, John, & Keltner, 2009), then one has established a physical mechanism by which a characteristic might be heritable. The interaction of this physical mechanism with culture and situational stimuli can enrich the evidence network to provide more detail na about how the adapted characteristic functions in society. There is evidence for the sense of smell as a mechanism that produces sexual aversion to close kin, thus incest avoidance (Weisfeld, Czilli, Phillips, Gall, & Lichtman, 2003) 6. Medical evidence: This is similar to the physiological evidence but based in medical cases of the supposed physiological mechanism going wrong. When the physiology Fi is upset, are the functional relationships of the characteristics also upset (see e.g. the use of brain damage cases in Chapter 2)? Schmitt and Pilcher (2004) do not list any medical evidence for incest avoidance. 7. Phylogenetic evidence: Finding similar patterns in other species, where the theory leads one to expect the patterns, is another set of nodes in the network of evidence. For some characteristics (e.g. the effects of oxytocin on social behavior) one might expect to see a range of species across all mammals (Rodrigues et al., 2009), while for other characteristics (like a sense of fairness) one may expect only similarities among other primates (de Waal, 2006; Preston & de Waal, 2002). In terms of incest, animals rarely mate with parents or siblings (Schmitt & Pilcher, 2004). 8. Genetic evidence: We are increasingly able to use genomic evidence to trace the timing of events in human evolution (Richerson et al., 2010) and this will become a rich source of data that can connect with the others in this list. Schmitt and Pilcher (2004) do not list any genetic evidence for incest avoidance. Taking Moral Action Schmitt and Pilcher (2004) use this framework to survey the evidence for four psychologically relevant characteristics as evolutionary adaptations. Profet (1988) has followed the possibility that pregnancy sickness and its associated food aversions are an adaptation that allows for the fetus to be protected against toxins in plants that would cause birth defects. This story suggests that pregnancy sickness will follow a particular pattern (certain food avoidances, a particular timeline, the relationship of sickness to miscarriage, similarity across cultures, etc.) and there is much evidence for this rich network of relationships (Schmitt & Pilcher, 2004). Schmitt and Pilcher (2004) find less extensive, but still “exemplary,” evidence for incest avoidance. They find only “extensive” evidence for men’s greater desire for short-­term sexual variety than that of women, and “moderate” levels of evidence that we have evolved a mechanism that makes it easier to learn fear of snakes. s 1.4 Evolutionary Building Blocks for a Robust Morality of So, what can we learn about our moral nature by seeing it through the lens of ­evolutionary adaptation? At the most complex level, this might mean we have inherited a distinct and structured universal moral grammar, much like what has been ro claimed for the deep structure of a universal linguistic grammar (Huebner, Dwyer, & Hauser, 2009; Mikhail, 2007). We will evaluate this claim in a moment, but the picture of morality we provide in this book attempts a much wider claim. Moral action certainly involves a kind of structure of moral intuition, but the full picture includes lP far more: emotional intuitions, strategic planning, self-­regulation, self-­concept and group identity, and much more. Each of these might have an evolutionary underpinning. But it seems unlikely that they would have all evolved together as one piece. The usual pattern of evolutionary adaptation that moves toward complexity is more one of building that complexity slowly based on some existing variation.10 Given that na many of these aspects, such as opposing values, are often at odds with one another (and that self-­regulation is, in one sense, a mechanism to help adjudicate these conflicts), an evolutionary story would expect the complexity of moral action in humans to have been built up slowly across many species and a great deal of time. For instance, maternal care for the young is common to all mammals, but it plays an important part Fi in human morality (Preston & de Waal, 2002). For an overview of how these building blocks might come together, we will follow the proposal by Krebs (2008) of the various psychological building blocks that likely came together to constitute what we now call morality. This overview itself will suggest additional pieces that remain to be covered, and we address them in Section 1.5. 1.4.1 Adaptive Sociality The first and fundamental building block that Krebs lists is that of sociality – or living in groups. Group living is built out of interdependence among animals and the 10 Evolution does not always build toward complexity. Even “build” is a metaphor that contains intention. “Natural” selection has no intention. An organism may evolve toward less complexity if that makes it fit better in an environment. Evolution 13 complexities of how that interdependence is negotiated. This sociality is the basic ­background for the development of all the other building blocks. One thing to note: in Krebs’s phrase, social life is built of both confluence and conflict of interest. For organisms to work in a group there must be some attachment to the group, some confluence of interest, and this attachment can be elaborated in many directions. As de Waal (2002) and Goetz et al. (2010) have documented, one origin (at least in mammals) of this social attraction must have been the giving and receiving of care between parents and offspring, which became more crucial as the time for complete maturation of offspring increased. And there is of course conflict of interest that must also be managed. This conflict and confluence is the arena in which moral action and judgment evolved. 1.4.2 Pro-­social Behavior Strategies Based in Social Emotions s Emotions are not simply “feelings” but are instead a complexity of: (1) cognitive appraisal (that arouses and shapes the emotion); (2) directed arousal (that provides of the “feel” of the emotion and signals its urgency); and (3) action tendency (that links action to the reaction of the emotion). (See Oatley, Keltner, & Jenkins, 2006 or Chapter 8 for an overview). How this complex itself has evolved is a fine puzzle; but for social animals, it certainly evolved in connection with socially relevant behavior. ro Krebs (2008) lists three relevant sets of emotions tied to pro-­ social behaviors: (1) ­deference in dominance hierarchies based in fear and respect; (2) cooperation among individuals based in gratitude, anger, and indignation; and (3) altruism based in love, sympathy, and empathy. We suggest some more in Chapter 8. lP 1.4.3 Strategic Interaction Simply having social emotions and reacting based on them produces a sort of mechanical social order. But, once sociality is established, cheating is possible when one can na take the other’s perspective in order to deceive. A basic requirement for strategic social interaction is theory of mind, recognizing and ascribing mental states to ourselves and others (Wellman, 2018). There is evidence that even infants have basic aspects of theory of mind (Hudac & Sommerville, 2020) though its developmental trajectory looks similar to that of reading (Heyes, 2020), suggesting that the full Fi capacity is some mix of built-­in capability and cultural shaping. The capacity to take perspective can then produce an “arms race” (Krebs, 2008) when it makes it possible to detect cheating and punish free riders. It can become even more complex when we keep track not only of cheaters but also those among us who do not punish the cheaters. (Boyd, Gintis, & Bowles, 2010; Boyd et al., 2003). This strategic level of interaction can apply to areas as abstract as what de Waal has called “community concern,” the strategic intervention in group processes to produce desired outcomes at the group level (de Waal, 2006). 1.4.4 Conscience Krebs (2008), citing Darwin (1859), lists the linking of emotional responses with anticipatory fear of punishment from others (and later the internalized other) as a potential origin for what we call conscience. There is some evidence for this linkage. Taking Moral Action For instance, physical responses associated with negative self-­emotions (like shame and guilt) mirror behavior shown in appeasement displays in humans and other primates (Keltner & Buswell, 1997; Leary, 2007). Leary (2007) provides an overview of the research that makes this link between what we might call conscience and anticipatory reactions of real or imagined others. But one need not assume that this effect runs on anticipatory punishment alone. One can find evidence of an evolved capacity for compassion that can motivate behavior, not merely of avoiding the bad but also approaching the good (Goetz et al., 2010). 1.4.5 Moral Judgment and Reasoning Krebs (2008) proposes that the origin of moral reasoning lies in moral c­ ommunication – in verbal influence attempts to get others to behave in morally prescribed ways. But s this is surely starting too late in the process. Tse (2008) looks back even further to a proposed delinking of attention from concrete objects in the world that allows arbiof trary symbols to be associated with each other.11 This is likely a basis for the flexibility of human reasoning, and the basis of things like metaphor, allowing for the association of arbitrary symbols and ideas in metaphor (a poem as lovely as a tree) but also the association of actions with abstract classes of good and bad. There is currently a ro vigorous debate about whether something as structured as a moral “grammar” is an evolutionary heritage of humans. This idea is an analogy from what seems to be an evolved grammar in language. There is currently only suggestive evidence for this hypothesis (Beller, 2010) and nothing like the strong networks of evidence we have lP reviewed for other adaptations (see Greene, 2008; Mikhail, 2007 for some idea of the controversy). 1.4.6 Moral Norms na Earlier we reviewed at least one moral norm (the incest taboo) that seems to have an evolutionary basis (Schmitt & Pilcher, 2004). But we clearly have a large store of moral norms that are in regular use, and that vary widely from culture to culture. In Chapters 7 and 8, we review the evidence that there is a structure to these norms that is cross-­culturally consistent, with the same value sets showing up across all cultures Fi but differently emphasized by each culture (Haidt & Joseph, 2004; Haidt, Koller, & Dias, 1993; Schwartz, 2006). This cross-­cultural evidence of a universal structure might argue for an evolutionary origin (see Haidt & Joseph, 2007 for an evolutionary argument). Managing these norms involves a complex cultural process of protecting against deviance while promoting diversity (Wright, 2021). We already have a long list of building blocks, and Krebs (2008) provides some idea of how these might come together to support what we call moral judgment and action. However, the chapters in this text suggest we need to add even more complexity to this picture. There must be some accounting of the development and 11 There is currently little evidence for this interesting proposal. Whether one calls this an interesting theoretical proposal or a “just so story” depends on one’s attitude toward the likelihood that such evidence will turn up (Dietrich, 2008). Evolution 15 integration of short-­and long-­term self-­regulation. How and why might willpower (and variations in willpower) have evolved (Heatherton, 2011)? While it is merely difficult to assemble the network of evidence for short-­term self-­regulation as an ­evolutionary adaptation, work on the evolutionary underpinnings of longer-­term self-­ regulation seems quite thin (Heatherton, 2011); though Miller (2007) suggests the sexual selection of moral virtues like dependability might play a role. We know that storytelling (McAdams, 2009) and religion (Graham & Haidt, 2010; Kirkpatrick, 1999) play a role in moral judgment and action. For many of these more complex and higher-­level aspects of morality it may well be that the relatively new approaches to culture and coevolution (Wilson & Sober, 1998) will provide us with a way to understand their construction. We will now look at a list of many of these additional aspects of morality that may (or may not) find some evolutionary underpinning. s of 1.5 Human Distinctiveness: How Large is the Gap? We have spent most of this chapter looking at the processes of evolution and the building blocks of human morality. The goal has been to see how we can ground ro human morality in, or derive it from, various aspects of the capacities and behavior of our ancestors. An older version of this approach, disparagingly called “veneer theory” by de Waal (2006), proposes that humans have only a veneer of politeness and hypocrisy overlaying the motivation of brute selfishness. Higgins and Pittman (2008) lP ­suggest that this version of human moral evolution is mirrored in the historical split in evolutionary approaches in different sub-­fields of psychology. In cognition, we are said to have “developed from” prior species, while in motivation, we have been presented as merely “deriving” our animal motivations from prior species. This results in an image, they claim, of “humans as having the mind of a god and the motives of a na brute” (Higgins & Pittman, 2008, p. 363). In the realm of morality, this image of the supremacy of reason is aided and abetted by philosophical approaches to ethics (e.g. Kant, 1999; Rawls, 1971/1999) that portray reason as both the foundation and the limit of real (that is, human) morality. But current approaches to human morality that we review in this book suggest Fi that: (1) human morality is constituted of more complex stuff than pure reason; and (2) the differences with other animals and our primate ancestors lie in a range of ­distinctly human abilities and motivations (Higgins & Pittman, 2008) and not just differences in reason alone. There is unanimity in recognizing that there are deep differences between humans and other animals in morality but the nature, structure, and meaning of those differences is still in dispute.12 12 Some claims might underestimate these differences (Adolphs, 2009) in the way veneer theory does. Other claims may underestimate the unique abilities of other animals by making human morality the criterion, and missing uniquely adapted, species-­specific capacities of other animals (Emery & Clayton, 2009). Crows, for example, do not have a full-­blown theory of mind like humans, but they are remarkably good at hiding food from other crows (Emery & Clayton, 2009). De Waal (2006, 2009), Emery and Clayton (2009), and Adolphs (2009) provide some insight into the debates about these differences. Taking Moral Action The dimensions associated with morality on which humans differ from other ­animals include at least the eleven categories noted in Sections 1.5.1–1.5.11. We have constructed this incomplete list from the literature in evolutionary psychology. The effort to build coherent networks of evidence for the origins of human ability in each of these categories may, of course, suggest additional categories or the merging of some. The list makes it clear that we are, indeed, at the very beginning of an evolutionary understanding of the structure and development of a truly human morality. 1.5.1 Symbolizing and Reasoning The beginning of the ability to reason lies, perhaps, in the ability to take any particular representation of an object and link it arbitrarily to some other mental representation, e.g. a poem is like a tree (Tse, 2008). This may provide the basis for human ability to s represent things symbolically (think of early cave paintings and whether any animal other than humans would “get” them). The empirical evidence for an evolutionary of basis for moral reasoning and judgment remains unclear (Beller, 2010). Some researchers claim that regularities in the way people ignore logical structure and reason in specific content areas (e.g. cheating, incest) show the primacy of evolutionary modules for content-­ specific reasoning (Cosmides & Tooby, 2008; Cushman ro et al., 2006).13 But this claim is disputed by both philosophers (Prinz, 2008) and psychologists (Chater & Oaksford, 1996; Pietraszewski & Wertz, 2021). This is a disagreement about how ought-­based (or deontic) reasoning might have evolved in humans. But it is also a dispute anchored in an agreement that human capabilities for lP deontic reasoning are vastly more complex than that of other animals. 1.5.2 Time Perspective Time perspective underlies the ability to think about the moral consequences of an na action or to make plans to achieve moral goals. In order to support some conception of a past or a future time, or of an alternative present, one must construct a mental representation and distinguish it from one’s own current experience (Higgins & Pittman, 2008). Thus, a conception of time requires the symbolizing abilities ­mentioned in Section 1.5.1. It remains unclear whether any animals other than Fi humans can experience an imagined point of view (Adolphs, 2009) and thus have some sense of time. The sense of the future and past allows humans to construct moral stories about the past and about the future, and compare the self to them (Higgins & Pittman, 2008). This adoption of another point of view than that of immediate consciousness is likely one that underlies the ability to recognize other minds (Adolphs, 2009). 13 For an example of this content-­specific reasoning, see the discussion on moral dumbfounding in Chapter 7. In short, careful experimentation can find instances where people will simply say “I know it is wrong, but I do not know why.” Such moral intuition suggests that these particular moral judgments do not derive from a general reasoning mechanism. But this does not mean that no moral judgments derive from a general reasoning mechanism. Evolution 17 1.5.3 Cognitive Control and Self-­Regulation As we argue in Chapters 6 and 9, self-­regulation is central to moral action. It is ­certainly the case that other animals can exert cognitive control over immediate desire, both to deceive other animals (de Waal, 2006) and in response to training by humans (H. C. Miller et al., 2010). This sort of immediate willpower of response suppression seems to share similar biological substrates in humans and other mammals (e.g. it uses glucose-­based energy: Baumeister, Bratslavsky, Muraven, & Tice, 1998; H. C. Miller et al., 2010). But the extent, complexity, and flexibility of human self-­control mechanisms far outpaces those of other animals (Heatherton, 2011). It extends to what the philosopher Frankfurt (1971) has called “second order desires,” or the desire to have a particular desire and to the planning of outside influences that will help one attain future states (for example, by going to school: Cohen, 2005). It s also requires directed planning and practice to achieve long-­term goals (Baumeister, Masicampo, & Vohs, 2011; Cervone, Shadel, Smith, & Fiori, 2006; Lord, Diefendorff, of Schmidt, & Hall, 2009; McRae, Ochsner, & Gross, 2011). 1.5.4 Extensive Integration of Reason and Emotion ro Moll and colleagues (de Oliveira-­Souza, Zahn, & Moll, 2016; Moll, de ­Oliveira-­Souza, & Eslinger, 2003; Moll, De Oliveira-­Souza, & Zahn, 2009) have hypothesized that the most important thing about human reason may well be its integration with rather than its opposition to emotion.14 Even philosophical champions of reason as a marker lP of human morality (Korsgaard, 2006) have suggested that the integration of reason and emotion is a central puzzle in the evolution of morality (Korsgaard, 2010). It is not simply the addition of rationality to an “emotional animal” that makes humans special and human morality possible. It is the extensive integration of that rationality with emotion that allows them to influence and “tune” each other. Emotions influna ence our implicit and explicit moral reasoning by guiding intuition (Haidt, 2001) and reasoning (Goldin et al., 2008; McRae et al., 2011). And rationality influences emotion through the multifaceted self-­regulation processes mentioned in Section 1.5.3, through the appraisal and re-­appraisal process (Lazarus, 1991; Ochsner et al., 2010), and through the planned construction of culture (Cohen, 2005). Fi 1.5.5 Extensive Culture Humans have complex, stable, and constantly adapting cultural systems with ­enduring artifacts, language, artistic expression, economies, ritual, values, social structures, and extensive bodies of knowledge and practice (McElreath, 2010; Richerson & Boyd, 2005). These cultural achievements are clearly one of the major differences between humans and other animals. There is some evidence for social transmission of information among other primates (Adolphs, 2009) and thus some rudimentary socially shared culture. Understanding the linkages among evolution, neuroscience, and cultural processes will be a crucial undertaking for a complete understanding of moral action (Kitayama, Varnum, & Salvador, 2019; Wright, 2021). 14 We review evidence for this integration in Chapters 2 and 8. Taking Moral Action 1.5.6 Self-­Consciousness and Self-­Awareness The classic experimental demonstration of self-­ consciousness in children and in ­non-­humans is the body awareness test. This involves placing some marker on the body in a place that is difficult to see without a mirror and then measuring the attempts to examine the new decoration. Evidence for such awareness has been found in chimpanzees, bonobos, dolphins, elephants, and monkeys (Adolphs, 2009). This seems adequate to demonstrate body awareness but its evidential status for awareness of one’s own mind is unclear (Adolphs, 2009; Gallup & Anderson, 2020). For ­normally functioning adolescent and adult humans, there is unanimity that a comawareness is present (Byrne & plex, multidimensional, and morally relevant self-­ Whiten, 1988; Robins, 2021). s 1.5.7 Social Consciousness of Dogs and some other domesticated animals, perhaps because they have been shaped by human intervention over many generations, are skilled at interpreting gestures (e.g. pointing) and in responding correctly in the guesser–knower paradigm (in which they must choose a person based on that person’s knowledge of ro where some food is hidden) (Emery & Clayton, 2009). But dogs do not appear to have some basic t­ heory of mind characteristics that human infants share, like preferring helpers over hinderers in an attention task (Hamlin, 2013,; McAuliffe et al., 2019; Van de Vondervoort & Hamlin, 2018). Primates are particularly lP skilled at tracking kinship and dominance relationships over time (Adolphs, 2009). However, if one asks for a full-­fledged human theory of mind in other primates, it appears to be lacking (Emery & Clayton, 2009) – although one can likely find components of it. For example, there is evidence that other primates know that others know something but probably cannot grasp the complexity that the other’s na knowledge may be false (Emery & Clayton, 2009). Waytz and colleagues (Waytz, Cacioppo, & Epley, 2010; Waytz et al., 2010) have shown that humans’ perception of agency (even the anthropomorphic perception of agency in inanimate objects) includes a moral dimension allowing for blame and suggesting that the roots of moral perception go quite deep into basic perception. And though other Fi primates form coalitions (de Waal, 2007) the complexity of human tribalism is much greater (Clark et al., 2019). 1.5.8 Manipulation of Others’ Perception There is evidence that other primates understand and practice deception (Adolphs, 2009; Emery & Clayton, 2009). There is even evidence that crows and other corvids cache food in ways that make it difficult for other crows to find it, but only if other crows who might take it are present (Emery & Clayton, 2009). But again, even in young children, human manipulation of others’ perception is vastly more complex, multidimensional, and subtle (Higgins & Pittman, 2008). Humans are deeply concerned about what others think (Higgins & Pittman, 2008) and particularly what others think about them (Leary, 2007). Evolution 19 1.5.9 Sharing Reality With Other People Humans have a deep need to share their understanding of the world with others (Higgins & Pittman, 2008). All mammals have some abilities at social coordination and signaling (Goetz et al., 2010) and some have components of a theory of mind (Emery & Clayton, 2009). But even human children are competent in communicating shared social knowledge, sharing joint attention, and explicit teaching. Language is a primary achievement of this need (Byrne & Whiten, 1988). 1.5.10 Universalized Normative Evaluations People’s concern about what others think of them has been included in models of the “generalized other” (Heatherton, 2011; Mead & Morris, 1934) as one source of s how humans universalize normative evaluations. The philosopher Korsgaard (2006) argues that this concern is more than simply worrying about how others might think of of us, it involves seeing a moral reason as a reason for behavior, and using that reason to guide planning and action. In short, it involves some version of moral autonomy where the desires associated with moral reason become dominant over other desires or appetites.15 Managing these norms in a society involves a complex cultural process ro of protecting against deviance while promoting diversity (Wright, 2021). Psychologically, these reasons are experienced as “natural law,” as a moral imperative that trumps any social convention or personal preference (Shweder, 2012; Shweder, Mahapatra, & Miller, 1987); and this experience is one of the aspects of human morallP ity that is a cultural universal. Despite clear evidence that other primates have some expectation about the nature of their social world, and show clear distress and attempts at punishment or repair when they are violated, it seems unlikely that one would find evidence for this aspect of moral expectation in non-­human primates (Kitcher, 2006; Korsgaard, 2006). Indeed, it is unclear how one could even collect such evidence. na 1.5.11 Self-­Actualization, Religious Experience, and Self-­Transcendence Although some evolutionary theorists would prefer to dismiss self-­actualization since Fi it is not “clearly linked to reproductive fitness” (Schaller et al., 2010, p. 336), others find it both compatible with evolutionary theory and essential in understanding human experience (Peterson & Park, 2010). Both sides in the controversy agree that they do not expect to find it in other animals. A similar pattern emerges with another human universal: religion (Brown, 1991). Though there is disagreement about the status of religion and its relationship to evolutionary theory (Dawkins, 2006; Kirkpatrick, 1999), any suggestion that one might find something like human religion in other animals is conspicuous by its absence. Self-­transcendence goes beyond the fulfillment of the self, and invests the self in some purpose beyond the self (Maslow, 1969). It seems to be both a natural product of adult development and a 15 Note how desire and reason are integrated in this account. Taking Moral Action process that can lead to extraordinary moral commitment (Walker & Frimer, 2015). This commitment has a dark side, depending in part on the cause one chooses (Koltko-­Rivera, 2006; Skitka & Mullen, 2002). 1.6 Discussion 1.6.1 Conclusion An evolutionary understanding of morality can primarily help us in understanding our capacities for taking moral action. How those capacities are shaped, influenced, and directed is the subject of the other chapters of this book. However, an ­understanding of capacity, its structures, and its limitations can help to articulate the s structure and limits of our morality, help us see how good and evil are linked, and allow us to grasp the precarious human condition that is balanced in the gray zone of between those two: 1. Moral action is deeply tied to the social nature of being human. Much philosophy and psychology have presented morality as the achievement of ro reason and will alone. Evolutionary theory confronts us with how our human morality is deeply rooted in the social nature of our species. The need to negotiate a complex social hierarchy within groups and to compete between groups has produced a set of capacities that we list in Section"
1,1.4,"Evolutionary Building Blocks for a Robust Morality of So, what can we learn about our moral nature by seeing it through the lens of ­evolutionary adaptation? At the most complex level, this might mean we have inherited a distinct and structured universal moral grammar, much like what has been ro claimed for the deep structure of a universal linguistic grammar (Huebner, Dwyer, & Hauser, 2009; Mikhail, 2007). We will evaluate this claim in a moment, but the picture of morality we provide in this book attempts a much wider claim. Moral action certainly involves a kind of structure of moral intuition, but the full picture includes lP far more: emotional intuitions, strategic planning, self-­regulation, self-­concept and group identity, and much more. Each of these might have an evolutionary underpinning. But it seems unlikely that they would have all evolved together as one piece. The usual pattern of evolutionary adaptation that moves toward complexity is more one of building that complexity slowly based on some existing variation.10 Given that na many of these aspects, such as opposing values, are often at odds with one another (and that self-­regulation is, in one sense, a mechanism to help adjudicate these conflicts), an evolutionary story would expect the complexity of moral action in humans to have been built up slowly across many species and a great deal of time. For instance, maternal care for the young is common to all mammals, but it plays an important part Fi in human morality (Preston & de Waal, 2002). For an overview of how these building blocks might come together, we will follow the proposal by Krebs (2008) of the various psychological building blocks that likely came together to constitute what we now call morality. This overview itself will suggest additional pieces that remain to be covered, and we address them in Section 1.5. 1.4.1 Adaptive Sociality The first and fundamental building block that Krebs lists is that of sociality – or living in groups. Group living is built out of interdependence among animals and the 10 Evolution does not always build toward complexity. Even “build” is a metaphor that contains intention. “Natural” selection has no intention. An organism may evolve toward less complexity if that makes it fit better in an environment. Evolution 13 complexities of how that interdependence is negotiated. This sociality is the basic ­background for the development of all the other building blocks. One thing to note: in Krebs’s phrase, social life is built of both confluence and conflict of interest. For organisms to work in a group there must be some attachment to the group, some confluence of interest, and this attachment can be elaborated in many directions. As de Waal (2002) and Goetz et al. (2010) have documented, one origin (at least in mammals) of this social attraction must have been the giving and receiving of care between parents and offspring, which became more crucial as the time for complete maturation of offspring increased. And there is of course conflict of interest that must also be managed. This conflict and confluence is the arena in which moral action and judgment evolved. 1.4.2 Pro-­social Behavior Strategies Based in Social Emotions s Emotions are not simply “feelings” but are instead a complexity of: (1) cognitive appraisal (that arouses and shapes the emotion); (2) directed arousal (that provides of the “feel” of the emotion and signals its urgency); and (3) action tendency (that links action to the reaction of the emotion). (See Oatley, Keltner, & Jenkins, 2006 or Chapter 8 for an overview). How this complex itself has evolved is a fine puzzle; but for social animals, it certainly evolved in connection with socially relevant behavior. ro Krebs (2008) lists three relevant sets of emotions tied to pro-­ social behaviors: (1) ­deference in dominance hierarchies based in fear and respect; (2) cooperation among individuals based in gratitude, anger, and indignation; and (3) altruism based in love, sympathy, and empathy. We suggest some more in Chapter 8. lP 1.4.3 Strategic Interaction Simply having social emotions and reacting based on them produces a sort of mechanical social order. But, once sociality is established, cheating is possible when one can na take the other’s perspective in order to deceive. A basic requirement for strategic social interaction is theory of mind, recognizing and ascribing mental states to ourselves and others (Wellman, 2018). There is evidence that even infants have basic aspects of theory of mind (Hudac & Sommerville, 2020) though its developmental trajectory looks similar to that of reading (Heyes, 2020), suggesting that the full Fi capacity is some mix of built-­in capability and cultural shaping. The capacity to take perspective can then produce an “arms race” (Krebs, 2008) when it makes it possible to detect cheating and punish free riders. It can become even more complex when we keep track not only of cheaters but also those among us who do not punish the cheaters. (Boyd, Gintis, & Bowles, 2010; Boyd et al., 2003). This strategic level of interaction can apply to areas as abstract as what de Waal has called “community concern,” the strategic intervention in group processes to produce desired outcomes at the group level (de Waal, 2006). 1.4.4 Conscience Krebs (2008), citing Darwin (1859), lists the linking of emotional responses with anticipatory fear of punishment from others (and later the internalized other) as a potential origin for what we call conscience. There is some evidence for this linkage. Taking Moral Action For instance, physical responses associated with negative self-­emotions (like shame and guilt) mirror behavior shown in appeasement displays in humans and other primates (Keltner & Buswell, 1997; Leary, 2007). Leary (2007) provides an overview of the research that makes this link between what we might call conscience and anticipatory reactions of real or imagined others. But one need not assume that this effect runs on anticipatory punishment alone. One can find evidence of an evolved capacity for compassion that can motivate behavior, not merely of avoiding the bad but also approaching the good (Goetz et al., 2010). 1.4.5 Moral Judgment and Reasoning Krebs (2008) proposes that the origin of moral reasoning lies in moral c­ ommunication – in verbal influence attempts to get others to behave in morally prescribed ways. But s this is surely starting too late in the process. Tse (2008) looks back even further to a proposed delinking of attention from concrete objects in the world that allows arbiof trary symbols to be associated with each other.11 This is likely a basis for the flexibility of human reasoning, and the basis of things like metaphor, allowing for the association of arbitrary symbols and ideas in metaphor (a poem as lovely as a tree) but also the association of actions with abstract classes of good and bad. There is currently a ro vigorous debate about whether something as structured as a moral “grammar” is an evolutionary heritage of humans. This idea is an analogy from what seems to be an evolved grammar in language. There is currently only suggestive evidence for this hypothesis (Beller, 2010) and nothing like the strong networks of evidence we have lP reviewed for other adaptations (see Greene, 2008; Mikhail, 2007 for some idea of the controversy). 1.4.6 Moral Norms na Earlier we reviewed at least one moral norm (the incest taboo) that seems to have an evolutionary basis (Schmitt & Pilcher, 2004). But we clearly have a large store of moral norms that are in regular use, and that vary widely from culture to culture. In Chapters 7 and 8, we review the evidence that there is a structure to these norms that is cross-­culturally consistent, with the same value sets showing up across all cultures Fi but differently emphasized by each culture (Haidt & Joseph, 2004; Haidt, Koller, & Dias, 1993; Schwartz, 2006). This cross-­cultural evidence of a universal structure might argue for an evolutionary origin (see Haidt & Joseph, 2007 for an evolutionary argument). Managing these norms involves a complex cultural process of protecting against deviance while promoting diversity (Wright, 2021). We already have a long list of building blocks, and Krebs (2008) provides some idea of how these might come together to support what we call moral judgment and action. However, the chapters in this text suggest we need to add even more complexity to this picture. There must be some accounting of the development and 11 There is currently little evidence for this interesting proposal. Whether one calls this an interesting theoretical proposal or a “just so story” depends on one’s attitude toward the likelihood that such evidence will turn up (Dietrich, 2008). Evolution 15 integration of short-­and long-­term self-­regulation. How and why might willpower (and variations in willpower) have evolved (Heatherton, 2011)? While it is merely difficult to assemble the network of evidence for short-­term self-­regulation as an ­evolutionary adaptation, work on the evolutionary underpinnings of longer-­term self-­ regulation seems quite thin (Heatherton, 2011); though Miller (2007) suggests the sexual selection of moral virtues like dependability might play a role. We know that storytelling (McAdams, 2009) and religion (Graham & Haidt, 2010; Kirkpatrick, 1999) play a role in moral judgment and action. For many of these more complex and higher-­level aspects of morality it may well be that the relatively new approaches to culture and coevolution (Wilson & Sober, 1998) will provide us with a way to understand their construction. We will now look at a list of many of these additional aspects of morality that may (or may not) find some evolutionary underpinning. s of 1.5 Human Distinctiveness: How Large is the Gap? We have spent most of this chapter looking at the processes of evolution and the building blocks of human morality. The goal has been to see how we can ground ro human morality in, or derive it from, various aspects of the capacities and behavior of our ancestors. An older version of this approach, disparagingly called “veneer theory” by de Waal (2006), proposes that humans have only a veneer of politeness and hypocrisy overlaying the motivation of brute selfishness. Higgins and Pittman (2008) lP ­suggest that this version of human moral evolution is mirrored in the historical split in evolutionary approaches in different sub-­fields of psychology. In cognition, we are said to have “developed from” prior species, while in motivation, we have been presented as merely “deriving” our animal motivations from prior species. This results in an image, they claim, of “humans as having the mind of a god and the motives of a na brute” (Higgins & Pittman, 2008, p. 363). In the realm of morality, this image of the supremacy of reason is aided and abetted by philosophical approaches to ethics (e.g. Kant, 1999; Rawls, 1971/1999) that portray reason as both the foundation and the limit of real (that is, human) morality. But current approaches to human morality that we review in this book suggest Fi that: (1) human morality is constituted of more complex stuff than pure reason; and (2) the differences with other animals and our primate ancestors lie in a range of ­distinctly human abilities and motivations (Higgins & Pittman, 2008) and not just differences in reason alone. There is unanimity in recognizing that there are deep differences between humans and other animals in morality but the nature, structure, and meaning of those differences is still in dispute.12 12 Some claims might underestimate these differences (Adolphs, 2009) in the way veneer theory does. Other claims may underestimate the unique abilities of other animals by making human morality the criterion, and missing uniquely adapted, species-­specific capacities of other animals (Emery & Clayton, 2009). Crows, for example, do not have a full-­blown theory of mind like humans, but they are remarkably good at hiding food from other crows (Emery & Clayton, 2009). De Waal (2006, 2009), Emery and Clayton (2009), and Adolphs (2009) provide some insight into the debates about these differences. Taking Moral Action The dimensions associated with morality on which humans differ from other ­animals include at least the eleven categories noted in Sections 1.5.1–1.5.11. We have constructed this incomplete list from the literature in evolutionary psychology. The effort to build coherent networks of evidence for the origins of human ability in each of these categories may, of course, suggest additional categories or the merging of some. The list makes it clear that we are, indeed, at the very beginning of an evolutionary understanding of the structure and development of a truly human morality. 1.5.1 Symbolizing and Reasoning The beginning of the ability to reason lies, perhaps, in the ability to take any particular representation of an object and link it arbitrarily to some other mental representation, e.g. a poem is like a tree (Tse, 2008). This may provide the basis for human ability to s represent things symbolically (think of early cave paintings and whether any animal other than humans would “get” them). The empirical evidence for an evolutionary of basis for moral reasoning and judgment remains unclear (Beller, 2010). Some researchers claim that regularities in the way people ignore logical structure and reason in specific content areas (e.g. cheating, incest) show the primacy of evolutionary modules for content-­ specific reasoning (Cosmides & Tooby, 2008; Cushman ro et al., 2006).13 But this claim is disputed by both philosophers (Prinz, 2008) and psychologists (Chater & Oaksford, 1996; Pietraszewski & Wertz, 2021). This is a disagreement about how ought-­based (or deontic) reasoning might have evolved in humans. But it is also a dispute anchored in an agreement that human capabilities for lP deontic reasoning are vastly more complex than that of other animals. 1.5.2 Time Perspective Time perspective underlies the ability to think about the moral consequences of an na action or to make plans to achieve moral goals. In order to support some conception of a past or a future time, or of an alternative present, one must construct a mental representation and distinguish it from one’s own current experience (Higgins & Pittman, 2008). Thus, a conception of time requires the symbolizing abilities ­mentioned in Section 1.5.1. It remains unclear whether any animals other than Fi humans can experience an imagined point of view (Adolphs, 2009) and thus have some sense of time. The sense of the future and past allows humans to construct moral stories about the past and about the future, and compare the self to them (Higgins & Pittman, 2008). This adoption of another point of view than that of immediate consciousness is likely one that underlies the ability to recognize other minds (Adolphs, 2009). 13 For an example of this content-­specific reasoning, see the discussion on moral dumbfounding in Chapter 7. In short, careful experimentation can find instances where people will simply say “I know it is wrong, but I do not know why.” Such moral intuition suggests that these particular moral judgments do not derive from a general reasoning mechanism. But this does not mean that no moral judgments derive from a general reasoning mechanism. Evolution 17 1.5.3 Cognitive Control and Self-­Regulation As we argue in Chapters 6 and 9, self-­regulation is central to moral action. It is ­certainly the case that other animals can exert cognitive control over immediate desire, both to deceive other animals (de Waal, 2006) and in response to training by humans (H. C. Miller et al., 2010). This sort of immediate willpower of response suppression seems to share similar biological substrates in humans and other mammals (e.g. it uses glucose-­based energy: Baumeister, Bratslavsky, Muraven, & Tice, 1998; H. C. Miller et al., 2010). But the extent, complexity, and flexibility of human self-­control mechanisms far outpaces those of other animals (Heatherton, 2011). It extends to what the philosopher Frankfurt (1971) has called “second order desires,” or the desire to have a particular desire and to the planning of outside influences that will help one attain future states (for example, by going to school: Cohen, 2005). It s also requires directed planning and practice to achieve long-­term goals (Baumeister, Masicampo, & Vohs, 2011; Cervone, Shadel, Smith, & Fiori, 2006; Lord, Diefendorff, of Schmidt, & Hall, 2009; McRae, Ochsner, & Gross, 2011). 1.5.4 Extensive Integration of Reason and Emotion ro Moll and colleagues (de Oliveira-­Souza, Zahn, & Moll, 2016; Moll, de ­Oliveira-­Souza, & Eslinger, 2003; Moll, De Oliveira-­Souza, & Zahn, 2009) have hypothesized that the most important thing about human reason may well be its integration with rather than its opposition to emotion.14 Even philosophical champions of reason as a marker lP of human morality (Korsgaard, 2006) have suggested that the integration of reason and emotion is a central puzzle in the evolution of morality (Korsgaard, 2010). It is not simply the addition of rationality to an “emotional animal” that makes humans special and human morality possible. It is the extensive integration of that rationality with emotion that allows them to influence and “tune” each other. Emotions influna ence our implicit and explicit moral reasoning by guiding intuition (Haidt, 2001) and reasoning (Goldin et al., 2008; McRae et al., 2011). And rationality influences emotion through the multifaceted self-­regulation processes mentioned in Section 1.5.3, through the appraisal and re-­appraisal process (Lazarus, 1991; Ochsner et al., 2010), and through the planned construction of culture (Cohen, 2005). Fi 1.5.5 Extensive Culture Humans have complex, stable, and constantly adapting cultural systems with ­enduring artifacts, language, artistic expression, economies, ritual, values, social structures, and extensive bodies of knowledge and practice (McElreath, 2010; Richerson & Boyd, 2005). These cultural achievements are clearly one of the major differences between humans and other animals. There is some evidence for social transmission of information among other primates (Adolphs, 2009) and thus some rudimentary socially shared culture. Understanding the linkages among evolution, neuroscience, and cultural processes will be a crucial undertaking for a complete understanding of moral action (Kitayama, Varnum, & Salvador, 2019; Wright, 2021). 14 We review evidence for this integration in Chapters 2 and 8. Taking Moral Action 1.5.6 Self-­Consciousness and Self-­Awareness The classic experimental demonstration of self-­ consciousness in children and in ­non-­humans is the body awareness test. This involves placing some marker on the body in a place that is difficult to see without a mirror and then measuring the attempts to examine the new decoration. Evidence for such awareness has been found in chimpanzees, bonobos, dolphins, elephants, and monkeys (Adolphs, 2009). This seems adequate to demonstrate body awareness but its evidential status for awareness of one’s own mind is unclear (Adolphs, 2009; Gallup & Anderson, 2020). For ­normally functioning adolescent and adult humans, there is unanimity that a comawareness is present (Byrne & plex, multidimensional, and morally relevant self-­ Whiten, 1988; Robins, 2021). s 1.5.7 Social Consciousness of Dogs and some other domesticated animals, perhaps because they have been shaped by human intervention over many generations, are skilled at interpreting gestures (e.g. pointing) and in responding correctly in the guesser–knower paradigm (in which they must choose a person based on that person’s knowledge of ro where some food is hidden) (Emery & Clayton, 2009). But dogs do not appear to have some basic t­ heory of mind characteristics that human infants share, like preferring helpers over hinderers in an attention task (Hamlin, 2013,; McAuliffe et al., 2019; Van de Vondervoort & Hamlin, 2018). Primates are particularly lP skilled at tracking kinship and dominance relationships over time (Adolphs, 2009). However, if one asks for a full-­fledged human theory of mind in other primates, it appears to be lacking (Emery & Clayton, 2009) – although one can likely find components of it. For example, there is evidence that other primates know that others know something but probably cannot grasp the complexity that the other’s na knowledge may be false (Emery & Clayton, 2009). Waytz and colleagues (Waytz, Cacioppo, & Epley, 2010; Waytz et al., 2010) have shown that humans’ perception of agency (even the anthropomorphic perception of agency in inanimate objects) includes a moral dimension allowing for blame and suggesting that the roots of moral perception go quite deep into basic perception. And though other Fi primates form coalitions (de Waal, 2007) the complexity of human tribalism is much greater (Clark et al., 2019). 1.5.8 Manipulation of Others’ Perception There is evidence that other primates understand and practice deception (Adolphs, 2009; Emery & Clayton, 2009). There is even evidence that crows and other corvids cache food in ways that make it difficult for other crows to find it, but only if other crows who might take it are present (Emery & Clayton, 2009). But again, even in young children, human manipulation of others’ perception is vastly more complex, multidimensional, and subtle (Higgins & Pittman, 2008). Humans are deeply concerned about what others think (Higgins & Pittman, 2008) and particularly what others think about them (Leary, 2007). Evolution 19 1.5.9 Sharing Reality With Other People Humans have a deep need to share their understanding of the world with others (Higgins & Pittman, 2008). All mammals have some abilities at social coordination and signaling (Goetz et al., 2010) and some have components of a theory of mind (Emery & Clayton, 2009). But even human children are competent in communicating shared social knowledge, sharing joint attention, and explicit teaching. Language is a primary achievement of this need (Byrne & Whiten, 1988). 1.5.10 Universalized Normative Evaluations People’s concern about what others think of them has been included in models of the “generalized other” (Heatherton, 2011; Mead & Morris, 1934) as one source of s how humans universalize normative evaluations. The philosopher Korsgaard (2006) argues that this concern is more than simply worrying about how others might think of of us, it involves seeing a moral reason as a reason for behavior, and using that reason to guide planning and action. In short, it involves some version of moral autonomy where the desires associated with moral reason become dominant over other desires or appetites.15 Managing these norms in a society involves a complex cultural process ro of protecting against deviance while promoting diversity (Wright, 2021). Psychologically, these reasons are experienced as “natural law,” as a moral imperative that trumps any social convention or personal preference (Shweder, 2012; Shweder, Mahapatra, & Miller, 1987); and this experience is one of the aspects of human morallP ity that is a cultural universal. Despite clear evidence that other primates have some expectation about the nature of their social world, and show clear distress and attempts at punishment or repair when they are violated, it seems unlikely that one would find evidence for this aspect of moral expectation in non-­human primates (Kitcher, 2006; Korsgaard, 2006). Indeed, it is unclear how one could even collect such evidence. na 1.5.11 Self-­Actualization, Religious Experience, and Self-­Transcendence Although some evolutionary theorists would prefer to dismiss self-­actualization since Fi it is not “clearly linked to reproductive fitness” (Schaller et al., 2010, p. 336), others find it both compatible with evolutionary theory and essential in understanding human experience (Peterson & Park, 2010). Both sides in the controversy agree that they do not expect to find it in other animals. A similar pattern emerges with another human universal: religion (Brown, 1991). Though there is disagreement about the status of religion and its relationship to evolutionary theory (Dawkins, 2006; Kirkpatrick, 1999), any suggestion that one might find something like human religion in other animals is conspicuous by its absence. Self-­transcendence goes beyond the fulfillment of the self, and invests the self in some purpose beyond the self (Maslow, 1969). It seems to be both a natural product of adult development and a 15 Note how desire and reason are integrated in this account. Taking Moral Action process that can lead to extraordinary moral commitment (Walker & Frimer, 2015). This commitment has a dark side, depending in part on the cause one chooses (Koltko-­Rivera, 2006; Skitka & Mullen, 2002). 1.6 Discussion 1.6.1 Conclusion An evolutionary understanding of morality can primarily help us in understanding our capacities for taking moral action. How those capacities are shaped, influenced, and directed is the subject of the other chapters of this book. However, an ­understanding of capacity, its structures, and its limitations can help to articulate the s structure and limits of our morality, help us see how good and evil are linked, and allow us to grasp the precarious human condition that is balanced in the gray zone of between those two: 1. Moral action is deeply tied to the social nature of being human. Much philosophy and psychology have presented morality as the achievement of ro reason and will alone. Evolutionary theory confronts us with how our human morality is deeply rooted in the social nature of our species. The need to negotiate a complex social hierarchy within groups and to compete between groups has produced a set of capacities that we list in Section 1.4. These capacities are densely lP interwoven and help us to see how moral action results from the complex interplay among social emotions, planning, and rationality. Any understanding of morality that does not take this interplay into account will be inadequate. 2. The dark side of morality is, ironically, enabled by our desire to do good. An evolutionary approach to morality also helps us to understand the peculiar dual-­ na sided interaction of morality with social motives and structures. Social status in social hierarchies and in between groups is based in respect but also anger and fear. Cooperation among individuals and groups is based in gratitude and respect but also vicarious anger and indignation. Compassion for others is based in love and empathy but also vicarious anger and revenge against those who hurt loved ones. Fi This complex set of social emotions can be harnessed by our rationality and culture in the service of a range of goals, producing both international aid organizations and organized ethnic cleansing and self-­giving care for a partner and abuse for a partner. In this way, the psychology of being moral is also the psychology of evil. 1.6.2 Application In the Introduction, we presented the story of Rick Munson and his wife.16 The Munsons began by hosting foster children, then went on to host disabled foster children. Eventually, they founded a charitable organization and a facility that provided 16 Rick Munson is a pseudonym for a participant in a study of volunteerism (Hart & Atkins, 2006). The report of the study does not give a pseudonym for his wife, though it makes it clear they made decisions together. Evolution 21 integrated services to children with physical challenges. One can chart this as a move from the pro-­social integration of the two individuals into a committed couple, ­followed by the expression of their concern for others in caring for children, followed by the extension of that concern to community action. Their taking in of foster children already stretches our conception of a narrow evolutionary basis for pro-­social action, as it was likely an extension of the desire to have children to those who were clearly outside their genetic family. But their actions were surely due to a capacity for compassion that is a part of their evolutionary heritage and was shaped and supported by their religious culture. It was also made possible by an organized cultural practice of finding homes for children without any. The empathy the Munsons had for other disabled children and their parents and the couple’s capacity for planning and ­rationality led them to a more general community concern, which was expressed by volunteering in charitable organizations. This in turn lead to their founding of organs izations to meet community needs. One can see in this example the integration of evolutionarily shaped emotional and of rational capacities with culturally constructed social structures to produce good. This provides an example of the fit of these capacities (rationality, planning, compassion, empathy) to the local ecology in which the Munsons were embedded. But it is also an example of the shaping of those capacities by the wider moral ecology (e.g. religious ro practice) and the local ecology (the lack of integrated service for disabled children and the practice of founding organizations to meet needs). An understanding of the evolutionary basis of morality will require this sort of complexity. lP 1.6.3 Open Questions 1. We have an excellent beginning of a model of the evolution of morality and a long way to go in developing it. The review of building blocks (Section 1.4) suggests that we are beginning to na accumulate an evidential network of the underpinning of the moral ability in humans. But a comparison of the standards for making an evolutionary argument (Section 1.3) with the evidence for each building block suggests we still have a long way to go to fill in the argument. 2. There is a significant collection of capacities that underlie moral action for which we Fi so far have no viable evolutionary explanations. Section"
1,1.5,"Human Distinctiveness: How Large is the Gap? We have spent most of this chapter looking at the processes of evolution and the building blocks of human morality. The goal has been to see how we can ground ro human morality in, or derive it from, various aspects of the capacities and behavior of our ancestors. An older version of this approach, disparagingly called “veneer theory” by de Waal (2006), proposes that humans have only a veneer of politeness and hypocrisy overlaying the motivation of brute selfishness. Higgins and Pittman (2008) lP ­suggest that this version of human moral evolution is mirrored in the historical split in evolutionary approaches in different sub-­fields of psychology. In cognition, we are said to have “developed from” prior species, while in motivation, we have been presented as merely “deriving” our animal motivations from prior species. This results in an image, they claim, of “humans as having the mind of a god and the motives of a na brute” (Higgins & Pittman, 2008, p. 363). In the realm of morality, this image of the supremacy of reason is aided and abetted by philosophical approaches to ethics (e.g. Kant, 1999; Rawls, 1971/1999) that portray reason as both the foundation and the limit of real (that is, human) morality. But current approaches to human morality that we review in this book suggest Fi that: (1) human morality is constituted of more complex stuff than pure reason; and (2) the differences with other animals and our primate ancestors lie in a range of ­distinctly human abilities and motivations (Higgins & Pittman, 2008) and not just differences in reason alone. There is unanimity in recognizing that there are deep differences between humans and other animals in morality but the nature, structure, and meaning of those differences is still in dispute.12 12 Some claims might underestimate these differences (Adolphs, 2009) in the way veneer theory does. Other claims may underestimate the unique abilities of other animals by making human morality the criterion, and missing uniquely adapted, species-­specific capacities of other animals (Emery & Clayton, 2009). Crows, for example, do not have a full-­blown theory of mind like humans, but they are remarkably good at hiding food from other crows (Emery & Clayton, 2009). De Waal (2006, 2009), Emery and Clayton (2009), and Adolphs (2009) provide some insight into the debates about these differences. Taking Moral Action The dimensions associated with morality on which humans differ from other ­animals include at least the eleven categories noted in Sections 1.5.1–1.5.11. We have constructed this incomplete list from the literature in evolutionary psychology. The effort to build coherent networks of evidence for the origins of human ability in each of these categories may, of course, suggest additional categories or the merging of some. The list makes it clear that we are, indeed, at the very beginning of an evolutionary understanding of the structure and development of a truly human morality. 1.5.1 Symbolizing and Reasoning The beginning of the ability to reason lies, perhaps, in the ability to take any particular representation of an object and link it arbitrarily to some other mental representation, e.g. a poem is like a tree (Tse, 2008). This may provide the basis for human ability to s represent things symbolically (think of early cave paintings and whether any animal other than humans would “get” them). The empirical evidence for an evolutionary of basis for moral reasoning and judgment remains unclear (Beller, 2010). Some researchers claim that regularities in the way people ignore logical structure and reason in specific content areas (e.g. cheating, incest) show the primacy of evolutionary modules for content-­ specific reasoning (Cosmides & Tooby, 2008; Cushman ro et al., 2006).13 But this claim is disputed by both philosophers (Prinz, 2008) and psychologists (Chater & Oaksford, 1996; Pietraszewski & Wertz, 2021). This is a disagreement about how ought-­based (or deontic) reasoning might have evolved in humans. But it is also a dispute anchored in an agreement that human capabilities for lP deontic reasoning are vastly more complex than that of other animals. 1.5.2 Time Perspective Time perspective underlies the ability to think about the moral consequences of an na action or to make plans to achieve moral goals. In order to support some conception of a past or a future time, or of an alternative present, one must construct a mental representation and distinguish it from one’s own current experience (Higgins & Pittman, 2008). Thus, a conception of time requires the symbolizing abilities ­mentioned in Section 1.5.1. It remains unclear whether any animals other than Fi humans can experience an imagined point of view (Adolphs, 2009) and thus have some sense of time. The sense of the future and past allows humans to construct moral stories about the past and about the future, and compare the self to them (Higgins & Pittman, 2008). This adoption of another point of view than that of immediate consciousness is likely one that underlies the ability to recognize other minds (Adolphs, 2009). 13 For an example of this content-­specific reasoning, see the discussion on moral dumbfounding in Chapter 7. In short, careful experimentation can find instances where people will simply say “I know it is wrong, but I do not know why.” Such moral intuition suggests that these particular moral judgments do not derive from a general reasoning mechanism. But this does not mean that no moral judgments derive from a general reasoning mechanism. Evolution 17 1.5.3 Cognitive Control and Self-­Regulation As we argue in Chapters 6 and 9, self-­regulation is central to moral action. It is ­certainly the case that other animals can exert cognitive control over immediate desire, both to deceive other animals (de Waal, 2006) and in response to training by humans (H. C. Miller et al., 2010). This sort of immediate willpower of response suppression seems to share similar biological substrates in humans and other mammals (e.g. it uses glucose-­based energy: Baumeister, Bratslavsky, Muraven, & Tice, 1998; H. C. Miller et al., 2010). But the extent, complexity, and flexibility of human self-­control mechanisms far outpaces those of other animals (Heatherton, 2011). It extends to what the philosopher Frankfurt (1971) has called “second order desires,” or the desire to have a particular desire and to the planning of outside influences that will help one attain future states (for example, by going to school: Cohen, 2005). It s also requires directed planning and practice to achieve long-­term goals (Baumeister, Masicampo, & Vohs, 2011; Cervone, Shadel, Smith, & Fiori, 2006; Lord, Diefendorff, of Schmidt, & Hall, 2009; McRae, Ochsner, & Gross, 2011). 1.5.4 Extensive Integration of Reason and Emotion ro Moll and colleagues (de Oliveira-­Souza, Zahn, & Moll, 2016; Moll, de ­Oliveira-­Souza, & Eslinger, 2003; Moll, De Oliveira-­Souza, & Zahn, 2009) have hypothesized that the most important thing about human reason may well be its integration with rather than its opposition to emotion.14 Even philosophical champions of reason as a marker lP of human morality (Korsgaard, 2006) have suggested that the integration of reason and emotion is a central puzzle in the evolution of morality (Korsgaard, 2010). It is not simply the addition of rationality to an “emotional animal” that makes humans special and human morality possible. It is the extensive integration of that rationality with emotion that allows them to influence and “tune” each other. Emotions influna ence our implicit and explicit moral reasoning by guiding intuition (Haidt, 2001) and reasoning (Goldin et al., 2008; McRae et al., 2011). And rationality influences emotion through the multifaceted self-­regulation processes mentioned in Section 1.5.3, through the appraisal and re-­appraisal process (Lazarus, 1991; Ochsner et al., 2010), and through the planned construction of culture (Cohen, 2005). Fi 1.5.5 Extensive Culture Humans have complex, stable, and constantly adapting cultural systems with ­enduring artifacts, language, artistic expression, economies, ritual, values, social structures, and extensive bodies of knowledge and practice (McElreath, 2010; Richerson & Boyd, 2005). These cultural achievements are clearly one of the major differences between humans and other animals. There is some evidence for social transmission of information among other primates (Adolphs, 2009) and thus some rudimentary socially shared culture. Understanding the linkages among evolution, neuroscience, and cultural processes will be a crucial undertaking for a complete understanding of moral action (Kitayama, Varnum, & Salvador, 2019; Wright, 2021). 14 We review evidence for this integration in Chapters 2 and 8. Taking Moral Action 1.5.6 Self-­Consciousness and Self-­Awareness The classic experimental demonstration of self-­ consciousness in children and in ­non-­humans is the body awareness test. This involves placing some marker on the body in a place that is difficult to see without a mirror and then measuring the attempts to examine the new decoration. Evidence for such awareness has been found in chimpanzees, bonobos, dolphins, elephants, and monkeys (Adolphs, 2009). This seems adequate to demonstrate body awareness but its evidential status for awareness of one’s own mind is unclear (Adolphs, 2009; Gallup & Anderson, 2020). For ­normally functioning adolescent and adult humans, there is unanimity that a comawareness is present (Byrne & plex, multidimensional, and morally relevant self-­ Whiten, 1988; Robins, 2021). s 1.5.7 Social Consciousness of Dogs and some other domesticated animals, perhaps because they have been shaped by human intervention over many generations, are skilled at interpreting gestures (e.g. pointing) and in responding correctly in the guesser–knower paradigm (in which they must choose a person based on that person’s knowledge of ro where some food is hidden) (Emery & Clayton, 2009). But dogs do not appear to have some basic t­ heory of mind characteristics that human infants share, like preferring helpers over hinderers in an attention task (Hamlin, 2013,; McAuliffe et al., 2019; Van de Vondervoort & Hamlin, 2018). Primates are particularly lP skilled at tracking kinship and dominance relationships over time (Adolphs, 2009). However, if one asks for a full-­fledged human theory of mind in other primates, it appears to be lacking (Emery & Clayton, 2009) – although one can likely find components of it. For example, there is evidence that other primates know that others know something but probably cannot grasp the complexity that the other’s na knowledge may be false (Emery & Clayton, 2009). Waytz and colleagues (Waytz, Cacioppo, & Epley, 2010; Waytz et al., 2010) have shown that humans’ perception of agency (even the anthropomorphic perception of agency in inanimate objects) includes a moral dimension allowing for blame and suggesting that the roots of moral perception go quite deep into basic perception. And though other Fi primates form coalitions (de Waal, 2007) the complexity of human tribalism is much greater (Clark et al., 2019). 1.5.8 Manipulation of Others’ Perception There is evidence that other primates understand and practice deception (Adolphs, 2009; Emery & Clayton, 2009). There is even evidence that crows and other corvids cache food in ways that make it difficult for other crows to find it, but only if other crows who might take it are present (Emery & Clayton, 2009). But again, even in young children, human manipulation of others’ perception is vastly more complex, multidimensional, and subtle (Higgins & Pittman, 2008). Humans are deeply concerned about what others think (Higgins & Pittman, 2008) and particularly what others think about them (Leary, 2007). Evolution 19 1.5.9 Sharing Reality With Other People Humans have a deep need to share their understanding of the world with others (Higgins & Pittman, 2008). All mammals have some abilities at social coordination and signaling (Goetz et al., 2010) and some have components of a theory of mind (Emery & Clayton, 2009). But even human children are competent in communicating shared social knowledge, sharing joint attention, and explicit teaching. Language is a primary achievement of this need (Byrne & Whiten, 1988). 1.5.10 Universalized Normative Evaluations People’s concern about what others think of them has been included in models of the “generalized other” (Heatherton, 2011; Mead & Morris, 1934) as one source of s how humans universalize normative evaluations. The philosopher Korsgaard (2006) argues that this concern is more than simply worrying about how others might think of of us, it involves seeing a moral reason as a reason for behavior, and using that reason to guide planning and action. In short, it involves some version of moral autonomy where the desires associated with moral reason become dominant over other desires or appetites.15 Managing these norms in a society involves a complex cultural process ro of protecting against deviance while promoting diversity (Wright, 2021). Psychologically, these reasons are experienced as “natural law,” as a moral imperative that trumps any social convention or personal preference (Shweder, 2012; Shweder, Mahapatra, & Miller, 1987); and this experience is one of the aspects of human morallP ity that is a cultural universal. Despite clear evidence that other primates have some expectation about the nature of their social world, and show clear distress and attempts at punishment or repair when they are violated, it seems unlikely that one would find evidence for this aspect of moral expectation in non-­human primates (Kitcher, 2006; Korsgaard, 2006). Indeed, it is unclear how one could even collect such evidence. na 1.5.11 Self-­Actualization, Religious Experience, and Self-­Transcendence Although some evolutionary theorists would prefer to dismiss self-­actualization since Fi it is not “clearly linked to reproductive fitness” (Schaller et al., 2010, p. 336), others find it both compatible with evolutionary theory and essential in understanding human experience (Peterson & Park, 2010). Both sides in the controversy agree that they do not expect to find it in other animals. A similar pattern emerges with another human universal: religion (Brown, 1991). Though there is disagreement about the status of religion and its relationship to evolutionary theory (Dawkins, 2006; Kirkpatrick, 1999), any suggestion that one might find something like human religion in other animals is conspicuous by its absence. Self-­transcendence goes beyond the fulfillment of the self, and invests the self in some purpose beyond the self (Maslow, 1969). It seems to be both a natural product of adult development and a 15 Note how desire and reason are integrated in this account. Taking Moral Action process that can lead to extraordinary moral commitment (Walker & Frimer, 2015). This commitment has a dark side, depending in part on the cause one chooses (Koltko-­Rivera, 2006; Skitka & Mullen, 2002). 1.6 Discussion 1.6.1 Conclusion An evolutionary understanding of morality can primarily help us in understanding our capacities for taking moral action. How those capacities are shaped, influenced, and directed is the subject of the other chapters of this book. However, an ­understanding of capacity, its structures, and its limitations can help to articulate the s structure and limits of our morality, help us see how good and evil are linked, and allow us to grasp the precarious human condition that is balanced in the gray zone of between those two: 1. Moral action is deeply tied to the social nature of being human. Much philosophy and psychology have presented morality as the achievement of ro reason and will alone. Evolutionary theory confronts us with how our human morality is deeply rooted in the social nature of our species. The need to negotiate a complex social hierarchy within groups and to compete between groups has produced a set of capacities that we list in Section 1.4. These capacities are densely lP interwoven and help us to see how moral action results from the complex interplay among social emotions, planning, and rationality. Any understanding of morality that does not take this interplay into account will be inadequate. 2. The dark side of morality is, ironically, enabled by our desire to do good. An evolutionary approach to morality also helps us to understand the peculiar dual-­ na sided interaction of morality with social motives and structures. Social status in social hierarchies and in between groups is based in respect but also anger and fear. Cooperation among individuals and groups is based in gratitude and respect but also vicarious anger and indignation. Compassion for others is based in love and empathy but also vicarious anger and revenge against those who hurt loved ones. Fi This complex set of social emotions can be harnessed by our rationality and culture in the service of a range of goals, producing both international aid organizations and organized ethnic cleansing and self-­giving care for a partner and abuse for a partner. In this way, the psychology of being moral is also the psychology of evil. 1.6.2 Application In the Introduction, we presented the story of Rick Munson and his wife.16 The Munsons began by hosting foster children, then went on to host disabled foster children. Eventually, they founded a charitable organization and a facility that provided 16 Rick Munson is a pseudonym for a participant in a study of volunteerism (Hart & Atkins, 2006). The report of the study does not give a pseudonym for his wife, though it makes it clear they made decisions together. Evolution 21 integrated services to children with physical challenges. One can chart this as a move from the pro-­social integration of the two individuals into a committed couple, ­followed by the expression of their concern for others in caring for children, followed by the extension of that concern to community action. Their taking in of foster children already stretches our conception of a narrow evolutionary basis for pro-­social action, as it was likely an extension of the desire to have children to those who were clearly outside their genetic family. But their actions were surely due to a capacity for compassion that is a part of their evolutionary heritage and was shaped and supported by their religious culture. It was also made possible by an organized cultural practice of finding homes for children without any. The empathy the Munsons had for other disabled children and their parents and the couple’s capacity for planning and ­rationality led them to a more general community concern, which was expressed by volunteering in charitable organizations. This in turn lead to their founding of organs izations to meet community needs. One can see in this example the integration of evolutionarily shaped emotional and of rational capacities with culturally constructed social structures to produce good. This provides an example of the fit of these capacities (rationality, planning, compassion, empathy) to the local ecology in which the Munsons were embedded. But it is also an example of the shaping of those capacities by the wider moral ecology (e.g. religious ro practice) and the local ecology (the lack of integrated service for disabled children and the practice of founding organizations to meet needs). An understanding of the evolutionary basis of morality will require this sort of complexity. lP"
1,1.6,"Discussion 1.6.1 Conclusion An evolutionary understanding of morality can primarily help us in understanding our capacities for taking moral action. How those capacities are shaped, influenced, and directed is the subject of the other chapters of this book. However, an ­understanding of capacity, its structures, and its limitations can help to articulate the s structure and limits of our morality, help us see how good and evil are linked, and allow us to grasp the precarious human condition that is balanced in the gray zone of between those two: 1. Moral action is deeply tied to the social nature of being human. Much philosophy and psychology have presented morality as the achievement of ro reason and will alone. Evolutionary theory confronts us with how our human morality is deeply rooted in the social nature of our species. The need to negotiate a complex social hierarchy within groups and to compete between groups has produced a set of capacities that we list in Section 1.4. These capacities are densely lP interwoven and help us to see how moral action results from the complex interplay among social emotions, planning, and rationality. Any understanding of morality that does not take this interplay into account will be inadequate. 2. The dark side of morality is, ironically, enabled by our desire to do good. An evolutionary approach to morality also helps us to understand the peculiar dual-­ na sided interaction of morality with social motives and structures. Social status in social hierarchies and in between groups is based in respect but also anger and fear. Cooperation among individuals and groups is based in gratitude and respect but also vicarious anger and indignation. Compassion for others is based in love and empathy but also vicarious anger and revenge against those who hurt loved ones. Fi This complex set of social emotions can be harnessed by our rationality and culture in the service of a range of goals, producing both international aid organizations and organized ethnic cleansing and self-­giving care for a partner and abuse for a partner. In this way, the psychology of being moral is also the psychology of evil. 1.6.2 Application In the Introduction, we presented the story of Rick Munson and his wife.16 The Munsons began by hosting foster children, then went on to host disabled foster children. Eventually, they founded a charitable organization and a facility that provided 16 Rick Munson is a pseudonym for a participant in a study of volunteerism (Hart & Atkins, 2006). The report of the study does not give a pseudonym for his wife, though it makes it clear they made decisions together. Evolution 21 integrated services to children with physical challenges. One can chart this as a move from the pro-­social integration of the two individuals into a committed couple, ­followed by the expression of their concern for others in caring for children, followed by the extension of that concern to community action. Their taking in of foster children already stretches our conception of a narrow evolutionary basis for pro-­social action, as it was likely an extension of the desire to have children to those who were clearly outside their genetic family. But their actions were surely due to a capacity for compassion that is a part of their evolutionary heritage and was shaped and supported by their religious culture. It was also made possible by an organized cultural practice of finding homes for children without any. The empathy the Munsons had for other disabled children and their parents and the couple’s capacity for planning and ­rationality led them to a more general community concern, which was expressed by volunteering in charitable organizations. This in turn lead to their founding of organs izations to meet community needs. One can see in this example the integration of evolutionarily shaped emotional and of rational capacities with culturally constructed social structures to produce good. This provides an example of the fit of these capacities (rationality, planning, compassion, empathy) to the local ecology in which the Munsons were embedded. But it is also an example of the shaping of those capacities by the wider moral ecology (e.g. religious ro practice) and the local ecology (the lack of integrated service for disabled children and the practice of founding organizations to meet needs). An understanding of the evolutionary basis of morality will require this sort of complexity. lP 1.6.3 Open Questions 1. We have an excellent beginning of a model of the evolution of morality and a long way to go in developing it. The review of building blocks (Section 1.4) suggests that we are beginning to na accumulate an evidential network of the underpinning of the moral ability in humans. But a comparison of the standards for making an evolutionary argument (Section 1.3) with the evidence for each building block suggests we still have a long way to go to fill in the argument. 2. There is a significant collection of capacities that underlie moral action for which we Fi so far have no viable evolutionary explanations. Section 1.5 gives a list of eleven areas in which there is an easily discernable distinction between the moral capacities of humans and other animals. There is clearly a vast field of opportunity for good research and theory here. But doing this work will require changing the way the question is asked. Instead of asking whether humans are different from other animals in their morality, we should begin asking how they are different, and how those differences have come about. It is some combination of these morally relevant differences in how that differentiates human morality from what might be called the proto-­morality of other species. 3. Exploring the fit of the evolved moral capacities of humans with their social and physical ecology will provide for a more complete evolutionary understanding of human morality. A central mistake in work on theory of mind is the tendency to measure other animals by their differences from human theory of mind, rather than by the Taking Moral Action ecologically valid fit of the abilities of the particular species with that species’ social and physical ecology. The field of moral psychology should take a clue from this ­mistake and insist on an ecologically valid explanation of human morality. Thus, rather than simply looking for universals, we should look for a more complete understanding of human morality in the fit of the moral capacities of humans with their varied social and physical ecologies. This will necessarily include an evolutionary perspective, but is unlikely to be reducible to only that perspective. 4. The evolution of morality and immorality are closely linked and interdependent. Neither morality nor immorality is more “basic.” Aggression against outsiders and norm-­violators is integral to our understanding of how moral commitment to a group evolved. We can regulate this, and even balance it with compassion, but altruistic punishment based in revenge motives will likely remain central to doing so. Empirical and theoretical work might help us find ways to motivate pro-­social s behavior and discourage anti-­social behavior that work within the limits of our evolutionary heritage and are still acceptable to ethical norms."
1,1.7,"Further Readings of ro These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. lP • Aktipis and Kurzban (2004). “Is Homo economicus extinct? Vernon Smith, Daniel Kahneman and the Evolutionary Perspective.” An historical overview of the idea of the selfish “economic human” and its diminishing psychological appeal in the face of a wave of research suggesting its falsity (or at least incompleteness). • Curry et al. (2019). “Is it good to cooperate?” An excellent example of cross-­ na cultural work to establish an evolutionary basis for morality. • de Waal (2008). “Putting the altruism back into altruism: The evolution of empathy.” Primatologist Franz de Waal provides a useful presentation of the evidence for the evolution of empathy and its role in altruism. • Gallup and Anderson (2020). “Self-­Recognition in animals.” A review of a half-­ Fi century of research on animal consciousness that argues that the gap between great apes/humans and other species is larger than usually acknowledged. • Krebs (2008). “Morality: An evolutionary account.” A thoughtful presentation of the main issues in an evolutionary account of human morality. • Schmitt and Pilcher (2004). “Evaluating evidence of psychological adaptation: How do we know one when we see one?” A readable and systematic overview of what it means to say that some psychological characteristic is an evolutionary adaptation. • Sober (2006) Conceptual Issues in Evolutionary Biology (3rd ed.). Excellent volume edited by a philosopher deeply involved in the evolutionary debates within the biological disciplines. Every chapter is an example of how to think carefully about evolution. Essays on what fitness means, levels of selection, race, culture, ethics, etc. Evolution 23"
2,2.1,"Neural Systems and Moral Function, or How to use Neuroscience This chapter is an attempt to draw some lessons from neuroscience about how human morality functions. If we want to use neuroscience to understand moral psychology, we need two things: (1) good psychological theory and data about aspects of the processes themselves; and (2) good neuroscientific models and data about the locations and interconnections of the systems that support them (Kihlstrom, 2007). These two sources can work interactively to help us construct an increasingly better picture of the biological, psychological, social, and cultural processes that constitute our morality. In this collaboration, it is the psychological theory that describes what we (think we) know about the function, and the neuroscience that maps the location s and interconnections of the neural systems supporting that function in the brain.2 In turn, understanding which locations and interconnections (that is, which systems) are active in supporting that function, over the time process of the function, can help us of make better inferences about that function.3 For instance, one might ask what moral functions the amygdala serves; we ask rather what neural systems are involved in showing empathy. Thus, we begin with the ro psychological function (e.g. empathy) and move to the neuroscience (e.g. a shifting system of locations that often but not always includes the amygdala, over the varied time processes and varied experiences,4 and how those systems work in synchrony with systems in other people’s brains). This frees us from thinking that any single lP location (or even regular set of locations) is “the place” where that function occurs. We still cite work that implicates particular locations since those offer clues to the system(s), their interconnections, and the unfolding of the process over time. For instance, Lebois et al. (2020) have shown that different neural systems with only mild overlap (as little as 11.5%) are responsible for social-­exclusion fear vs. physical-­harm fear and social-­exclusion anger vs. physical-­harm anger. The psychona logical theory (see Chapter 8) is that these are situated forms of anger and fear, and 2 Kihlstrom (2007) gives a good example of this with the saga of the famous H. M. As psychological theory progressed, the explanation for H. M.’s symptoms changed over Fi several decades: from (1) learning capacity loss; to (2) long-­but not short-­term memory loss; to (3) deep but not shallow processing loss; to (4) declarative but not procedural memory loss; then most recently to (5) relational but not non-­relational memory loss. Almost all this change in the description of the function of the Hippocampus and amygdala was driven by psychological and not neuroscientific research. Thus, the attributed functions of the areas changed, not because of advances or new findings in neuroscience, but because of our changing understanding of the functions. 3 Most reviews of the neural substrates of morality are organized based on the neural structures themselves (Casebeer, 2003; Greene & Haidt, 2002; Mendez, 2009; Moll, de Oliveira-­Souza, & Eslinger, 2003; Moll et al., 2009). One can find a few reviews of moral neuroscience organized, like ours, on function (Barrett, 2017; de Oliveira-­Souza, Zahn, & Moll, 2016; Narvaez, 2008; Narvaez & Vaydich, 2008). 4 Remembering that the experience we designate with a single word (empathy, anger, fear) is really a family of experiences – there is fear of physical danger and fear of social negative evaluation (Lebois et al., 2020) and they look quite different in their neuroscientific embodiment. Neuroscience 31 that the differences in the neurological underpinning are driven by the meaning of the situation that drives the type of fear or anger. So here, it seems that meaning is shaping or structuring (or even constructing) the neural system that underpins the specific emotion. This is a move away from simple mental categories and toward how they are embedded in particular situations and complex behaviors (Pessoa, 2022; Pessoa, Medina, & Desfilis, 2022). Thus, we need to take a moment for a note on philosophy of science before beginning our survey. Too often those who review the neuroscience of morality (or of anything, really) see neuroscience as a talisman of truth. We are all taught that correlation does not imply causation, and then promptly forget it when looking at hot spots on an fMRI (functional magnetic resonance imaging) brain scan.5 We attempt to be careful with causal language in this chapter (and indeed in all chapters). Neuroscience is amazingly useful in both science and technology, but we too often s (1) see the neural structures and processes as the “real” structures and processes; and (2) see the psychology (and anthropology, and philosophy, and religion) as things of that can be reduced to the neuroscience. These two mistakes have been termed neuro-­realism and neuro-­essentialism (Racine et al., 2005). This involves making philosophical assumptions (e.g. only one level of explanation is “real”) that are often unspoken and undefended. The current state of the field does not really support any ro simple version of reduction of mind to brain. Thus, rather than saying the physiology causes the psychological function, we prefer to speak of it underlying, supporting, or embodying the function.6 One final and related point: any search for a “moral center” that is said to “ ­ control” lP some function of the brain disregards the massive interactivity of all the various brain structures (Pessoa, 2008, 2009; Sinnott-­Armstrong, 2016) and the likely distribution of any function across many parts of the brain. Consider the career of the hormone/ neurotransmitter oxytocin. Once talked of as the “love hormone” its effects have become clouded by reports that it has contradictory effects, sometimes affiliative and na sometimes antisocial (Alvarez, Quintana, & Whitehouse, 2016). This puzzle is beginning to be resolved by the work that shows that psychological systems condition its effects. For instance, individuals with insecure attachments in childhood can respond to oxytocin increases with antisocial behavior, perhaps because of the fear that affiliation engenders in them (Bartz, 2016; Bartz et al., 2015). Mierop et al. (2020, Fi p. 1228) in reviewing the field, suggest that it is still “virtually impossible” to know which of these effects are replicable at this point. So, now we turn to a review of various aspects of, contexts for, influences on, and processes of moral action as represented by the chapters of this text. 5 The methodological issues associated with analysis and interpretation of fMRI data are legion (for examples of these difficulties, see Poldrack & Mumford, 2009; Racine, ­Bar-­Ilan, & Illes, 2005; Vul et al., 2009). Postle (2016) suggests that increased activity in an area may not be diagnostic of the use of information associated with that area (e.g. emotional or relational information) and Elliot et al. (2020) provide meta-­analytic evidence that test–retest reliabilities are far too low to support the prediction of clinical outcomes. 6 See Brigandt and Love (2017) for a further philosophical explanation of reductionism and some of its alternatives and (Barrett, 2017) for a complex version of determinism that is not reductionist. Taking Moral Action 2.2 Moral Ecology In an article on the emerging field of cultural neuroscience, Ambady and Bharucha (2009) called the brain “the organ of culture.” The brain is indeed at least one place where the patterns and influences of our social surround encounter the patterns and proclivities of our inner life. To be embodied in the individuals who make up a moral ecology, the social complexities we describe in Chapter 3 still need to be channeled through those people. This channeling is done by processes of imitation, social influence, and social cognition, and is supported by a network of interacting brain processes (and interacting brains) that neuroscientists are only beginning to map. In this section, we will review a subset of what we know about how moral ecology influences individuals through imitation, social cognition, and social influence. s 2.2.1 Imitation and Mirror Neurons of Humans have a ubiquitous tendency to imitate one another. We align our behavior with others in both literal (e.g. posture, speech) and symbolic (e.g. stereotype-­based) ways, and do so unintentionally, even without conscious awareness (Iacoboni, 2009). ro This is a very basic and pervasive form of social influence. It is supported by a complex network of action perception and interpretation that involve one of the most fashionable topics in neuroscience: mirror neurons. These are neurons that are part of the sequence involved in controlling motor movement for the macaque monkeys in the original study (moving the hand to the mouth to eat) but that were also found to lP activate when the monkey watched the experimenter perform the same action (di Pellegrino et al., 1992). Thus, they “mirrored” the perceived activity in a section of the brain devoted to physically performing the activity. Accumulated research in humans since this initial finding now shows that there is a section of the superior temporal sulcus that processes intentional movement in others and that connects to na two separate areas of mirror neurons, one that represents the motor aspects of the movement (parietal mirror neuron area) and one that represents the goal aspects of the movement (frontal lobe mirror neurons) (Iacoboni, 2009). It seems clear at this point that mirror neuron brain areas contribute to imitative action (e.g. copying body movement) but not directly to higher level processes like inferring intentions Fi (Campbell & Cunnington, 2017; Grigaityte & Iacoboni, 2016; Heyes & Catmur, 2022). Tracking how mirror neurons are integrated into larger systems is work that remains to be done. 2.2.2 Thinking About, and With, Others One of the central psychological processes that underlies social influence is our ability to think about others, to take their perspective, and to recognize that they are judging us. This ability requires representing the mental states of others. Again, we find that the medial prefrontal cortex (mPFC) is involved in this, the same structure that is centrally involved in processing information about the self (Heatherton, 2011). There seems to be specialization within the mPFC, with other-­mind processing areas toward the dorsal (top) side of the mPFC and self-­processing areas toward the ventral (bottom) side. Interestingly, there are some clues that the processing may differ for Neuroscience 33 in-­group and out-­group members, with activation reported in both the self-­processing and other-­ processing areas for people who are considered similar to the self (Heatherton, 2011). Others also influence us because we are concerned about judgments they might make about us. This awareness of other people can be threatening and emotional, and thus – in addition to mPFC – the awareness of threat from others involves areas that modulate and tune emotional expression. We have covered this social threat detection in Section 2.4 and processes of empathy in Section 2.8. In a significant advance in theory and method, Tamir and Thornton (2018) have paired advanced techniques in neuroscience imaging with a dimensional model of social perception that looks at three levels of social perception:7 perception of character traits of the other, perception of the current state of the other, and evaluations of the actions of the other. This is a complex and promising model of how social infers ence plays out at the neural level. It is another example of the massive interactivity evident at both the psychological and neural levels. of 2.2.3 Cultural, Group, and Individual Influence on Brain Processes We have already seen that psychological characteristics can modify the way the brain ro processes information.8 The mPFC in individuals with low self-­ esteem processes information about others differently and information about out-­groups is processed differently than information about in-­groups (Heatherton, 2011; Kitayama, Varnum, & Salvador, 2019; Somerville, Heatherton, & Kelley, 2006). The extent to which a lP culture is tight (vs. loose9) is associated with more reactivity in brain areas linked with norm violation detection (Kitayama et al., 2019). There also seems to be evidence that the neuroanatomy associated with thinking about the self is different in different cultures (Kitayama et al., 2019). Zhu et al. (2007) have shown differences in Chinese and Western college students’ neural representations of self and mother.10 As menna tioned before, mPFC is associated in Western studies with active representation of the self, but in this study Chinese students’ active representations of their mothers also showed significant activity in mPFC (among other cultural differences in processing). Thus, the functions associated with particular areas of the cortex (the functional anatomy) differ in these samples, based on culture. For Chinese people, there is “neural Fi unification” of the self and the mother, while for Westerners there is “neural separation” (Zhu et al., 2007, pp. 1314–1315). Western culture is, on average, much more 7 They use representational similarity analysis in fMRI. This advanced analytic approach allows comparison of the similarity of reaction in entire neural systems across people who have been shown similar stimuli. With carefully chosen stimuli, this allows one to see ­ similarities in neural response patterns that represent the psychological dimension (e.g. perceptions of social power). 8 This should only be surprising to those who see neural events as the single “real” level of explanation (see neuro-­essentialism in Section 2.1). 9 The extent to which a culture requires close observance of morals and customs or allows a looser relationship to them. See Chapter 9, Section 9.3.1.3. 10 These studies are done by looking for brain areas that are activated when people are asked to think about themselves, about their mother, about important others, etc. Taking Moral Action individualistic than Chinese culture, which tends to see others as forming a very close bond with the self. Thus, the “neural unification” of an important other suggests a cultural influence on functional neuroanatomy. This effect is complicated when one looks at Chinese people with significant exposure to Western, individualistic culture (Kitayama et al., 2019) 2.2.4 Interpersonal Neuroscience It is now possible to track how two or more brains show synchrony in patterns of activity, opening the possibly of a truly interpersonal neuroscience (Pan, Novembre, & Olsson, 2021).11 This brain-­to-­brain synchrony (BB synchrony) has been shown to strongly correlate with social learning in dyads and even at the classroom level (Pan et al., 2021). Facial, voice, and movement cues seem foundational in this process of s establishing synchrony, and synchrony occurs at behavioral, affective, perceptual, and neural levels (e.g. emotional contagion is associated with neural synchrony or entrainof ment) (Wheatley et al., 2011). BB synchrony, but not self-­reported group identification, has been shown to predict team performance in both an economic game and problem-­solving tasks. Basso, Satyal, and Rugh (2020) collate evidence suggesting that BB synchrony is important in shared dance, helping to explain the social synchroro nizing function of shared dance and movement (e.g. ritual, folk dance, etc.) across cultures. lP 2.2.5 The Mutual Constitution of Brain and Cultural Processes Kitayama et al. (2019, p. 80), in a review of cultural neuroscience, collate the empirical evidence for a claim long dominant in cultural anthropology. Their summary of the claim is worth quoting at some length: na the body (and now the brain as well) is closely attuned to the sociocultural environment, while at the same time … autonomous, thereby constituting agency, being capable of producing volitional actions, which can lead to changes in the environment from which the agency has been derived. This circular or recursive process occurs continuously, not only in each person’s lifetime but also across generations, … giving rise to changes in both historical and Fi evolutionary timescales. [emphasis ours] The central point here is the close attunement and mutual influence of brain–body systems and cultural systems. Cultural systems both resist change and provide resources for individuals and groups to produce change. Individuals can both resist and seek individual change using resources available to them from culture. Each one influences and structures the other over both short and long timescales. 11 The methods for tracking synchrony involve some measurement of activity, e.g. electroencephalogram (EEG) or fMRI or functional near-­infrared spectroscopy (fNIRS, a less invasive approach in which the subject wears a cap that tracks brain activity in a similar, but less detailed, way to fMRI). Mathematical models are then used to highlight parallelism in activity between two or more brains in people who are interacting. Neuroscience 35 In summary, we can see that social influence and moral ecology are attuned to brain processes and systems at many different levels. This ranges from low-­level mirroring of motor action, to the mirroring of feeling states, to fears of social sanction from others and cognition about others to synchronization of movement, affect, and intention. This attunement to moral ecology provides the support and channel for effective volitional action within that moral ecology. 2.3 Personality The attempt to connect personality to physiological processes is as old as the classical Greek theories of the humors (Zuckerman, 1995). The human body was thought to contain four kinds of humors (fluids) and various personality traits (e.g. melancholy) s were thought to be associated with imbalances in these humors. But it is only with the recent, rapid development of neuroscience measurement techniques that we have of been able to make some empirical progress in actually evaluating proposed theoretical connections. We call the enduring patterns of how individuals relate to the world their personality. This corresponds to the organizing question in Chapter 4: What does a person ro like me do in a situation like this?12 These enduring patterns structure moral action at three levels. Traits (e.g. extraversion, cynicism) describe broad patterns of individual consistency across time and situation. Characteristic adaptations (such as personal projects, life goals) provide a more fine-­grained analysis of patterns of consistency. A lP final level of personality consists of the patterns in the narratives we construct to seek out and identify meaning in our lives. These are unique to each individual, but one can find patterns even here – e.g. people differ in the kinds of themes they include in their life stories (McAdams, 2009). Most of the work we review has been done at the level of traits, and almost nothing na has been done at other levels of personality, such as narrative. De Young and Gray (2009) provide a useful overview of various theorists’ claims about the relation of personality to neuroscience and state that it is simply too early in personality neuroscience to link neural structure to the more specific levels of personality – e.g. personal adaptations and narrative (McAdams & Olson, 2010). These levels are heavily Fi dependent on personal developmental trajectory and unique cultural surround and it will likely be difficult, though not impossible, to connect them to neural structure. Markett, Montag, and Reuter (2018) propose a move in personality neuroscience similar to that documented in Section 2.2: looking for the patterns not in particular brain structures but in networks of brain structures as they interact across time. In a movement in that direction, Wright et al. (2019) provide evidence that differences in serotonin functioning (and thus the systems implicated in this functioning) underlie differences on the personality meta-­trait of stability.13 But beyond this, we are currently limited to looking at associations with particular structures. 12 Both how I characteristically view myself and how I characteristically view situations are enduring aspects of my personality. 13 Consisting of three – conscientiousness, agreeableness, and neuroticism (reverse coded) – of the “Big-­5” personality traits. Taking Moral Action Although alternative models are still occasionally floated (Zuckerman, 1995), the most widely accepted structure for a trait-­level description of personality is the “Big 5” (McCrae & Costa, 1997). Recent work with structural MRI scans by deYoung et al. (2010) provides a comprehensive view of the relationship of the size14 of particular neural structures associated with differences in the Big 5 personality traits, replicating findings from other work. They found clear associations for four of the Big 5 traits (openness to experience had less firm, but still suggestive, patterns). For instance, individuals high in extraversion tended to have a larger medial orbitofrontal cortex, an area involved in assessing the reward value of stimuli. Those individuals scoring higher in agreeableness tended to have smaller posterior left superior temporal sulci (plSTS) – an area associated with inferring intention based on patterns of movement – and to have a larger posterior cingulate (PC) – an area associated with understanding other’s beliefs. The functions associated with these areas are crucial perceptual s and cognitive components of empathy. Individuals high in conscientiousness tended to have larger middle frontal gyri – an area of the frontal cortex that is central in mainof taining working memory and executing planned action. Finally, individuals high in neuroticism had a more complex pattern of structure, with some structures being smaller and others larger but all associated with emotional sensitivity to threat and punishment (DeYoung et al., 2010). ro Note the pattern of the scientific inference in all these claims: (1) a correlation of a personality trait with size of a structure is reported (agreeableness with the plSTS); (2) the structure itself is then characterized in terms of other functions that might explain the correlation (tracking intention is associated with plSTS). Thus, we know lP that higher scores on both agreeableness and altruism are related to a brain structure associated with inferring intention (Tankersley, Stowe, & Huettel, 2007). But that does not make the plSTS the “altruism center.” Tracking intention and understanding other’s beliefs are only a part of the larger complex of coordinated activity that supports altruistic action. The larger personality aspect of altruism is not identical to or na reducible to the specific brain structure. But we can tie particular aspects of the neurological activity to specific aspects of the psychological function. More recent work that maps psychological constructs at the neural level shows how extraordinary altruism is supported by the functional neural processes that underlie empathy. Individuals who have taken the unusual step of donating a kidney to a stranFi ger have been shown to have a greater overlap of activation in the anterior insula for fearful stimuli not only for the self but also for others (as compared to matched controls). The suggestion is that this activation is one aspect of an “affective salience network” that is more responsive to harm in others than usual (Brethel-­Haurwitz et al., 2018, p. 1638). Again, we see aspects of psychological processes for empathy underpinned by distributed networks associated with psychological functions. 14 DeYoung (2010) provides a useful discussion about whether the volume of an area is the right metric for measuring its relative performance of a function. We agree that simple interpretations of volume leave much to be desired, and remind one of earlier, discredited phrenological approaches. But we also note that there does seem to be a replicable association of size with personality functions. As with all work in this area, scientific humility is in order. Neuroscience 37 2.4 Moral Identity and the Self The moral self-­concept, or moral identity, has begun to play an increasing role in explanations of why people take moral action. There are two aspects of the self that allow it to become involved in influencing moral action: (1) the content and structure of self-­knowledge; and (2) those self-­conscious emotions (pride, embarrassment) that guide action and action planning.15 Self-­knowledge and self-­conscious emotion are linked because we can think about ourselves over time and reflect on our reactions to evaluations by ourself and by others (Leary, 2007). One particular brain structure is closely associated with tasks that involve moral self-­concept: the medial prefrontal cortex (mPFC). Still, though self-­related tasks show heightened mPFC activity, there are few aspects of the moral experience that s can be isolated to one specific region of the brain. The mPFC by itself cannot be called the location of the self. In a review paper section titled “Is the mPFC the self?” Heatherton (2011) explains: “the experience of the self involves various sensory, of affective, and motor processes contributed by disparate brain regions outside the cortical midline area [containing the mPFC]” (p. 370). For example, an early finding identified the mPFC as the most active when Western individuals were asked to think ro about themselves in terms of abstract personality traits. But when this same task was given to a Chinese sample, the activation in the mPFC was much weaker. This is consistent with the idea that individuals with an interdependent conception of the self (one tightly connected to others) do not think of themselves as much in terms of lP abstract personality traits (Kitayama et al., 2019).16 In short, to find those aspects of the brain that underlie the experience of the self, one must look to a system of structures, processes, and functions, some of which may be distributed across multiple individuals (via e.g. BB synchrony) and cannot be precisely localized even in any one brain. na 2.4.1 Self-­Knowledge Research has shown that the mPFC is strongly related to semantic knowledge about the self. Most studies that compare thinking about the self with thinking about other things or people identify the mPFC as showing heightened activity for thinking about Fi the self.17 Beer (1999) proposes that the high “resting metabolic rate” of the mPFC suggests that it is involved in the constant self-­evaluation that accompanies our 15 Non-­self-­conscious or outwardly focused emotions (e.g. vicarious anger, empathy) can also guide moral action, and their ability to promote moral action may be related to ­self-­concept in a more complex manner (e.g. by reducing inhibition to action). However, these influences are speculative, and there is little to no neuroscience research that investigates them. 16 We should note that though this assumes collectivist societies consist of many people with interdependent views of the self, the picture is more complicated. Latin American societies are strongly collectivist, but they also emphasize an independent view of the self (Krys, 2022) 17 See Heatherton (2011) for a review and Mitchell et al. (2005) for divergent findings that show mPFC occasionally involved in judging others, even dogs. Taking Moral Action everyday activity. The range of self-­evaluative tasks that have been shown to involve the mPFC (free-­form reflection, self-­referential memory, self-­judgment all show activation of mPFC; mindfulness meditation shows deactivation) and the deficits shown with damage to this area (memory for personal preferences and other self-­knowledge) all suggest that this area is central in processing knowledge (and likely moral knowledge) about the self (Heatherton, 2011). One must be careful in making broad claims. Kitayama et al. (2019) review evidence that these patterns differ markedly across cultures, and that the ventro-­mPFC (vmPFC) is less active when thinking about the self in cultures where the self is typically interdependent, though in Latin American cultures these aspects seem to be independent (Krys, 2022). 2.4.2 Self-­Conscious Emotion s Self-­conscious emotion is a response to an appraisal of some threat to the self or of some incentive for the self (see Chapter 8 for how appraisal works). This distinction of between threat and incentive is based on Higgins’s (1997) distinction between promotion and prevention goals. Promotion goals seem to be associated with heightened activity in the left orbital and mPFC, areas associated with processing reward information and self-­referential knowledge respectively (Eddington et al., 2007; Strauman et al., 2012). ro Not surprisingly, the amygdala is involved when threats are detected and prevention becomes important. But it seems to be the anterior cingulate cortex (ACC) – immediately adjacent to the mPFC with its self-­relevant functions – that regulates the lP connection between the mPFC and the amygdala in the regulation of threatening social emotion (Heatherton, 2011; Strauman et al., 2012). Thus, the psychological processes associated with promotion and prevention goals seem to be subserved by different neural circuitry and therefore the evaluation and pursuit of these different goals may differ qualitatively.18 But work needs to be done before one can make such na strong conclusions. To complicate matters, these brain areas do their work in concert with a range of other areas. For instance, another area in the frontal cortex (the orbito-­frontal cortex, OFC) seems to be involved in the appraisal process for social emotions (Beer, 2007; Beer, Lombardo, & Bhanji, 2010). Damage to this area produces patients who can Fi generate social emotions but often the inappropriate ones. Yet another complication is that the ACC seems to do its threat-­detection work differentially in those with low self-­esteem (much more active in response) than in those with normal or high self-­ esteem (Somerville et al., 2006). Thus, it seems we have a complex of areas in the midline of the cortex (mPFC, ACC, OFC, but also amygdala) that are centrally involved in mediating the self’s involvement in moral perception, reaction, and action. They act in concert but they are not isolated from much other activity. We are only beginning to understand how this activity might be related to the self and to moral action. Constructing that understanding will likely involve identifying shifting neural systems over the timescale of the experience. 18 See Chapter 9 for more explanation about these different motivational and self-­regulatory systems. Neuroscience 39 2.5 Skills and Knowledge Since moral action implies agency, skill is inevitably implicated. Skill is involved not only in executing action but also in perceiving the need or opportunity for it, ­evaluating ­possibilities, and planning for action. Skill is also involved in the emotional regulation associated with effective social action, and its neural underpinning can differ depending on the shape emotional regulation takes in different cultures (Kitayama et al., 2019, p. 95). It is well established that increases in training (e.g. comparing novices to experts in some area) can produce increases in the size, density, and/or reactivity of related brain areas that serve the skill (one example of a general process called neuroplasticity). This has been replicated in music (Herdener et al., 2010; Kleber et al., 2009), motor skill and motivational aspects of skill training (Boyke et al., 2008), perception s (Herdener et al., 2010), and even compassion meditation (Lutz et al., 2009; for a review, see Tang, Holzel, & Posner, 2015). As a habit develops based on repeated practice, its neural underpinnings shift from of the cortical networks associated with goal-­driven action control to the habit-­based sensorimotor cortico-­basal ganglia (Wood, Mazar, & Neal, 2021, p. 3). Computational models suggest that movement back and forth between goal-­based and habit-­based ro action could take multiple forms, allowing one to think of the two systems as either separate or as tightly conjoined (Wood et al., 2021, p. 4). Basso et al. (2020) review evidence that dance and associated BB synchrony facilitate group cohesion and that the cortico-­spinal tract in dancers and athletes shows increased organization. This lP suggests yet another expansion of neural areas related to moral action. The evidence that different kinds of expertise produce a wide variety of changes at the neuroanatomical level suggests that we need to expand dramatically our map of those brain areas that support the wide variety of moral action. To the extent that particular skills and expertise are inextricably intertwined with moral goals (e.g. compassion, the design of safe computing systems, supporting group functioning) it is na difficult to argue that the neural systems that support these skills are not parts of the “moral brain.” This expansion of the territory of the moral brain opens the door to a host of other neuroscience findings in cognition, learning, habit, expertise, and emotion. As moral judgment and decision-­making is pushed into automatic skills and habits, so also their neural underpinnings must be expanded into those brain areas Fi serving those processes. This expansion may be so large that it might be better to stop talking about particular areas being most associated with abstract-­level morality.19 2.6 Moral Reason Long considered the paragon and defining characteristic of morality, reason has been somewhat under siege (Haidt, 2010; Narvaez, 2010). The recent spate of neuroscience findings linking emotion centers to moral judgment has been one of the driving 19 For instance, Ellemers and van Nunspeet (2020) review work showing that conformity changes brain activity associated with visual perception, indicating that social influence may change the way we perceive the world, and providing yet another expansion of the moral brain. Taking Moral Action forces in this assault (Greene & Haidt, 2002; Greene et al., 2001). Here we review work that tries to isolate or characterize the role of reason in moral action by identifying its neural correlates. 2.6.1 Pure Reason Work in the neuro-­economics tradition by Shenhav and Greene (2010) tracks the neural underpinnings of the mental calculation of expected moral value, a combination of the magnitude of a possible moral loss/gain and the probability of that loss/ gain. Changes in expected moral value are particularly related to the vmPFC, and the medial OFC (mOFC). In this study, individuals made judgments about expected moral value while being presented with a range of possible values of magnitude in gain/loss and probability. This design allowed the researchers to show that these s structures were particularly sensitive to changes in these values. The pattern of results suggests that these calculations of moral value are done using the same processes that of other work has found to be active in more straightforward self-­interested economic decision-­making. This particular value tracking is, they argue, not a specialized moral calculation but a more general-­purpose process. Shenhav and Greene (2010) also tracked the individual differences that might lead ro one person to be more utilitarian in their approach than another. Individuals who are more likely to hew closely to utilitarian judgments show more activation in the OFC. This activation seems to be in line with the association of the OFC in identifying and modulating emotional reactions (Beer, Knight, & D’Espositio, 2006). Perhaps the lP people doing pure utilitarian calculations were better at blocking out emotional reactions. 2.6.2 Balancing Reason and (Social/Emotional) Reward na The utilitarians in Shanhav and Greene’s (2010) study seem to be blocking out emotional input in favor of a stark, mathematical moral calculus. But clearly others are including emotional aspects in their judgment. Is including emotion in moral judgment a good thing, or should all moral judgment instead resemble the pure utilitarians just discussed? Fi Extensive work in developmental psychology on risk-­taking in adolescence can provide some enlightenment here. Why are adolescents more willing to take risks, particularly when they are together with their friends? There appear to be two different systems involved in calculations of risk: a socio-­emotional dopaminergic reward-­seeking system (centering on the limbic system) and a cognitive control network involving planning, thinking ahead, and self-­regulation (Steinberg, 2007). The emotional system develops earlier, and excessive risk-­taking in adolescence seems to be associated with the imbalance between socio-­emotional reward for risk and cognitive control that might (but cannot yet) modulate it. It is achieving the balance between these systems that produces adult-­level risk-­taking. Adolescent reasoning ability, considered alone, is comparable to adults, but adolescents find the psychosocial rewards associated with risk (particularly risk taken in peer groups) to be more alluring (Steinberg, 2007). It is the development of the planning, thinking ahead, and self-­regulation networks that allows the balance between socio-­emotional reward and logical reasoning to happen. Neuroscience 41 Thus, is not either emotional reward or calculated caution but an appropriate balance between them. This is reminiscent of the admonition in Aristotle (340 BCE/1941, 1106a31–1106b8) that virtue is found in the median, but that the median can be different for different people and in different situations.20 2.6.3 Blending Reason and Emotion Earlier work in moral neuroscience (Greene et al., 2001) has characterized emotion and reason as playing competitive roles in determining moral judgment and action. But we do not need to construct the relation between emotion and reason as competitive. The work reviewed earlier by Shenhav and Greene (2010) and Steinberg (2007) can also be construed as detailing how emotion/reward/escape and reason/ planning/cognitive control are appropriately blended together to influence judgment s and action. This is also the approach that Beer et al. (2006) take in their work. Complex moral motivations and values are represented as configurations of declaraof tive content and emotion. Moll et al. (2003, 2009) emphasize the cooperative ­interaction of cognition and emotion in their model of moral judgment and track the various neural components underlying each. Moll et al. (2006) demonstrated that different cognitive-­emotional complexes (considered at the psychological level) are ro selectively activated (measured as fMRI activation in areas associated with emotion or reason) in decisions to donate to charities with which one agrees or disagrees (e.g. regarding abortion). Thus, cultural knowledge, self-­knowledge, and emotion (e.g. anticipatory guilt vs. anticipatory disgust) combine into “cognitive emotional lP complexes” that are balanced or play off against one another.21 Of course, reason and emotion can also be blended through the feedback loops associated with what has been called “embodied emotion,” the “perceptual, somatovisceral, and motoric” aspects of the ‘feelyness’ of an emotion that are perceived and then integrated into moral judgment and action” (Niedenthal, 2007, p. 1002). Ellemers and colleagues na also emphasize the interaction and balance between reason and emotion (Ellemers et al., 2019; Ellemers & van Nunspeet, 2020). In Cohen’s (2005, p. 4) words, “most evaluations – from the most primitive to the most sophisticated – engage multiple different brain systems” (see also Cushman, Young, & Greene, 2010; Pessoa, 2008). Fi 2.6.4 Planning for Cognitive-­Emotional Effectiveness How do we attempt to make these balances appropriate to the situation and to our abilities? We have some knowledge of the neural systems that help internally in making this balance, such as the orbitofrontal cortex (Beer et al., 2006). And it seems that generating options and choosing among them are separate actions with somewhat separate neural underpinning (Morris et al., 2021), with option generation being constrained by “cached value estimates” based on past experience. 20 Aristotle explicitly includes appropriate emotion in his description of the characteristics of a virtuous act. 21 Note that this balance of complex influences is some justification for the complex model of consistency that we present in Chapter 5, and for the idea of “reflective socio-­emotional reflective equilibrium” presented in Chapters 8 and 9. Taking Moral Action Cohen (2005) argues that we use training programs and other social structures to give us the appropriate experiences (and thus cached value estimates) that help to shape our decision-­making. That is, we structure our environments to support the balancing of influences as we learn to make decisions. Thus, the causal sequence that allows for balance runs outside the brain and the person, into the situation and culture: For example, the specialized training given to doctors and soldiers involves the cultivation of mechanisms for averting or overcoming strong emotional responses that may interfere with their professional functions.22 These mechanisms may not rely directly on the prefrontal cortex; instead, they may involve the training of other lower-­level mechanisms specific to the particular circumstances involved23 (Cohen, 2005, p. 19) s Some of the processes to which Cohen refers here are social structures like training programs that “overtrain” particular responses such as procedures in surgery, rescue, of or battle. But someone must plan the procedures and assess them. Cohen continues: “Importantly, however, the social structures that devised and support the training procedures almost certainly did rely on the prefrontal cortex” (Cohen, 2005, p. 19). These planned social structures then influence the individual as he or she performs ro the planned action. This planning ahead to shape our future responses has been called “situational self-­control” and has been shown to be quite effective (Duckworth, Gendler, & Gross, 2016). Thus, reasoning can be seen as something that helps to construct the future envilP ronment in order to train and to circumscribe future cognitive-­emotional processing.24 Oddly enough, this cultural emphasis of reason over emotion may itself be an achievement of reason in the service of training ourselves to better balance cognition and emotion in moral action. na 2.7 Moral Emotion 2.7.1 Emotion as Bias One of the main reasons that emotion has been seen as the enemy of thoughtful Fi moral judgment is that an emotion-­free standard has been assumed by early theories of moral judgment (Lapsley & Narvaez, 2005), though, of course, similar assumptions 22 Cold scientific rationality can, on the other hand, sabotage the physician–patient relationship. The technically competent doctor may appear to lack “respect and empathy” for the patient if they do not address the existential threat that the patient is experiencing (Agledahl et al., 2011). There is a new movement in physician training that focuses on integrating concern for existential and spiritual aspects in physician–patient interactions (Paal, Helo, & Frick, 2015). Again, emotion and reason regulate each other. 23 We disagree with Cohen’s implication that this sort of planning is needed to circumscribe only those problems associated with emotion. As we explain in Chapter 7, we should also beware of the significant failings associated with reason. 24 One pathology of this balance can be seen in post-­traumatic stress disorder (PTSD) symptoms of dissociation of emotion and reason with regard to particular domains associated with the traumatic experience (Butollo et al., 2015). Neuroscience 43 reach back to the pre-­Socratic philosophers. And emotion can indeed bias evaluation. Particularly when we are highly partisan, the way we evaluate information is driven by our emotional opposition (or commitment) to our partisan positions. Westen et al. (2006) asked political partisans to judge information that was threatening to their preferred candidate in a presidential election. They documented the neural underpinnings of a two-­stage process: first an emotional response to the negative information, activating the mPFC and vmPFC, followed by a reward system activation (caudate nucleus) as soon as they had assimilated and explained away the threat. Thus, emotion seems to be at least part of the “push” associated with implicit evaluation. Luo et al. (2006) have tracked the neural correlates of emotional engagement in what has been called the implicit association test (IAT). This involves pairing the target judgment (in this case pictures of legal or illegal behavior) with emotionally congruent pictures (positive valence animals, e.g. puppies) or incongruent (negative s valence animals, e.g. snakes). Participants were then asked to make a judgment about the behavior. Reaction times for these judgments were slower on incongruent trials of than on congruent ones. This suggests that the emotional incongruence is interfering with the response. Participants are not aware of this difference and even when instructed and given practice, cannot easily influence it (Steffens, 2004). Luo et al. (2006) found that amygdala response correlated with the intensity of the stimulus ro and of the IAT effect. This suggests that it is the amygdala that is involved in the emotional “push” to the implicit judgment that is tracked by the IAT, presumably as part of some larger evaluative system (Barrett, 2017). These emotion-­laden judgments can also drive our desire to punish others (or at lP least those who deserve it). Though we have a range of rational theories available to explain why punishment is a good thing to do (e.g. deterrence), in the end we punish people (or judge other’s punishment to be good) because it feels good to us. The perception of unfairness activates emotion centers such as the anterior insula (Sanfey et al., 2003) and administering punishment to an individual who deserves it activates na reward centers such as the nucleus accumbens (Strobel et al., 2011). This does not, of course, resolve ethical puzzles about justifiable punishment, but it does suggest that we find it rewarding to punish those who deserve it. Even given the significant role that emotional reaction might play in biasing judgment, it is possible to reappraise the causes of our emotional reactions (when we are Fi aware of them) or to attempt to suppress them. Reappraisal involves reinterpreting the emotion-­inducing event as something different, while suppression involves simply attempting not to experience the emotion. Most research has shown that reappraisal is more effective in controlling emotional reactions than is repression (Quirk & Beer, 2006). These two approaches to emotional regulation have different neural components that interestingly track their different outcomes. Goldin et al. (2008) had participants watch negative emotion-­arousing film clips and asked them to either reappraise the emotion or suppress it. Different parts of the PFC were involved in reappraisal and suppression. In reappraisal, these areas were active early in the clip, reduced their activity as the clip continued, and showed suppressed activity in the amygdala throughout the clip. But suppression showed PFC activity increasing over the course of the film, along with increased amygdala activity. This complex pattern shows the role that various interacting networks play in constructing our experience of emotion and its meaning (Lebois et al., 2020). Taking Moral Action 2.7.2 Questioning the Cognitive/Emotion Distinction The complex relationship of emotion to perception, judgment, and action and the dense interconnectedness of “emotional” and “cognitive” structures in the brain has led some to call for abandonment of the cognition/emotion dichotomy, at least at the structural neural level. Pessoa (2008, 2009) provides three neuroscientific reasons why the dichotomy does not stand scrutiny. Brain areas that are often labeled as “affective” are often also involved in cognition, and similarly, areas labeled cognitive are involved in affective reactions. Finally, cognition and emotion are integrated in the brain, both behaviorally in that evaluations involve both affective and cognitive areas, and structurally in that connection maps of these areas show little separation and massive interconnectivity. (See also Barrett, 2009 for a parallel view.) This complex interaction between reason and emotion is the basis for the approach to moral s emotion that we review in Chapters 7 and 8. We reviewed in Section 2.6.3 the work of Moll and colleagues (Moll et al., 2002, of 2003, 2006, 2009;) on cognitive-­emotional complexes. Complex moral motivations and values are represented as configurations of declarative content and emotion (Moll et al., 2009). Thus, the cognitive-­emotional complexes for attachment/compassion and for anger/disgust may be separable from each other, but they are not easily separo rable into emotional and cognitive components. This seems congruent with the difficulty we have in separating emotion from reason in our decision-­making. Perhaps we can conclude that it is not the primacy or autonomy of reason that drives human morality and makes humans unique among species but the unique ability to link emolP tional and motivational states to abstract ideas. It is reason and emotion, as they interact to construct our evaluations and our motivations toward action (Barrett, 2013; Lebois et al., 2020; Lindquist et al., 2012). And here lies one central challenge of moral acting. na 2.8 Moral Formation Chapter 9 discusses in depth how we learn skills and adopt values in order to become more moral. Part of this process involves training our self-­regulation skills. As we have Fi outlined it in Chapter 9, performing and planning is about both short-­and long-­term self-­regulation. By self-­regulation we do not mean simply self-­control (suppression or distraction or reappraisal of incompatible responses to a goal) but all the goal-­directed activity that is relevant to the moral life. This includes metacognition, self-­reflection, and moral creativity in planning at both projects and a life-­goals levels. It also includes the planning and execution of behavioral initiation, maintenance, and habit (Rothman et al., 2011), and what the philosopher Frankfurt (1971) has called second-­order volitions, or “wanting to have (or not have) certain desires and motives” (p. 7) (see also Lapsley, 2008). This also includes how the stories we construct about ourselves affect and guide our moral identity and action (McAdams, 2009). Almost all of these psychological processes are highly abstract, involving complex metacognition and self-­reflection, etc., which makes it difficult to track them with current fMRI or other neuroscience methods (Barrett, 2009; Pessoa, 2008). Though we can measure the extent of neural activity in a place, we can only “read its content” Neuroscience 45 to the extent that changes in the task we give a subject will produce changes in ­localization. And this only allows us to infer that something about the difference in conditions produced the change in localization. Thus, a great deal of work has been done about the neural underpinnings of emotional regulation (Damasio, 1994; Heatherton, 2011; McRae, Ochsner, & Gross, 2011; Quirk & Beer, 2006) but very little about the higher-­order concepts listed earlier (Heatherton, 2011). For the rare exception to this rule, see the work of Eddington et al. (2007); and Strauman et al. (2012), which not surprisingly implicates the PFC in tracking aspirational goals. Cohen (2005) observes that we use reason (and the PFC) to construct the environment in order to train the self, but beyond that useful observation he provides no suggestion about how one might track the neural underpinnings of this process. One might expect that the affective-­cognitive complexes that Moll et al. (2009) identify may play a significant role in this process, s and the decision paradigm they use to track the neural correlates of charitable giving over short periods of time could provide a template for work in long-­term self-­ of regulation. Alternatively, the work on the development of cognitive control networks in adolescence (Blakemore & Choudhury, 2006; Kuhn, 2006; Steinberg, 2007) might provide another paradigm for beginning research in this area. Finally, the constructivist understanding of how situated emotions (e.g. social vs. physical fear) are ro learned may give some insight into how different framing of emotions can help to shape them and their neural underpinnings (Lebois et al., 2020). There is much systematic work to be done in this area if the measurement and methodology hurdles can be overcome. lP 2.8.1 Empathy We not only think about others we also feel with and for them, one of the important markers for moral emotions. How do the feelings of others become connected to our na own? A remapping of internal sense information in the insular cortex (located between the frontal and temporal lobes) has been proposed as the basis for the conscious awareness of how we feel, that is, for the “feelyness” of our emotions (Damasio, 1994). But this area where our feelings are represented to ourselves is also activated by many tasks that involve thinking about or perceiving other people (Adolphs, 2009). This Fi parallel activation suggests that a kind of internal mapping of others’ feelings onto our own feelings helps to account for the sharing of emotions we call empathy (Adolphs, 2009). It also connects with the more complex description of emotion in Chapter 8 as involving the interpretation of perceived reality. We have long known that people in cooperative interactions tend to synchronize their behavior patterns with each other (Bernieri & Rosenthal, 1991). Recent work has shown that this non-­verbal matching is underpinned by what, as discussed in Section"
2,2.2,"Moral Ecology In an article on the emerging field of cultural neuroscience, Ambady and Bharucha (2009) called the brain “the organ of culture.” The brain is indeed at least one place where the patterns and influences of our social surround encounter the patterns and proclivities of our inner life. To be embodied in the individuals who make up a moral ecology, the social complexities we describe in Chapter 3 still need to be channeled through those people. This channeling is done by processes of imitation, social influence, and social cognition, and is supported by a network of interacting brain processes (and interacting brains) that neuroscientists are only beginning to map. In this section, we will review a subset of what we know about how moral ecology influences individuals through imitation, social cognition, and social influence. s 2.2.1 Imitation and Mirror Neurons of Humans have a ubiquitous tendency to imitate one another. We align our behavior with others in both literal (e.g. posture, speech) and symbolic (e.g. stereotype-­based) ways, and do so unintentionally, even without conscious awareness (Iacoboni, 2009). ro This is a very basic and pervasive form of social influence. It is supported by a complex network of action perception and interpretation that involve one of the most fashionable topics in neuroscience: mirror neurons. These are neurons that are part of the sequence involved in controlling motor movement for the macaque monkeys in the original study (moving the hand to the mouth to eat) but that were also found to lP activate when the monkey watched the experimenter perform the same action (di Pellegrino et al., 1992). Thus, they “mirrored” the perceived activity in a section of the brain devoted to physically performing the activity. Accumulated research in humans since this initial finding now shows that there is a section of the superior temporal sulcus that processes intentional movement in others and that connects to na two separate areas of mirror neurons, one that represents the motor aspects of the movement (parietal mirror neuron area) and one that represents the goal aspects of the movement (frontal lobe mirror neurons) (Iacoboni, 2009). It seems clear at this point that mirror neuron brain areas contribute to imitative action (e.g. copying body movement) but not directly to higher level processes like inferring intentions Fi (Campbell & Cunnington, 2017; Grigaityte & Iacoboni, 2016; Heyes & Catmur, 2022). Tracking how mirror neurons are integrated into larger systems is work that remains to be done. 2.2.2 Thinking About, and With, Others One of the central psychological processes that underlies social influence is our ability to think about others, to take their perspective, and to recognize that they are judging us. This ability requires representing the mental states of others. Again, we find that the medial prefrontal cortex (mPFC) is involved in this, the same structure that is centrally involved in processing information about the self (Heatherton, 2011). There seems to be specialization within the mPFC, with other-­mind processing areas toward the dorsal (top) side of the mPFC and self-­processing areas toward the ventral (bottom) side. Interestingly, there are some clues that the processing may differ for Neuroscience 33 in-­group and out-­group members, with activation reported in both the self-­processing and other-­ processing areas for people who are considered similar to the self (Heatherton, 2011). Others also influence us because we are concerned about judgments they might make about us. This awareness of other people can be threatening and emotional, and thus – in addition to mPFC – the awareness of threat from others involves areas that modulate and tune emotional expression. We have covered this social threat detection in Section 2.4 and processes of empathy in Section 2.8. In a significant advance in theory and method, Tamir and Thornton (2018) have paired advanced techniques in neuroscience imaging with a dimensional model of social perception that looks at three levels of social perception:7 perception of character traits of the other, perception of the current state of the other, and evaluations of the actions of the other. This is a complex and promising model of how social infers ence plays out at the neural level. It is another example of the massive interactivity evident at both the psychological and neural levels. of 2.2.3 Cultural, Group, and Individual Influence on Brain Processes We have already seen that psychological characteristics can modify the way the brain ro processes information.8 The mPFC in individuals with low self-­ esteem processes information about others differently and information about out-­groups is processed differently than information about in-­groups (Heatherton, 2011; Kitayama, Varnum, & Salvador, 2019; Somerville, Heatherton, & Kelley, 2006). The extent to which a lP culture is tight (vs. loose9) is associated with more reactivity in brain areas linked with norm violation detection (Kitayama et al., 2019). There also seems to be evidence that the neuroanatomy associated with thinking about the self is different in different cultures (Kitayama et al., 2019). Zhu et al. (2007) have shown differences in Chinese and Western college students’ neural representations of self and mother.10 As menna tioned before, mPFC is associated in Western studies with active representation of the self, but in this study Chinese students’ active representations of their mothers also showed significant activity in mPFC (among other cultural differences in processing). Thus, the functions associated with particular areas of the cortex (the functional anatomy) differ in these samples, based on culture. For Chinese people, there is “neural Fi unification” of the self and the mother, while for Westerners there is “neural separation” (Zhu et al., 2007, pp. 1314–1315). Western culture is, on average, much more 7 They use representational similarity analysis in fMRI. This advanced analytic approach allows comparison of the similarity of reaction in entire neural systems across people who have been shown similar stimuli. With carefully chosen stimuli, this allows one to see ­ similarities in neural response patterns that represent the psychological dimension (e.g. perceptions of social power). 8 This should only be surprising to those who see neural events as the single “real” level of explanation (see neuro-­essentialism in Section 2.1). 9 The extent to which a culture requires close observance of morals and customs or allows a looser relationship to them. See Chapter 9, Section 9.3.1.3. 10 These studies are done by looking for brain areas that are activated when people are asked to think about themselves, about their mother, about important others, etc. Taking Moral Action individualistic than Chinese culture, which tends to see others as forming a very close bond with the self. Thus, the “neural unification” of an important other suggests a cultural influence on functional neuroanatomy. This effect is complicated when one looks at Chinese people with significant exposure to Western, individualistic culture (Kitayama et al., 2019) 2.2.4 Interpersonal Neuroscience It is now possible to track how two or more brains show synchrony in patterns of activity, opening the possibly of a truly interpersonal neuroscience (Pan, Novembre, & Olsson, 2021).11 This brain-­to-­brain synchrony (BB synchrony) has been shown to strongly correlate with social learning in dyads and even at the classroom level (Pan et al., 2021). Facial, voice, and movement cues seem foundational in this process of s establishing synchrony, and synchrony occurs at behavioral, affective, perceptual, and neural levels (e.g. emotional contagion is associated with neural synchrony or entrainof ment) (Wheatley et al., 2011). BB synchrony, but not self-­reported group identification, has been shown to predict team performance in both an economic game and problem-­solving tasks. Basso, Satyal, and Rugh (2020) collate evidence suggesting that BB synchrony is important in shared dance, helping to explain the social synchroro nizing function of shared dance and movement (e.g. ritual, folk dance, etc.) across cultures. lP 2.2.5 The Mutual Constitution of Brain and Cultural Processes Kitayama et al. (2019, p. 80), in a review of cultural neuroscience, collate the empirical evidence for a claim long dominant in cultural anthropology. Their summary of the claim is worth quoting at some length: na the body (and now the brain as well) is closely attuned to the sociocultural environment, while at the same time … autonomous, thereby constituting agency, being capable of producing volitional actions, which can lead to changes in the environment from which the agency has been derived. This circular or recursive process occurs continuously, not only in each person’s lifetime but also across generations, … giving rise to changes in both historical and Fi evolutionary timescales. [emphasis ours] The central point here is the close attunement and mutual influence of brain–body systems and cultural systems. Cultural systems both resist change and provide resources for individuals and groups to produce change. Individuals can both resist and seek individual change using resources available to them from culture. Each one influences and structures the other over both short and long timescales. 11 The methods for tracking synchrony involve some measurement of activity, e.g. electroencephalogram (EEG) or fMRI or functional near-­infrared spectroscopy (fNIRS, a less invasive approach in which the subject wears a cap that tracks brain activity in a similar, but less detailed, way to fMRI). Mathematical models are then used to highlight parallelism in activity between two or more brains in people who are interacting. Neuroscience 35 In summary, we can see that social influence and moral ecology are attuned to brain processes and systems at many different levels. This ranges from low-­level mirroring of motor action, to the mirroring of feeling states, to fears of social sanction from others and cognition about others to synchronization of movement, affect, and intention. This attunement to moral ecology provides the support and channel for effective volitional action within that moral ecology."
2,2.3,"Cultural, Group, and Individual Influence on Brain Processes We have already seen that psychological characteristics can modify the way the brain ro processes information.8 The mPFC in individuals with low self-­ esteem processes information about others differently and information about out-­groups is processed differently than information about in-­groups (Heatherton, 2011; Kitayama, Varnum, & Salvador, 2019; Somerville, Heatherton, & Kelley, 2006). The extent to which a lP culture is tight (vs. loose9) is associated with more reactivity in brain areas linked with norm violation detection (Kitayama et al., 2019). There also seems to be evidence that the neuroanatomy associated with thinking about the self is different in different cultures (Kitayama et al., 2019). Zhu et al. (2007) have shown differences in Chinese and Western college students’ neural representations of self and mother.10 As menna tioned before, mPFC is associated in Western studies with active representation of the self, but in this study Chinese students’ active representations of their mothers also showed significant activity in mPFC (among other cultural differences in processing). Thus, the functions associated with particular areas of the cortex (the functional anatomy) differ in these samples, based on culture. For Chinese people, there is “neural Fi unification” of the self and the mother, while for Westerners there is “neural separation” (Zhu et al., 2007, pp. 1314–1315). Western culture is, on average, much more 7 They use representational similarity analysis in fMRI. This advanced analytic approach allows comparison of the similarity of reaction in entire neural systems across people who have been shown similar stimuli. With carefully chosen stimuli, this allows one to see ­ similarities in neural response patterns that represent the psychological dimension (e.g. perceptions of social power). 8 This should only be surprising to those who see neural events as the single “real” level of explanation (see neuro-­essentialism in Section 2.1). 9 The extent to which a culture requires close observance of morals and customs or allows a looser relationship to them. See Chapter 9, Section 9.3.1.3. 10 These studies are done by looking for brain areas that are activated when people are asked to think about themselves, about their mother, about important others, etc. Taking Moral Action individualistic than Chinese culture, which tends to see others as forming a very close bond with the self. Thus, the “neural unification” of an important other suggests a cultural influence on functional neuroanatomy. This effect is complicated when one looks at Chinese people with significant exposure to Western, individualistic culture (Kitayama et al., 2019) 2.2.4 Interpersonal Neuroscience It is now possible to track how two or more brains show synchrony in patterns of activity, opening the possibly of a truly interpersonal neuroscience (Pan, Novembre, & Olsson, 2021).11 This brain-­to-­brain synchrony (BB synchrony) has been shown to strongly correlate with social learning in dyads and even at the classroom level (Pan et al., 2021). Facial, voice, and movement cues seem foundational in this process of s establishing synchrony, and synchrony occurs at behavioral, affective, perceptual, and neural levels (e.g. emotional contagion is associated with neural synchrony or entrainof ment) (Wheatley et al., 2011). BB synchrony, but not self-­reported group identification, has been shown to predict team performance in both an economic game and problem-­solving tasks. Basso, Satyal, and Rugh (2020) collate evidence suggesting that BB synchrony is important in shared dance, helping to explain the social synchroro nizing function of shared dance and movement (e.g. ritual, folk dance, etc.) across cultures. lP 2.2.5 The Mutual Constitution of Brain and Cultural Processes Kitayama et al. (2019, p. 80), in a review of cultural neuroscience, collate the empirical evidence for a claim long dominant in cultural anthropology. Their summary of the claim is worth quoting at some length: na the body (and now the brain as well) is closely attuned to the sociocultural environment, while at the same time … autonomous, thereby constituting agency, being capable of producing volitional actions, which can lead to changes in the environment from which the agency has been derived. This circular or recursive process occurs continuously, not only in each person’s lifetime but also across generations, … giving rise to changes in both historical and Fi evolutionary timescales. [emphasis ours] The central point here is the close attunement and mutual influence of brain–body systems and cultural systems. Cultural systems both resist change and provide resources for individuals and groups to produce change. Individuals can both resist and seek individual change using resources available to them from culture. Each one influences and structures the other over both short and long timescales. 11 The methods for tracking synchrony involve some measurement of activity, e.g. electroencephalogram (EEG) or fMRI or functional near-­infrared spectroscopy (fNIRS, a less invasive approach in which the subject wears a cap that tracks brain activity in a similar, but less detailed, way to fMRI). Mathematical models are then used to highlight parallelism in activity between two or more brains in people who are interacting. Neuroscience 35 In summary, we can see that social influence and moral ecology are attuned to brain processes and systems at many different levels. This ranges from low-­level mirroring of motor action, to the mirroring of feeling states, to fears of social sanction from others and cognition about others to synchronization of movement, affect, and intention. This attunement to moral ecology provides the support and channel for effective volitional action within that moral ecology. 2.3 Personality The attempt to connect personality to physiological processes is as old as the classical Greek theories of the humors (Zuckerman, 1995). The human body was thought to contain four kinds of humors (fluids) and various personality traits (e.g. melancholy) s were thought to be associated with imbalances in these humors. But it is only with the recent, rapid development of neuroscience measurement techniques that we have of been able to make some empirical progress in actually evaluating proposed theoretical connections. We call the enduring patterns of how individuals relate to the world their personality. This corresponds to the organizing question in Chapter 4: What does a person ro like me do in a situation like this?12 These enduring patterns structure moral action at three levels. Traits (e.g. extraversion, cynicism) describe broad patterns of individual consistency across time and situation. Characteristic adaptations (such as personal projects, life goals) provide a more fine-­grained analysis of patterns of consistency. A lP final level of personality consists of the patterns in the narratives we construct to seek out and identify meaning in our lives. These are unique to each individual, but one can find patterns even here – e.g. people differ in the kinds of themes they include in their life stories (McAdams, 2009). Most of the work we review has been done at the level of traits, and almost nothing na has been done at other levels of personality, such as narrative. De Young and Gray (2009) provide a useful overview of various theorists’ claims about the relation of personality to neuroscience and state that it is simply too early in personality neuroscience to link neural structure to the more specific levels of personality – e.g. personal adaptations and narrative (McAdams & Olson, 2010). These levels are heavily Fi dependent on personal developmental trajectory and unique cultural surround and it will likely be difficult, though not impossible, to connect them to neural structure. Markett, Montag, and Reuter (2018) propose a move in personality neuroscience similar to that documented in Section 2.2: looking for the patterns not in particular brain structures but in networks of brain structures as they interact across time. In a movement in that direction, Wright et al. (2019) provide evidence that differences in serotonin functioning (and thus the systems implicated in this functioning) underlie differences on the personality meta-­trait of stability.13 But beyond this, we are currently limited to looking at associations with particular structures. 12 Both how I characteristically view myself and how I characteristically view situations are enduring aspects of my personality. 13 Consisting of three – conscientiousness, agreeableness, and neuroticism (reverse coded) – of the “Big-­5” personality traits. Taking Moral Action Although alternative models are still occasionally floated (Zuckerman, 1995), the most widely accepted structure for a trait-­level description of personality is the “Big 5” (McCrae & Costa, 1997). Recent work with structural MRI scans by deYoung et al. (2010) provides a comprehensive view of the relationship of the size14 of particular neural structures associated with differences in the Big 5 personality traits, replicating findings from other work. They found clear associations for four of the Big 5 traits (openness to experience had less firm, but still suggestive, patterns). For instance, individuals high in extraversion tended to have a larger medial orbitofrontal cortex, an area involved in assessing the reward value of stimuli. Those individuals scoring higher in agreeableness tended to have smaller posterior left superior temporal sulci (plSTS) – an area associated with inferring intention based on patterns of movement – and to have a larger posterior cingulate (PC) – an area associated with understanding other’s beliefs. The functions associated with these areas are crucial perceptual s and cognitive components of empathy. Individuals high in conscientiousness tended to have larger middle frontal gyri – an area of the frontal cortex that is central in mainof taining working memory and executing planned action. Finally, individuals high in neuroticism had a more complex pattern of structure, with some structures being smaller and others larger but all associated with emotional sensitivity to threat and punishment (DeYoung et al., 2010). ro Note the pattern of the scientific inference in all these claims: (1) a correlation of a personality trait with size of a structure is reported (agreeableness with the plSTS); (2) the structure itself is then characterized in terms of other functions that might explain the correlation (tracking intention is associated with plSTS). Thus, we know lP that higher scores on both agreeableness and altruism are related to a brain structure associated with inferring intention (Tankersley, Stowe, & Huettel, 2007). But that does not make the plSTS the “altruism center.” Tracking intention and understanding other’s beliefs are only a part of the larger complex of coordinated activity that supports altruistic action. The larger personality aspect of altruism is not identical to or na reducible to the specific brain structure. But we can tie particular aspects of the neurological activity to specific aspects of the psychological function. More recent work that maps psychological constructs at the neural level shows how extraordinary altruism is supported by the functional neural processes that underlie empathy. Individuals who have taken the unusual step of donating a kidney to a stranFi ger have been shown to have a greater overlap of activation in the anterior insula for fearful stimuli not only for the self but also for others (as compared to matched controls). The suggestion is that this activation is one aspect of an “affective salience network” that is more responsive to harm in others than usual (Brethel-­Haurwitz et al., 2018, p. 1638). Again, we see aspects of psychological processes for empathy underpinned by distributed networks associated with psychological functions. 14 DeYoung (2010) provides a useful discussion about whether the volume of an area is the right metric for measuring its relative performance of a function. We agree that simple interpretations of volume leave much to be desired, and remind one of earlier, discredited phrenological approaches. But we also note that there does seem to be a replicable association of size with personality functions. As with all work in this area, scientific humility is in order. Neuroscience 37 2.4 Moral Identity and the Self The moral self-­concept, or moral identity, has begun to play an increasing role in explanations of why people take moral action. There are two aspects of the self that allow it to become involved in influencing moral action: (1) the content and structure of self-­knowledge; and (2) those self-­conscious emotions (pride, embarrassment) that guide action and action planning.15 Self-­knowledge and self-­conscious emotion are linked because we can think about ourselves over time and reflect on our reactions to evaluations by ourself and by others (Leary, 2007). One particular brain structure is closely associated with tasks that involve moral self-­concept: the medial prefrontal cortex (mPFC). Still, though self-­related tasks show heightened mPFC activity, there are few aspects of the moral experience that s can be isolated to one specific region of the brain. The mPFC by itself cannot be called the location of the self. In a review paper section titled “Is the mPFC the self?” Heatherton (2011) explains: “the experience of the self involves various sensory, of affective, and motor processes contributed by disparate brain regions outside the cortical midline area [containing the mPFC]” (p. 370). For example, an early finding identified the mPFC as the most active when Western individuals were asked to think ro about themselves in terms of abstract personality traits. But when this same task was given to a Chinese sample, the activation in the mPFC was much weaker. This is consistent with the idea that individuals with an interdependent conception of the self (one tightly connected to others) do not think of themselves as much in terms of lP abstract personality traits (Kitayama et al., 2019).16 In short, to find those aspects of the brain that underlie the experience of the self, one must look to a system of structures, processes, and functions, some of which may be distributed across multiple individuals (via e.g. BB synchrony) and cannot be precisely localized even in any one brain. na 2.4.1 Self-­Knowledge Research has shown that the mPFC is strongly related to semantic knowledge about the self. Most studies that compare thinking about the self with thinking about other things or people identify the mPFC as showing heightened activity for thinking about Fi the self.17 Beer (1999) proposes that the high “resting metabolic rate” of the mPFC suggests that it is involved in the constant self-­evaluation that accompanies our 15 Non-­self-­conscious or outwardly focused emotions (e.g. vicarious anger, empathy) can also guide moral action, and their ability to promote moral action may be related to ­self-­concept in a more complex manner (e.g. by reducing inhibition to action). However, these influences are speculative, and there is little to no neuroscience research that investigates them. 16 We should note that though this assumes collectivist societies consist of many people with interdependent views of the self, the picture is more complicated. Latin American societies are strongly collectivist, but they also emphasize an independent view of the self (Krys, 2022) 17 See Heatherton (2011) for a review and Mitchell et al. (2005) for divergent findings that show mPFC occasionally involved in judging others, even dogs. Taking Moral Action everyday activity. The range of self-­evaluative tasks that have been shown to involve the mPFC (free-­form reflection, self-­referential memory, self-­judgment all show activation of mPFC; mindfulness meditation shows deactivation) and the deficits shown with damage to this area (memory for personal preferences and other self-­knowledge) all suggest that this area is central in processing knowledge (and likely moral knowledge) about the self (Heatherton, 2011). One must be careful in making broad claims. Kitayama et al. (2019) review evidence that these patterns differ markedly across cultures, and that the ventro-­mPFC (vmPFC) is less active when thinking about the self in cultures where the self is typically interdependent, though in Latin American cultures these aspects seem to be independent (Krys, 2022). 2.4.2 Self-­Conscious Emotion s Self-­conscious emotion is a response to an appraisal of some threat to the self or of some incentive for the self (see Chapter 8 for how appraisal works). This distinction of between threat and incentive is based on Higgins’s (1997) distinction between promotion and prevention goals. Promotion goals seem to be associated with heightened activity in the left orbital and mPFC, areas associated with processing reward information and self-­referential knowledge respectively (Eddington et al., 2007; Strauman et al., 2012). ro Not surprisingly, the amygdala is involved when threats are detected and prevention becomes important. But it seems to be the anterior cingulate cortex (ACC) – immediately adjacent to the mPFC with its self-­relevant functions – that regulates the lP connection between the mPFC and the amygdala in the regulation of threatening social emotion (Heatherton, 2011; Strauman et al., 2012). Thus, the psychological processes associated with promotion and prevention goals seem to be subserved by different neural circuitry and therefore the evaluation and pursuit of these different goals may differ qualitatively.18 But work needs to be done before one can make such na strong conclusions. To complicate matters, these brain areas do their work in concert with a range of other areas. For instance, another area in the frontal cortex (the orbito-­frontal cortex, OFC) seems to be involved in the appraisal process for social emotions (Beer, 2007; Beer, Lombardo, & Bhanji, 2010). Damage to this area produces patients who can Fi generate social emotions but often the inappropriate ones. Yet another complication is that the ACC seems to do its threat-­detection work differentially in those with low self-­esteem (much more active in response) than in those with normal or high self-­ esteem (Somerville et al., 2006). Thus, it seems we have a complex of areas in the midline of the cortex (mPFC, ACC, OFC, but also amygdala) that are centrally involved in mediating the self’s involvement in moral perception, reaction, and action. They act in concert but they are not isolated from much other activity. We are only beginning to understand how this activity might be related to the self and to moral action. Constructing that understanding will likely involve identifying shifting neural systems over the timescale of the experience. 18 See Chapter 9 for more explanation about these different motivational and self-­regulatory systems. Neuroscience 39 2.5 Skills and Knowledge Since moral action implies agency, skill is inevitably implicated. Skill is involved not only in executing action but also in perceiving the need or opportunity for it, ­evaluating ­possibilities, and planning for action. Skill is also involved in the emotional regulation associated with effective social action, and its neural underpinning can differ depending on the shape emotional regulation takes in different cultures (Kitayama et al., 2019, p. 95). It is well established that increases in training (e.g. comparing novices to experts in some area) can produce increases in the size, density, and/or reactivity of related brain areas that serve the skill (one example of a general process called neuroplasticity). This has been replicated in music (Herdener et al., 2010; Kleber et al., 2009), motor skill and motivational aspects of skill training (Boyke et al., 2008), perception s (Herdener et al., 2010), and even compassion meditation (Lutz et al., 2009; for a review, see Tang, Holzel, & Posner, 2015). As a habit develops based on repeated practice, its neural underpinnings shift from of the cortical networks associated with goal-­driven action control to the habit-­based sensorimotor cortico-­basal ganglia (Wood, Mazar, & Neal, 2021, p. 3). Computational models suggest that movement back and forth between goal-­based and habit-­based ro action could take multiple forms, allowing one to think of the two systems as either separate or as tightly conjoined (Wood et al., 2021, p. 4). Basso et al. (2020) review evidence that dance and associated BB synchrony facilitate group cohesion and that the cortico-­spinal tract in dancers and athletes shows increased organization. This lP suggests yet another expansion of neural areas related to moral action. The evidence that different kinds of expertise produce a wide variety of changes at the neuroanatomical level suggests that we need to expand dramatically our map of those brain areas that support the wide variety of moral action. To the extent that particular skills and expertise are inextricably intertwined with moral goals (e.g. compassion, the design of safe computing systems, supporting group functioning) it is na difficult to argue that the neural systems that support these skills are not parts of the “moral brain.” This expansion of the territory of the moral brain opens the door to a host of other neuroscience findings in cognition, learning, habit, expertise, and emotion. As moral judgment and decision-­making is pushed into automatic skills and habits, so also their neural underpinnings must be expanded into those brain areas Fi serving those processes. This expansion may be so large that it might be better to stop talking about particular areas being most associated with abstract-­level morality.19 2.6 Moral Reason Long considered the paragon and defining characteristic of morality, reason has been somewhat under siege (Haidt, 2010; Narvaez, 2010). The recent spate of neuroscience findings linking emotion centers to moral judgment has been one of the driving 19 For instance, Ellemers and van Nunspeet (2020) review work showing that conformity changes brain activity associated with visual perception, indicating that social influence may change the way we perceive the world, and providing yet another expansion of the moral brain. Taking Moral Action forces in this assault (Greene & Haidt, 2002; Greene et al., 2001). Here we review work that tries to isolate or characterize the role of reason in moral action by identifying its neural correlates. 2.6.1 Pure Reason Work in the neuro-­economics tradition by Shenhav and Greene (2010) tracks the neural underpinnings of the mental calculation of expected moral value, a combination of the magnitude of a possible moral loss/gain and the probability of that loss/ gain. Changes in expected moral value are particularly related to the vmPFC, and the medial OFC (mOFC). In this study, individuals made judgments about expected moral value while being presented with a range of possible values of magnitude in gain/loss and probability. This design allowed the researchers to show that these s structures were particularly sensitive to changes in these values. The pattern of results suggests that these calculations of moral value are done using the same processes that of other work has found to be active in more straightforward self-­interested economic decision-­making. This particular value tracking is, they argue, not a specialized moral calculation but a more general-­purpose process. Shenhav and Greene (2010) also tracked the individual differences that might lead ro one person to be more utilitarian in their approach than another. Individuals who are more likely to hew closely to utilitarian judgments show more activation in the OFC. This activation seems to be in line with the association of the OFC in identifying and modulating emotional reactions (Beer, Knight, & D’Espositio, 2006). Perhaps the lP people doing pure utilitarian calculations were better at blocking out emotional reactions. 2.6.2 Balancing Reason and (Social/Emotional) Reward na The utilitarians in Shanhav and Greene’s (2010) study seem to be blocking out emotional input in favor of a stark, mathematical moral calculus. But clearly others are including emotional aspects in their judgment. Is including emotion in moral judgment a good thing, or should all moral judgment instead resemble the pure utilitarians just discussed? Fi Extensive work in developmental psychology on risk-­taking in adolescence can provide some enlightenment here. Why are adolescents more willing to take risks, particularly when they are together with their friends? There appear to be two different systems involved in calculations of risk: a socio-­emotional dopaminergic reward-­seeking system (centering on the limbic system) and a cognitive control network involving planning, thinking ahead, and self-­regulation (Steinberg, 2007). The emotional system develops earlier, and excessive risk-­taking in adolescence seems to be associated with the imbalance between socio-­emotional reward for risk and cognitive control that might (but cannot yet) modulate it. It is achieving the balance between these systems that produces adult-­level risk-­taking. Adolescent reasoning ability, considered alone, is comparable to adults, but adolescents find the psychosocial rewards associated with risk (particularly risk taken in peer groups) to be more alluring (Steinberg, 2007). It is the development of the planning, thinking ahead, and self-­regulation networks that allows the balance between socio-­emotional reward and logical reasoning to happen. Neuroscience 41 Thus, is not either emotional reward or calculated caution but an appropriate balance between them. This is reminiscent of the admonition in Aristotle (340 BCE/1941, 1106a31–1106b8) that virtue is found in the median, but that the median can be different for different people and in different situations.20 2.6.3 Blending Reason and Emotion Earlier work in moral neuroscience (Greene et al., 2001) has characterized emotion and reason as playing competitive roles in determining moral judgment and action. But we do not need to construct the relation between emotion and reason as competitive. The work reviewed earlier by Shenhav and Greene (2010) and Steinberg (2007) can also be construed as detailing how emotion/reward/escape and reason/ planning/cognitive control are appropriately blended together to influence judgment s and action. This is also the approach that Beer et al. (2006) take in their work. Complex moral motivations and values are represented as configurations of declaraof tive content and emotion. Moll et al. (2003, 2009) emphasize the cooperative ­interaction of cognition and emotion in their model of moral judgment and track the various neural components underlying each. Moll et al. (2006) demonstrated that different cognitive-­emotional complexes (considered at the psychological level) are ro selectively activated (measured as fMRI activation in areas associated with emotion or reason) in decisions to donate to charities with which one agrees or disagrees (e.g. regarding abortion). Thus, cultural knowledge, self-­knowledge, and emotion (e.g. anticipatory guilt vs. anticipatory disgust) combine into “cognitive emotional lP complexes” that are balanced or play off against one another.21 Of course, reason and emotion can also be blended through the feedback loops associated with what has been called “embodied emotion,” the “perceptual, somatovisceral, and motoric” aspects of the ‘feelyness’ of an emotion that are perceived and then integrated into moral judgment and action” (Niedenthal, 2007, p. 1002). Ellemers and colleagues na also emphasize the interaction and balance between reason and emotion (Ellemers et al., 2019; Ellemers & van Nunspeet, 2020). In Cohen’s (2005, p. 4) words, “most evaluations – from the most primitive to the most sophisticated – engage multiple different brain systems” (see also Cushman, Young, & Greene, 2010; Pessoa, 2008). Fi 2.6.4 Planning for Cognitive-­Emotional Effectiveness How do we attempt to make these balances appropriate to the situation and to our abilities? We have some knowledge of the neural systems that help internally in making this balance, such as the orbitofrontal cortex (Beer et al., 2006). And it seems that generating options and choosing among them are separate actions with somewhat separate neural underpinning (Morris et al., 2021), with option generation being constrained by “cached value estimates” based on past experience. 20 Aristotle explicitly includes appropriate emotion in his description of the characteristics of a virtuous act. 21 Note that this balance of complex influences is some justification for the complex model of consistency that we present in Chapter 5, and for the idea of “reflective socio-­emotional reflective equilibrium” presented in Chapters 8 and 9. Taking Moral Action Cohen (2005) argues that we use training programs and other social structures to give us the appropriate experiences (and thus cached value estimates) that help to shape our decision-­making. That is, we structure our environments to support the balancing of influences as we learn to make decisions. Thus, the causal sequence that allows for balance runs outside the brain and the person, into the situation and culture: For example, the specialized training given to doctors and soldiers involves the cultivation of mechanisms for averting or overcoming strong emotional responses that may interfere with their professional functions.22 These mechanisms may not rely directly on the prefrontal cortex; instead, they may involve the training of other lower-­level mechanisms specific to the particular circumstances involved23 (Cohen, 2005, p. 19) s Some of the processes to which Cohen refers here are social structures like training programs that “overtrain” particular responses such as procedures in surgery, rescue, of or battle. But someone must plan the procedures and assess them. Cohen continues: “Importantly, however, the social structures that devised and support the training procedures almost certainly did rely on the prefrontal cortex” (Cohen, 2005, p. 19). These planned social structures then influence the individual as he or she performs ro the planned action. This planning ahead to shape our future responses has been called “situational self-­control” and has been shown to be quite effective (Duckworth, Gendler, & Gross, 2016). Thus, reasoning can be seen as something that helps to construct the future envilP ronment in order to train and to circumscribe future cognitive-­emotional processing.24 Oddly enough, this cultural emphasis of reason over emotion may itself be an achievement of reason in the service of training ourselves to better balance cognition and emotion in moral action. na 2.7 Moral Emotion 2.7.1 Emotion as Bias One of the main reasons that emotion has been seen as the enemy of thoughtful Fi moral judgment is that an emotion-­free standard has been assumed by early theories of moral judgment (Lapsley & Narvaez, 2005), though, of course, similar assumptions 22 Cold scientific rationality can, on the other hand, sabotage the physician–patient relationship. The technically competent doctor may appear to lack “respect and empathy” for the patient if they do not address the existential threat that the patient is experiencing (Agledahl et al., 2011). There is a new movement in physician training that focuses on integrating concern for existential and spiritual aspects in physician–patient interactions (Paal, Helo, & Frick, 2015). Again, emotion and reason regulate each other. 23 We disagree with Cohen’s implication that this sort of planning is needed to circumscribe only those problems associated with emotion. As we explain in Chapter 7, we should also beware of the significant failings associated with reason. 24 One pathology of this balance can be seen in post-­traumatic stress disorder (PTSD) symptoms of dissociation of emotion and reason with regard to particular domains associated with the traumatic experience (Butollo et al., 2015). Neuroscience 43 reach back to the pre-­Socratic philosophers. And emotion can indeed bias evaluation. Particularly when we are highly partisan, the way we evaluate information is driven by our emotional opposition (or commitment) to our partisan positions. Westen et al. (2006) asked political partisans to judge information that was threatening to their preferred candidate in a presidential election. They documented the neural underpinnings of a two-­stage process: first an emotional response to the negative information, activating the mPFC and vmPFC, followed by a reward system activation (caudate nucleus) as soon as they had assimilated and explained away the threat. Thus, emotion seems to be at least part of the “push” associated with implicit evaluation. Luo et al. (2006) have tracked the neural correlates of emotional engagement in what has been called the implicit association test (IAT). This involves pairing the target judgment (in this case pictures of legal or illegal behavior) with emotionally congruent pictures (positive valence animals, e.g. puppies) or incongruent (negative s valence animals, e.g. snakes). Participants were then asked to make a judgment about the behavior. Reaction times for these judgments were slower on incongruent trials of than on congruent ones. This suggests that the emotional incongruence is interfering with the response. Participants are not aware of this difference and even when instructed and given practice, cannot easily influence it (Steffens, 2004). Luo et al. (2006) found that amygdala response correlated with the intensity of the stimulus ro and of the IAT effect. This suggests that it is the amygdala that is involved in the emotional “push” to the implicit judgment that is tracked by the IAT, presumably as part of some larger evaluative system (Barrett, 2017). These emotion-­laden judgments can also drive our desire to punish others (or at lP least those who deserve it). Though we have a range of rational theories available to explain why punishment is a good thing to do (e.g. deterrence), in the end we punish people (or judge other’s punishment to be good) because it feels good to us. The perception of unfairness activates emotion centers such as the anterior insula (Sanfey et al., 2003) and administering punishment to an individual who deserves it activates na reward centers such as the nucleus accumbens (Strobel et al., 2011). This does not, of course, resolve ethical puzzles about justifiable punishment, but it does suggest that we find it rewarding to punish those who deserve it. Even given the significant role that emotional reaction might play in biasing judgment, it is possible to reappraise the causes of our emotional reactions (when we are Fi aware of them) or to attempt to suppress them. Reappraisal involves reinterpreting the emotion-­inducing event as something different, while suppression involves simply attempting not to experience the emotion. Most research has shown that reappraisal is more effective in controlling emotional reactions than is repression (Quirk & Beer, 2006). These two approaches to emotional regulation have different neural components that interestingly track their different outcomes. Goldin et al. (2008) had participants watch negative emotion-­arousing film clips and asked them to either reappraise the emotion or suppress it. Different parts of the PFC were involved in reappraisal and suppression. In reappraisal, these areas were active early in the clip, reduced their activity as the clip continued, and showed suppressed activity in the amygdala throughout the clip. But suppression showed PFC activity increasing over the course of the film, along with increased amygdala activity. This complex pattern shows the role that various interacting networks play in constructing our experience of emotion and its meaning (Lebois et al., 2020). Taking Moral Action 2.7.2 Questioning the Cognitive/Emotion Distinction The complex relationship of emotion to perception, judgment, and action and the dense interconnectedness of “emotional” and “cognitive” structures in the brain has led some to call for abandonment of the cognition/emotion dichotomy, at least at the structural neural level. Pessoa (2008, 2009) provides three neuroscientific reasons why the dichotomy does not stand scrutiny. Brain areas that are often labeled as “affective” are often also involved in cognition, and similarly, areas labeled cognitive are involved in affective reactions. Finally, cognition and emotion are integrated in the brain, both behaviorally in that evaluations involve both affective and cognitive areas, and structurally in that connection maps of these areas show little separation and massive interconnectivity. (See also Barrett, 2009 for a parallel view.) This complex interaction between reason and emotion is the basis for the approach to moral s emotion that we review in Chapters 7 and 8. We reviewed in Section 2.6.3 the work of Moll and colleagues (Moll et al., 2002, of 2003, 2006, 2009;) on cognitive-­emotional complexes. Complex moral motivations and values are represented as configurations of declarative content and emotion (Moll et al., 2009). Thus, the cognitive-­emotional complexes for attachment/compassion and for anger/disgust may be separable from each other, but they are not easily separo rable into emotional and cognitive components. This seems congruent with the difficulty we have in separating emotion from reason in our decision-­making. Perhaps we can conclude that it is not the primacy or autonomy of reason that drives human morality and makes humans unique among species but the unique ability to link emolP tional and motivational states to abstract ideas. It is reason and emotion, as they interact to construct our evaluations and our motivations toward action (Barrett, 2013; Lebois et al., 2020; Lindquist et al., 2012). And here lies one central challenge of moral acting. na 2.8 Moral Formation Chapter 9 discusses in depth how we learn skills and adopt values in order to become more moral. Part of this process involves training our self-­regulation skills. As we have Fi outlined it in Chapter 9, performing and planning is about both short-­and long-­term self-­regulation. By self-­regulation we do not mean simply self-­control (suppression or distraction or reappraisal of incompatible responses to a goal) but all the goal-­directed activity that is relevant to the moral life. This includes metacognition, self-­reflection, and moral creativity in planning at both projects and a life-­goals levels. It also includes the planning and execution of behavioral initiation, maintenance, and habit (Rothman et al., 2011), and what the philosopher Frankfurt (1971) has called second-­order volitions, or “wanting to have (or not have) certain desires and motives” (p. 7) (see also Lapsley, 2008). This also includes how the stories we construct about ourselves affect and guide our moral identity and action (McAdams, 2009). Almost all of these psychological processes are highly abstract, involving complex metacognition and self-­reflection, etc., which makes it difficult to track them with current fMRI or other neuroscience methods (Barrett, 2009; Pessoa, 2008). Though we can measure the extent of neural activity in a place, we can only “read its content” Neuroscience 45 to the extent that changes in the task we give a subject will produce changes in ­localization. And this only allows us to infer that something about the difference in conditions produced the change in localization. Thus, a great deal of work has been done about the neural underpinnings of emotional regulation (Damasio, 1994; Heatherton, 2011; McRae, Ochsner, & Gross, 2011; Quirk & Beer, 2006) but very little about the higher-­order concepts listed earlier (Heatherton, 2011). For the rare exception to this rule, see the work of Eddington et al. (2007); and Strauman et al. (2012), which not surprisingly implicates the PFC in tracking aspirational goals. Cohen (2005) observes that we use reason (and the PFC) to construct the environment in order to train the self, but beyond that useful observation he provides no suggestion about how one might track the neural underpinnings of this process. One might expect that the affective-­cognitive complexes that Moll et al. (2009) identify may play a significant role in this process, s and the decision paradigm they use to track the neural correlates of charitable giving over short periods of time could provide a template for work in long-­term self-­ of regulation. Alternatively, the work on the development of cognitive control networks in adolescence (Blakemore & Choudhury, 2006; Kuhn, 2006; Steinberg, 2007) might provide another paradigm for beginning research in this area. Finally, the constructivist understanding of how situated emotions (e.g. social vs. physical fear) are ro learned may give some insight into how different framing of emotions can help to shape them and their neural underpinnings (Lebois et al., 2020). There is much systematic work to be done in this area if the measurement and methodology hurdles can be overcome. lP 2.8.1 Empathy We not only think about others we also feel with and for them, one of the important markers for moral emotions. How do the feelings of others become connected to our na own? A remapping of internal sense information in the insular cortex (located between the frontal and temporal lobes) has been proposed as the basis for the conscious awareness of how we feel, that is, for the “feelyness” of our emotions (Damasio, 1994). But this area where our feelings are represented to ourselves is also activated by many tasks that involve thinking about or perceiving other people (Adolphs, 2009). This Fi parallel activation suggests that a kind of internal mapping of others’ feelings onto our own feelings helps to account for the sharing of emotions we call empathy (Adolphs, 2009). It also connects with the more complex description of emotion in Chapter 8 as involving the interpretation of perceived reality. We have long known that people in cooperative interactions tend to synchronize their behavior patterns with each other (Bernieri & Rosenthal, 1991). Recent work has shown that this non-­verbal matching is underpinned by what, as discussed in Section 2."
2,2.4,"Interpersonal Neuroscience It is now possible to track how two or more brains show synchrony in patterns of activity, opening the possibly of a truly interpersonal neuroscience (Pan, Novembre, & Olsson, 2021).11 This brain-­to-­brain synchrony (BB synchrony) has been shown to strongly correlate with social learning in dyads and even at the classroom level (Pan et al., 2021). Facial, voice, and movement cues seem foundational in this process of s establishing synchrony, and synchrony occurs at behavioral, affective, perceptual, and neural levels (e.g. emotional contagion is associated with neural synchrony or entrainof ment) (Wheatley et al., 2011). BB synchrony, but not self-­reported group identification, has been shown to predict team performance in both an economic game and problem-­solving tasks. Basso, Satyal, and Rugh (2020) collate evidence suggesting that BB synchrony is important in shared dance, helping to explain the social synchroro nizing function of shared dance and movement (e.g. ritual, folk dance, etc.) across cultures. lP 2.2.5 The Mutual Constitution of Brain and Cultural Processes Kitayama et al. (2019, p. 80), in a review of cultural neuroscience, collate the empirical evidence for a claim long dominant in cultural anthropology. Their summary of the claim is worth quoting at some length: na the body (and now the brain as well) is closely attuned to the sociocultural environment, while at the same time … autonomous, thereby constituting agency, being capable of producing volitional actions, which can lead to changes in the environment from which the agency has been derived. This circular or recursive process occurs continuously, not only in each person’s lifetime but also across generations, … giving rise to changes in both historical and Fi evolutionary timescales. [emphasis ours] The central point here is the close attunement and mutual influence of brain–body systems and cultural systems. Cultural systems both resist change and provide resources for individuals and groups to produce change. Individuals can both resist and seek individual change using resources available to them from culture. Each one influences and structures the other over both short and long timescales. 11 The methods for tracking synchrony involve some measurement of activity, e.g. electroencephalogram (EEG) or fMRI or functional near-­infrared spectroscopy (fNIRS, a less invasive approach in which the subject wears a cap that tracks brain activity in a similar, but less detailed, way to fMRI). Mathematical models are then used to highlight parallelism in activity between two or more brains in people who are interacting. Neuroscience 35 In summary, we can see that social influence and moral ecology are attuned to brain processes and systems at many different levels. This ranges from low-­level mirroring of motor action, to the mirroring of feeling states, to fears of social sanction from others and cognition about others to synchronization of movement, affect, and intention. This attunement to moral ecology provides the support and channel for effective volitional action within that moral ecology. 2.3 Personality The attempt to connect personality to physiological processes is as old as the classical Greek theories of the humors (Zuckerman, 1995). The human body was thought to contain four kinds of humors (fluids) and various personality traits (e.g. melancholy) s were thought to be associated with imbalances in these humors. But it is only with the recent, rapid development of neuroscience measurement techniques that we have of been able to make some empirical progress in actually evaluating proposed theoretical connections. We call the enduring patterns of how individuals relate to the world their personality. This corresponds to the organizing question in Chapter 4: What does a person ro like me do in a situation like this?12 These enduring patterns structure moral action at three levels. Traits (e.g. extraversion, cynicism) describe broad patterns of individual consistency across time and situation. Characteristic adaptations (such as personal projects, life goals) provide a more fine-­grained analysis of patterns of consistency. A lP final level of personality consists of the patterns in the narratives we construct to seek out and identify meaning in our lives. These are unique to each individual, but one can find patterns even here – e.g. people differ in the kinds of themes they include in their life stories (McAdams, 2009). Most of the work we review has been done at the level of traits, and almost nothing na has been done at other levels of personality, such as narrative. De Young and Gray (2009) provide a useful overview of various theorists’ claims about the relation of personality to neuroscience and state that it is simply too early in personality neuroscience to link neural structure to the more specific levels of personality – e.g. personal adaptations and narrative (McAdams & Olson, 2010). These levels are heavily Fi dependent on personal developmental trajectory and unique cultural surround and it will likely be difficult, though not impossible, to connect them to neural structure. Markett, Montag, and Reuter (2018) propose a move in personality neuroscience similar to that documented in Section 2.2: looking for the patterns not in particular brain structures but in networks of brain structures as they interact across time. In a movement in that direction, Wright et al. (2019) provide evidence that differences in serotonin functioning (and thus the systems implicated in this functioning) underlie differences on the personality meta-­trait of stability.13 But beyond this, we are currently limited to looking at associations with particular structures. 12 Both how I characteristically view myself and how I characteristically view situations are enduring aspects of my personality. 13 Consisting of three – conscientiousness, agreeableness, and neuroticism (reverse coded) – of the “Big-­5” personality traits. Taking Moral Action Although alternative models are still occasionally floated (Zuckerman, 1995), the most widely accepted structure for a trait-­level description of personality is the “Big 5” (McCrae & Costa, 1997). Recent work with structural MRI scans by deYoung et al. (2010) provides a comprehensive view of the relationship of the size14 of particular neural structures associated with differences in the Big 5 personality traits, replicating findings from other work. They found clear associations for four of the Big 5 traits (openness to experience had less firm, but still suggestive, patterns). For instance, individuals high in extraversion tended to have a larger medial orbitofrontal cortex, an area involved in assessing the reward value of stimuli. Those individuals scoring higher in agreeableness tended to have smaller posterior left superior temporal sulci (plSTS) – an area associated with inferring intention based on patterns of movement – and to have a larger posterior cingulate (PC) – an area associated with understanding other’s beliefs. The functions associated with these areas are crucial perceptual s and cognitive components of empathy. Individuals high in conscientiousness tended to have larger middle frontal gyri – an area of the frontal cortex that is central in mainof taining working memory and executing planned action. Finally, individuals high in neuroticism had a more complex pattern of structure, with some structures being smaller and others larger but all associated with emotional sensitivity to threat and punishment (DeYoung et al., 2010). ro Note the pattern of the scientific inference in all these claims: (1) a correlation of a personality trait with size of a structure is reported (agreeableness with the plSTS); (2) the structure itself is then characterized in terms of other functions that might explain the correlation (tracking intention is associated with plSTS). Thus, we know lP that higher scores on both agreeableness and altruism are related to a brain structure associated with inferring intention (Tankersley, Stowe, & Huettel, 2007). But that does not make the plSTS the “altruism center.” Tracking intention and understanding other’s beliefs are only a part of the larger complex of coordinated activity that supports altruistic action. The larger personality aspect of altruism is not identical to or na reducible to the specific brain structure. But we can tie particular aspects of the neurological activity to specific aspects of the psychological function. More recent work that maps psychological constructs at the neural level shows how extraordinary altruism is supported by the functional neural processes that underlie empathy. Individuals who have taken the unusual step of donating a kidney to a stranFi ger have been shown to have a greater overlap of activation in the anterior insula for fearful stimuli not only for the self but also for others (as compared to matched controls). The suggestion is that this activation is one aspect of an “affective salience network” that is more responsive to harm in others than usual (Brethel-­Haurwitz et al., 2018, p. 1638). Again, we see aspects of psychological processes for empathy underpinned by distributed networks associated with psychological functions. 14 DeYoung (2010) provides a useful discussion about whether the volume of an area is the right metric for measuring its relative performance of a function. We agree that simple interpretations of volume leave much to be desired, and remind one of earlier, discredited phrenological approaches. But we also note that there does seem to be a replicable association of size with personality functions. As with all work in this area, scientific humility is in order. Neuroscience 37 2.4 Moral Identity and the Self The moral self-­concept, or moral identity, has begun to play an increasing role in explanations of why people take moral action. There are two aspects of the self that allow it to become involved in influencing moral action: (1) the content and structure of self-­knowledge; and (2) those self-­conscious emotions (pride, embarrassment) that guide action and action planning.15 Self-­knowledge and self-­conscious emotion are linked because we can think about ourselves over time and reflect on our reactions to evaluations by ourself and by others (Leary, 2007). One particular brain structure is closely associated with tasks that involve moral self-­concept: the medial prefrontal cortex (mPFC). Still, though self-­related tasks show heightened mPFC activity, there are few aspects of the moral experience that s can be isolated to one specific region of the brain. The mPFC by itself cannot be called the location of the self. In a review paper section titled “Is the mPFC the self?” Heatherton (2011) explains: “the experience of the self involves various sensory, of affective, and motor processes contributed by disparate brain regions outside the cortical midline area [containing the mPFC]” (p. 370). For example, an early finding identified the mPFC as the most active when Western individuals were asked to think ro about themselves in terms of abstract personality traits. But when this same task was given to a Chinese sample, the activation in the mPFC was much weaker. This is consistent with the idea that individuals with an interdependent conception of the self (one tightly connected to others) do not think of themselves as much in terms of lP abstract personality traits (Kitayama et al., 2019).16 In short, to find those aspects of the brain that underlie the experience of the self, one must look to a system of structures, processes, and functions, some of which may be distributed across multiple individuals (via e.g. BB synchrony) and cannot be precisely localized even in any one brain. na 2.4.1 Self-­Knowledge Research has shown that the mPFC is strongly related to semantic knowledge about the self. Most studies that compare thinking about the self with thinking about other things or people identify the mPFC as showing heightened activity for thinking about Fi the self.17 Beer (1999) proposes that the high “resting metabolic rate” of the mPFC suggests that it is involved in the constant self-­evaluation that accompanies our 15 Non-­self-­conscious or outwardly focused emotions (e.g. vicarious anger, empathy) can also guide moral action, and their ability to promote moral action may be related to ­self-­concept in a more complex manner (e.g. by reducing inhibition to action). However, these influences are speculative, and there is little to no neuroscience research that investigates them. 16 We should note that though this assumes collectivist societies consist of many people with interdependent views of the self, the picture is more complicated. Latin American societies are strongly collectivist, but they also emphasize an independent view of the self (Krys, 2022) 17 See Heatherton (2011) for a review and Mitchell et al. (2005) for divergent findings that show mPFC occasionally involved in judging others, even dogs. Taking Moral Action everyday activity. The range of self-­evaluative tasks that have been shown to involve the mPFC (free-­form reflection, self-­referential memory, self-­judgment all show activation of mPFC; mindfulness meditation shows deactivation) and the deficits shown with damage to this area (memory for personal preferences and other self-­knowledge) all suggest that this area is central in processing knowledge (and likely moral knowledge) about the self (Heatherton, 2011). One must be careful in making broad claims. Kitayama et al. (2019) review evidence that these patterns differ markedly across cultures, and that the ventro-­mPFC (vmPFC) is less active when thinking about the self in cultures where the self is typically interdependent, though in Latin American cultures these aspects seem to be independent (Krys, 2022). 2.4.2 Self-­Conscious Emotion s Self-­conscious emotion is a response to an appraisal of some threat to the self or of some incentive for the self (see Chapter 8 for how appraisal works). This distinction of between threat and incentive is based on Higgins’s (1997) distinction between promotion and prevention goals. Promotion goals seem to be associated with heightened activity in the left orbital and mPFC, areas associated with processing reward information and self-­referential knowledge respectively (Eddington et al., 2007; Strauman et al., 2012). ro Not surprisingly, the amygdala is involved when threats are detected and prevention becomes important. But it seems to be the anterior cingulate cortex (ACC) – immediately adjacent to the mPFC with its self-­relevant functions – that regulates the lP connection between the mPFC and the amygdala in the regulation of threatening social emotion (Heatherton, 2011; Strauman et al., 2012). Thus, the psychological processes associated with promotion and prevention goals seem to be subserved by different neural circuitry and therefore the evaluation and pursuit of these different goals may differ qualitatively.18 But work needs to be done before one can make such na strong conclusions. To complicate matters, these brain areas do their work in concert with a range of other areas. For instance, another area in the frontal cortex (the orbito-­frontal cortex, OFC) seems to be involved in the appraisal process for social emotions (Beer, 2007; Beer, Lombardo, & Bhanji, 2010). Damage to this area produces patients who can Fi generate social emotions but often the inappropriate ones. Yet another complication is that the ACC seems to do its threat-­detection work differentially in those with low self-­esteem (much more active in response) than in those with normal or high self-­ esteem (Somerville et al., 2006). Thus, it seems we have a complex of areas in the midline of the cortex (mPFC, ACC, OFC, but also amygdala) that are centrally involved in mediating the self’s involvement in moral perception, reaction, and action. They act in concert but they are not isolated from much other activity. We are only beginning to understand how this activity might be related to the self and to moral action. Constructing that understanding will likely involve identifying shifting neural systems over the timescale of the experience. 18 See Chapter 9 for more explanation about these different motivational and self-­regulatory systems. Neuroscience 39"
2,2.5,"The Mutual Constitution of Brain and Cultural Processes Kitayama et al. (2019, p. 80), in a review of cultural neuroscience, collate the empirical evidence for a claim long dominant in cultural anthropology. Their summary of the claim is worth quoting at some length: na the body (and now the brain as well) is closely attuned to the sociocultural environment, while at the same time … autonomous, thereby constituting agency, being capable of producing volitional actions, which can lead to changes in the environment from which the agency has been derived. This circular or recursive process occurs continuously, not only in each person’s lifetime but also across generations, … giving rise to changes in both historical and Fi evolutionary timescales. [emphasis ours] The central point here is the close attunement and mutual influence of brain–body systems and cultural systems. Cultural systems both resist change and provide resources for individuals and groups to produce change. Individuals can both resist and seek individual change using resources available to them from culture. Each one influences and structures the other over both short and long timescales. 11 The methods for tracking synchrony involve some measurement of activity, e.g. electroencephalogram (EEG) or fMRI or functional near-­infrared spectroscopy (fNIRS, a less invasive approach in which the subject wears a cap that tracks brain activity in a similar, but less detailed, way to fMRI). Mathematical models are then used to highlight parallelism in activity between two or more brains in people who are interacting. Neuroscience 35 In summary, we can see that social influence and moral ecology are attuned to brain processes and systems at many different levels. This ranges from low-­level mirroring of motor action, to the mirroring of feeling states, to fears of social sanction from others and cognition about others to synchronization of movement, affect, and intention. This attunement to moral ecology provides the support and channel for effective volitional action within that moral ecology. 2.3 Personality The attempt to connect personality to physiological processes is as old as the classical Greek theories of the humors (Zuckerman, 1995). The human body was thought to contain four kinds of humors (fluids) and various personality traits (e.g. melancholy) s were thought to be associated with imbalances in these humors. But it is only with the recent, rapid development of neuroscience measurement techniques that we have of been able to make some empirical progress in actually evaluating proposed theoretical connections. We call the enduring patterns of how individuals relate to the world their personality. This corresponds to the organizing question in Chapter 4: What does a person ro like me do in a situation like this?12 These enduring patterns structure moral action at three levels. Traits (e.g. extraversion, cynicism) describe broad patterns of individual consistency across time and situation. Characteristic adaptations (such as personal projects, life goals) provide a more fine-­grained analysis of patterns of consistency. A lP final level of personality consists of the patterns in the narratives we construct to seek out and identify meaning in our lives. These are unique to each individual, but one can find patterns even here – e.g. people differ in the kinds of themes they include in their life stories (McAdams, 2009). Most of the work we review has been done at the level of traits, and almost nothing na has been done at other levels of personality, such as narrative. De Young and Gray (2009) provide a useful overview of various theorists’ claims about the relation of personality to neuroscience and state that it is simply too early in personality neuroscience to link neural structure to the more specific levels of personality – e.g. personal adaptations and narrative (McAdams & Olson, 2010). These levels are heavily Fi dependent on personal developmental trajectory and unique cultural surround and it will likely be difficult, though not impossible, to connect them to neural structure. Markett, Montag, and Reuter (2018) propose a move in personality neuroscience similar to that documented in Section 2.2: looking for the patterns not in particular brain structures but in networks of brain structures as they interact across time. In a movement in that direction, Wright et al. (2019) provide evidence that differences in serotonin functioning (and thus the systems implicated in this functioning) underlie differences on the personality meta-­trait of stability.13 But beyond this, we are currently limited to looking at associations with particular structures. 12 Both how I characteristically view myself and how I characteristically view situations are enduring aspects of my personality. 13 Consisting of three – conscientiousness, agreeableness, and neuroticism (reverse coded) – of the “Big-­5” personality traits. Taking Moral Action Although alternative models are still occasionally floated (Zuckerman, 1995), the most widely accepted structure for a trait-­level description of personality is the “Big 5” (McCrae & Costa, 1997). Recent work with structural MRI scans by deYoung et al. (2010) provides a comprehensive view of the relationship of the size14 of particular neural structures associated with differences in the Big 5 personality traits, replicating findings from other work. They found clear associations for four of the Big 5 traits (openness to experience had less firm, but still suggestive, patterns). For instance, individuals high in extraversion tended to have a larger medial orbitofrontal cortex, an area involved in assessing the reward value of stimuli. Those individuals scoring higher in agreeableness tended to have smaller posterior left superior temporal sulci (plSTS) – an area associated with inferring intention based on patterns of movement – and to have a larger posterior cingulate (PC) – an area associated with understanding other’s beliefs. The functions associated with these areas are crucial perceptual s and cognitive components of empathy. Individuals high in conscientiousness tended to have larger middle frontal gyri – an area of the frontal cortex that is central in mainof taining working memory and executing planned action. Finally, individuals high in neuroticism had a more complex pattern of structure, with some structures being smaller and others larger but all associated with emotional sensitivity to threat and punishment (DeYoung et al., 2010). ro Note the pattern of the scientific inference in all these claims: (1) a correlation of a personality trait with size of a structure is reported (agreeableness with the plSTS); (2) the structure itself is then characterized in terms of other functions that might explain the correlation (tracking intention is associated with plSTS). Thus, we know lP that higher scores on both agreeableness and altruism are related to a brain structure associated with inferring intention (Tankersley, Stowe, & Huettel, 2007). But that does not make the plSTS the “altruism center.” Tracking intention and understanding other’s beliefs are only a part of the larger complex of coordinated activity that supports altruistic action. The larger personality aspect of altruism is not identical to or na reducible to the specific brain structure. But we can tie particular aspects of the neurological activity to specific aspects of the psychological function. More recent work that maps psychological constructs at the neural level shows how extraordinary altruism is supported by the functional neural processes that underlie empathy. Individuals who have taken the unusual step of donating a kidney to a stranFi ger have been shown to have a greater overlap of activation in the anterior insula for fearful stimuli not only for the self but also for others (as compared to matched controls). The suggestion is that this activation is one aspect of an “affective salience network” that is more responsive to harm in others than usual (Brethel-­Haurwitz et al., 2018, p. 1638). Again, we see aspects of psychological processes for empathy underpinned by distributed networks associated with psychological functions. 14 DeYoung (2010) provides a useful discussion about whether the volume of an area is the right metric for measuring its relative performance of a function. We agree that simple interpretations of volume leave much to be desired, and remind one of earlier, discredited phrenological approaches. But we also note that there does seem to be a replicable association of size with personality functions. As with all work in this area, scientific humility is in order. Neuroscience 37 2.4 Moral Identity and the Self The moral self-­concept, or moral identity, has begun to play an increasing role in explanations of why people take moral action. There are two aspects of the self that allow it to become involved in influencing moral action: (1) the content and structure of self-­knowledge; and (2) those self-­conscious emotions (pride, embarrassment) that guide action and action planning.15 Self-­knowledge and self-­conscious emotion are linked because we can think about ourselves over time and reflect on our reactions to evaluations by ourself and by others (Leary, 2007). One particular brain structure is closely associated with tasks that involve moral self-­concept: the medial prefrontal cortex (mPFC). Still, though self-­related tasks show heightened mPFC activity, there are few aspects of the moral experience that s can be isolated to one specific region of the brain. The mPFC by itself cannot be called the location of the self. In a review paper section titled “Is the mPFC the self?” Heatherton (2011) explains: “the experience of the self involves various sensory, of affective, and motor processes contributed by disparate brain regions outside the cortical midline area [containing the mPFC]” (p. 370). For example, an early finding identified the mPFC as the most active when Western individuals were asked to think ro about themselves in terms of abstract personality traits. But when this same task was given to a Chinese sample, the activation in the mPFC was much weaker. This is consistent with the idea that individuals with an interdependent conception of the self (one tightly connected to others) do not think of themselves as much in terms of lP abstract personality traits (Kitayama et al., 2019).16 In short, to find those aspects of the brain that underlie the experience of the self, one must look to a system of structures, processes, and functions, some of which may be distributed across multiple individuals (via e.g. BB synchrony) and cannot be precisely localized even in any one brain. na 2.4.1 Self-­Knowledge Research has shown that the mPFC is strongly related to semantic knowledge about the self. Most studies that compare thinking about the self with thinking about other things or people identify the mPFC as showing heightened activity for thinking about Fi the self.17 Beer (1999) proposes that the high “resting metabolic rate” of the mPFC suggests that it is involved in the constant self-­evaluation that accompanies our 15 Non-­self-­conscious or outwardly focused emotions (e.g. vicarious anger, empathy) can also guide moral action, and their ability to promote moral action may be related to ­self-­concept in a more complex manner (e.g. by reducing inhibition to action). However, these influences are speculative, and there is little to no neuroscience research that investigates them. 16 We should note that though this assumes collectivist societies consist of many people with interdependent views of the self, the picture is more complicated. Latin American societies are strongly collectivist, but they also emphasize an independent view of the self (Krys, 2022) 17 See Heatherton (2011) for a review and Mitchell et al. (2005) for divergent findings that show mPFC occasionally involved in judging others, even dogs. Taking Moral Action everyday activity. The range of self-­evaluative tasks that have been shown to involve the mPFC (free-­form reflection, self-­referential memory, self-­judgment all show activation of mPFC; mindfulness meditation shows deactivation) and the deficits shown with damage to this area (memory for personal preferences and other self-­knowledge) all suggest that this area is central in processing knowledge (and likely moral knowledge) about the self (Heatherton, 2011). One must be careful in making broad claims. Kitayama et al. (2019) review evidence that these patterns differ markedly across cultures, and that the ventro-­mPFC (vmPFC) is less active when thinking about the self in cultures where the self is typically interdependent, though in Latin American cultures these aspects seem to be independent (Krys, 2022). 2.4.2 Self-­Conscious Emotion s Self-­conscious emotion is a response to an appraisal of some threat to the self or of some incentive for the self (see Chapter 8 for how appraisal works). This distinction of between threat and incentive is based on Higgins’s (1997) distinction between promotion and prevention goals. Promotion goals seem to be associated with heightened activity in the left orbital and mPFC, areas associated with processing reward information and self-­referential knowledge respectively (Eddington et al., 2007; Strauman et al., 2012). ro Not surprisingly, the amygdala is involved when threats are detected and prevention becomes important. But it seems to be the anterior cingulate cortex (ACC) – immediately adjacent to the mPFC with its self-­relevant functions – that regulates the lP connection between the mPFC and the amygdala in the regulation of threatening social emotion (Heatherton, 2011; Strauman et al., 2012). Thus, the psychological processes associated with promotion and prevention goals seem to be subserved by different neural circuitry and therefore the evaluation and pursuit of these different goals may differ qualitatively.18 But work needs to be done before one can make such na strong conclusions. To complicate matters, these brain areas do their work in concert with a range of other areas. For instance, another area in the frontal cortex (the orbito-­frontal cortex, OFC) seems to be involved in the appraisal process for social emotions (Beer, 2007; Beer, Lombardo, & Bhanji, 2010). Damage to this area produces patients who can Fi generate social emotions but often the inappropriate ones. Yet another complication is that the ACC seems to do its threat-­detection work differentially in those with low self-­esteem (much more active in response) than in those with normal or high self-­ esteem (Somerville et al., 2006). Thus, it seems we have a complex of areas in the midline of the cortex (mPFC, ACC, OFC, but also amygdala) that are centrally involved in mediating the self’s involvement in moral perception, reaction, and action. They act in concert but they are not isolated from much other activity. We are only beginning to understand how this activity might be related to the self and to moral action. Constructing that understanding will likely involve identifying shifting neural systems over the timescale of the experience. 18 See Chapter 9 for more explanation about these different motivational and self-­regulatory systems. Neuroscience 39 2.5 Skills and Knowledge Since moral action implies agency, skill is inevitably implicated. Skill is involved not only in executing action but also in perceiving the need or opportunity for it, ­evaluating ­possibilities, and planning for action. Skill is also involved in the emotional regulation associated with effective social action, and its neural underpinning can differ depending on the shape emotional regulation takes in different cultures (Kitayama et al., 2019, p. 95). It is well established that increases in training (e.g. comparing novices to experts in some area) can produce increases in the size, density, and/or reactivity of related brain areas that serve the skill (one example of a general process called neuroplasticity). This has been replicated in music (Herdener et al., 2010; Kleber et al., 2009), motor skill and motivational aspects of skill training (Boyke et al., 2008), perception s (Herdener et al., 2010), and even compassion meditation (Lutz et al., 2009; for a review, see Tang, Holzel, & Posner, 2015). As a habit develops based on repeated practice, its neural underpinnings shift from of the cortical networks associated with goal-­driven action control to the habit-­based sensorimotor cortico-­basal ganglia (Wood, Mazar, & Neal, 2021, p. 3). Computational models suggest that movement back and forth between goal-­based and habit-­based ro action could take multiple forms, allowing one to think of the two systems as either separate or as tightly conjoined (Wood et al., 2021, p. 4). Basso et al. (2020) review evidence that dance and associated BB synchrony facilitate group cohesion and that the cortico-­spinal tract in dancers and athletes shows increased organization. This lP suggests yet another expansion of neural areas related to moral action. The evidence that different kinds of expertise produce a wide variety of changes at the neuroanatomical level suggests that we need to expand dramatically our map of those brain areas that support the wide variety of moral action. To the extent that particular skills and expertise are inextricably intertwined with moral goals (e.g. compassion, the design of safe computing systems, supporting group functioning) it is na difficult to argue that the neural systems that support these skills are not parts of the “moral brain.” This expansion of the territory of the moral brain opens the door to a host of other neuroscience findings in cognition, learning, habit, expertise, and emotion. As moral judgment and decision-­making is pushed into automatic skills and habits, so also their neural underpinnings must be expanded into those brain areas Fi serving those processes. This expansion may be so large that it might be better to stop talking about particular areas being most associated with abstract-­level morality.19 2.6 Moral Reason Long considered the paragon and defining characteristic of morality, reason has been somewhat under siege (Haidt, 2010; Narvaez, 2010). The recent spate of neuroscience findings linking emotion centers to moral judgment has been one of the driving 19 For instance, Ellemers and van Nunspeet (2020) review work showing that conformity changes brain activity associated with visual perception, indicating that social influence may change the way we perceive the world, and providing yet another expansion of the moral brain. Taking Moral Action forces in this assault (Greene & Haidt, 2002; Greene et al., 2001). Here we review work that tries to isolate or characterize the role of reason in moral action by identifying its neural correlates. 2.6.1 Pure Reason Work in the neuro-­economics tradition by Shenhav and Greene (2010) tracks the neural underpinnings of the mental calculation of expected moral value, a combination of the magnitude of a possible moral loss/gain and the probability of that loss/ gain. Changes in expected moral value are particularly related to the vmPFC, and the medial OFC (mOFC). In this study, individuals made judgments about expected moral value while being presented with a range of possible values of magnitude in gain/loss and probability. This design allowed the researchers to show that these s structures were particularly sensitive to changes in these values. The pattern of results suggests that these calculations of moral value are done using the same processes that of other work has found to be active in more straightforward self-­interested economic decision-­making. This particular value tracking is, they argue, not a specialized moral calculation but a more general-­purpose process. Shenhav and Greene (2010) also tracked the individual differences that might lead ro one person to be more utilitarian in their approach than another. Individuals who are more likely to hew closely to utilitarian judgments show more activation in the OFC. This activation seems to be in line with the association of the OFC in identifying and modulating emotional reactions (Beer, Knight, & D’Espositio, 2006). Perhaps the lP people doing pure utilitarian calculations were better at blocking out emotional reactions. 2.6.2 Balancing Reason and (Social/Emotional) Reward na The utilitarians in Shanhav and Greene’s (2010) study seem to be blocking out emotional input in favor of a stark, mathematical moral calculus. But clearly others are including emotional aspects in their judgment. Is including emotion in moral judgment a good thing, or should all moral judgment instead resemble the pure utilitarians just discussed? Fi Extensive work in developmental psychology on risk-­taking in adolescence can provide some enlightenment here. Why are adolescents more willing to take risks, particularly when they are together with their friends? There appear to be two different systems involved in calculations of risk: a socio-­emotional dopaminergic reward-­seeking system (centering on the limbic system) and a cognitive control network involving planning, thinking ahead, and self-­regulation (Steinberg, 2007). The emotional system develops earlier, and excessive risk-­taking in adolescence seems to be associated with the imbalance between socio-­emotional reward for risk and cognitive control that might (but cannot yet) modulate it. It is achieving the balance between these systems that produces adult-­level risk-­taking. Adolescent reasoning ability, considered alone, is comparable to adults, but adolescents find the psychosocial rewards associated with risk (particularly risk taken in peer groups) to be more alluring (Steinberg, 2007). It is the development of the planning, thinking ahead, and self-­regulation networks that allows the balance between socio-­emotional reward and logical reasoning to happen. Neuroscience 41 Thus, is not either emotional reward or calculated caution but an appropriate balance between them. This is reminiscent of the admonition in Aristotle (340 BCE/1941, 1106a31–1106b8) that virtue is found in the median, but that the median can be different for different people and in different situations.20 2.6.3 Blending Reason and Emotion Earlier work in moral neuroscience (Greene et al., 2001) has characterized emotion and reason as playing competitive roles in determining moral judgment and action. But we do not need to construct the relation between emotion and reason as competitive. The work reviewed earlier by Shenhav and Greene (2010) and Steinberg (2007) can also be construed as detailing how emotion/reward/escape and reason/ planning/cognitive control are appropriately blended together to influence judgment s and action. This is also the approach that Beer et al. (2006) take in their work. Complex moral motivations and values are represented as configurations of declaraof tive content and emotion. Moll et al. (2003, 2009) emphasize the cooperative ­interaction of cognition and emotion in their model of moral judgment and track the various neural components underlying each. Moll et al. (2006) demonstrated that different cognitive-­emotional complexes (considered at the psychological level) are ro selectively activated (measured as fMRI activation in areas associated with emotion or reason) in decisions to donate to charities with which one agrees or disagrees (e.g. regarding abortion). Thus, cultural knowledge, self-­knowledge, and emotion (e.g. anticipatory guilt vs. anticipatory disgust) combine into “cognitive emotional lP complexes” that are balanced or play off against one another.21 Of course, reason and emotion can also be blended through the feedback loops associated with what has been called “embodied emotion,” the “perceptual, somatovisceral, and motoric” aspects of the ‘feelyness’ of an emotion that are perceived and then integrated into moral judgment and action” (Niedenthal, 2007, p. 1002). Ellemers and colleagues na also emphasize the interaction and balance between reason and emotion (Ellemers et al., 2019; Ellemers & van Nunspeet, 2020). In Cohen’s (2005, p. 4) words, “most evaluations – from the most primitive to the most sophisticated – engage multiple different brain systems” (see also Cushman, Young, & Greene, 2010; Pessoa, 2008). Fi 2.6.4 Planning for Cognitive-­Emotional Effectiveness How do we attempt to make these balances appropriate to the situation and to our abilities? We have some knowledge of the neural systems that help internally in making this balance, such as the orbitofrontal cortex (Beer et al., 2006). And it seems that generating options and choosing among them are separate actions with somewhat separate neural underpinning (Morris et al., 2021), with option generation being constrained by “cached value estimates” based on past experience. 20 Aristotle explicitly includes appropriate emotion in his description of the characteristics of a virtuous act. 21 Note that this balance of complex influences is some justification for the complex model of consistency that we present in Chapter 5, and for the idea of “reflective socio-­emotional reflective equilibrium” presented in Chapters 8 and 9. Taking Moral Action Cohen (2005) argues that we use training programs and other social structures to give us the appropriate experiences (and thus cached value estimates) that help to shape our decision-­making. That is, we structure our environments to support the balancing of influences as we learn to make decisions. Thus, the causal sequence that allows for balance runs outside the brain and the person, into the situation and culture: For example, the specialized training given to doctors and soldiers involves the cultivation of mechanisms for averting or overcoming strong emotional responses that may interfere with their professional functions.22 These mechanisms may not rely directly on the prefrontal cortex; instead, they may involve the training of other lower-­level mechanisms specific to the particular circumstances involved23 (Cohen, 2005, p. 19) s Some of the processes to which Cohen refers here are social structures like training programs that “overtrain” particular responses such as procedures in surgery, rescue, of or battle. But someone must plan the procedures and assess them. Cohen continues: “Importantly, however, the social structures that devised and support the training procedures almost certainly did rely on the prefrontal cortex” (Cohen, 2005, p. 19). These planned social structures then influence the individual as he or she performs ro the planned action. This planning ahead to shape our future responses has been called “situational self-­control” and has been shown to be quite effective (Duckworth, Gendler, & Gross, 2016). Thus, reasoning can be seen as something that helps to construct the future envilP ronment in order to train and to circumscribe future cognitive-­emotional processing.24 Oddly enough, this cultural emphasis of reason over emotion may itself be an achievement of reason in the service of training ourselves to better balance cognition and emotion in moral action. na 2.7 Moral Emotion 2.7.1 Emotion as Bias One of the main reasons that emotion has been seen as the enemy of thoughtful Fi moral judgment is that an emotion-­free standard has been assumed by early theories of moral judgment (Lapsley & Narvaez, 2005), though, of course, similar assumptions 22 Cold scientific rationality can, on the other hand, sabotage the physician–patient relationship. The technically competent doctor may appear to lack “respect and empathy” for the patient if they do not address the existential threat that the patient is experiencing (Agledahl et al., 2011). There is a new movement in physician training that focuses on integrating concern for existential and spiritual aspects in physician–patient interactions (Paal, Helo, & Frick, 2015). Again, emotion and reason regulate each other. 23 We disagree with Cohen’s implication that this sort of planning is needed to circumscribe only those problems associated with emotion. As we explain in Chapter 7, we should also beware of the significant failings associated with reason. 24 One pathology of this balance can be seen in post-­traumatic stress disorder (PTSD) symptoms of dissociation of emotion and reason with regard to particular domains associated with the traumatic experience (Butollo et al., 2015). Neuroscience 43 reach back to the pre-­Socratic philosophers. And emotion can indeed bias evaluation. Particularly when we are highly partisan, the way we evaluate information is driven by our emotional opposition (or commitment) to our partisan positions. Westen et al. (2006) asked political partisans to judge information that was threatening to their preferred candidate in a presidential election. They documented the neural underpinnings of a two-­stage process: first an emotional response to the negative information, activating the mPFC and vmPFC, followed by a reward system activation (caudate nucleus) as soon as they had assimilated and explained away the threat. Thus, emotion seems to be at least part of the “push” associated with implicit evaluation. Luo et al. (2006) have tracked the neural correlates of emotional engagement in what has been called the implicit association test (IAT). This involves pairing the target judgment (in this case pictures of legal or illegal behavior) with emotionally congruent pictures (positive valence animals, e.g. puppies) or incongruent (negative s valence animals, e.g. snakes). Participants were then asked to make a judgment about the behavior. Reaction times for these judgments were slower on incongruent trials of than on congruent ones. This suggests that the emotional incongruence is interfering with the response. Participants are not aware of this difference and even when instructed and given practice, cannot easily influence it (Steffens, 2004). Luo et al. (2006) found that amygdala response correlated with the intensity of the stimulus ro and of the IAT effect. This suggests that it is the amygdala that is involved in the emotional “push” to the implicit judgment that is tracked by the IAT, presumably as part of some larger evaluative system (Barrett, 2017). These emotion-­laden judgments can also drive our desire to punish others (or at lP least those who deserve it). Though we have a range of rational theories available to explain why punishment is a good thing to do (e.g. deterrence), in the end we punish people (or judge other’s punishment to be good) because it feels good to us. The perception of unfairness activates emotion centers such as the anterior insula (Sanfey et al., 2003) and administering punishment to an individual who deserves it activates na reward centers such as the nucleus accumbens (Strobel et al., 2011). This does not, of course, resolve ethical puzzles about justifiable punishment, but it does suggest that we find it rewarding to punish those who deserve it. Even given the significant role that emotional reaction might play in biasing judgment, it is possible to reappraise the causes of our emotional reactions (when we are Fi aware of them) or to attempt to suppress them. Reappraisal involves reinterpreting the emotion-­inducing event as something different, while suppression involves simply attempting not to experience the emotion. Most research has shown that reappraisal is more effective in controlling emotional reactions than is repression (Quirk & Beer, 2006). These two approaches to emotional regulation have different neural components that interestingly track their different outcomes. Goldin et al. (2008) had participants watch negative emotion-­arousing film clips and asked them to either reappraise the emotion or suppress it. Different parts of the PFC were involved in reappraisal and suppression. In reappraisal, these areas were active early in the clip, reduced their activity as the clip continued, and showed suppressed activity in the amygdala throughout the clip. But suppression showed PFC activity increasing over the course of the film, along with increased amygdala activity. This complex pattern shows the role that various interacting networks play in constructing our experience of emotion and its meaning (Lebois et al., 2020). Taking Moral Action 2.7.2 Questioning the Cognitive/Emotion Distinction The complex relationship of emotion to perception, judgment, and action and the dense interconnectedness of “emotional” and “cognitive” structures in the brain has led some to call for abandonment of the cognition/emotion dichotomy, at least at the structural neural level. Pessoa (2008, 2009) provides three neuroscientific reasons why the dichotomy does not stand scrutiny. Brain areas that are often labeled as “affective” are often also involved in cognition, and similarly, areas labeled cognitive are involved in affective reactions. Finally, cognition and emotion are integrated in the brain, both behaviorally in that evaluations involve both affective and cognitive areas, and structurally in that connection maps of these areas show little separation and massive interconnectivity. (See also Barrett, 2009 for a parallel view.) This complex interaction between reason and emotion is the basis for the approach to moral s emotion that we review in Chapters 7 and 8. We reviewed in Section"
2,2.6,"Moral Reason Long considered the paragon and defining characteristic of morality, reason has been somewhat under siege (Haidt, 2010; Narvaez, 2010). The recent spate of neuroscience findings linking emotion centers to moral judgment has been one of the driving 19 For instance, Ellemers and van Nunspeet (2020) review work showing that conformity changes brain activity associated with visual perception, indicating that social influence may change the way we perceive the world, and providing yet another expansion of the moral brain. Taking Moral Action forces in this assault (Greene & Haidt, 2002; Greene et al., 2001). Here we review work that tries to isolate or characterize the role of reason in moral action by identifying its neural correlates. 2.6.1 Pure Reason Work in the neuro-­economics tradition by Shenhav and Greene (2010) tracks the neural underpinnings of the mental calculation of expected moral value, a combination of the magnitude of a possible moral loss/gain and the probability of that loss/ gain. Changes in expected moral value are particularly related to the vmPFC, and the medial OFC (mOFC). In this study, individuals made judgments about expected moral value while being presented with a range of possible values of magnitude in gain/loss and probability. This design allowed the researchers to show that these s structures were particularly sensitive to changes in these values. The pattern of results suggests that these calculations of moral value are done using the same processes that of other work has found to be active in more straightforward self-­interested economic decision-­making. This particular value tracking is, they argue, not a specialized moral calculation but a more general-­purpose process. Shenhav and Greene (2010) also tracked the individual differences that might lead ro one person to be more utilitarian in their approach than another. Individuals who are more likely to hew closely to utilitarian judgments show more activation in the OFC. This activation seems to be in line with the association of the OFC in identifying and modulating emotional reactions (Beer, Knight, & D’Espositio, 2006). Perhaps the lP people doing pure utilitarian calculations were better at blocking out emotional reactions. 2.6.2 Balancing Reason and (Social/Emotional) Reward na The utilitarians in Shanhav and Greene’s (2010) study seem to be blocking out emotional input in favor of a stark, mathematical moral calculus. But clearly others are including emotional aspects in their judgment. Is including emotion in moral judgment a good thing, or should all moral judgment instead resemble the pure utilitarians just discussed? Fi Extensive work in developmental psychology on risk-­taking in adolescence can provide some enlightenment here. Why are adolescents more willing to take risks, particularly when they are together with their friends? There appear to be two different systems involved in calculations of risk: a socio-­emotional dopaminergic reward-­seeking system (centering on the limbic system) and a cognitive control network involving planning, thinking ahead, and self-­regulation (Steinberg, 2007). The emotional system develops earlier, and excessive risk-­taking in adolescence seems to be associated with the imbalance between socio-­emotional reward for risk and cognitive control that might (but cannot yet) modulate it. It is achieving the balance between these systems that produces adult-­level risk-­taking. Adolescent reasoning ability, considered alone, is comparable to adults, but adolescents find the psychosocial rewards associated with risk (particularly risk taken in peer groups) to be more alluring (Steinberg, 2007). It is the development of the planning, thinking ahead, and self-­regulation networks that allows the balance between socio-­emotional reward and logical reasoning to happen. Neuroscience 41 Thus, is not either emotional reward or calculated caution but an appropriate balance between them. This is reminiscent of the admonition in Aristotle (340 BCE/1941, 1106a31–1106b8) that virtue is found in the median, but that the median can be different for different people and in different situations.20 2.6.3 Blending Reason and Emotion Earlier work in moral neuroscience (Greene et al., 2001) has characterized emotion and reason as playing competitive roles in determining moral judgment and action. But we do not need to construct the relation between emotion and reason as competitive. The work reviewed earlier by Shenhav and Greene (2010) and Steinberg (2007) can also be construed as detailing how emotion/reward/escape and reason/ planning/cognitive control are appropriately blended together to influence judgment s and action. This is also the approach that Beer et al. (2006) take in their work. Complex moral motivations and values are represented as configurations of declaraof tive content and emotion. Moll et al. (2003, 2009) emphasize the cooperative ­interaction of cognition and emotion in their model of moral judgment and track the various neural components underlying each. Moll et al. (2006) demonstrated that different cognitive-­emotional complexes (considered at the psychological level) are ro selectively activated (measured as fMRI activation in areas associated with emotion or reason) in decisions to donate to charities with which one agrees or disagrees (e.g. regarding abortion). Thus, cultural knowledge, self-­knowledge, and emotion (e.g. anticipatory guilt vs. anticipatory disgust) combine into “cognitive emotional lP complexes” that are balanced or play off against one another.21 Of course, reason and emotion can also be blended through the feedback loops associated with what has been called “embodied emotion,” the “perceptual, somatovisceral, and motoric” aspects of the ‘feelyness’ of an emotion that are perceived and then integrated into moral judgment and action” (Niedenthal, 2007, p. 1002). Ellemers and colleagues na also emphasize the interaction and balance between reason and emotion (Ellemers et al., 2019; Ellemers & van Nunspeet, 2020). In Cohen’s (2005, p. 4) words, “most evaluations – from the most primitive to the most sophisticated – engage multiple different brain systems” (see also Cushman, Young, & Greene, 2010; Pessoa, 2008). Fi 2.6.4 Planning for Cognitive-­Emotional Effectiveness How do we attempt to make these balances appropriate to the situation and to our abilities? We have some knowledge of the neural systems that help internally in making this balance, such as the orbitofrontal cortex (Beer et al., 2006). And it seems that generating options and choosing among them are separate actions with somewhat separate neural underpinning (Morris et al., 2021), with option generation being constrained by “cached value estimates” based on past experience. 20 Aristotle explicitly includes appropriate emotion in his description of the characteristics of a virtuous act. 21 Note that this balance of complex influences is some justification for the complex model of consistency that we present in Chapter 5, and for the idea of “reflective socio-­emotional reflective equilibrium” presented in Chapters 8 and 9. Taking Moral Action Cohen (2005) argues that we use training programs and other social structures to give us the appropriate experiences (and thus cached value estimates) that help to shape our decision-­making. That is, we structure our environments to support the balancing of influences as we learn to make decisions. Thus, the causal sequence that allows for balance runs outside the brain and the person, into the situation and culture: For example, the specialized training given to doctors and soldiers involves the cultivation of mechanisms for averting or overcoming strong emotional responses that may interfere with their professional functions.22 These mechanisms may not rely directly on the prefrontal cortex; instead, they may involve the training of other lower-­level mechanisms specific to the particular circumstances involved23 (Cohen, 2005, p. 19) s Some of the processes to which Cohen refers here are social structures like training programs that “overtrain” particular responses such as procedures in surgery, rescue, of or battle. But someone must plan the procedures and assess them. Cohen continues: “Importantly, however, the social structures that devised and support the training procedures almost certainly did rely on the prefrontal cortex” (Cohen, 2005, p. 19). These planned social structures then influence the individual as he or she performs ro the planned action. This planning ahead to shape our future responses has been called “situational self-­control” and has been shown to be quite effective (Duckworth, Gendler, & Gross, 2016). Thus, reasoning can be seen as something that helps to construct the future envilP ronment in order to train and to circumscribe future cognitive-­emotional processing.24 Oddly enough, this cultural emphasis of reason over emotion may itself be an achievement of reason in the service of training ourselves to better balance cognition and emotion in moral action. na 2.7 Moral Emotion 2.7.1 Emotion as Bias One of the main reasons that emotion has been seen as the enemy of thoughtful Fi moral judgment is that an emotion-­free standard has been assumed by early theories of moral judgment (Lapsley & Narvaez, 2005), though, of course, similar assumptions 22 Cold scientific rationality can, on the other hand, sabotage the physician–patient relationship. The technically competent doctor may appear to lack “respect and empathy” for the patient if they do not address the existential threat that the patient is experiencing (Agledahl et al., 2011). There is a new movement in physician training that focuses on integrating concern for existential and spiritual aspects in physician–patient interactions (Paal, Helo, & Frick, 2015). Again, emotion and reason regulate each other. 23 We disagree with Cohen’s implication that this sort of planning is needed to circumscribe only those problems associated with emotion. As we explain in Chapter 7, we should also beware of the significant failings associated with reason. 24 One pathology of this balance can be seen in post-­traumatic stress disorder (PTSD) symptoms of dissociation of emotion and reason with regard to particular domains associated with the traumatic experience (Butollo et al., 2015). Neuroscience 43 reach back to the pre-­Socratic philosophers. And emotion can indeed bias evaluation. Particularly when we are highly partisan, the way we evaluate information is driven by our emotional opposition (or commitment) to our partisan positions. Westen et al. (2006) asked political partisans to judge information that was threatening to their preferred candidate in a presidential election. They documented the neural underpinnings of a two-­stage process: first an emotional response to the negative information, activating the mPFC and vmPFC, followed by a reward system activation (caudate nucleus) as soon as they had assimilated and explained away the threat. Thus, emotion seems to be at least part of the “push” associated with implicit evaluation. Luo et al. (2006) have tracked the neural correlates of emotional engagement in what has been called the implicit association test (IAT). This involves pairing the target judgment (in this case pictures of legal or illegal behavior) with emotionally congruent pictures (positive valence animals, e.g. puppies) or incongruent (negative s valence animals, e.g. snakes). Participants were then asked to make a judgment about the behavior. Reaction times for these judgments were slower on incongruent trials of than on congruent ones. This suggests that the emotional incongruence is interfering with the response. Participants are not aware of this difference and even when instructed and given practice, cannot easily influence it (Steffens, 2004). Luo et al. (2006) found that amygdala response correlated with the intensity of the stimulus ro and of the IAT effect. This suggests that it is the amygdala that is involved in the emotional “push” to the implicit judgment that is tracked by the IAT, presumably as part of some larger evaluative system (Barrett, 2017). These emotion-­laden judgments can also drive our desire to punish others (or at lP least those who deserve it). Though we have a range of rational theories available to explain why punishment is a good thing to do (e.g. deterrence), in the end we punish people (or judge other’s punishment to be good) because it feels good to us. The perception of unfairness activates emotion centers such as the anterior insula (Sanfey et al., 2003) and administering punishment to an individual who deserves it activates na reward centers such as the nucleus accumbens (Strobel et al., 2011). This does not, of course, resolve ethical puzzles about justifiable punishment, but it does suggest that we find it rewarding to punish those who deserve it. Even given the significant role that emotional reaction might play in biasing judgment, it is possible to reappraise the causes of our emotional reactions (when we are Fi aware of them) or to attempt to suppress them. Reappraisal involves reinterpreting the emotion-­inducing event as something different, while suppression involves simply attempting not to experience the emotion. Most research has shown that reappraisal is more effective in controlling emotional reactions than is repression (Quirk & Beer, 2006). These two approaches to emotional regulation have different neural components that interestingly track their different outcomes. Goldin et al. (2008) had participants watch negative emotion-­arousing film clips and asked them to either reappraise the emotion or suppress it. Different parts of the PFC were involved in reappraisal and suppression. In reappraisal, these areas were active early in the clip, reduced their activity as the clip continued, and showed suppressed activity in the amygdala throughout the clip. But suppression showed PFC activity increasing over the course of the film, along with increased amygdala activity. This complex pattern shows the role that various interacting networks play in constructing our experience of emotion and its meaning (Lebois et al., 2020). Taking Moral Action"
2,2.7,"Moral Emotion 2.7.1 Emotion as Bias One of the main reasons that emotion has been seen as the enemy of thoughtful Fi moral judgment is that an emotion-­free standard has been assumed by early theories of moral judgment (Lapsley & Narvaez, 2005), though, of course, similar assumptions 22 Cold scientific rationality can, on the other hand, sabotage the physician–patient relationship. The technically competent doctor may appear to lack “respect and empathy” for the patient if they do not address the existential threat that the patient is experiencing (Agledahl et al., 2011). There is a new movement in physician training that focuses on integrating concern for existential and spiritual aspects in physician–patient interactions (Paal, Helo, & Frick, 2015). Again, emotion and reason regulate each other. 23 We disagree with Cohen’s implication that this sort of planning is needed to circumscribe only those problems associated with emotion. As we explain in Chapter 7, we should also beware of the significant failings associated with reason. 24 One pathology of this balance can be seen in post-­traumatic stress disorder (PTSD) symptoms of dissociation of emotion and reason with regard to particular domains associated with the traumatic experience (Butollo et al., 2015). Neuroscience 43 reach back to the pre-­Socratic philosophers. And emotion can indeed bias evaluation. Particularly when we are highly partisan, the way we evaluate information is driven by our emotional opposition (or commitment) to our partisan positions. Westen et al. (2006) asked political partisans to judge information that was threatening to their preferred candidate in a presidential election. They documented the neural underpinnings of a two-­stage process: first an emotional response to the negative information, activating the mPFC and vmPFC, followed by a reward system activation (caudate nucleus) as soon as they had assimilated and explained away the threat. Thus, emotion seems to be at least part of the “push” associated with implicit evaluation. Luo et al. (2006) have tracked the neural correlates of emotional engagement in what has been called the implicit association test (IAT). This involves pairing the target judgment (in this case pictures of legal or illegal behavior) with emotionally congruent pictures (positive valence animals, e.g. puppies) or incongruent (negative s valence animals, e.g. snakes). Participants were then asked to make a judgment about the behavior. Reaction times for these judgments were slower on incongruent trials of than on congruent ones. This suggests that the emotional incongruence is interfering with the response. Participants are not aware of this difference and even when instructed and given practice, cannot easily influence it (Steffens, 2004). Luo et al. (2006) found that amygdala response correlated with the intensity of the stimulus ro and of the IAT effect. This suggests that it is the amygdala that is involved in the emotional “push” to the implicit judgment that is tracked by the IAT, presumably as part of some larger evaluative system (Barrett, 2017). These emotion-­laden judgments can also drive our desire to punish others (or at lP least those who deserve it). Though we have a range of rational theories available to explain why punishment is a good thing to do (e.g. deterrence), in the end we punish people (or judge other’s punishment to be good) because it feels good to us. The perception of unfairness activates emotion centers such as the anterior insula (Sanfey et al., 2003) and administering punishment to an individual who deserves it activates na reward centers such as the nucleus accumbens (Strobel et al., 2011). This does not, of course, resolve ethical puzzles about justifiable punishment, but it does suggest that we find it rewarding to punish those who deserve it. Even given the significant role that emotional reaction might play in biasing judgment, it is possible to reappraise the causes of our emotional reactions (when we are Fi aware of them) or to attempt to suppress them. Reappraisal involves reinterpreting the emotion-­inducing event as something different, while suppression involves simply attempting not to experience the emotion. Most research has shown that reappraisal is more effective in controlling emotional reactions than is repression (Quirk & Beer, 2006). These two approaches to emotional regulation have different neural components that interestingly track their different outcomes. Goldin et al. (2008) had participants watch negative emotion-­arousing film clips and asked them to either reappraise the emotion or suppress it. Different parts of the PFC were involved in reappraisal and suppression. In reappraisal, these areas were active early in the clip, reduced their activity as the clip continued, and showed suppressed activity in the amygdala throughout the clip. But suppression showed PFC activity increasing over the course of the film, along with increased amygdala activity. This complex pattern shows the role that various interacting networks play in constructing our experience of emotion and its meaning (Lebois et al., 2020). Taking Moral Action 2.7.2 Questioning the Cognitive/Emotion Distinction The complex relationship of emotion to perception, judgment, and action and the dense interconnectedness of “emotional” and “cognitive” structures in the brain has led some to call for abandonment of the cognition/emotion dichotomy, at least at the structural neural level. Pessoa (2008, 2009) provides three neuroscientific reasons why the dichotomy does not stand scrutiny. Brain areas that are often labeled as “affective” are often also involved in cognition, and similarly, areas labeled cognitive are involved in affective reactions. Finally, cognition and emotion are integrated in the brain, both behaviorally in that evaluations involve both affective and cognitive areas, and structurally in that connection maps of these areas show little separation and massive interconnectivity. (See also Barrett, 2009 for a parallel view.) This complex interaction between reason and emotion is the basis for the approach to moral s emotion that we review in Chapters 7 and 8. We reviewed in Section 2.6.3 the work of Moll and colleagues (Moll et al., 2002, of 2003, 2006, 2009;) on cognitive-­emotional complexes. Complex moral motivations and values are represented as configurations of declarative content and emotion (Moll et al., 2009). Thus, the cognitive-­emotional complexes for attachment/compassion and for anger/disgust may be separable from each other, but they are not easily separo rable into emotional and cognitive components. This seems congruent with the difficulty we have in separating emotion from reason in our decision-­making. Perhaps we can conclude that it is not the primacy or autonomy of reason that drives human morality and makes humans unique among species but the unique ability to link emolP tional and motivational states to abstract ideas. It is reason and emotion, as they interact to construct our evaluations and our motivations toward action (Barrett, 2013; Lebois et al., 2020; Lindquist et al., 2012). And here lies one central challenge of moral acting. na 2.8 Moral Formation Chapter 9 discusses in depth how we learn skills and adopt values in order to become more moral. Part of this process involves training our self-­regulation skills. As we have Fi outlined it in Chapter 9, performing and planning is about both short-­and long-­term self-­regulation. By self-­regulation we do not mean simply self-­control (suppression or distraction or reappraisal of incompatible responses to a goal) but all the goal-­directed activity that is relevant to the moral life. This includes metacognition, self-­reflection, and moral creativity in planning at both projects and a life-­goals levels. It also includes the planning and execution of behavioral initiation, maintenance, and habit (Rothman et al., 2011), and what the philosopher Frankfurt (1971) has called second-­order volitions, or “wanting to have (or not have) certain desires and motives” (p. 7) (see also Lapsley, 2008). This also includes how the stories we construct about ourselves affect and guide our moral identity and action (McAdams, 2009). Almost all of these psychological processes are highly abstract, involving complex metacognition and self-­reflection, etc., which makes it difficult to track them with current fMRI or other neuroscience methods (Barrett, 2009; Pessoa, 2008). Though we can measure the extent of neural activity in a place, we can only “read its content” Neuroscience 45 to the extent that changes in the task we give a subject will produce changes in ­localization. And this only allows us to infer that something about the difference in conditions produced the change in localization. Thus, a great deal of work has been done about the neural underpinnings of emotional regulation (Damasio, 1994; Heatherton, 2011; McRae, Ochsner, & Gross, 2011; Quirk & Beer, 2006) but very little about the higher-­order concepts listed earlier (Heatherton, 2011). For the rare exception to this rule, see the work of Eddington et al. (2007); and Strauman et al. (2012), which not surprisingly implicates the PFC in tracking aspirational goals. Cohen (2005) observes that we use reason (and the PFC) to construct the environment in order to train the self, but beyond that useful observation he provides no suggestion about how one might track the neural underpinnings of this process. One might expect that the affective-­cognitive complexes that Moll et al. (2009) identify may play a significant role in this process, s and the decision paradigm they use to track the neural correlates of charitable giving over short periods of time could provide a template for work in long-­term self-­ of regulation. Alternatively, the work on the development of cognitive control networks in adolescence (Blakemore & Choudhury, 2006; Kuhn, 2006; Steinberg, 2007) might provide another paradigm for beginning research in this area. Finally, the constructivist understanding of how situated emotions (e.g. social vs. physical fear) are ro learned may give some insight into how different framing of emotions can help to shape them and their neural underpinnings (Lebois et al., 2020). There is much systematic work to be done in this area if the measurement and methodology hurdles can be overcome. lP 2.8.1 Empathy We not only think about others we also feel with and for them, one of the important markers for moral emotions. How do the feelings of others become connected to our na own? A remapping of internal sense information in the insular cortex (located between the frontal and temporal lobes) has been proposed as the basis for the conscious awareness of how we feel, that is, for the “feelyness” of our emotions (Damasio, 1994). But this area where our feelings are represented to ourselves is also activated by many tasks that involve thinking about or perceiving other people (Adolphs, 2009). This Fi parallel activation suggests that a kind of internal mapping of others’ feelings onto our own feelings helps to account for the sharing of emotions we call empathy (Adolphs, 2009). It also connects with the more complex description of emotion in Chapter 8 as involving the interpretation of perceived reality. We have long known that people in cooperative interactions tend to synchronize their behavior patterns with each other (Bernieri & Rosenthal, 1991). Recent work has shown that this non-­verbal matching is underpinned by what, as discussed in Section 2.2.4, is called BB synchrony. This synchrony is measured with sensitive EEG monitors that simultaneously collect brain activity information from two or more people. It turns out that the matching involved is not simply a matching of brain activation associated with non-­verbal behavior but a matching based on interpersonal social connection. It is seen, for instance, between friends but not strangers, between parents and their children but not others’ children. For instance, in one study romantic couples showed BB synchrony during even short periods of shared gaze and Taking Moral Action positive affect, while strangers needed much longer periods of shared gaze to establish synchrony (Kinreich et al., 2017). This synchrony occurred in the junction between the parietal and temporal lobes, an area that incorporates information from a wide range of other brain systems with functions including perception, emotion, and theory of mind. This tracking of neuro-­synchrony promises to provide an important window on the neural underpinning of empathy shared sociality and to help us understand how the ways that the social world influences the functional neuroscience."
2,2.8,"Moral Formation Chapter 9 discusses in depth how we learn skills and adopt values in order to become more moral. Part of this process involves training our self-­regulation skills. As we have Fi outlined it in Chapter 9, performing and planning is about both short-­and long-­term self-­regulation. By self-­regulation we do not mean simply self-­control (suppression or distraction or reappraisal of incompatible responses to a goal) but all the goal-­directed activity that is relevant to the moral life. This includes metacognition, self-­reflection, and moral creativity in planning at both projects and a life-­goals levels. It also includes the planning and execution of behavioral initiation, maintenance, and habit (Rothman et al., 2011), and what the philosopher Frankfurt (1971) has called second-­order volitions, or “wanting to have (or not have) certain desires and motives” (p. 7) (see also Lapsley, 2008). This also includes how the stories we construct about ourselves affect and guide our moral identity and action (McAdams, 2009). Almost all of these psychological processes are highly abstract, involving complex metacognition and self-­reflection, etc., which makes it difficult to track them with current fMRI or other neuroscience methods (Barrett, 2009; Pessoa, 2008). Though we can measure the extent of neural activity in a place, we can only “read its content” Neuroscience 45 to the extent that changes in the task we give a subject will produce changes in ­localization. And this only allows us to infer that something about the difference in conditions produced the change in localization. Thus, a great deal of work has been done about the neural underpinnings of emotional regulation (Damasio, 1994; Heatherton, 2011; McRae, Ochsner, & Gross, 2011; Quirk & Beer, 2006) but very little about the higher-­order concepts listed earlier (Heatherton, 2011). For the rare exception to this rule, see the work of Eddington et al. (2007); and Strauman et al. (2012), which not surprisingly implicates the PFC in tracking aspirational goals. Cohen (2005) observes that we use reason (and the PFC) to construct the environment in order to train the self, but beyond that useful observation he provides no suggestion about how one might track the neural underpinnings of this process. One might expect that the affective-­cognitive complexes that Moll et al. (2009) identify may play a significant role in this process, s and the decision paradigm they use to track the neural correlates of charitable giving over short periods of time could provide a template for work in long-­term self-­ of regulation. Alternatively, the work on the development of cognitive control networks in adolescence (Blakemore & Choudhury, 2006; Kuhn, 2006; Steinberg, 2007) might provide another paradigm for beginning research in this area. Finally, the constructivist understanding of how situated emotions (e.g. social vs. physical fear) are ro learned may give some insight into how different framing of emotions can help to shape them and their neural underpinnings (Lebois et al., 2020). There is much systematic work to be done in this area if the measurement and methodology hurdles can be overcome. lP 2.8.1 Empathy We not only think about others we also feel with and for them, one of the important markers for moral emotions. How do the feelings of others become connected to our na own? A remapping of internal sense information in the insular cortex (located between the frontal and temporal lobes) has been proposed as the basis for the conscious awareness of how we feel, that is, for the “feelyness” of our emotions (Damasio, 1994). But this area where our feelings are represented to ourselves is also activated by many tasks that involve thinking about or perceiving other people (Adolphs, 2009). This Fi parallel activation suggests that a kind of internal mapping of others’ feelings onto our own feelings helps to account for the sharing of emotions we call empathy (Adolphs, 2009). It also connects with the more complex description of emotion in Chapter 8 as involving the interpretation of perceived reality. We have long known that people in cooperative interactions tend to synchronize their behavior patterns with each other (Bernieri & Rosenthal, 1991). Recent work has shown that this non-­verbal matching is underpinned by what, as discussed in Section 2.2.4, is called BB synchrony. This synchrony is measured with sensitive EEG monitors that simultaneously collect brain activity information from two or more people. It turns out that the matching involved is not simply a matching of brain activation associated with non-­verbal behavior but a matching based on interpersonal social connection. It is seen, for instance, between friends but not strangers, between parents and their children but not others’ children. For instance, in one study romantic couples showed BB synchrony during even short periods of shared gaze and Taking Moral Action positive affect, while strangers needed much longer periods of shared gaze to establish synchrony (Kinreich et al., 2017). This synchrony occurred in the junction between the parietal and temporal lobes, an area that incorporates information from a wide range of other brain systems with functions including perception, emotion, and theory of mind. This tracking of neuro-­synchrony promises to provide an important window on the neural underpinning of empathy shared sociality and to help us understand how the ways that the social world influences the functional neuroscience. 2.8.2 The Value Space of Moral Formation In the formation chapter we track a possible three-­dimensional space within which one might plot various trajectories of moral formation. The first dimension is movement from simple agency to agency in the service of others (Walker & Frimer, 2015). s The second is a (likely flexible) preference for stability vs. change that might shape the way one views the others one wants to serve (Zapko-­Willmes et al., 2021). And the of third is a movement from more exclusive commitments to one’s in-­group towards a more expansive view of who is considered to have high moral priority, termed moral inclusion (Passini & Morselli, 2016). See Chapter 9, Section 9.3.1.3 for an in-­depth explanation of this. ro Two neuroscientific findings seem relevant here. Soutschek et al. (2016) have established the role of the posterior temporo-­parietal junction25 in egocentricity bias in a pro-­social sharing task. When they disrupted the activity of this area, individuals shared less with out-­group members. Sharing was reduced to a smaller extent with lP in-­group members, and not at all for the self. This kind of discounting is likely associated with a more expansive view of who counts morally. Ellemers and van Nunspeet (2020) review evidence that neural areas associated with empathic concern and reward processing are involved in in-­group favoritism and openness to moral feedback from out-­group members, respectively. This begins to give us clues about how na the empathic concern and reward processing might be involved in navigating the value space of moral formation. 2.9 Discussion Fi 2.9.1 Conclusion This somewhat scattered overview of the many different neural contributions to moral perception, judgment, and action has led us over much of the neural landscape, from middle-­level sensory and motor areas to high-­level cognition and emotion. One straightforward conclusion is that when we consider moral action broadly, there is no single “moral center” to the brain. Morality is served by processes and functions that are distributed throughout the brain (also in other parts of our physiology, and indeed in our culture). A second conclusion is that our moral action is neither cold nor hot but a blend of both reason and emotion. A third conclusion is that causal influence in 25 A location thought to be involved in taking the perspective of the future self. Neuroscience 47 moral action is more complicated than simple reductionist models suggest; moral action is structured by our brain’s organization and our brain’s organization is structured by our taking moral action. It is a cycle of influence. 1. There is no moral “center” in the brain. Though neuroscience can help to map the “moral brain,” there is no single neural structure one could identify as the center of morality. Instead, the moral brain seems to show just as rich a pattern of variety on the neural level as moral action does on the psychological and social level, including cultural influences.26 Once we recast our understanding of morality as involving a broad range of influences and processes, as we do in this book, it becomes quite clear that morality is not localized but distributed throughout the body, embodied if you will, as well as embedded in culture.27 It seems to be more a property of the person, like acting and s reacting in the world and culture, than it is a property of specific brain areas or of specific psychological functions. of 2. There is little neurological warrant for a strong reason/emotion dichotomy. The neural basis for our taking moral action is embodied in the neural processes that occur across the massive interconnectivity of the sensory, reason/cognition/ control, emotional, and motor areas of the brain. It is becoming increasingly more ro difficult to sustain the reason vs. emotion dichotomy in descriptions of moral judgment or action. What seems to explain individual variation in morality is less to be found in competing emotion-­reason processes but more in a person’s unique ability to mediate both using personal, social, and cultural resources. This ability, at lP least in adulthood, is not so much a ready-­made capacity but rather a skill that can be practiced.28 Extensive and complicated interconnections among “cognitive” and “emotional” centers are evident in any of the wide range of functions we review here as moral (Pessoa, 2008). This suggests we might be better off talking of affective-­cognitive complexes (Moll et al., 2009) or patterns in brain states na (Barrett, 2009; Pessoa, 2008), or neuro-­synchrony (Kinreich et al., 2017) and encouraging interdisciplinary research into how the achievement of what we call social-­emotional reflective balance is achieved and maintained. It is this regulated balance between emotion and reason, supported by social and cultural resources, that makes human morality unique (and uniquely complicated) rather than the Fi likely unattainable and surely unwise triumph of reason over emotion. 3. Causal models of the neuroscience of morality need to recognize that taking moral action is a property of the person-­in-­context. 26 See Sinnott-­Armstrong (2016) for a comprehensive argument that neither morality nor its neural infrastructure are united in a single system. 27 Because emotion is distributed throughout the body, so is morality through the extended nervous system, its interactions with the endocrine system, and the effects of both on the other tissues of the body (Niedenthal, 2007). 28 See Chapter 9. It is misleading to call this balancing of emotion and rationality “emotional self-­regulation.” We do not seem to have a comparable study of the “self-­regulation of rationality” (though perhaps we should) that would help in establishing this balance. As we see in Chapter 7, rationality can also go horribly astray, and needs somehow to be regulated, perhaps by emotions like compassion. Taking Moral Action Neuro-­ essentialist, reductionist accounts of morality would say that all the ­important action is occurring at a neuronal level (while perhaps including the rest of the body, too). The structure of our moral action is certainly shaped by neural and physiological processes, but understanding this also requires an in-­depth psychological description of moral action. This description is further embedded in processes and structures beyond the person, in groups, organizations, and ­cultures. And all these levels interact in influencing which aspects of which neural networks will be involved in any particular aspect of a moral action. For this reason, we will need to integrate multiple narratives of moral action to help us grasp its complexity: anthropological, sociological, philosophical, and theological narratives.29 These three conclusions are interdependent. The idea that moral processing is distributed across many brain areas implies the conclusion that moral action s depends on a balance or blend of reason and emotion in order to translate one’s moral convictions or moral identity into a skilled action in a certain situation, conof text, and time. The distribution of moral processing is also at least intertwined with the idea that causality can run “outside the brain,” through psychological concepts and plans, to social structures, then return as situational influence on brain processes and even structure. And the conclusion that there is a cycle of influence ro suggests several ways the balance between reason and emotion might be achieved. 2.9.2 Application lP We began this chapter with a sketch of Henry Moliason’s contributions to psychology and neuroscience and will end by applying some of the lessons we have learned in this chapter to understand him. While most of the scholarly conversation about H. M.’s case was centered on his memory, very little of the copious research on his case could have been done if H. M. had lost his social sensitivity. In the New York na Times obituary, H. M. was described as unfailingly polite and welcoming to the troops of researchers who constantly visited him to ask him questions and give him tasks. This positive demeanor was consistent with his earlier character. One might describe this characteristic way of behaving to all as showing evidence of the moral virtue of hospitality.30 This is true despite everyone who entered his house after his Fi 29 For an example of a theological narrative, the heart has been a metaphor for the center of the person at least since early Hebrew scriptures were written (Peters, 1999). The theologian Kierkegaard does probably the earliest modern psychological analysis of morality using this heart metaphor. He describes in some complexity how an individual appropriates knowledge and values, taking them “to heart.” See Chapter 9 for the complexities of this process. This analysis has influenced theologians such as Tillich and, through Tillich, psychologists such as Rollo May and Irvin Yalom (see Furchert, 2011 for an intellectual history of these connections). The neuroscience of cognitive emotional complexes gives us a different view of how this is done. But the subtlety of Kierkegaard’s analysis offers different food for thought regarding the process – food that could result in a harvest of even more understanding (see e.g. Koole, Greenberg, & Pyszczynski, 2006). 30 For those who doubt this is a virtue, it is seen as central in the Abrahamic traditions (e.g. in Christian Benedictine monastic tradition (Merton, 2009) welcoming the stranger is akin to welcoming Christ). Neuroscience 49 surgery being a stranger of sorts to him and so needing to be welcomed anew. His consistent welcome did much for the cause of neuroscience but still cannot be laid entirely at the door of an internal virtue of hospitality. His living arrangement was such that he was constantly attended to by carers and his surrounding kept as similar as possible (given his severe memory problems). It is likely that the research visits were framed by his attendants as something to welcome, and there was a great deal of space in his schedule and support in his environment for the visit. One might say that Henry Molaison was a hospitable person in an environment that leant itself to hospitality."
2,2.9,"Discussion Fi 2.9.1 Conclusion This somewhat scattered overview of the many different neural contributions to moral perception, judgment, and action has led us over much of the neural landscape, from middle-­level sensory and motor areas to high-­level cognition and emotion. One straightforward conclusion is that when we consider moral action broadly, there is no single “moral center” to the brain. Morality is served by processes and functions that are distributed throughout the brain (also in other parts of our physiology, and indeed in our culture). A second conclusion is that our moral action is neither cold nor hot but a blend of both reason and emotion. A third conclusion is that causal influence in 25 A location thought to be involved in taking the perspective of the future self. Neuroscience 47 moral action is more complicated than simple reductionist models suggest; moral action is structured by our brain’s organization and our brain’s organization is structured by our taking moral action. It is a cycle of influence. 1. There is no moral “center” in the brain. Though neuroscience can help to map the “moral brain,” there is no single neural structure one could identify as the center of morality. Instead, the moral brain seems to show just as rich a pattern of variety on the neural level as moral action does on the psychological and social level, including cultural influences.26 Once we recast our understanding of morality as involving a broad range of influences and processes, as we do in this book, it becomes quite clear that morality is not localized but distributed throughout the body, embodied if you will, as well as embedded in culture.27 It seems to be more a property of the person, like acting and s reacting in the world and culture, than it is a property of specific brain areas or of specific psychological functions. of 2. There is little neurological warrant for a strong reason/emotion dichotomy. The neural basis for our taking moral action is embodied in the neural processes that occur across the massive interconnectivity of the sensory, reason/cognition/ control, emotional, and motor areas of the brain. It is becoming increasingly more ro difficult to sustain the reason vs. emotion dichotomy in descriptions of moral judgment or action. What seems to explain individual variation in morality is less to be found in competing emotion-­reason processes but more in a person’s unique ability to mediate both using personal, social, and cultural resources. This ability, at lP least in adulthood, is not so much a ready-­made capacity but rather a skill that can be practiced.28 Extensive and complicated interconnections among “cognitive” and “emotional” centers are evident in any of the wide range of functions we review here as moral (Pessoa, 2008). This suggests we might be better off talking of affective-­cognitive complexes (Moll et al., 2009) or patterns in brain states na (Barrett, 2009; Pessoa, 2008), or neuro-­synchrony (Kinreich et al., 2017) and encouraging interdisciplinary research into how the achievement of what we call social-­emotional reflective balance is achieved and maintained. It is this regulated balance between emotion and reason, supported by social and cultural resources, that makes human morality unique (and uniquely complicated) rather than the Fi likely unattainable and surely unwise triumph of reason over emotion. 3. Causal models of the neuroscience of morality need to recognize that taking moral action is a property of the person-­in-­context. 26 See Sinnott-­Armstrong (2016) for a comprehensive argument that neither morality nor its neural infrastructure are united in a single system. 27 Because emotion is distributed throughout the body, so is morality through the extended nervous system, its interactions with the endocrine system, and the effects of both on the other tissues of the body (Niedenthal, 2007). 28 See Chapter 9. It is misleading to call this balancing of emotion and rationality “emotional self-­regulation.” We do not seem to have a comparable study of the “self-­regulation of rationality” (though perhaps we should) that would help in establishing this balance. As we see in Chapter 7, rationality can also go horribly astray, and needs somehow to be regulated, perhaps by emotions like compassion. Taking Moral Action Neuro-­ essentialist, reductionist accounts of morality would say that all the ­important action is occurring at a neuronal level (while perhaps including the rest of the body, too). The structure of our moral action is certainly shaped by neural and physiological processes, but understanding this also requires an in-­depth psychological description of moral action. This description is further embedded in processes and structures beyond the person, in groups, organizations, and ­cultures. And all these levels interact in influencing which aspects of which neural networks will be involved in any particular aspect of a moral action. For this reason, we will need to integrate multiple narratives of moral action to help us grasp its complexity: anthropological, sociological, philosophical, and theological narratives.29 These three conclusions are interdependent. The idea that moral processing is distributed across many brain areas implies the conclusion that moral action s depends on a balance or blend of reason and emotion in order to translate one’s moral convictions or moral identity into a skilled action in a certain situation, conof text, and time. The distribution of moral processing is also at least intertwined with the idea that causality can run “outside the brain,” through psychological concepts and plans, to social structures, then return as situational influence on brain processes and even structure. And the conclusion that there is a cycle of influence ro suggests several ways the balance between reason and emotion might be achieved. 2.9.2 Application lP We began this chapter with a sketch of Henry Moliason’s contributions to psychology and neuroscience and will end by applying some of the lessons we have learned in this chapter to understand him. While most of the scholarly conversation about H. M.’s case was centered on his memory, very little of the copious research on his case could have been done if H. M. had lost his social sensitivity. In the New York na Times obituary, H. M. was described as unfailingly polite and welcoming to the troops of researchers who constantly visited him to ask him questions and give him tasks. This positive demeanor was consistent with his earlier character. One might describe this characteristic way of behaving to all as showing evidence of the moral virtue of hospitality.30 This is true despite everyone who entered his house after his Fi 29 For an example of a theological narrative, the heart has been a metaphor for the center of the person at least since early Hebrew scriptures were written (Peters, 1999). The theologian Kierkegaard does probably the earliest modern psychological analysis of morality using this heart metaphor. He describes in some complexity how an individual appropriates knowledge and values, taking them “to heart.” See Chapter 9 for the complexities of this process. This analysis has influenced theologians such as Tillich and, through Tillich, psychologists such as Rollo May and Irvin Yalom (see Furchert, 2011 for an intellectual history of these connections). The neuroscience of cognitive emotional complexes gives us a different view of how this is done. But the subtlety of Kierkegaard’s analysis offers different food for thought regarding the process – food that could result in a harvest of even more understanding (see e.g. Koole, Greenberg, & Pyszczynski, 2006). 30 For those who doubt this is a virtue, it is seen as central in the Abrahamic traditions (e.g. in Christian Benedictine monastic tradition (Merton, 2009) welcoming the stranger is akin to welcoming Christ). Neuroscience 49 surgery being a stranger of sorts to him and so needing to be welcomed anew. His consistent welcome did much for the cause of neuroscience but still cannot be laid entirely at the door of an internal virtue of hospitality. His living arrangement was such that he was constantly attended to by carers and his surrounding kept as similar as possible (given his severe memory problems). It is likely that the research visits were framed by his attendants as something to welcome, and there was a great deal of space in his schedule and support in his environment for the visit. One might say that Henry Molaison was a hospitable person in an environment that leant itself to hospitality. 2.9.3 Open Questions 1. How are emotion and reason integrated? s Rather than try to answer the question of emotional regulation we should be pursuing the problem of the integration of reason and emotion. We should explore of models of both emotional and rational regulation. The two processes are highly interdependent, and clearly influence each other. But how does emotion help to regulate the excesses of reason? How this happens will clearly change over the life span. We have the most information on the neural underpinning for childhood and ro adolescence, but new methods (see Section 2.8.3.3) should help us ask some of these questions for adulthood. 2. How does the causal cycle in moral action run “outside the brain”? This book’s emphasis on moral action makes us less likely to be satisfied with lP descriptions of morality that stay only in the head. How do social and cultural systems integrate into the cycle of influence shaping moral action? And how does personal initiative (e.g. metacognition, self-­reflection, and moral creativity in planning) mediate this cycle of influence? What neural systems interact in this cycle of influence and what roles do they play? na 3. Connecting social processes and neural processes. We are no longer limited to suggestions that activation in particular brain regions are associated with thinking about or feeling something. Recent work in neuroscience that connects social processes with their neural embodiment are a major step forward (de Oliveira-­Souza et al., 2016; Kinreich et al., 2017; Lebois Fi et al., 2020; Tamir & Thornton, 2018). These approaches allow us to track both social processes (e.g. moral decision-­making, person perception, empathy, social connection) and the shifting neural processes that underlie them over time and compare these across multiple individuals (or even with individuals in interaction with each other). Careful work of this sort can begin to give us an understanding of how the psychological processes of morality are interdependent with neural processes."
2,2.10,"Further Readings These suggested reading are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. Taking Moral Action • Barrett (2021). “This is how your brain makes your mind.” This is a readable review of the constructionist take on how our experiences, emotions, decisions, and actions are constructed by the brain and situated in situation and culture. • Brethel-­Haurwitz et al. (2018). “Extraordinary altruists exhibit enhanced self-­ other overlap in neural responses to distress.” A central paper in the ongoing research program by Abigail Marsh and colleagues on the neuroscience of altruism. Note the interactions between psychological terms (self–other overlap) and neuroscience findings. • Heatherton (2011). “Neuroscience of Self and Self-­Regulation.” An expansive and informative review of self and self-­regulation and its neural underpinnings. • Kihlstrom (2007). “Does neuroscience constrain social-­psychological theory?” A useful discussion of the relationship between psychological claims and theory and neuroscience findings. Kihlstrom makes the case that while neuroscience is helpful s in informing psychological theory and sparking creativity, it does not constrain it in any reductive sense. But see the paper by Tamir and Thornton (2018) later for of an example of the two working very closely in tandem. • Kitayama et al. (2019). “Cultural Neuroscience.” A review of the rapidly expanding field by one of its founders. • Tamir and Thornton (2018). “Modeling the Predictive Social Mind.” Example of ro the sort of complex work that can be done with current methods. It connects a multilayered framework of social cognition involved in thinking about others to the neural substrate, using fMRI to show the dimensional structure of the social cognition. lP • Tang et al. (2015). “The neuroscience of mindfulness meditation.” An excellent review of changes in brain structure associated with mindfulness meditation and of the psychological processes (e.g. attention, self-­regulation) involved. na"
3,3.1,"How Moral Ecology Changes the Conversation 3.1.1 Why Moral Ecology? A variety of terms have been used to identify social influence on moral action, and most seem too simplistic or limiting. Situational influence (Rauthmann & Sherman, 2020; Zimbardo, 2004) makes the influence sound narrowly unidirectional, in addition to limiting the focus to influence, ignoring underlying values, goods, procedures, roles, and other aspects of what Helton-­Fauth et al. (2003) have called the socio-­ technical system. Organizational culture (Hofstede, 2001; Leidner, 2006) allows for the complexity we mention, but its disadvantage is similar; culture is at times treated as monolithic, its influence on the individual seems unidirectional, and it appears to occur only in organizations. Organizational climate s (Denison, 1996) has the advantage of suggesting how flexible and adaptive influence can be and also encourages the analysis of macro vs. microclimates – what Brief, of Buttram, and Dukerich (2001) have referred to as moral microcosms. But climate still shares the disadvantage of a unidirectional causality on the isolated individual. Ernst Haeckel (1866, p. 286) first used oecologie to revise the unidirectional and hierarchical concept of “food chain” and to describe the interlinked, interworo ven, and interdependent lives of plants and animals.2 Robert Park (1952) of the Chicago school of sociology used social ecology to refer to the spheres and environments in which humans exist. Park viewed this complex interaction as mediated by morality, custom, and law – unlike the ecologies of all other animals.3 In lP philosophy, Flanagan (2008) has used human ecology with a similar referent to that of Park (1952). Huff and colleagues (Huff & Barnard, 2009; Huff, Barnard, & Frey, 2008a, 2008b) use the term moral ecology because it encourages us to consider the complex web of relationships and influences, the long persistence of some factors and the rapid evoluna tion of others, the variations in strength and composition over time, the microecologies that can exist within larger ones, and the multidirectional nature of causality in an ecology. This approach casts the issue as significantly larger than the much-­ publicized debate over whether situational influence makes virtue impossible (Doris, 2002; Fi Doris & Stich, 2005; Mischel, 1968, 2004; Snow, 2010). 3.1.2 Beyond Virtues vs. the Situation First, the reader should note that the moral ecology approach we take in this text differs from the more traditional deconstructive critiques of morality in social psychology (Nisbett & Ross, 1980; Zimbardo, 2004) and associated recent philosophy (Doris, 2002; Doris & Stich, 2005). These approaches often oppose individual virtue to situational influence. They take morality to be synonymous with individual virtue, 2 Haeckel’s work is in the tradition of Humboldtian science that we mention in the Introduction. 3 But see Chapter 1 to see how complicated this claim is. Moral Ecology 59 exercised without influence from external sources. They then show the pervasive influence of situational aspects that are often hidden from conscious awareness. Their conclusion is that true morality is either severely limited or not possible. In contrast, a moral ecology approach sees morality as arising out of the combination of numerous interacting influences. In this complex interweaving of processes, the distinction between external and internal influences becomes difficult, as does the distinction between a “pure” moral decision and illicit biases on that decision. Moral action arises out of the interaction of the individual within the moral ecology, and multiple influences both help and hinder that moral action. 3.2 Culture and Moral Diversity s Much of the work on culture and morality has been a catalog of differences: this group in this culture thinks cutting one’s hair while in mourning is immoral, that of group from another culture is puzzled by the judgment (Shweder et al., 1997, p. 131). The documentation of the diverse ways of being moral is indeed an important first step in understanding how people are moral. It has often been conceptualized in terms of evidence for better or worse morality (Kohlberg, 1963; Kohlberg & ro Mayer, 1972). However, more recent work has taken to simply documenting the diversity in ways of being moral (e.g. in goals, purposes, principles, skills, values, etc.). The catalog of diversity has had the salutary effect of making a plausible case that one need not posit a unitary morality, identical across cultures, and that doing so makes it lP more difficult to recognize the multitude of different ways of being good. In this section on culture, we will follow long tradition and give an incomplete catalog of these different ways of being good or valuing the good. At the end, we will introduce work that is asking the question of unity in the diversity: are there dimensions to the values that are similar across cultures or similarities in the processes by which culture has its na influence on morality? What has been missing until recently in the analysis of cultural differences is specification of the internal psychological processes by which these cultural differences have their effects (Heine, 2010; Markus & Kitayama, 2010). Inglehart and Welzel (2005) point to social and historical patterns that produce the differences, Fi as does Hofstede (2001). Haidt (Haidt, 2001, 2010) has specified nonconscious social ­processes that underlie judgments, and we will cover these in Chapters 7 and 8. Additionally, Schwartz and colleagues (Roccas et al., 2002) have investigated the relationship between the values in Haidt’s (2001) system and personality characteristics. But this work has been somewhat scattered. Markus and colleagues (Hamedani & Markus, 2019; Markus & Kitayama, 2010) propose a model of the “cycle of mutual constitution” of cultures and selves. They specify multiple pathways through which culture influences individuals and individuals influence culture, including: • The construction and maintenance of culturally pervasive ideas. • Institutions that shape ideas, language, and cultural narratives, and that exert direct power (e.g. education, political and legal entities). We would also add religious (Bellah, 2011) and medical institutions (Collins & Pinch, 2006) to this list. Taking Moral Action • Daily situations and practices that shape behavior and ideas at home, school, and the workplace. We would also add the built environment (Friedman & Nissenbaum, 1996; Winner, 1980). • The construction and maintenance of self and identity in interaction with the aforementioned influences. One can find this theme of mutual constitution throughout this chapter, as we explore how various levels of culture influence individuals and how individuals, in concert with each other, influence culture. Understanding these processes, and how they might differ in different cultures and subcultures, will be crucial to understanding how people live out their morality within their moral ecology. There is still much work to be done here. s 3.2.1 Moral Diversity Within Cultures of One need not begin with cross-­cultural differences in morality to catalog differences. There is sufficient moral diversity within cultures to provoke wonder (Heine, 2010; Kitayama et al., 2006). ro 3.2.1.1 Political Values A long-­standing research program on moral development based in Kohlberg’s stage model has identified one of these dimensions of difference: extensiveness and diversity of social experience.4 Within cultures, those who have access to a wider variety of social experience (as indexed by such things as age, lP socioeconomic status, social class, education) tend to think more that moral judgment requires shared standards of judgment, rather than simple obedience to authority.5 This is a difference found within each of the many cultures studied by those in the Kohlberg tradition (Gibbs et al., 2007). The Kohlberg tradition sees these differences in moral judgment as evidence of na moral development from less complex to more complex cognition. But others have cataloged differences in the reasons individuals give for moral judgment and treated them more as simple dimensions of difference. Haidt and colleagues (Graham, Haidt, & Nosek, 2009; Haidt & Joseph, 2004) have cataloged differences on five dimensions of judgment: harm/care, fairness/reciprocity, in-­ group/loyalty, authority/ Fi respect, and purity/sanctity. Many studies across a variety of cultures again document a difference within each culture: classical liberals are those who see harm/care and fairness/reciprocity as foundational values and are suspicious of the other three dimensions since they have been used unfairly to harm minorities and the disenfranchised. Classical conservatives try to balance all five dimensions and refer to all of them in their judgments. Haidt & Kesebir (2010) connect these value differences to a distinction made by Tönnes (1887/2001): Gesellschaft, an approach that sees a fair 4 We list Kohlberg’s approach under “political values” because commitment to the principle of justice at least overlaps with the political realm. It is no longer reasonable to think of justice as the only dimension in moral judgment, and it needs to be grouped with other similar values approaches. 5 This corresponds to a shift from pre-­conventional to conventional moral judgment in Kohlberg’s approach. See Chapter 7 for a short explanation of Kohlberg’s approach. Moral Ecology 61 public square as essential in a diverse society, and Gemeinschaft, an approach that values trust, cooperation, and mutual aid in tight-­knit communities (see also Markus & Kitayama, 2010 on this distinction). These differences in approach produce significant political strife and mistrust within societies that host them (Haidt & Kesebir, 2010) and correspond to two very different notions of the good. But they are, in the end, both widely accepted notions of the good within and across all cultures. And each can serve as a source of critique if the argument is reframed persuasively (Voelkel & Feinberg, 2017). 3.2.1.2 Religious Influence Work by Cohen and colleagues (Cohen & Rozin, 2001; Cohen, Rozin, & Keltner, 2004; Cohen, Siegel, & Rozin, 2003) documents the differences in moral thinking between Jews and Christian Protestants in America. The Jews they surveyed viewed practice – what one actually does – as the most central s moral aspect of their religious approach, while the Protestants viewed belief and practice to be equally important. Members in the groups are defined differently (for of Jews primarily by descent, for Protestants primarily by belief), and mental states such as temptation appear to matter more to Protestants than to Jews, for whom right action seems to be more important. Mormons and Muslims appear to moralize their religious norms, while Jews appear not to, suggesting there might be significant ro differences among religions on even what category of things one can call moral (Levine et al., 2021). Any culture that is multireligious can expect to find similar disagreements about moral issues. Fundamentalist approaches to religion can divide societies even if they are predominantly of one religion (Marty & Appleby, 1991). lP Indeed, in the current political climate in the United States, differences in religiously based values are a central issue (Graham & Haidt, 2012; Haidt, 2012). There is some evidence that political and cultural differences drive the religious ones (R. P. Jones, 2016). There appear to be individuals who are primarily motivated by their “coalitional commitment” to a religious group, rather than by perna sonal religious devotion (Ginges, Hansen, & Norenzayan, 2009). And these individuals are more likely to endorse violence against out-­groups (Bloom, 2012; Ginges et al., 2009), an extreme and unfortunately common example of the pattern in certain kinds of religious/cultural commitments. However, one can also use religious principle to critique a conventional morality Fi that falls short in some respect. One of the central characteristics of religion is its critique of conventional morality (Bellah, 2011). Gregg (2005, chapter 3) reviews how the values of Islam help to counter and limit the honor/shame system in Middle Eastern countries, and even help to “set the developmental task of identity formation … to integrate pursuits of honor and piety into a whole, or at least a balanced life” (Gregg, 2005, p. 167).6 Gibbs (1977) claims, for instance, that the post-­conventional reasoning one can find in Kohlberg’s interviews is not always simply justice based but can be more existential-­or religion-­based critiques of conventional morality (Gibbs et al., 2007). 6 Kohlberg would score basic religious commitments as a part of conventional morality (Richards & Davison, 1992) but might score more sophisticated religious reflection as post-­conventional (Gibbs, 1977). Taking Moral Action Thus, the influence of religion in culture and in morality is multifaceted, drawing from group commitments and personal piety, and providing organizational support and opportunity for action (Matsuba, Hart, & Atkins, 2007; Oliner & Oliner, 1988). 3.2.1.3 Class Differences Cultures with class differences can also expect to entertain moral diversity. In a series of experimental studies, Stellar et al. (2011) have found that lower-­class Americans exhibited more compassion than upper-­class individuals (e.g. in verbal response to other individuals and even in heart rate). Several studies have also shown that lower-­class individuals tend to have an interdependent view of the self, while upper-­ class individuals value independence (Heine, 2010). Complications quickly arise in this picture since, for instance, Bowman, Kitayama and Nisbett (2009) have found that middle-­class Americans gave and received more help to each other than working-­class individuals, who reported more self-­reliance. Like s religion, we are likely to find the cultural differences embedded in class to be complex and multilayered. of 3.2.1.4 Individual Variation in Goals Another kind of moral diversity is evident in the wide diversity of moral goals that individuals set for themselves. The pioneering work of Colby and Damon (1992) in moral exemplars shows great variety of goals ro among their sample of exemplars, even though their sample was primarily limited to individuals doing social service. These fell into two large groupings, those interested in reform of society and those interested in direct service to those in need. But even in these groupings, the exemplars they interviewed had some focus for their efforts, lP rather than being a “jack of all trades” in moral excellence. Huff and Barnard (2009) found a similar distinction among exemplars in the computing field, though they also found about a third of their exemplars fit neither category and instead cared deeply for some other passion, such as mentoring, education, or particular social-­ technical issues. na Walker, Frimer, and colleagues (Matsuba & Walker, 2004; Walker & Frimer, 2007, 2009; Walker & Hennig, 2004; Walker & Pitts, 1998) have done the most systematic work in identifying clusters of goals and personality characteristics that identify highly moral individuals. They have found clusters of “communal” and deliberative (Walker, Frimer, & Dunlop, 2010), just, brave, and caring (Walker & Fi Hennig, 2004), and caring/dependable and principled/idealistic (Reimer, DeWitt Goudelock, & Walker, 2009). The work on exemplars is somewhat cross-­cultural, including British, Scandinavian, Canadian, and American samples. Still, all these sub-­ types and different goals of moral excellence are from Western, educated, industrialized, rich democratic (WEIRD) societies (see Henrich, Heine, & Norenzayan, 2010) and it seems unlikely that the variety will diminish as further research encompasses other cultures. Thus, even within cultures one can find extensive moral diversity. Most of the work that relates to within-­culture moral diversity has been conducted in WEIRD societies (Henrich et al., 2010) though we are beginning to see some within Asian cultures (e.g., Kitayama et al., 2006). The variety of moral sub-­ecologies within any culture is likely to be wide, including regional, class, religious, race, and organizational differences, and the interactions of these. For instance, a national concern that corporations in Japan no longer serve the “household” function they used to has resulted in a recent Moral Ecology 63 upswing in interest in ethics among engineering schools and firms in that country (Downey, Lucena, & Mitcham, 2007). In contrast, because of their complicity in WWII, engineering firms in Germany have recently required a strong commitment to ethical practice, but engineering firms in France rarely talk explicitly about ethics, instead concentrating on the role of engineers as the elite vanguard of progress for the nation. In each of these cultures, local history and values have resulted in different ethical/moral approaches to a professional field. We really are just beginning to find our way in this multitude of differences. Work by Muthukrishna et al. (2020) provides a useful index of cultural distance that can be computed between any two cultures based on the World Values Survey. Dimensional models like this will facilitate comparisons across multiple cultures on psychologically relevant dimensions. s 3.2.2 Patterns in Moral Diversity Across Cultures There is a much longer history of research in the psychology of cross-­cultural differof ences (see Heine, 2010 for an overview). It is from this work that we will find some pattern in the diversity of cultural difference. There is evidence for some cultural moral universals. For instance, Curry, Mullins, and Whitehouse (2019) found broad agreement across sixty societies in basic principles that allow for cooperation. And ro Kinnier, Kernes, and Dautheribes (2000) provide four major categories of agreement across world religions. We have already covered the convergence across cultures of the early stages of the Kohlberg framework. Extensive work in this area (see Gibbs et al., 2007 for a review) lP has shown that access to broad social differences can serve as developmental pressure to move individuals from preconventional to conventional moral stages. But this unity falls apart in what Kohlberg hypothesizes to be the higher post-­conventional stage of moral development – for Kohlberg, this is a movement to a concern for principles of equal justice. It turns out that different cultures have different preferences na for the principles that can guide moral judgment at these higher levels. For instance, research shows that Americans prefer equity as a means of distributing scarce goods, while those from India prefer need and those from Japan prefer equality (Heine, 2010). Some theorists suggest that, rather than the “higher stages” being a Kohlbergian shift to thinking of a particular type (justice) across cultures, instead those who question Fi the conventional judgments within their society find culturally embedded and supported ways of questioning, supporting, and providing flexibility to conventional wisdom (Gibbs et al., 2007). Thus, they are still “post” conventional but question and modify conventional wisdom in a way that is locally relevant and culturally supported. On a more descriptive level, Schwartz and colleagues (Bardi & Schwartz, 2003; Roccas et al., 2002; Schwartz, 2006, 2010) have shown a two-­dimensional organization that defines the value dimensions on which individuals from differing cultures disagree. Work in over seventy countries using a variety of instruments converges on this solution that represents the similarities in the way values relate to each other, and the differences in the emphasis different cultures and individuals make on those values. Thus, there is agreement about what dimensions are ­important but variation on which ends of the dimensions to emphasize. Figure 3.1 shows the standard circumplex of these values, with the two dimensions labeled Taking Moral Action SelfTranscendence UniversSelfalism Direction Openness to Benevolence Change Stimulation Conformity Tradition Hedonism s Security Conservation of Achievement Power SelfEnhancement ro Figure 3.1 Schwartz circle of value regions. Source: Adapted from Borg et al. (2015). lP self-­enhancement – self-­transcendence and conservation – openness to change. Support of any one value on the circle tends to correlate with support for adjacent ones, and less support for those on the opposite pole. Work by Geert Hofstede (2001) and by Ronald Inglehart & Christian Welzel (2005) makes similar points na about variation in values among cultures. Distinctions among societies on the individualism–collectivism dimension have a long history in cultural psychology (Triandis et al., 1986) and seem also to be the most psychologically fruitful, encompassing a variety of cross-­cultural differences (Heine, 2010). Individualistic cultures emphasize both the self and others as Fi ­independent, agentic, and interested in self-­enhancement. All these differences, and many others relevant to this dimension (see Heine, 2010 for a review) have relevance for how people from within these cultures think about individual responsibility and agency. In an interesting convergence of within-­and cross-­cultural patterns, Kitayama at al. (2006) have shown that when frontier conditions prevail in a subset of a ­collectivist country (as in the Hokkaido frontier of Japan in the late 1800s) one finds a more individualist subculture emerging. A similar historical mechanism has been theorized to be behind the honor culture in the southern United States (Nisbett & Cohen, 1996). All the variation we have seen so far should lead us to be skeptical of work in moral psychology that makes universalistic claims but is done primarily in WEIRD cultures. When we look cross-­culturally at issues of morality we find both difference and ­similarity. There are differences in the kinds of values or moral foundations individuals Moral Ecology 65 hold (both cross-­ culturally and within cultures). But there are patterns to the ­differences. Haidt and Craig’s (2004) five foundations, Schwartz’s (2010) values ­circumplex, Hofstede’s (2001) intercultural dimensions, and Inglehart and Welzel’s (2005) World Values Survey all point to patterns in the ways that cultures and ­individuals both agree and disagree on moral issues. Recent work by Schwartz and colleagues (Zapko-­Willmes et al., 2021) suggests that the value circumplex and the moral foundations approach have both a shared structure and differences. More work like this is needed to help find some convergence among the diverse systems of cross-­cultural value difference. 3.3 Moral Ecology at the Organization Level s Organizations are important influences on moral action in part because of their of impact on individuals working or volunteering within them and in part because of the profound influence they exert on society and culture. For instance, the Association of Certified Fraud Examiners (2018) estimated that unethical conduct in organizations cost the global economy nearly US$4 trillion in 2017. Here we will review processes ro supporting both ethical and corrupt practices in organizations. 3.3.1 Organizational Values and Goals lP Organizations can also provide variation in moral environment within a culture or industry. In interviews with engineers in the Chicago area, Davis (1998) has found that engineering firms differ systematically in their moral ecology, and thus in the way they treat the engineering role. Finance-­driven organizations give priority to maximizing financial goals, and engineers in these firms do not participate in decision-­ na making, but instead stand outside the process in a consultant-­like role, providing information, producing design options, and answering questions. In this environment, engineering values are subordinated to management goals, and the engineer’s ethical responsibilities are limited to exercising due care when providing advice and services, avoiding conflicts of interest, and remaining loyal to the legitimate interests Fi and objectives of managers. This produces the classic due care blame-­avoidance memo documenting concern about a product or design strategy. In the other two kinds of organization, engineers participate in decision-­making, and managers seek consensus with engineers. Quality-­driven organizations see the achievement of quality products as the defining goal. For instance, one engineer is quoted by Davis (1998, p. 133) as saying, “Cost comes in only after quality standards are met.” And another offers that, “If a customer wants to take a chance, we won’t go along” (Davis, 1998, p. 133). Customer-­driven organizations see superior customer service as a defining goal. All three kinds of organization are constrained by financial issues, quality, and customer service, but they differ in terms of which goal they see as primary or fundamental. It is these differences that result in differing moral ecologies in the organizations and in differences in the moral roles and moral choices of the engineers in them, and the moral skills they need to practice. Taking Moral Action 3.3.2 Processes Supporting Organizational Corruption One way to ask about how organizations construct moral ecologies is to look at how they construct immoral ecologies, the systematic planning and execution of illegal activities. There is a significant literature in this area. In a review of work on organizational corruption, Ashforth and Anand (2003) propose three processes by which organizational misbehavior is supported: rationalization, institutionalization, and socialization. In rationalization, actors in the organization convince themselves that the behavior is legitimate. These acts are then institutionalized as a matter of routine in the organization, and those new to the organization are selected and socialized into the routine performance of the actions. These processes provide a structure for our review of influence toward both ethical and unethical action in organizations. s 3.3.2.1 Rationalization There are at least two approaches that individuals can use to separate action from its moral implications domain limitations and cognitive of distancing. Domain limitations are ways to make moral consideration in a particular situation or domain not relevant. Thus, the moral question simply does not arise. Once the moral question arises, then one can use a variety of cognitive strategies to minimize its relevance. ro Moral action can seem relevant in some domains or circles of action but not in others. Colby and Damon (1992) note this in the lives of their moral exemplars: people who give their lives to causes such as racial equality or feeding the poor often treat their families with much less concern than one might expect for such compaslP sionate individuals. In organizations, this occurs in part because of the way the organization defines the situation. Treviño, Weaver, and Reynolds (2006) speak of this as “situationally defined identities becom[ing] entrenched within organizations” (p. 962). In one study (Weber & Wasieleski, 2001) business managers enrolled in MBA courses were found to respond at lower levels of moral reasoning na (in Kohlberg’s scheme) when asked about work-­domain issues than asked about non-­work-­domain issues. The salience of the moral aspects of an action is ­influenced by what T. M. Jones (1991) calls moral intensity. Moral intensity is a combination of: (1) magnitude of the consequences; (2) concentration of the effect; (3) probability of the effect; (4) its temporal immediacy; (5) social consensus on the moral Fi status of the action; and (6) proximity (see Treviño et al., 2006, pp. 953–954 for a review of research on this concept). High moral intensity can jar the senses and make it difficult to maintain a definition of the situation.7 Still, as the Milgram (1963, 1974) studies have shown, a definition of the situation can trap the actor into a situation even when moral intensity is quite high. It is the combination of high moral intensity (giving clearly painful shocks to a helpless, suffering, and protesting acquaintance in the next room) and the strong situational definition (having promised to be a good subject to help science) that produced the stress reactions that Milgram’s subjects experienced. 7 One can imagine designing organizational procedures to highlight the moral intensity of proposed actions (Epley & Tannenbaum, 2017). For example, in software design, design procedures that incorporate concern for those affected by the software are available (Leveson, 1995; Nissenbaum, 2011; Shilton, 2018; Umbrello, 2019). Moral Ecology 67 When domain limitations fail in making the moral aspects of organizational actions irrelevant, there are a host of cognitive strategies available to help the individual justify the course of action. In their article on corruption, Ashforth and Anand (2003, pp. 16–22) list legality, denial of responsibility, denial of injury, denial of victim status, denial of status to those who critique, appealing to higher loyalties, metaphor of ledger, and refocusing attention. Bandura (1999, 2002) has a similar list of “moral disengagement strategies” compiled from a separate theoretical approach: moral justification, advantageous comparison, euphemistic labeling, minimizing, ignoring, misconstruing, dehumanization, blaming the victim, displacement of responsibility, and diffusion of responsibility. The point of all these disengagement strategies is to distance the actor from moral responsibility for an action.8 3.3.2.2 Institutionalization When an action becomes “standard operating procedure” s it becomes institutionalized (Ashforth & Anand, 2003). This means that it no longer requires a decision process. In institutionalizing corruption, it is usually the avoidance of of a decision process that is institutionalized (Ashforth & Anand, 2003). It is not just procedures that are institutionalized, the structure of an organization can also be affected. Since the adoption of the Federal Sentencing Guidelines for Organizations in 1991 made them a factor in recommended criminal sentences, organizational ro ethics programs in the United States (often called offices of ethics and compliance) have become a standard part of organizational hierarchy (Stansbury & Barry, 2007). Organizations that want to provide plausible deniability for ethical misconduct have been known to establish a position to support corrupt practices ironically titled by lP Braithwaite (1989, p. 350) “vice president responsible for going to jail” allowing others to be willfully blind of misconduct. In cases of corruption, the organization “comes to expect and then depend on the payoffs from corruption. In time, goals, budgets, information flows, rewards and punishments and so on may be skewed to support the practices” (Ashforth & na Anand, 2003, p. 9). The common claim is that, particularly in countries known for corrupt business practice, this sort of activity is required to do business. This claim seems only to be partly true. In a study of 480 of the world’s largest corporations across many different cultures, Healy and Serafeim (2012) show that organizations that report and combat corruption have slower but more profitable sales growth and Fi return on investment, but that this difference only occurs in high corruption countries. They speculate that establishing a reputation as corruption free gives an advantage that results in slower sales growth but increases in return business based on trustworthiness. The corruption-­fighting companies establish this reputation in part by institutionalizing policies and procedures that encourage and support reporting (Healy & Serafeim, 2012). One can institutionalize ethical action in firms by adopting business procedures that embed ethical considerations as in the proposed procedure of Helen Nissenbaum (2011) for privacy in software or that of Nancy Leveson for safety in complex systems 8 A systematic comparison of the Ashforth and Anand (2003) and Bandura (1999, 2002) strategies with the dimensions of moral intensity would be an interesting endeavor and might bring some order to what now stand as mere lists. Taking Moral Action (1995). Another proposal for institutionalizing ethical reflection and action is the idea that one can design this into organization structure (Epley & Tannenbaum, 2017). A widely recognized form of institutionalization to support ethical action is the adoption of an organizational code of ethics. The bad news for such approaches is that across the broad range of codes of ethics in organizations, there seems to be little effect on employee or organizational misconduct (Treviño et al., 2006). The good news is that one approach to such codes does offer some promise: what Treviño et al. (2006) call “value internalization” approaches. These approaches are less about compelling compliance with rules and more about providing support and socialization. They operate through the organizational culture and leadership commitment, and through what Gehman, Treviño, and Garud (2013) call values practices: those activities that embody and shape concern for values in an organization. These practices not only shape employees but also reaffirm and maintain (or challenge and modify) s organizational structure and are thus a vital part of institutionalization. An example of such practices comes from a study of the daily interactions in a national funding of agency responsible for research in information and communication technology (Grimpe et al., 2020). In-­depth interviews revealed that the workers collaboratively constructed the organization’s response to responsible conduct of research issues by embedding the issues in daily conversations and tasks. It became a matter of habit to ro take these issues into consideration in everyday tasks, and in this way, without fanfare, the workers were contributing to the moral ecology of the organization. As long as employees think basic procedural justice is being served in the organization (e.g. one does not suffer for ethical behavior), then these values practices are more broadly lP effective than compliance-­based efforts (e.g. punishing noncompliance with rules). This pattern is called the paradox of control (Stansbury & Barry, 2007), where attempts to directly control employees’ ethical actions are viewed as coercive,9 while the socialization approach of value internalization gives flexibility and professional commitment to employees’ existing ethical goals. A widely cited form of this ­advantage na for socialization rather than control approaches is the relative success of socialization-­ based (vs. control-­based) diversity programs in organizations (Dobbin & Kalev, 2016; Paluck et al., 2021). This brings us then to the topic of socialization. 3.3.2.3 Socialization As implied by the paradox of control, socialization is more Fi than simple passive absorption of the dominant culture. It involves active choice on the individual’s part. Much of the description of socialization here is taken from the organizational psychology literature, but parallels can be found in cultural psychology (Markus & Kitayama, 2010) and developmental psychology (Tomasello & Vaish, 2012). The attraction–selection–attrition cycle (Ashforth & Anand, 2003) is the gateway to socialization in organizations. Individuals with similar values are attracted to the organization, the organization seeks out these people, and those who find a bad fit between themselves and the organization often leave. Once hired, participation in values practices helps to educate, influence, and motivate employees to adopt the 9 See references to “Darley’s Law” that any system of coercion will be gamed (Darley, 1994) in proportion to the extent that its metrics are quantitative. Moral Ecology 69 values and practices of the organization. People don’t expect to suffer for ethical behavior, but the relationship between reward and ethical behavior is complex (Treviño et al., 2006). Socialization occurs primarily at the local level and, though influenced by organizational climate and ethics codes, it is identification with veterans (Ashforth & Anand, 2003) and local values practices that carry the day. For instance, the extent to which ethical language is actually used in a company is a good (though not infallible) guide to ethical behavior within it (Gehman et al., 2013). Another effective strategy is reintegrative and dis-­integrative shaming (Braithwaite, 1989; Stansbury & Barry, 2007) involving public attempts to influence those who do not seem to understand the local culture (whether that culture supports or opposes corruption) with an eye to inducing them to join in the culture or to leave it. This moral seduction leads the receptive newcomer to view the world through the “moral microcosm” of the local organization unit (Moore et al., 2006). s of 3.4 Close Relationships in Friendship and Community If local units within organizations are the most powerful agents of moral ecology for the individual, then outside of organizations the most powerful agents should also be ro local: small communities and personal relationships. In this section, we look at the most intimate and smallest scale of moral ecology. Ironically, one of the pioneers of research on the role of the community in morality is the person most known for championing the cognitive aspects of morality, Lawrence lP Kohlberg. In part in reaction to his experiences on a kibbutz (Walsh, 2001), Kohlberg helped found the first just community school, the Cluster School in Cambridge, MA. This is the school from which the quote at the beginning of this chapter is taken. Though just community schools were designed to be democratic, with students and staff each having only one vote, their primary innovation was the attempt to develop na a moral community: “a group that shares an explicit commitment to a common life characterized by norms embodying high moral ideals” (Power, 2004, p. 50). The approach was theoretically based in Durkeim’s (1925/1973) work on moral communities in education.10 The just community approach recognized that norms and values were important but also emphasized individual commitment to shared ideals Fi within the framework of a responsible community.11 As Power explains (2004, p. 52): “The self does not experience a sense of obligation or responsibility to act in isolation but with others within a cultural setting.” The just community schools and their progeny serve as laboratories in which to observe these processes. But of course, these processes do not occur only in laboratories. They are crucial to the maintenance of all communities. Daniel Hart has pursued a research program on moral commitment and volunteerism in neighborhood and community that has charted the ways that individual moral commitment and development are rooted in 10 This grounding in Durkheim is somewhat ironic, given Durkheim’s clear relativism and Kohlberg’s trenchant critique of relativism (Eberhardt, 2014). 11 In this respect, Kohlberg and Gilligan were much closer together in their approaches than is commonly realized. Taking Moral Action social groups (Hart, 2005; Hart, Atkins, & Southerland, 2006; Hart & Carlo, 2005; Hart & Fegley, 1995; Hart & Matsuba, 2007, 2009; Matsuba et al., 2007). He summarizes: Moral identity, a commitment to advance the welfare of others that is consistent with one’s self-­image and moral goals, emerges from the interplay of family background, personality, moral cognitions and attitudes, self-­perceptions and moral emotions, and social relationships and interactions with social institutions. No single element is the keystone; there are multiple routes to moral identity formation. (Hart & Matsuba, 2009, p. 228). However, one consequence of moral identity being embedded in community is that it then becomes subject to domain limitations. It becomes focused on our obligations to each other, often to the exclusion of others, resulting in moral collapse s (Hart, 2005). When identity becomes fused within a limited community in this way, great evil can result (Graham & Haidt, 2012; Hart & Matsuba, 2007; Staub, 1999). of Community-­based morality is a fragile achievement that requires constant maintenance and is in part a result of the good fortune and thoughtful choice of one’s social surroundings (Hart, 2005, p. 260). The smallest unit of social influence in morality is the dyad. Work on the moral ro psychology of this level of influence has been quite rare until recently. But work on what has been called the Michelangelo phenomenon has important implications for thinking about how individuals achieve and maintain their moral action. The Michelangelo phenomenon occurs when one member of a dyad helps to shape a lP close partner’s skills and traits in support of achieving the partner’s ideal self (Rusbult, Finkel, & Kumashiro, 2009).12 Research has mostly concentrated on romantic partners, though Rusbult et al. (2009) argue that the effect should equally be seen in family, friendship, and collegial relationships to the extent that these are closely interdependent. In another example of the paradox of control, this sculpting na effect requires ­special conditions. First, the partner must be supportive of the other’s ideal self, not just supportive of what the partner thinks is best for the other (Drigotas et al. 1999). In fact, this latter kind of “support” appears to hamper both the partner and the r­ elationship (Rusbult et al., 2009). Second, the support for the ideal self of the other needs to be in the context of movement toward the goal of Fi attaining it, and not simply in assessment of the discrepancy (Kumashiro et al. 2007). The assessment approach involves a primary focus on evaluation and critique, and when one is the target of the sculpting process (you have a partner who simply assesses your discrepancy to your ideal self), this leads one to think the other is not supportive. When one is the sculptor, the assessment approach leads one to be less affirming, disapproving of the goals, less involved in the sculptee’s pursuits. Mere assessment is debilitating to the sculpting process. Locomotion involves a 12 Like many of the concepts reviewed in this book, the socially constructed self has a long theoretical history going back to Aristotle’s emphasis on friendship, social science formulated by James (1890), Cooley (1902), and Mead (1934), and continental thought from Kierkegaard (1846/1992) to Jaspers (1919) to Gadamer (1975). Moral Ecology 71 focus on affirmation and moving toward the goal of the sculptee. This effect may well be culture-­dependent (Markus & Kitayama, 2010). Research on the Michelangelo phenomenon has only recently been extended to influence among friends and between supervisor–supervisee work pairs (Bagci et al., 2016) and it also appears to hold in these relationships.13 Thus, the Michelangelo phenomenon may provide a window into one way that social influence in communities, organizations, and culture may work. The influence of the local unit in organizations comes through close, interdependent interactions with coworkers. The influence of culture comes from socialization experiences with proximate others too. The Michelangelo phenomenon may play a central role in much of the influence that Markus and Kitayama (2010) propose in the “daily situations and practices” aspect of their model of cultural influence on the self. There are, of course other levels to the model of culture and self (language, media, education, pervasive ideas, etc.), but this s cooperative sculpting process may play a central role in how we become (or avoid or fail to become) moral. 3.5 Influencing the Moral Ecology of ro The moral ecology metaphor encourages us to think about cultural influence as reciprocal. We often have the freedom to choose our influencers, to volunteer, to join organizations, to move cultures, to protest our treatment, to encourage moral action in others, to try to change our surroundings or to leave them behind. In short, we lP often have the freedom to influence both the small-­and (less often) large-­scale moral ecology that surrounds us. 3.5.1 Organizational Ethics As a Design Problem na Epley and Tannenbaum (2017) propose we construe ethical action in organizations as a design problem. How do we design organizations so that they promote and produce ethical action? They review a large literature in organizational psychology (some of which is included in Section 3.3) and then propose that organizations can construct hiring, compensation, reputation management, and operations processes so Fi that they support ethical action. They list three psychological levels on which this ethical design can occur: attention, construal, and motivation. 3.5.1.1 Attention: Are Ethics Top of Mind? In organizations attention is often focused on goals of efficiency or profit. But organizational processes can be designed to make ethical concern and evaluation a part of routine decision processes. They offer the hiring interview protocol that companies like Johnson & Johnson use. The interview is structured in part to begin the socialization process of new employees into corporate culture. It includes numerous questions focusing on how prospective employees 13 The process may also be similar to some kinds of parental influence (Patrick & Gibbs, 2012). Taking Moral Action might support the company value of ­prioritizing the needs of the people it serves. This focuses attention on the values that are held in that organization. 3.5.1.2 Construal: Are People Asking “is It Right?” The procedures that a company follows are often simply implemented without ever being evaluated. But do employees ever ask, “Is this the right thing to do?” Compensation policies that tie executive performance to clear measures of values can help connect personal decisions made by executives to values the organization supports. Southwest Airlines, for instance, has an “every employee matters” slogan that is incorporated into the compensation packages of executives by tying compensation to measures of voluntary turnover in that executive’s division. 3.5.1.3 Motivation: Are You Using Pro-­social Goals? Most employees are interested in s doing (or at least seeing) some good in the work they do. Organizations can leverage this already existing desire and align it with values the organization supports. Virgin of Atlantic rewarded its pilots for increasing fuel efficiency by donating money to charities of the pilot’s choice. This change in policy significantly increased job satisfaction. It seems clear there are ways for organizations to influence the ethical behavior of ro their employees and executives. These approaches are fraught with complexity (e.g. the paradox of control) but they can produce significant organizational change and support moral action within organizational cultures. lP 3.5.2 Moral Exemplars and Social Reformers The pioneering work of Colby and Damon (1992) in moral exemplars shows great variety of goals among their exemplars, even though their sample was primarily limited to individuals doing social service. Among their exemplars were people na who campaigned for justice in civil rights, for health care, or for equal economic opportunity. Huff and Barnard (2009) found a similar distinction among cases in the computing field. The computer scientists, software engineers, and policy advocates they interviewed included a significant number of reformers campaigning for opensource software, privacy policy, inclusion of women in the field, safety standFi ards in software, and other goals. In both studies, those working for social change often expressed frustration at the opposition they faced, and the difficulties involved in producing social change. Working for social change is difficult, and these exemplars leveraged social support and their own optimism to maintain their motivation. Hirschman’s (1970) Exit, Voice and Loyalty provides a structure for the choices facing those who work in firms, organizations, and government as these begin to conflict with the values and principles of members. The framework (with the addition of a “neglect” option) has been used to explain a wide variety of choices for and against social change including the decision to blow the whistle in government and business (Uys, 2022), organizational change, and human resources (Allen, 2014). These choices resonate most clearly with the case of the 2020 presidential election in the United States that we outlined in the Introduction. Different actors in the Republican Party chose differently, some opting for voice (as did the two in our case), Moral Ecology 73 some opting for exit (as did some of their colleagues who resigned), and some opting for loyalty to the president in his last days in office. 3.5.3 Moral Action as Critique and as Design Leadership and social change work are classic examples of how the moral ecology is shaped, but there are many other informal approaches. The three processes we reviewed in Section 3."
3,3.2,"Culture and Moral Diversity s Much of the work on culture and morality has been a catalog of differences: this group in this culture thinks cutting one’s hair while in mourning is immoral, that of group from another culture is puzzled by the judgment (Shweder et al., 1997, p. 131). The documentation of the diverse ways of being moral is indeed an important first step in understanding how people are moral. It has often been conceptualized in terms of evidence for better or worse morality (Kohlberg, 1963; Kohlberg & ro Mayer, 1972). However, more recent work has taken to simply documenting the diversity in ways of being moral (e.g. in goals, purposes, principles, skills, values, etc.). The catalog of diversity has had the salutary effect of making a plausible case that one need not posit a unitary morality, identical across cultures, and that doing so makes it lP more difficult to recognize the multitude of different ways of being good. In this section on culture, we will follow long tradition and give an incomplete catalog of these different ways of being good or valuing the good. At the end, we will introduce work that is asking the question of unity in the diversity: are there dimensions to the values that are similar across cultures or similarities in the processes by which culture has its na influence on morality? What has been missing until recently in the analysis of cultural differences is specification of the internal psychological processes by which these cultural differences have their effects (Heine, 2010; Markus & Kitayama, 2010). Inglehart and Welzel (2005) point to social and historical patterns that produce the differences, Fi as does Hofstede (2001). Haidt (Haidt, 2001, 2010) has specified nonconscious social ­processes that underlie judgments, and we will cover these in Chapters 7 and 8. Additionally, Schwartz and colleagues (Roccas et al., 2002) have investigated the relationship between the values in Haidt’s (2001) system and personality characteristics. But this work has been somewhat scattered. Markus and colleagues (Hamedani & Markus, 2019; Markus & Kitayama, 2010) propose a model of the “cycle of mutual constitution” of cultures and selves. They specify multiple pathways through which culture influences individuals and individuals influence culture, including: • The construction and maintenance of culturally pervasive ideas. • Institutions that shape ideas, language, and cultural narratives, and that exert direct power (e.g. education, political and legal entities). We would also add religious (Bellah, 2011) and medical institutions (Collins & Pinch, 2006) to this list. Taking Moral Action • Daily situations and practices that shape behavior and ideas at home, school, and the workplace. We would also add the built environment (Friedman & Nissenbaum, 1996; Winner, 1980). • The construction and maintenance of self and identity in interaction with the aforementioned influences. One can find this theme of mutual constitution throughout this chapter, as we explore how various levels of culture influence individuals and how individuals, in concert with each other, influence culture. Understanding these processes, and how they might differ in different cultures and subcultures, will be crucial to understanding how people live out their morality within their moral ecology. There is still much work to be done here. s 3.2.1 Moral Diversity Within Cultures of One need not begin with cross-­cultural differences in morality to catalog differences. There is sufficient moral diversity within cultures to provoke wonder (Heine, 2010; Kitayama et al., 2006). ro 3.2.1.1 Political Values A long-­standing research program on moral development based in Kohlberg’s stage model has identified one of these dimensions of difference: extensiveness and diversity of social experience.4 Within cultures, those who have access to a wider variety of social experience (as indexed by such things as age, lP socioeconomic status, social class, education) tend to think more that moral judgment requires shared standards of judgment, rather than simple obedience to authority.5 This is a difference found within each of the many cultures studied by those in the Kohlberg tradition (Gibbs et al., 2007). The Kohlberg tradition sees these differences in moral judgment as evidence of na moral development from less complex to more complex cognition. But others have cataloged differences in the reasons individuals give for moral judgment and treated them more as simple dimensions of difference. Haidt and colleagues (Graham, Haidt, & Nosek, 2009; Haidt & Joseph, 2004) have cataloged differences on five dimensions of judgment: harm/care, fairness/reciprocity, in-­ group/loyalty, authority/ Fi respect, and purity/sanctity. Many studies across a variety of cultures again document a difference within each culture: classical liberals are those who see harm/care and fairness/reciprocity as foundational values and are suspicious of the other three dimensions since they have been used unfairly to harm minorities and the disenfranchised. Classical conservatives try to balance all five dimensions and refer to all of them in their judgments. Haidt & Kesebir (2010) connect these value differences to a distinction made by Tönnes (1887/2001): Gesellschaft, an approach that sees a fair 4 We list Kohlberg’s approach under “political values” because commitment to the principle of justice at least overlaps with the political realm. It is no longer reasonable to think of justice as the only dimension in moral judgment, and it needs to be grouped with other similar values approaches. 5 This corresponds to a shift from pre-­conventional to conventional moral judgment in Kohlberg’s approach. See Chapter 7 for a short explanation of Kohlberg’s approach. Moral Ecology 61 public square as essential in a diverse society, and Gemeinschaft, an approach that values trust, cooperation, and mutual aid in tight-­knit communities (see also Markus & Kitayama, 2010 on this distinction). These differences in approach produce significant political strife and mistrust within societies that host them (Haidt & Kesebir, 2010) and correspond to two very different notions of the good. But they are, in the end, both widely accepted notions of the good within and across all cultures. And each can serve as a source of critique if the argument is reframed persuasively (Voelkel & Feinberg, 2017). 3.2.1.2 Religious Influence Work by Cohen and colleagues (Cohen & Rozin, 2001; Cohen, Rozin, & Keltner, 2004; Cohen, Siegel, & Rozin, 2003) documents the differences in moral thinking between Jews and Christian Protestants in America. The Jews they surveyed viewed practice – what one actually does – as the most central s moral aspect of their religious approach, while the Protestants viewed belief and practice to be equally important. Members in the groups are defined differently (for of Jews primarily by descent, for Protestants primarily by belief), and mental states such as temptation appear to matter more to Protestants than to Jews, for whom right action seems to be more important. Mormons and Muslims appear to moralize their religious norms, while Jews appear not to, suggesting there might be significant ro differences among religions on even what category of things one can call moral (Levine et al., 2021). Any culture that is multireligious can expect to find similar disagreements about moral issues. Fundamentalist approaches to religion can divide societies even if they are predominantly of one religion (Marty & Appleby, 1991). lP Indeed, in the current political climate in the United States, differences in religiously based values are a central issue (Graham & Haidt, 2012; Haidt, 2012). There is some evidence that political and cultural differences drive the religious ones (R. P. Jones, 2016). There appear to be individuals who are primarily motivated by their “coalitional commitment” to a religious group, rather than by perna sonal religious devotion (Ginges, Hansen, & Norenzayan, 2009). And these individuals are more likely to endorse violence against out-­groups (Bloom, 2012; Ginges et al., 2009), an extreme and unfortunately common example of the pattern in certain kinds of religious/cultural commitments. However, one can also use religious principle to critique a conventional morality Fi that falls short in some respect. One of the central characteristics of religion is its critique of conventional morality (Bellah, 2011). Gregg (2005, chapter 3) reviews how the values of Islam help to counter and limit the honor/shame system in Middle Eastern countries, and even help to “set the developmental task of identity formation … to integrate pursuits of honor and piety into a whole, or at least a balanced life” (Gregg, 2005, p. 167).6 Gibbs (1977) claims, for instance, that the post-­conventional reasoning one can find in Kohlberg’s interviews is not always simply justice based but can be more existential-­or religion-­based critiques of conventional morality (Gibbs et al., 2007). 6 Kohlberg would score basic religious commitments as a part of conventional morality (Richards & Davison, 1992) but might score more sophisticated religious reflection as post-­conventional (Gibbs, 1977). Taking Moral Action Thus, the influence of religion in culture and in morality is multifaceted, drawing from group commitments and personal piety, and providing organizational support and opportunity for action (Matsuba, Hart, & Atkins, 2007; Oliner & Oliner, 1988). 3.2.1.3 Class Differences Cultures with class differences can also expect to entertain moral diversity. In a series of experimental studies, Stellar et al. (2011) have found that lower-­class Americans exhibited more compassion than upper-­class individuals (e.g. in verbal response to other individuals and even in heart rate). Several studies have also shown that lower-­class individuals tend to have an interdependent view of the self, while upper-­ class individuals value independence (Heine, 2010). Complications quickly arise in this picture since, for instance, Bowman, Kitayama and Nisbett (2009) have found that middle-­class Americans gave and received more help to each other than working-­class individuals, who reported more self-­reliance. Like s religion, we are likely to find the cultural differences embedded in class to be complex and multilayered. of 3.2.1.4 Individual Variation in Goals Another kind of moral diversity is evident in the wide diversity of moral goals that individuals set for themselves. The pioneering work of Colby and Damon (1992) in moral exemplars shows great variety of goals ro among their sample of exemplars, even though their sample was primarily limited to individuals doing social service. These fell into two large groupings, those interested in reform of society and those interested in direct service to those in need. But even in these groupings, the exemplars they interviewed had some focus for their efforts, lP rather than being a “jack of all trades” in moral excellence. Huff and Barnard (2009) found a similar distinction among exemplars in the computing field, though they also found about a third of their exemplars fit neither category and instead cared deeply for some other passion, such as mentoring, education, or particular social-­ technical issues. na Walker, Frimer, and colleagues (Matsuba & Walker, 2004; Walker & Frimer, 2007, 2009; Walker & Hennig, 2004; Walker & Pitts, 1998) have done the most systematic work in identifying clusters of goals and personality characteristics that identify highly moral individuals. They have found clusters of “communal” and deliberative (Walker, Frimer, & Dunlop, 2010), just, brave, and caring (Walker & Fi Hennig, 2004), and caring/dependable and principled/idealistic (Reimer, DeWitt Goudelock, & Walker, 2009). The work on exemplars is somewhat cross-­cultural, including British, Scandinavian, Canadian, and American samples. Still, all these sub-­ types and different goals of moral excellence are from Western, educated, industrialized, rich democratic (WEIRD) societies (see Henrich, Heine, & Norenzayan, 2010) and it seems unlikely that the variety will diminish as further research encompasses other cultures. Thus, even within cultures one can find extensive moral diversity. Most of the work that relates to within-­culture moral diversity has been conducted in WEIRD societies (Henrich et al., 2010) though we are beginning to see some within Asian cultures (e.g., Kitayama et al., 2006). The variety of moral sub-­ecologies within any culture is likely to be wide, including regional, class, religious, race, and organizational differences, and the interactions of these. For instance, a national concern that corporations in Japan no longer serve the “household” function they used to has resulted in a recent Moral Ecology 63 upswing in interest in ethics among engineering schools and firms in that country (Downey, Lucena, & Mitcham, 2007). In contrast, because of their complicity in WWII, engineering firms in Germany have recently required a strong commitment to ethical practice, but engineering firms in France rarely talk explicitly about ethics, instead concentrating on the role of engineers as the elite vanguard of progress for the nation. In each of these cultures, local history and values have resulted in different ethical/moral approaches to a professional field. We really are just beginning to find our way in this multitude of differences. Work by Muthukrishna et al. (2020) provides a useful index of cultural distance that can be computed between any two cultures based on the World Values Survey. Dimensional models like this will facilitate comparisons across multiple cultures on psychologically relevant dimensions. s 3.2.2 Patterns in Moral Diversity Across Cultures There is a much longer history of research in the psychology of cross-­cultural differof ences (see Heine, 2010 for an overview). It is from this work that we will find some pattern in the diversity of cultural difference. There is evidence for some cultural moral universals. For instance, Curry, Mullins, and Whitehouse (2019) found broad agreement across sixty societies in basic principles that allow for cooperation. And ro Kinnier, Kernes, and Dautheribes (2000) provide four major categories of agreement across world religions. We have already covered the convergence across cultures of the early stages of the Kohlberg framework. Extensive work in this area (see Gibbs et al., 2007 for a review) lP has shown that access to broad social differences can serve as developmental pressure to move individuals from preconventional to conventional moral stages. But this unity falls apart in what Kohlberg hypothesizes to be the higher post-­conventional stage of moral development – for Kohlberg, this is a movement to a concern for principles of equal justice. It turns out that different cultures have different preferences na for the principles that can guide moral judgment at these higher levels. For instance, research shows that Americans prefer equity as a means of distributing scarce goods, while those from India prefer need and those from Japan prefer equality (Heine, 2010). Some theorists suggest that, rather than the “higher stages” being a Kohlbergian shift to thinking of a particular type (justice) across cultures, instead those who question Fi the conventional judgments within their society find culturally embedded and supported ways of questioning, supporting, and providing flexibility to conventional wisdom (Gibbs et al., 2007). Thus, they are still “post” conventional but question and modify conventional wisdom in a way that is locally relevant and culturally supported. On a more descriptive level, Schwartz and colleagues (Bardi & Schwartz, 2003; Roccas et al., 2002; Schwartz, 2006, 2010) have shown a two-­dimensional organization that defines the value dimensions on which individuals from differing cultures disagree. Work in over seventy countries using a variety of instruments converges on this solution that represents the similarities in the way values relate to each other, and the differences in the emphasis different cultures and individuals make on those values. Thus, there is agreement about what dimensions are ­important but variation on which ends of the dimensions to emphasize. Figure 3.1 shows the standard circumplex of these values, with the two dimensions labeled Taking Moral Action SelfTranscendence UniversSelfalism Direction Openness to Benevolence Change Stimulation Conformity Tradition Hedonism s Security Conservation of Achievement Power SelfEnhancement ro Figure 3.1 Schwartz circle of value regions. Source: Adapted from Borg et al. (2015). lP self-­enhancement – self-­transcendence and conservation – openness to change. Support of any one value on the circle tends to correlate with support for adjacent ones, and less support for those on the opposite pole. Work by Geert Hofstede (2001) and by Ronald Inglehart & Christian Welzel (2005) makes similar points na about variation in values among cultures. Distinctions among societies on the individualism–collectivism dimension have a long history in cultural psychology (Triandis et al., 1986) and seem also to be the most psychologically fruitful, encompassing a variety of cross-­cultural differences (Heine, 2010). Individualistic cultures emphasize both the self and others as Fi ­independent, agentic, and interested in self-­enhancement. All these differences, and many others relevant to this dimension (see Heine, 2010 for a review) have relevance for how people from within these cultures think about individual responsibility and agency. In an interesting convergence of within-­and cross-­cultural patterns, Kitayama at al. (2006) have shown that when frontier conditions prevail in a subset of a ­collectivist country (as in the Hokkaido frontier of Japan in the late 1800s) one finds a more individualist subculture emerging. A similar historical mechanism has been theorized to be behind the honor culture in the southern United States (Nisbett & Cohen, 1996). All the variation we have seen so far should lead us to be skeptical of work in moral psychology that makes universalistic claims but is done primarily in WEIRD cultures. When we look cross-­culturally at issues of morality we find both difference and ­similarity. There are differences in the kinds of values or moral foundations individuals Moral Ecology 65 hold (both cross-­ culturally and within cultures). But there are patterns to the ­differences. Haidt and Craig’s (2004) five foundations, Schwartz’s (2010) values ­circumplex, Hofstede’s (2001) intercultural dimensions, and Inglehart and Welzel’s (2005) World Values Survey all point to patterns in the ways that cultures and ­individuals both agree and disagree on moral issues. Recent work by Schwartz and colleagues (Zapko-­Willmes et al., 2021) suggests that the value circumplex and the moral foundations approach have both a shared structure and differences. More work like this is needed to help find some convergence among the diverse systems of cross-­cultural value difference. 3.3 Moral Ecology at the Organization Level s Organizations are important influences on moral action in part because of their of impact on individuals working or volunteering within them and in part because of the profound influence they exert on society and culture. For instance, the Association of Certified Fraud Examiners (2018) estimated that unethical conduct in organizations cost the global economy nearly US$4 trillion in 2017. Here we will review processes ro supporting both ethical and corrupt practices in organizations. 3.3.1 Organizational Values and Goals lP Organizations can also provide variation in moral environment within a culture or industry. In interviews with engineers in the Chicago area, Davis (1998) has found that engineering firms differ systematically in their moral ecology, and thus in the way they treat the engineering role. Finance-­driven organizations give priority to maximizing financial goals, and engineers in these firms do not participate in decision-­ na making, but instead stand outside the process in a consultant-­like role, providing information, producing design options, and answering questions. In this environment, engineering values are subordinated to management goals, and the engineer’s ethical responsibilities are limited to exercising due care when providing advice and services, avoiding conflicts of interest, and remaining loyal to the legitimate interests Fi and objectives of managers. This produces the classic due care blame-­avoidance memo documenting concern about a product or design strategy. In the other two kinds of organization, engineers participate in decision-­making, and managers seek consensus with engineers. Quality-­driven organizations see the achievement of quality products as the defining goal. For instance, one engineer is quoted by Davis (1998, p. 133) as saying, “Cost comes in only after quality standards are met.” And another offers that, “If a customer wants to take a chance, we won’t go along” (Davis, 1998, p. 133). Customer-­driven organizations see superior customer service as a defining goal. All three kinds of organization are constrained by financial issues, quality, and customer service, but they differ in terms of which goal they see as primary or fundamental. It is these differences that result in differing moral ecologies in the organizations and in differences in the moral roles and moral choices of the engineers in them, and the moral skills they need to practice. Taking Moral Action 3.3.2 Processes Supporting Organizational Corruption One way to ask about how organizations construct moral ecologies is to look at how they construct immoral ecologies, the systematic planning and execution of illegal activities. There is a significant literature in this area. In a review of work on organizational corruption, Ashforth and Anand (2003) propose three processes by which organizational misbehavior is supported: rationalization, institutionalization, and socialization. In rationalization, actors in the organization convince themselves that the behavior is legitimate. These acts are then institutionalized as a matter of routine in the organization, and those new to the organization are selected and socialized into the routine performance of the actions. These processes provide a structure for our review of influence toward both ethical and unethical action in organizations. s 3.3.2.1 Rationalization There are at least two approaches that individuals can use to separate action from its moral implications domain limitations and cognitive of distancing. Domain limitations are ways to make moral consideration in a particular situation or domain not relevant. Thus, the moral question simply does not arise. Once the moral question arises, then one can use a variety of cognitive strategies to minimize its relevance. ro Moral action can seem relevant in some domains or circles of action but not in others. Colby and Damon (1992) note this in the lives of their moral exemplars: people who give their lives to causes such as racial equality or feeding the poor often treat their families with much less concern than one might expect for such compaslP sionate individuals. In organizations, this occurs in part because of the way the organization defines the situation. Treviño, Weaver, and Reynolds (2006) speak of this as “situationally defined identities becom[ing] entrenched within organizations” (p. 962). In one study (Weber & Wasieleski, 2001) business managers enrolled in MBA courses were found to respond at lower levels of moral reasoning na (in Kohlberg’s scheme) when asked about work-­domain issues than asked about non-­work-­domain issues. The salience of the moral aspects of an action is ­influenced by what T. M. Jones (1991) calls moral intensity. Moral intensity is a combination of: (1) magnitude of the consequences; (2) concentration of the effect; (3) probability of the effect; (4) its temporal immediacy; (5) social consensus on the moral Fi status of the action; and (6) proximity (see Treviño et al., 2006, pp. 953–954 for a review of research on this concept). High moral intensity can jar the senses and make it difficult to maintain a definition of the situation.7 Still, as the Milgram (1963, 1974) studies have shown, a definition of the situation can trap the actor into a situation even when moral intensity is quite high. It is the combination of high moral intensity (giving clearly painful shocks to a helpless, suffering, and protesting acquaintance in the next room) and the strong situational definition (having promised to be a good subject to help science) that produced the stress reactions that Milgram’s subjects experienced. 7 One can imagine designing organizational procedures to highlight the moral intensity of proposed actions (Epley & Tannenbaum, 2017). For example, in software design, design procedures that incorporate concern for those affected by the software are available (Leveson, 1995; Nissenbaum, 2011; Shilton, 2018; Umbrello, 2019). Moral Ecology 67 When domain limitations fail in making the moral aspects of organizational actions irrelevant, there are a host of cognitive strategies available to help the individual justify the course of action. In their article on corruption, Ashforth and Anand (2003, pp. 16–22) list legality, denial of responsibility, denial of injury, denial of victim status, denial of status to those who critique, appealing to higher loyalties, metaphor of ledger, and refocusing attention. Bandura (1999, 2002) has a similar list of “moral disengagement strategies” compiled from a separate theoretical approach: moral justification, advantageous comparison, euphemistic labeling, minimizing, ignoring, misconstruing, dehumanization, blaming the victim, displacement of responsibility, and diffusion of responsibility. The point of all these disengagement strategies is to distance the actor from moral responsibility for an action.8 3.3.2.2 Institutionalization When an action becomes “standard operating procedure” s it becomes institutionalized (Ashforth & Anand, 2003). This means that it no longer requires a decision process. In institutionalizing corruption, it is usually the avoidance of of a decision process that is institutionalized (Ashforth & Anand, 2003). It is not just procedures that are institutionalized, the structure of an organization can also be affected. Since the adoption of the Federal Sentencing Guidelines for Organizations in 1991 made them a factor in recommended criminal sentences, organizational ro ethics programs in the United States (often called offices of ethics and compliance) have become a standard part of organizational hierarchy (Stansbury & Barry, 2007). Organizations that want to provide plausible deniability for ethical misconduct have been known to establish a position to support corrupt practices ironically titled by lP Braithwaite (1989, p. 350) “vice president responsible for going to jail” allowing others to be willfully blind of misconduct. In cases of corruption, the organization “comes to expect and then depend on the payoffs from corruption. In time, goals, budgets, information flows, rewards and punishments and so on may be skewed to support the practices” (Ashforth & na Anand, 2003, p. 9). The common claim is that, particularly in countries known for corrupt business practice, this sort of activity is required to do business. This claim seems only to be partly true. In a study of 480 of the world’s largest corporations across many different cultures, Healy and Serafeim (2012) show that organizations that report and combat corruption have slower but more profitable sales growth and Fi return on investment, but that this difference only occurs in high corruption countries. They speculate that establishing a reputation as corruption free gives an advantage that results in slower sales growth but increases in return business based on trustworthiness. The corruption-­fighting companies establish this reputation in part by institutionalizing policies and procedures that encourage and support reporting (Healy & Serafeim, 2012). One can institutionalize ethical action in firms by adopting business procedures that embed ethical considerations as in the proposed procedure of Helen Nissenbaum (2011) for privacy in software or that of Nancy Leveson for safety in complex systems 8 A systematic comparison of the Ashforth and Anand (2003) and Bandura (1999, 2002) strategies with the dimensions of moral intensity would be an interesting endeavor and might bring some order to what now stand as mere lists. Taking Moral Action (1995). Another proposal for institutionalizing ethical reflection and action is the idea that one can design this into organization structure (Epley & Tannenbaum, 2017). A widely recognized form of institutionalization to support ethical action is the adoption of an organizational code of ethics. The bad news for such approaches is that across the broad range of codes of ethics in organizations, there seems to be little effect on employee or organizational misconduct (Treviño et al., 2006). The good news is that one approach to such codes does offer some promise: what Treviño et al. (2006) call “value internalization” approaches. These approaches are less about compelling compliance with rules and more about providing support and socialization. They operate through the organizational culture and leadership commitment, and through what Gehman, Treviño, and Garud (2013) call values practices: those activities that embody and shape concern for values in an organization. These practices not only shape employees but also reaffirm and maintain (or challenge and modify) s organizational structure and are thus a vital part of institutionalization. An example of such practices comes from a study of the daily interactions in a national funding of agency responsible for research in information and communication technology (Grimpe et al., 2020). In-­depth interviews revealed that the workers collaboratively constructed the organization’s response to responsible conduct of research issues by embedding the issues in daily conversations and tasks. It became a matter of habit to ro take these issues into consideration in everyday tasks, and in this way, without fanfare, the workers were contributing to the moral ecology of the organization. As long as employees think basic procedural justice is being served in the organization (e.g. one does not suffer for ethical behavior), then these values practices are more broadly lP effective than compliance-­based efforts (e.g. punishing noncompliance with rules). This pattern is called the paradox of control (Stansbury & Barry, 2007), where attempts to directly control employees’ ethical actions are viewed as coercive,9 while the socialization approach of value internalization gives flexibility and professional commitment to employees’ existing ethical goals. A widely cited form of this ­advantage na for socialization rather than control approaches is the relative success of socialization-­ based (vs. control-­based) diversity programs in organizations (Dobbin & Kalev, 2016; Paluck et al., 2021). This brings us then to the topic of socialization. 3.3.2.3 Socialization As implied by the paradox of control, socialization is more Fi than simple passive absorption of the dominant culture. It involves active choice on the individual’s part. Much of the description of socialization here is taken from the organizational psychology literature, but parallels can be found in cultural psychology (Markus & Kitayama, 2010) and developmental psychology (Tomasello & Vaish, 2012). The attraction–selection–attrition cycle (Ashforth & Anand, 2003) is the gateway to socialization in organizations. Individuals with similar values are attracted to the organization, the organization seeks out these people, and those who find a bad fit between themselves and the organization often leave. Once hired, participation in values practices helps to educate, influence, and motivate employees to adopt the 9 See references to “Darley’s Law” that any system of coercion will be gamed (Darley, 1994) in proportion to the extent that its metrics are quantitative. Moral Ecology 69 values and practices of the organization. People don’t expect to suffer for ethical behavior, but the relationship between reward and ethical behavior is complex (Treviño et al., 2006). Socialization occurs primarily at the local level and, though influenced by organizational climate and ethics codes, it is identification with veterans (Ashforth & Anand, 2003) and local values practices that carry the day. For instance, the extent to which ethical language is actually used in a company is a good (though not infallible) guide to ethical behavior within it (Gehman et al., 2013). Another effective strategy is reintegrative and dis-­integrative shaming (Braithwaite, 1989; Stansbury & Barry, 2007) involving public attempts to influence those who do not seem to understand the local culture (whether that culture supports or opposes corruption) with an eye to inducing them to join in the culture or to leave it. This moral seduction leads the receptive newcomer to view the world through the “moral microcosm” of the local organization unit (Moore et al., 2006). s of 3.4 Close Relationships in Friendship and Community If local units within organizations are the most powerful agents of moral ecology for the individual, then outside of organizations the most powerful agents should also be ro local: small communities and personal relationships. In this section, we look at the most intimate and smallest scale of moral ecology. Ironically, one of the pioneers of research on the role of the community in morality is the person most known for championing the cognitive aspects of morality, Lawrence lP Kohlberg. In part in reaction to his experiences on a kibbutz (Walsh, 2001), Kohlberg helped found the first just community school, the Cluster School in Cambridge, MA. This is the school from which the quote at the beginning of this chapter is taken. Though just community schools were designed to be democratic, with students and staff each having only one vote, their primary innovation was the attempt to develop na a moral community: “a group that shares an explicit commitment to a common life characterized by norms embodying high moral ideals” (Power, 2004, p. 50). The approach was theoretically based in Durkeim’s (1925/1973) work on moral communities in education.10 The just community approach recognized that norms and values were important but also emphasized individual commitment to shared ideals Fi within the framework of a responsible community.11 As Power explains (2004, p. 52): “The self does not experience a sense of obligation or responsibility to act in isolation but with others within a cultural setting.” The just community schools and their progeny serve as laboratories in which to observe these processes. But of course, these processes do not occur only in laboratories. They are crucial to the maintenance of all communities. Daniel Hart has pursued a research program on moral commitment and volunteerism in neighborhood and community that has charted the ways that individual moral commitment and development are rooted in 10 This grounding in Durkheim is somewhat ironic, given Durkheim’s clear relativism and Kohlberg’s trenchant critique of relativism (Eberhardt, 2014). 11 In this respect, Kohlberg and Gilligan were much closer together in their approaches than is commonly realized. Taking Moral Action social groups (Hart, 2005; Hart, Atkins, & Southerland, 2006; Hart & Carlo, 2005; Hart & Fegley, 1995; Hart & Matsuba, 2007, 2009; Matsuba et al., 2007). He summarizes: Moral identity, a commitment to advance the welfare of others that is consistent with one’s self-­image and moral goals, emerges from the interplay of family background, personality, moral cognitions and attitudes, self-­perceptions and moral emotions, and social relationships and interactions with social institutions. No single element is the keystone; there are multiple routes to moral identity formation. (Hart & Matsuba, 2009, p. 228). However, one consequence of moral identity being embedded in community is that it then becomes subject to domain limitations. It becomes focused on our obligations to each other, often to the exclusion of others, resulting in moral collapse s (Hart, 2005). When identity becomes fused within a limited community in this way, great evil can result (Graham & Haidt, 2012; Hart & Matsuba, 2007; Staub, 1999). of Community-­based morality is a fragile achievement that requires constant maintenance and is in part a result of the good fortune and thoughtful choice of one’s social surroundings (Hart, 2005, p. 260). The smallest unit of social influence in morality is the dyad. Work on the moral ro psychology of this level of influence has been quite rare until recently. But work on what has been called the Michelangelo phenomenon has important implications for thinking about how individuals achieve and maintain their moral action. The Michelangelo phenomenon occurs when one member of a dyad helps to shape a lP close partner’s skills and traits in support of achieving the partner’s ideal self (Rusbult, Finkel, & Kumashiro, 2009).12 Research has mostly concentrated on romantic partners, though Rusbult et al. (2009) argue that the effect should equally be seen in family, friendship, and collegial relationships to the extent that these are closely interdependent. In another example of the paradox of control, this sculpting na effect requires ­special conditions. First, the partner must be supportive of the other’s ideal self, not just supportive of what the partner thinks is best for the other (Drigotas et al. 1999). In fact, this latter kind of “support” appears to hamper both the partner and the r­ elationship (Rusbult et al., 2009). Second, the support for the ideal self of the other needs to be in the context of movement toward the goal of Fi attaining it, and not simply in assessment of the discrepancy (Kumashiro et al. 2007). The assessment approach involves a primary focus on evaluation and critique, and when one is the target of the sculpting process (you have a partner who simply assesses your discrepancy to your ideal self), this leads one to think the other is not supportive. When one is the sculptor, the assessment approach leads one to be less affirming, disapproving of the goals, less involved in the sculptee’s pursuits. Mere assessment is debilitating to the sculpting process. Locomotion involves a 12 Like many of the concepts reviewed in this book, the socially constructed self has a long theoretical history going back to Aristotle’s emphasis on friendship, social science formulated by James (1890), Cooley (1902), and Mead (1934), and continental thought from Kierkegaard (1846/1992) to Jaspers (1919) to Gadamer (1975). Moral Ecology 71 focus on affirmation and moving toward the goal of the sculptee. This effect may well be culture-­dependent (Markus & Kitayama, 2010). Research on the Michelangelo phenomenon has only recently been extended to influence among friends and between supervisor–supervisee work pairs (Bagci et al., 2016) and it also appears to hold in these relationships.13 Thus, the Michelangelo phenomenon may provide a window into one way that social influence in communities, organizations, and culture may work. The influence of the local unit in organizations comes through close, interdependent interactions with coworkers. The influence of culture comes from socialization experiences with proximate others too. The Michelangelo phenomenon may play a central role in much of the influence that Markus and Kitayama (2010) propose in the “daily situations and practices” aspect of their model of cultural influence on the self. There are, of course other levels to the model of culture and self (language, media, education, pervasive ideas, etc.), but this s cooperative sculpting process may play a central role in how we become (or avoid or fail to become) moral. 3.5 Influencing the Moral Ecology of ro The moral ecology metaphor encourages us to think about cultural influence as reciprocal. We often have the freedom to choose our influencers, to volunteer, to join organizations, to move cultures, to protest our treatment, to encourage moral action in others, to try to change our surroundings or to leave them behind. In short, we lP often have the freedom to influence both the small-­and (less often) large-­scale moral ecology that surrounds us. 3.5.1 Organizational Ethics As a Design Problem na Epley and Tannenbaum (2017) propose we construe ethical action in organizations as a design problem. How do we design organizations so that they promote and produce ethical action? They review a large literature in organizational psychology (some of which is included in Section 3.3) and then propose that organizations can construct hiring, compensation, reputation management, and operations processes so Fi that they support ethical action. They list three psychological levels on which this ethical design can occur: attention, construal, and motivation. 3.5.1.1 Attention: Are Ethics Top of Mind? In organizations attention is often focused on goals of efficiency or profit. But organizational processes can be designed to make ethical concern and evaluation a part of routine decision processes. They offer the hiring interview protocol that companies like Johnson & Johnson use. The interview is structured in part to begin the socialization process of new employees into corporate culture. It includes numerous questions focusing on how prospective employees 13 The process may also be similar to some kinds of parental influence (Patrick & Gibbs, 2012). Taking Moral Action might support the company value of ­prioritizing the needs of the people it serves. This focuses attention on the values that are held in that organization. 3.5.1.2 Construal: Are People Asking “is It Right?” The procedures that a company follows are often simply implemented without ever being evaluated. But do employees ever ask, “Is this the right thing to do?” Compensation policies that tie executive performance to clear measures of values can help connect personal decisions made by executives to values the organization supports. Southwest Airlines, for instance, has an “every employee matters” slogan that is incorporated into the compensation packages of executives by tying compensation to measures of voluntary turnover in that executive’s division. 3.5.1.3 Motivation: Are You Using Pro-­social Goals? Most employees are interested in s doing (or at least seeing) some good in the work they do. Organizations can leverage this already existing desire and align it with values the organization supports. Virgin of Atlantic rewarded its pilots for increasing fuel efficiency by donating money to charities of the pilot’s choice. This change in policy significantly increased job satisfaction. It seems clear there are ways for organizations to influence the ethical behavior of ro their employees and executives. These approaches are fraught with complexity (e.g. the paradox of control) but they can produce significant organizational change and support moral action within organizational cultures. lP 3.5.2 Moral Exemplars and Social Reformers The pioneering work of Colby and Damon (1992) in moral exemplars shows great variety of goals among their exemplars, even though their sample was primarily limited to individuals doing social service. Among their exemplars were people na who campaigned for justice in civil rights, for health care, or for equal economic opportunity. Huff and Barnard (2009) found a similar distinction among cases in the computing field. The computer scientists, software engineers, and policy advocates they interviewed included a significant number of reformers campaigning for opensource software, privacy policy, inclusion of women in the field, safety standFi ards in software, and other goals. In both studies, those working for social change often expressed frustration at the opposition they faced, and the difficulties involved in producing social change. Working for social change is difficult, and these exemplars leveraged social support and their own optimism to maintain their motivation. Hirschman’s (1970) Exit, Voice and Loyalty provides a structure for the choices facing those who work in firms, organizations, and government as these begin to conflict with the values and principles of members. The framework (with the addition of a “neglect” option) has been used to explain a wide variety of choices for and against social change including the decision to blow the whistle in government and business (Uys, 2022), organizational change, and human resources (Allen, 2014). These choices resonate most clearly with the case of the 2020 presidential election in the United States that we outlined in the Introduction. Different actors in the Republican Party chose differently, some opting for voice (as did the two in our case), Moral Ecology 73 some opting for exit (as did some of their colleagues who resigned), and some opting for loyalty to the president in his last days in office. 3.5.3 Moral Action as Critique and as Design Leadership and social change work are classic examples of how the moral ecology is shaped, but there are many other informal approaches. The three processes we reviewed in Section 3.3.2 – rationalization, institutionalization, and socialization – are also modes of influence to change the moral ecology for the better or worse. One can use cognitive and motivational strategies to make stakeholders more (or less) ­visible, risks more (or less) considered, and choices more (or less) conscious (Epley & Tannenbaum, 2017; Messick, 1996). One can institutionalize these strategies in offices of ethics and compliance, or in the process models used in the development of s products. And one can socialize individuals into these processes. When organizations or culture do not meet one’s moral standards, one can of attempt social change (choosing voice over exit or loyalty). The work on volunteerism, social reform, and, as a last hope, courageous resistance provides examples of this strategy that are widely spread across cultures (see the Introduction for examples). Much of the work of moral exemplars in social service (Colby & ro Damon, 1992) and computing (Huff & Barnard, 2009) consists of trying to change moral ecologies, often in face of stiff resistance. In addition, when others offend the moral standards of a community, individuals in that community can take it upon themselves to defend the standards by punishing the offender, often lP at cost to themselves (Bowles et al., 2012; Boyd, Gintis, & Bowles, 2010; Boyd et al., 2003). Even children engage in vocal protest against injustice in social relations, ever more effectively as they develop skills such as perspective taking (Killen & Dahl, 2021). na 3.5.4 Leadership One place where we might expect this design to happen is in leadership in organizations. In agreement with the emphasis here on ecology, models of leadership have moved from classical great-­man and matching approaches to an understandFi ing of the complexity of leadership in organizations as a “dynamic cocreational process among leaders, followers, and environments” (Thoroughgood et al., 2016, p. 627). Leadership is now recognized as being shared and distributed, even in hierarchical and control-­ oriented organizations (Avolio, Walumbwa, & Weber, 2009; Hogg, 2001). And the process by which leaders influence others has been expanded to include emotion, value, and self-­concept variables in addition to classical control models (Avolio et al., 2009). For instance, work by Vianello and Haidt (2010) shows that one way that leaders influence others is through eliciting the moral emotion of elevation in response to the leader’s display of interpersonal fairness and self-­sacrifice. Bad leadership can produce negative moral emotions (e.g. anger, disgust) and these emotions can be contagious, spreading to other workers without the need for direct negative experience (Dasborough et al., 2009). In this respect, moral potency has been suggested as a central measure of a leader’s effectiveness in inducing change, and is the combined effect of courage, efficacy, Taking Moral Action and ownership (Hannah & Avolio, 2010). However, it concentrates narrowly on characteristics of the leader. An important lesson emerges from the evolution of leadership theories. One must beware of romanticizing a role as primarily constituted by the excellent or expert characteristics of the person inhabiting that role. There has been a trenchant critique of this romanticizing of the leader in leadership research (Collinson, Jones, & Grint, 2018; Ford, Harding, & Gilmore, 2022; Meindl, Ehrlich, & Dukerich, 1985) and a concomitant focus on the complexity of the social interactions among leaders, followers, and the environment. Hogg (2001), for example, uses social identity theory to construct a model of leadership that is a function of the social system rather than the leader. Shared social identity and an in-­group-­based influence process identify some members as prototypical leaders thereby producing in-­group status differences. While both leaders and followers negotiate over the values, purposes, and plans of the group, s there is an attributional process that misattributes all, or most of, the influence to the leader (Hogg, 2001). of The literature on moral exemplars and moral expertise needs to take note of this critique, and this chapter is the right place to do so. We know very little of how moral exemplars interact with their collaborators, followers, and the surrounding moral ecology. Colby and Damon’s (1992) classic study of exemplars looks carero fully at their exemplars’ interactions with others as a part of their developmental trajectory; but it still treats the exemplariness of their action as mostly originating from their exemplary character rather than from the “dynamic cocreational process” between exemplars and their moral ecology. One can find the beginning of lP this critique in some places in the exemplar literature (Frimer, 2018; King, Mueller, & Furrow, 2013). With this section on influencing the moral ecology, we come full circle in the cycle of mutual constitution of individuals and culture (Hamedani & Markus, 2019; Markus & Kitayama, 2010). This is a process constantly in flux, na at a variety of levels of influence and resistance, and we can only gesture to its complexity here. 3.6 Discussion Fi This review of the ways that moral ecology can influence moral action, and be influenced by it, is admittedly spotty. The point is not to make a comprehensive review of moral psychology as influenced by friendship, families, groups, organizations, and culture.14 It is more to show the wide variety of ways that moral action can be supported or led astray by the social surround, and the ways that the social environment can be influenced so it is more supportive of moral action. If the review provides windows into the processes of moral ecology and some idea of its variety and importance, then it has been successful. Still, there are some tentative conclusions we can make from the work reviewed so far. 14 This would be a book in itself and we know of no volume attempting this. Moral Ecology 75 3.6.1 Conclusion The range of moral ecologies is wide, but they share characteristics across their v­ ariety. The extent to which these characteristics are shared across all levels is a matter for empirical investigation, so these conclusions should be taken as tentative. Some conclusions (e.g. Section 3.6.1.1) share an evidence base from other chapters and can be thought of as more established: 1. Moral psychology is also the psychology of evil. Many of the moral ecology processes we have covered have a complex relationship to the content of the moral action they support or hinder. Designing institutional processes to support particular valued employee and executive actions might be a way to support either corruption or ethical action. The limits of the Michelangelo s phenomenon have yet to be explored but it seems reasonable that it would work for one partner to help another to obtain an ideal self that might harm the self (e.g. of anorexia) or others (e.g. terrorism). We may find some processes in moral psychology that are more likely to result in immoral rather than moral action. For instance, the moral disengagement strategy of minimizing harm is pervasive in justifications of aggression. Still, surgeons and doctors may need to psychologically minimize ro the harm they do to allow themselves permission to do surgery (Collins & Pinch, 2005). And soldiers in combat need to objectivize the enemy to do their job (Grossman, 1996). In this way, moral psychology is likely to be immoral psychology, and the psychology of moral exemplars also becomes the psychology of lP evil. 2. Moral ecologies can support domain limits in moral judgment and action, making integrity across situations difficult. A specific moral ecology can provide domain-­limited morally relevant information (Is this a moral issue? Are these people I should care about?). It can also prime na particular moral emotions and skills and thereby make certain kinds of (im)moral action more relevant and/or likely. Cultural institutions, values, activities, organizational procedures, domains of concern in volunteer organizations, and the moral support of close others can define particular issues as important or irrelevant to the moral self. It can even make some individuals subject to compassion and others Fi subject to attack (Hart, 2005). Some moral principles (e.g. group loyalty, Haidt & Joseph, 2004) have this domain limitation as an integral part of their structure. This may be a more general problem about the limitation of human resources: focus on anything requires one to remove focus from something else. 3. There is a structure to the moral differences both across and within cultures. Our catalog of moral differences within and across cultures is already quite long even in this short review. But what is often missed is that these cultural differences have a structure to them that allows one to see a larger pattern to the agreement and disagreement within and across cultures. There are still multiple ways to describe the dimensions in these differences, and it may take some time to determine the best empirical solutions to a description. But there is agreement that there is indeed a structure and that cultures and individuals do not simply randomly choose to value some things (e.g. the color blue) and not others. This makes the empirical case for radical “anything goes” cultural relativism less persuasive. Taking Moral Action A more likely description is that there is some finite set of values or dimensions of valuing that are framed by evolution or the constraints of social interaction and that individuals and societies make choices within this limited space. 4. Moral diversity within and across cultures is both a problem and a solution. Moral diversity and disagreement can be found within every culture and across cultures.15 This has usually been approached as a problem. From a philosophical standpoint, it looks too much like support for unthinking relativism. From a political and religious standpoint, it seems the nexus of a great deal of societal conflict and uncertainty. However, Lawrence Kohlberg’s work and that of many others reviewed in this and other chapters (Chapters 7, 8, and 9) make the clear point that this diversity serves as a resource for cultural critique. The shared structure and values within and across cultures make conversations possible across these value divides. They serve as resources for arguments that appeal to common expes rience, value, and intuition in the face of disagreement. This diversity may indeed be seen as similar in importance to genetic diversity in evolutionary processes: of without the existing diversity, change would be impossible. 5. One can approach morality as a design issue. Because (im)moral decisions are imbedded in the structures of relationships, families, organizations, and cultures, one can think of ways to change those relationro ships so that they are more likely to result in moral behavior. This approach connects current research on moral action to ancient traditions of moral thought from Greece, India, and China. Philosophers have long thought about how to structure society. This thought tradition makes it clear that the “design problem” lP approach has no easy solution, nor does it guarantee moral outcomes. But current work in moral psychology helps us discern some structure to the design problem that is based in the psychological capacities and motivations of people. 6. Recognition of diversity within and across cultures does not require radical relativism. The existence of cultural difference is indisputable, as are the patterns of those difna ferences across cultures: cultures agree on which principles they disagree about, and these disagreements have patterns (e.g. values that tend to be endorsed or sanctioned in cultures cluster together, see Schwartz, 2010). These differences may have their origins in evolutionary patterns required for successful group living (Tomasello & Vaish, 2012) and so to that extent they are objective in terms of Fi embodying what is needed for flourishing for the species (Flanagan, 1991; Flanagan et al., 2008). Thus, recognition of these patterns of cultural difference does not require acceptance of cultural relativism or an “anything goes as long as a group endorses it” approach (Flanagan et al., 2008; Taylor, 1982). It is at least compatible with a suitably complex pluralism, a recognition that there are in the human condition multiple foundational values and that different cultures come to different solutions about the appropriate balance among them. A pluralistic approach like this may help in guarding against the sort of moral objectivism (Goodwin & Darley, 2008, 2009, 2010, 2012) that associates a person’s culture’s judgments and actions unequivocally with the good, and demonizes those who disagree (Kekes, 1993). 15 My thanks to Jessica Salvatore, one of the reviewers of this text, for this insight. Moral Ecology 77 7. Humans are not passive recipients of influence in culture, but active co-­creators of it. In almost every section of this chapter we saw humans being influenced by culture, organization, leaders, friends, etc. However, we also saw multiple examples of people changing organizations, influencing each other, and taking action to support other people taking moral action. We provide links to some models of how this happens (e.g. Markus & Kitayama, 2010) but more work is needed. 3.6.2 Application The story of Nathaniel Borenstein’s decision presented in the Introduction is a story of conflicting and overlapping moral ecologies. In it we have a happy incident in which we see multiple moral ecologies influencing an actor to disregard his principles and thereby achieve a moral outcome. Borenstein is a computer scientist and pacifist with s a long history in the peace movement. His perception of the moral ecology of the military was that it was indifferent if not hostile to his concerns about the safety of nuclear of weapons systems. But that very system recruited him to help it critique its own performance on safety. He was motivated to help the military in its self-­critique despite his firm personal value commitment to not consulting for the military. As he began his collaboration, he discovered that the value conflict was more that some actors in the ro private consulting sector were unconcerned with safety if they could sell a contract. His action in altering military perception and policy about certain computer systems is an example of committed individuals taking moral action to change moral ecologies. The NATO lieutenant commander who persistently recruited Borenstein was a pivotal lP player, as was Borenstein himself. Each had different psychologies, goals, and moral influences, but they shared significant overlap that helped to produce conversation and change. The story is also an example of one moral ecology (NATO) using a representative of another moral ecology (the peace movement) to influence a third moral ecology (the military consulting industry). That these very different moral ecologies na had something to say to each other is evidence of the cross-­cultural similarities in the structure of values and an example of how differences are negotiated. 3.6.3 Open Questions Fi In this chapter, we have focused on the mutual influence that people and their surrounding moral ecologies exert on each other. This has led us to consider the complexities of how the various levels of moral ecology interact with each other. Most of these complexities are just beginning to be investigated. 1. Our knowledge of how groups take moral action is fragmented. Addressing this may move us from thinking of virtuous individuals to virtuous ecologies, or the interaction of these, as the source of effective virtue. Work on morality in groups is often isolated from work in moral psychology. In this chapter, we have mostly talked about moral ecology from the perspective of the individual moral actor and his or her role in the moral ecology. But it is possible to move to a group level of analysis. We need better conceptualizations of the group processes involved in moral awareness, judgment, motivation, and action that can help drive research at this level. Some of the work mentioned earlier in leadership Taking Moral Action (Section 3.5.4) might be a source from which to begin theorizing. We have specifically called for work in moral exemplars to start to account for this systemic level of exemplary action. With moral exemplars, one might focus on continued exemplary action (rather than just the single actor) and ask what systems support and hinder it. This might move the conceptual balance of moral character to seeing the “dynamic cocreational process among leaders, followers, and environments” (Thoroughgood et al., 2016, p. 627) as a source of effective virtue. 2. How do moral actors actively grapple with moral diversity? Clearly, cultures, organizations, and even friendships are not homogenous. It is at least clear that the reaction to moral diversity at all these levels is often negative: we judge those who have moral disagreements with us harshly. We need to know more about how people think about, support, or tolerate the diversity of moral judgments and goals in a moral ecology. How do people handle moral tradeoffs s when diverse values are in play? How do choice processes lead to different moral goals at these different levels? How do individuals lobby to turn optional moral of goals into mandatory goals? There are surely even more questions than these. 3. How do the different levels of a moral ecology interact with each other? Markus and Kitayama (2010) have given a beginning conceptualization of how self and culture mutually constitute each other, and their model involves interacro tions at all the levels we have reviewed in this chapter. They include internal representations of the moral ecology, for instance, how daily routines (e.g. hygiene) should be structured, or pervasive moral ideas such as how dependent or interdependent people should be with others. However, their model does not yet seem lP specific enough to drive programs of research in morality (e.g. the word moral only occurs twice in the article). We also do not know enough about the consistency of the structure of value differences across different levels of a moral ecology: Are self-­transcendence and self-­enhancement always viewed as in conflict in all cultures at all levels of a moral na ecology? Nor do we know much about how the larger moral ecology structures the relationships of its constituent units: Why are there such large differences in the frequency of volunteerism across cultures? 4. How does the active construction of identity interact with the various levels of moral ecology? We know from Chapter 5 that how (and whether) people think of themselves in Fi moral terms is of crucial importance. And we know that one cannot be a self by oneself. What does this mean for how a moral ecology helps to constitute the moral identities of those within it? We know there are significant moral differences within moral ecologies. How are moral identities related to those differences, and how do they construe the differences in the ecology? 3.7 Further Readings These suggested reading are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. • Ashforth and Anand (2003). “The normalization of corruption in organizations.” A literature review and a model of how organizations shape immoral behavior. Moral Ecology 79 • Epley and Tannenbaum (2017). “Treating ethics as a design problem.” A proposal that ethical issues in organizations can be treated as a design issue for them, making the point that an organization can shape the ethical behavior of its members. • Heine (2010). “Cultural psychology.” A readable overview of the work on psychological differences across culture. • Markus and Kitayama (2010). “Cultures and selves: A cycle of mutual constitution.” This proposes a multilayered model of how culture influences the self and how the self influences culture. • Nisbett and Ross (1980). Human Inference: Strategies and Shortcoming of Social Judgment. The classic early statement of the primacy of situational influence on judgment and decision-­making. • Sagiv and Schwartz (2022). “Personal values across cultures.” A comprehensive review of current work on values, focusing on Schwartz’s theory of values. It s explores cross-­cultural variation and similarity and the interlinking of cognitive representations, emotions, and motivational goals."
3,3.3,"Moral Ecology at the Organization Level s Organizations are important influences on moral action in part because of their of impact on individuals working or volunteering within them and in part because of the profound influence they exert on society and culture. For instance, the Association of Certified Fraud Examiners (2018) estimated that unethical conduct in organizations cost the global economy nearly US$4 trillion in 2017. Here we will review processes ro supporting both ethical and corrupt practices in organizations. 3.3.1 Organizational Values and Goals lP Organizations can also provide variation in moral environment within a culture or industry. In interviews with engineers in the Chicago area, Davis (1998) has found that engineering firms differ systematically in their moral ecology, and thus in the way they treat the engineering role. Finance-­driven organizations give priority to maximizing financial goals, and engineers in these firms do not participate in decision-­ na making, but instead stand outside the process in a consultant-­like role, providing information, producing design options, and answering questions. In this environment, engineering values are subordinated to management goals, and the engineer’s ethical responsibilities are limited to exercising due care when providing advice and services, avoiding conflicts of interest, and remaining loyal to the legitimate interests Fi and objectives of managers. This produces the classic due care blame-­avoidance memo documenting concern about a product or design strategy. In the other two kinds of organization, engineers participate in decision-­making, and managers seek consensus with engineers. Quality-­driven organizations see the achievement of quality products as the defining goal. For instance, one engineer is quoted by Davis (1998, p. 133) as saying, “Cost comes in only after quality standards are met.” And another offers that, “If a customer wants to take a chance, we won’t go along” (Davis, 1998, p. 133). Customer-­driven organizations see superior customer service as a defining goal. All three kinds of organization are constrained by financial issues, quality, and customer service, but they differ in terms of which goal they see as primary or fundamental. It is these differences that result in differing moral ecologies in the organizations and in differences in the moral roles and moral choices of the engineers in them, and the moral skills they need to practice. Taking Moral Action 3.3.2 Processes Supporting Organizational Corruption One way to ask about how organizations construct moral ecologies is to look at how they construct immoral ecologies, the systematic planning and execution of illegal activities. There is a significant literature in this area. In a review of work on organizational corruption, Ashforth and Anand (2003) propose three processes by which organizational misbehavior is supported: rationalization, institutionalization, and socialization. In rationalization, actors in the organization convince themselves that the behavior is legitimate. These acts are then institutionalized as a matter of routine in the organization, and those new to the organization are selected and socialized into the routine performance of the actions. These processes provide a structure for our review of influence toward both ethical and unethical action in organizations. s 3.3.2.1 Rationalization There are at least two approaches that individuals can use to separate action from its moral implications domain limitations and cognitive of distancing. Domain limitations are ways to make moral consideration in a particular situation or domain not relevant. Thus, the moral question simply does not arise. Once the moral question arises, then one can use a variety of cognitive strategies to minimize its relevance. ro Moral action can seem relevant in some domains or circles of action but not in others. Colby and Damon (1992) note this in the lives of their moral exemplars: people who give their lives to causes such as racial equality or feeding the poor often treat their families with much less concern than one might expect for such compaslP sionate individuals. In organizations, this occurs in part because of the way the organization defines the situation. Treviño, Weaver, and Reynolds (2006) speak of this as “situationally defined identities becom[ing] entrenched within organizations” (p. 962). In one study (Weber & Wasieleski, 2001) business managers enrolled in MBA courses were found to respond at lower levels of moral reasoning na (in Kohlberg’s scheme) when asked about work-­domain issues than asked about non-­work-­domain issues. The salience of the moral aspects of an action is ­influenced by what T. M. Jones (1991) calls moral intensity. Moral intensity is a combination of: (1) magnitude of the consequences; (2) concentration of the effect; (3) probability of the effect; (4) its temporal immediacy; (5) social consensus on the moral Fi status of the action; and (6) proximity (see Treviño et al., 2006, pp. 953–954 for a review of research on this concept). High moral intensity can jar the senses and make it difficult to maintain a definition of the situation.7 Still, as the Milgram (1963, 1974) studies have shown, a definition of the situation can trap the actor into a situation even when moral intensity is quite high. It is the combination of high moral intensity (giving clearly painful shocks to a helpless, suffering, and protesting acquaintance in the next room) and the strong situational definition (having promised to be a good subject to help science) that produced the stress reactions that Milgram’s subjects experienced. 7 One can imagine designing organizational procedures to highlight the moral intensity of proposed actions (Epley & Tannenbaum, 2017). For example, in software design, design procedures that incorporate concern for those affected by the software are available (Leveson, 1995; Nissenbaum, 2011; Shilton, 2018; Umbrello, 2019). Moral Ecology 67 When domain limitations fail in making the moral aspects of organizational actions irrelevant, there are a host of cognitive strategies available to help the individual justify the course of action. In their article on corruption, Ashforth and Anand (2003, pp. 16–22) list legality, denial of responsibility, denial of injury, denial of victim status, denial of status to those who critique, appealing to higher loyalties, metaphor of ledger, and refocusing attention. Bandura (1999, 2002) has a similar list of “moral disengagement strategies” compiled from a separate theoretical approach: moral justification, advantageous comparison, euphemistic labeling, minimizing, ignoring, misconstruing, dehumanization, blaming the victim, displacement of responsibility, and diffusion of responsibility. The point of all these disengagement strategies is to distance the actor from moral responsibility for an action.8 3.3.2.2 Institutionalization When an action becomes “standard operating procedure” s it becomes institutionalized (Ashforth & Anand, 2003). This means that it no longer requires a decision process. In institutionalizing corruption, it is usually the avoidance of of a decision process that is institutionalized (Ashforth & Anand, 2003). It is not just procedures that are institutionalized, the structure of an organization can also be affected. Since the adoption of the Federal Sentencing Guidelines for Organizations in 1991 made them a factor in recommended criminal sentences, organizational ro ethics programs in the United States (often called offices of ethics and compliance) have become a standard part of organizational hierarchy (Stansbury & Barry, 2007). Organizations that want to provide plausible deniability for ethical misconduct have been known to establish a position to support corrupt practices ironically titled by lP Braithwaite (1989, p. 350) “vice president responsible for going to jail” allowing others to be willfully blind of misconduct. In cases of corruption, the organization “comes to expect and then depend on the payoffs from corruption. In time, goals, budgets, information flows, rewards and punishments and so on may be skewed to support the practices” (Ashforth & na Anand, 2003, p. 9). The common claim is that, particularly in countries known for corrupt business practice, this sort of activity is required to do business. This claim seems only to be partly true. In a study of 480 of the world’s largest corporations across many different cultures, Healy and Serafeim (2012) show that organizations that report and combat corruption have slower but more profitable sales growth and Fi return on investment, but that this difference only occurs in high corruption countries. They speculate that establishing a reputation as corruption free gives an advantage that results in slower sales growth but increases in return business based on trustworthiness. The corruption-­fighting companies establish this reputation in part by institutionalizing policies and procedures that encourage and support reporting (Healy & Serafeim, 2012). One can institutionalize ethical action in firms by adopting business procedures that embed ethical considerations as in the proposed procedure of Helen Nissenbaum (2011) for privacy in software or that of Nancy Leveson for safety in complex systems 8 A systematic comparison of the Ashforth and Anand (2003) and Bandura (1999, 2002) strategies with the dimensions of moral intensity would be an interesting endeavor and might bring some order to what now stand as mere lists. Taking Moral Action (1995). Another proposal for institutionalizing ethical reflection and action is the idea that one can design this into organization structure (Epley & Tannenbaum, 2017). A widely recognized form of institutionalization to support ethical action is the adoption of an organizational code of ethics. The bad news for such approaches is that across the broad range of codes of ethics in organizations, there seems to be little effect on employee or organizational misconduct (Treviño et al., 2006). The good news is that one approach to such codes does offer some promise: what Treviño et al. (2006) call “value internalization” approaches. These approaches are less about compelling compliance with rules and more about providing support and socialization. They operate through the organizational culture and leadership commitment, and through what Gehman, Treviño, and Garud (2013) call values practices: those activities that embody and shape concern for values in an organization. These practices not only shape employees but also reaffirm and maintain (or challenge and modify) s organizational structure and are thus a vital part of institutionalization. An example of such practices comes from a study of the daily interactions in a national funding of agency responsible for research in information and communication technology (Grimpe et al., 2020). In-­depth interviews revealed that the workers collaboratively constructed the organization’s response to responsible conduct of research issues by embedding the issues in daily conversations and tasks. It became a matter of habit to ro take these issues into consideration in everyday tasks, and in this way, without fanfare, the workers were contributing to the moral ecology of the organization. As long as employees think basic procedural justice is being served in the organization (e.g. one does not suffer for ethical behavior), then these values practices are more broadly lP effective than compliance-­based efforts (e.g. punishing noncompliance with rules). This pattern is called the paradox of control (Stansbury & Barry, 2007), where attempts to directly control employees’ ethical actions are viewed as coercive,9 while the socialization approach of value internalization gives flexibility and professional commitment to employees’ existing ethical goals. A widely cited form of this ­advantage na for socialization rather than control approaches is the relative success of socialization-­ based (vs. control-­based) diversity programs in organizations (Dobbin & Kalev, 2016; Paluck et al., 2021). This brings us then to the topic of socialization. 3.3.2.3 Socialization As implied by the paradox of control, socialization is more Fi than simple passive absorption of the dominant culture. It involves active choice on the individual’s part. Much of the description of socialization here is taken from the organizational psychology literature, but parallels can be found in cultural psychology (Markus & Kitayama, 2010) and developmental psychology (Tomasello & Vaish, 2012). The attraction–selection–attrition cycle (Ashforth & Anand, 2003) is the gateway to socialization in organizations. Individuals with similar values are attracted to the organization, the organization seeks out these people, and those who find a bad fit between themselves and the organization often leave. Once hired, participation in values practices helps to educate, influence, and motivate employees to adopt the 9 See references to “Darley’s Law” that any system of coercion will be gamed (Darley, 1994) in proportion to the extent that its metrics are quantitative. Moral Ecology 69 values and practices of the organization. People don’t expect to suffer for ethical behavior, but the relationship between reward and ethical behavior is complex (Treviño et al., 2006). Socialization occurs primarily at the local level and, though influenced by organizational climate and ethics codes, it is identification with veterans (Ashforth & Anand, 2003) and local values practices that carry the day. For instance, the extent to which ethical language is actually used in a company is a good (though not infallible) guide to ethical behavior within it (Gehman et al., 2013). Another effective strategy is reintegrative and dis-­integrative shaming (Braithwaite, 1989; Stansbury & Barry, 2007) involving public attempts to influence those who do not seem to understand the local culture (whether that culture supports or opposes corruption) with an eye to inducing them to join in the culture or to leave it. This moral seduction leads the receptive newcomer to view the world through the “moral microcosm” of the local organization unit (Moore et al., 2006). s of"
3,3.4,"Close Relationships in Friendship and Community If local units within organizations are the most powerful agents of moral ecology for the individual, then outside of organizations the most powerful agents should also be ro local: small communities and personal relationships. In this section, we look at the most intimate and smallest scale of moral ecology. Ironically, one of the pioneers of research on the role of the community in morality is the person most known for championing the cognitive aspects of morality, Lawrence lP Kohlberg. In part in reaction to his experiences on a kibbutz (Walsh, 2001), Kohlberg helped found the first just community school, the Cluster School in Cambridge, MA. This is the school from which the quote at the beginning of this chapter is taken. Though just community schools were designed to be democratic, with students and staff each having only one vote, their primary innovation was the attempt to develop na a moral community: “a group that shares an explicit commitment to a common life characterized by norms embodying high moral ideals” (Power, 2004, p. 50). The approach was theoretically based in Durkeim’s (1925/1973) work on moral communities in education.10 The just community approach recognized that norms and values were important but also emphasized individual commitment to shared ideals Fi within the framework of a responsible community.11 As Power explains (2004, p. 52): “The self does not experience a sense of obligation or responsibility to act in isolation but with others within a cultural setting.” The just community schools and their progeny serve as laboratories in which to observe these processes. But of course, these processes do not occur only in laboratories. They are crucial to the maintenance of all communities. Daniel Hart has pursued a research program on moral commitment and volunteerism in neighborhood and community that has charted the ways that individual moral commitment and development are rooted in 10 This grounding in Durkheim is somewhat ironic, given Durkheim’s clear relativism and Kohlberg’s trenchant critique of relativism (Eberhardt, 2014). 11 In this respect, Kohlberg and Gilligan were much closer together in their approaches than is commonly realized. Taking Moral Action social groups (Hart, 2005; Hart, Atkins, & Southerland, 2006; Hart & Carlo, 2005; Hart & Fegley, 1995; Hart & Matsuba, 2007, 2009; Matsuba et al., 2007). He summarizes: Moral identity, a commitment to advance the welfare of others that is consistent with one’s self-­image and moral goals, emerges from the interplay of family background, personality, moral cognitions and attitudes, self-­perceptions and moral emotions, and social relationships and interactions with social institutions. No single element is the keystone; there are multiple routes to moral identity formation. (Hart & Matsuba, 2009, p. 228). However, one consequence of moral identity being embedded in community is that it then becomes subject to domain limitations. It becomes focused on our obligations to each other, often to the exclusion of others, resulting in moral collapse s (Hart, 2005). When identity becomes fused within a limited community in this way, great evil can result (Graham & Haidt, 2012; Hart & Matsuba, 2007; Staub, 1999). of Community-­based morality is a fragile achievement that requires constant maintenance and is in part a result of the good fortune and thoughtful choice of one’s social surroundings (Hart, 2005, p. 260). The smallest unit of social influence in morality is the dyad. Work on the moral ro psychology of this level of influence has been quite rare until recently. But work on what has been called the Michelangelo phenomenon has important implications for thinking about how individuals achieve and maintain their moral action. The Michelangelo phenomenon occurs when one member of a dyad helps to shape a lP close partner’s skills and traits in support of achieving the partner’s ideal self (Rusbult, Finkel, & Kumashiro, 2009).12 Research has mostly concentrated on romantic partners, though Rusbult et al. (2009) argue that the effect should equally be seen in family, friendship, and collegial relationships to the extent that these are closely interdependent. In another example of the paradox of control, this sculpting na effect requires ­special conditions. First, the partner must be supportive of the other’s ideal self, not just supportive of what the partner thinks is best for the other (Drigotas et al. 1999). In fact, this latter kind of “support” appears to hamper both the partner and the r­ elationship (Rusbult et al., 2009). Second, the support for the ideal self of the other needs to be in the context of movement toward the goal of Fi attaining it, and not simply in assessment of the discrepancy (Kumashiro et al. 2007). The assessment approach involves a primary focus on evaluation and critique, and when one is the target of the sculpting process (you have a partner who simply assesses your discrepancy to your ideal self), this leads one to think the other is not supportive. When one is the sculptor, the assessment approach leads one to be less affirming, disapproving of the goals, less involved in the sculptee’s pursuits. Mere assessment is debilitating to the sculpting process. Locomotion involves a 12 Like many of the concepts reviewed in this book, the socially constructed self has a long theoretical history going back to Aristotle’s emphasis on friendship, social science formulated by James (1890), Cooley (1902), and Mead (1934), and continental thought from Kierkegaard (1846/1992) to Jaspers (1919) to Gadamer (1975). Moral Ecology 71 focus on affirmation and moving toward the goal of the sculptee. This effect may well be culture-­dependent (Markus & Kitayama, 2010). Research on the Michelangelo phenomenon has only recently been extended to influence among friends and between supervisor–supervisee work pairs (Bagci et al., 2016) and it also appears to hold in these relationships.13 Thus, the Michelangelo phenomenon may provide a window into one way that social influence in communities, organizations, and culture may work. The influence of the local unit in organizations comes through close, interdependent interactions with coworkers. The influence of culture comes from socialization experiences with proximate others too. The Michelangelo phenomenon may play a central role in much of the influence that Markus and Kitayama (2010) propose in the “daily situations and practices” aspect of their model of cultural influence on the self. There are, of course other levels to the model of culture and self (language, media, education, pervasive ideas, etc.), but this s cooperative sculpting process may play a central role in how we become (or avoid or fail to become) moral. 3.5 Influencing the Moral Ecology of ro The moral ecology metaphor encourages us to think about cultural influence as reciprocal. We often have the freedom to choose our influencers, to volunteer, to join organizations, to move cultures, to protest our treatment, to encourage moral action in others, to try to change our surroundings or to leave them behind. In short, we lP often have the freedom to influence both the small-­and (less often) large-­scale moral ecology that surrounds us. 3.5.1 Organizational Ethics As a Design Problem na Epley and Tannenbaum (2017) propose we construe ethical action in organizations as a design problem. How do we design organizations so that they promote and produce ethical action? They review a large literature in organizational psychology (some of which is included in Section 3.3) and then propose that organizations can construct hiring, compensation, reputation management, and operations processes so Fi that they support ethical action. They list three psychological levels on which this ethical design can occur: attention, construal, and motivation. 3.5.1.1 Attention: Are Ethics Top of Mind? In organizations attention is often focused on goals of efficiency or profit. But organizational processes can be designed to make ethical concern and evaluation a part of routine decision processes. They offer the hiring interview protocol that companies like Johnson & Johnson use. The interview is structured in part to begin the socialization process of new employees into corporate culture. It includes numerous questions focusing on how prospective employees 13 The process may also be similar to some kinds of parental influence (Patrick & Gibbs, 2012). Taking Moral Action might support the company value of ­prioritizing the needs of the people it serves. This focuses attention on the values that are held in that organization. 3.5.1.2 Construal: Are People Asking “is It Right?” The procedures that a company follows are often simply implemented without ever being evaluated. But do employees ever ask, “Is this the right thing to do?” Compensation policies that tie executive performance to clear measures of values can help connect personal decisions made by executives to values the organization supports. Southwest Airlines, for instance, has an “every employee matters” slogan that is incorporated into the compensation packages of executives by tying compensation to measures of voluntary turnover in that executive’s division. 3.5.1.3 Motivation: Are You Using Pro-­social Goals? Most employees are interested in s doing (or at least seeing) some good in the work they do. Organizations can leverage this already existing desire and align it with values the organization supports. Virgin of Atlantic rewarded its pilots for increasing fuel efficiency by donating money to charities of the pilot’s choice. This change in policy significantly increased job satisfaction. It seems clear there are ways for organizations to influence the ethical behavior of ro their employees and executives. These approaches are fraught with complexity (e.g. the paradox of control) but they can produce significant organizational change and support moral action within organizational cultures. lP 3.5.2 Moral Exemplars and Social Reformers The pioneering work of Colby and Damon (1992) in moral exemplars shows great variety of goals among their exemplars, even though their sample was primarily limited to individuals doing social service. Among their exemplars were people na who campaigned for justice in civil rights, for health care, or for equal economic opportunity. Huff and Barnard (2009) found a similar distinction among cases in the computing field. The computer scientists, software engineers, and policy advocates they interviewed included a significant number of reformers campaigning for opensource software, privacy policy, inclusion of women in the field, safety standFi ards in software, and other goals. In both studies, those working for social change often expressed frustration at the opposition they faced, and the difficulties involved in producing social change. Working for social change is difficult, and these exemplars leveraged social support and their own optimism to maintain their motivation. Hirschman’s (1970) Exit, Voice and Loyalty provides a structure for the choices facing those who work in firms, organizations, and government as these begin to conflict with the values and principles of members. The framework (with the addition of a “neglect” option) has been used to explain a wide variety of choices for and against social change including the decision to blow the whistle in government and business (Uys, 2022), organizational change, and human resources (Allen, 2014). These choices resonate most clearly with the case of the 2020 presidential election in the United States that we outlined in the Introduction. Different actors in the Republican Party chose differently, some opting for voice (as did the two in our case), Moral Ecology 73 some opting for exit (as did some of their colleagues who resigned), and some opting for loyalty to the president in his last days in office. 3.5.3 Moral Action as Critique and as Design Leadership and social change work are classic examples of how the moral ecology is shaped, but there are many other informal approaches. The three processes we reviewed in Section 3.3.2 – rationalization, institutionalization, and socialization – are also modes of influence to change the moral ecology for the better or worse. One can use cognitive and motivational strategies to make stakeholders more (or less) ­visible, risks more (or less) considered, and choices more (or less) conscious (Epley & Tannenbaum, 2017; Messick, 1996). One can institutionalize these strategies in offices of ethics and compliance, or in the process models used in the development of s products. And one can socialize individuals into these processes. When organizations or culture do not meet one’s moral standards, one can of attempt social change (choosing voice over exit or loyalty). The work on volunteerism, social reform, and, as a last hope, courageous resistance provides examples of this strategy that are widely spread across cultures (see the Introduction for examples). Much of the work of moral exemplars in social service (Colby & ro Damon, 1992) and computing (Huff & Barnard, 2009) consists of trying to change moral ecologies, often in face of stiff resistance. In addition, when others offend the moral standards of a community, individuals in that community can take it upon themselves to defend the standards by punishing the offender, often lP at cost to themselves (Bowles et al., 2012; Boyd, Gintis, & Bowles, 2010; Boyd et al., 2003). Even children engage in vocal protest against injustice in social relations, ever more effectively as they develop skills such as perspective taking (Killen & Dahl, 2021). na"
3,3.5,"Influencing the Moral Ecology of ro The moral ecology metaphor encourages us to think about cultural influence as reciprocal. We often have the freedom to choose our influencers, to volunteer, to join organizations, to move cultures, to protest our treatment, to encourage moral action in others, to try to change our surroundings or to leave them behind. In short, we lP often have the freedom to influence both the small-­and (less often) large-­scale moral ecology that surrounds us. 3.5.1 Organizational Ethics As a Design Problem na Epley and Tannenbaum (2017) propose we construe ethical action in organizations as a design problem. How do we design organizations so that they promote and produce ethical action? They review a large literature in organizational psychology (some of which is included in Section 3.3) and then propose that organizations can construct hiring, compensation, reputation management, and operations processes so Fi that they support ethical action. They list three psychological levels on which this ethical design can occur: attention, construal, and motivation. 3.5.1.1 Attention: Are Ethics Top of Mind? In organizations attention is often focused on goals of efficiency or profit. But organizational processes can be designed to make ethical concern and evaluation a part of routine decision processes. They offer the hiring interview protocol that companies like Johnson & Johnson use. The interview is structured in part to begin the socialization process of new employees into corporate culture. It includes numerous questions focusing on how prospective employees 13 The process may also be similar to some kinds of parental influence (Patrick & Gibbs, 2012). Taking Moral Action might support the company value of ­prioritizing the needs of the people it serves. This focuses attention on the values that are held in that organization. 3.5.1.2 Construal: Are People Asking “is It Right?” The procedures that a company follows are often simply implemented without ever being evaluated. But do employees ever ask, “Is this the right thing to do?” Compensation policies that tie executive performance to clear measures of values can help connect personal decisions made by executives to values the organization supports. Southwest Airlines, for instance, has an “every employee matters” slogan that is incorporated into the compensation packages of executives by tying compensation to measures of voluntary turnover in that executive’s division. 3.5.1.3 Motivation: Are You Using Pro-­social Goals? Most employees are interested in s doing (or at least seeing) some good in the work they do. Organizations can leverage this already existing desire and align it with values the organization supports. Virgin of Atlantic rewarded its pilots for increasing fuel efficiency by donating money to charities of the pilot’s choice. This change in policy significantly increased job satisfaction. It seems clear there are ways for organizations to influence the ethical behavior of ro their employees and executives. These approaches are fraught with complexity (e.g. the paradox of control) but they can produce significant organizational change and support moral action within organizational cultures. lP 3.5.2 Moral Exemplars and Social Reformers The pioneering work of Colby and Damon (1992) in moral exemplars shows great variety of goals among their exemplars, even though their sample was primarily limited to individuals doing social service. Among their exemplars were people na who campaigned for justice in civil rights, for health care, or for equal economic opportunity. Huff and Barnard (2009) found a similar distinction among cases in the computing field. The computer scientists, software engineers, and policy advocates they interviewed included a significant number of reformers campaigning for opensource software, privacy policy, inclusion of women in the field, safety standFi ards in software, and other goals. In both studies, those working for social change often expressed frustration at the opposition they faced, and the difficulties involved in producing social change. Working for social change is difficult, and these exemplars leveraged social support and their own optimism to maintain their motivation. Hirschman’s (1970) Exit, Voice and Loyalty provides a structure for the choices facing those who work in firms, organizations, and government as these begin to conflict with the values and principles of members. The framework (with the addition of a “neglect” option) has been used to explain a wide variety of choices for and against social change including the decision to blow the whistle in government and business (Uys, 2022), organizational change, and human resources (Allen, 2014). These choices resonate most clearly with the case of the 2020 presidential election in the United States that we outlined in the Introduction. Different actors in the Republican Party chose differently, some opting for voice (as did the two in our case), Moral Ecology 73 some opting for exit (as did some of their colleagues who resigned), and some opting for loyalty to the president in his last days in office. 3.5.3 Moral Action as Critique and as Design Leadership and social change work are classic examples of how the moral ecology is shaped, but there are many other informal approaches. The three processes we reviewed in Section 3.3.2 – rationalization, institutionalization, and socialization – are also modes of influence to change the moral ecology for the better or worse. One can use cognitive and motivational strategies to make stakeholders more (or less) ­visible, risks more (or less) considered, and choices more (or less) conscious (Epley & Tannenbaum, 2017; Messick, 1996). One can institutionalize these strategies in offices of ethics and compliance, or in the process models used in the development of s products. And one can socialize individuals into these processes. When organizations or culture do not meet one’s moral standards, one can of attempt social change (choosing voice over exit or loyalty). The work on volunteerism, social reform, and, as a last hope, courageous resistance provides examples of this strategy that are widely spread across cultures (see the Introduction for examples). Much of the work of moral exemplars in social service (Colby & ro Damon, 1992) and computing (Huff & Barnard, 2009) consists of trying to change moral ecologies, often in face of stiff resistance. In addition, when others offend the moral standards of a community, individuals in that community can take it upon themselves to defend the standards by punishing the offender, often lP at cost to themselves (Bowles et al., 2012; Boyd, Gintis, & Bowles, 2010; Boyd et al., 2003). Even children engage in vocal protest against injustice in social relations, ever more effectively as they develop skills such as perspective taking (Killen & Dahl, 2021). na 3.5.4 Leadership One place where we might expect this design to happen is in leadership in organizations. In agreement with the emphasis here on ecology, models of leadership have moved from classical great-­man and matching approaches to an understandFi ing of the complexity of leadership in organizations as a “dynamic cocreational process among leaders, followers, and environments” (Thoroughgood et al., 2016, p. 627). Leadership is now recognized as being shared and distributed, even in hierarchical and control-­ oriented organizations (Avolio, Walumbwa, & Weber, 2009; Hogg, 2001). And the process by which leaders influence others has been expanded to include emotion, value, and self-­concept variables in addition to classical control models (Avolio et al., 2009). For instance, work by Vianello and Haidt (2010) shows that one way that leaders influence others is through eliciting the moral emotion of elevation in response to the leader’s display of interpersonal fairness and self-­sacrifice. Bad leadership can produce negative moral emotions (e.g. anger, disgust) and these emotions can be contagious, spreading to other workers without the need for direct negative experience (Dasborough et al., 2009). In this respect, moral potency has been suggested as a central measure of a leader’s effectiveness in inducing change, and is the combined effect of courage, efficacy, Taking Moral Action and ownership (Hannah & Avolio, 2010). However, it concentrates narrowly on characteristics of the leader. An important lesson emerges from the evolution of leadership theories. One must beware of romanticizing a role as primarily constituted by the excellent or expert characteristics of the person inhabiting that role. There has been a trenchant critique of this romanticizing of the leader in leadership research (Collinson, Jones, & Grint, 2018; Ford, Harding, & Gilmore, 2022; Meindl, Ehrlich, & Dukerich, 1985) and a concomitant focus on the complexity of the social interactions among leaders, followers, and the environment. Hogg (2001), for example, uses social identity theory to construct a model of leadership that is a function of the social system rather than the leader. Shared social identity and an in-­group-­based influence process identify some members as prototypical leaders thereby producing in-­group status differences. While both leaders and followers negotiate over the values, purposes, and plans of the group, s there is an attributional process that misattributes all, or most of, the influence to the leader (Hogg, 2001). of The literature on moral exemplars and moral expertise needs to take note of this critique, and this chapter is the right place to do so. We know very little of how moral exemplars interact with their collaborators, followers, and the surrounding moral ecology. Colby and Damon’s (1992) classic study of exemplars looks carero fully at their exemplars’ interactions with others as a part of their developmental trajectory; but it still treats the exemplariness of their action as mostly originating from their exemplary character rather than from the “dynamic cocreational process” between exemplars and their moral ecology. One can find the beginning of lP this critique in some places in the exemplar literature (Frimer, 2018; King, Mueller, & Furrow, 2013). With this section on influencing the moral ecology, we come full circle in the cycle of mutual constitution of individuals and culture (Hamedani & Markus, 2019; Markus & Kitayama, 2010). This is a process constantly in flux, na at a variety of levels of influence and resistance, and we can only gesture to its complexity here. 3.6 Discussion Fi This review of the ways that moral ecology can influence moral action, and be influenced by it, is admittedly spotty. The point is not to make a comprehensive review of moral psychology as influenced by friendship, families, groups, organizations, and culture.14 It is more to show the wide variety of ways that moral action can be supported or led astray by the social surround, and the ways that the social environment can be influenced so it is more supportive of moral action. If the review provides windows into the processes of moral ecology and some idea of its variety and importance, then it has been successful. Still, there are some tentative conclusions we can make from the work reviewed so far. 14 This would be a book in itself and we know of no volume attempting this. Moral Ecology 75 3.6.1 Conclusion The range of moral ecologies is wide, but they share characteristics across their v­ ariety. The extent to which these characteristics are shared across all levels is a matter for empirical investigation, so these conclusions should be taken as tentative. Some conclusions (e.g. Section 3.6.1.1) share an evidence base from other chapters and can be thought of as more established: 1. Moral psychology is also the psychology of evil. Many of the moral ecology processes we have covered have a complex relationship to the content of the moral action they support or hinder. Designing institutional processes to support particular valued employee and executive actions might be a way to support either corruption or ethical action. The limits of the Michelangelo s phenomenon have yet to be explored but it seems reasonable that it would work for one partner to help another to obtain an ideal self that might harm the self (e.g. of anorexia) or others (e.g. terrorism). We may find some processes in moral psychology that are more likely to result in immoral rather than moral action. For instance, the moral disengagement strategy of minimizing harm is pervasive in justifications of aggression. Still, surgeons and doctors may need to psychologically minimize ro the harm they do to allow themselves permission to do surgery (Collins & Pinch, 2005). And soldiers in combat need to objectivize the enemy to do their job (Grossman, 1996). In this way, moral psychology is likely to be immoral psychology, and the psychology of moral exemplars also becomes the psychology of lP evil. 2. Moral ecologies can support domain limits in moral judgment and action, making integrity across situations difficult. A specific moral ecology can provide domain-­limited morally relevant information (Is this a moral issue? Are these people I should care about?). It can also prime na particular moral emotions and skills and thereby make certain kinds of (im)moral action more relevant and/or likely. Cultural institutions, values, activities, organizational procedures, domains of concern in volunteer organizations, and the moral support of close others can define particular issues as important or irrelevant to the moral self. It can even make some individuals subject to compassion and others Fi subject to attack (Hart, 2005). Some moral principles (e.g. group loyalty, Haidt & Joseph, 2004) have this domain limitation as an integral part of their structure. This may be a more general problem about the limitation of human resources: focus on anything requires one to remove focus from something else. 3. There is a structure to the moral differences both across and within cultures. Our catalog of moral differences within and across cultures is already quite long even in this short review. But what is often missed is that these cultural differences have a structure to them that allows one to see a larger pattern to the agreement and disagreement within and across cultures. There are still multiple ways to describe the dimensions in these differences, and it may take some time to determine the best empirical solutions to a description. But there is agreement that there is indeed a structure and that cultures and individuals do not simply randomly choose to value some things (e.g. the color blue) and not others. This makes the empirical case for radical “anything goes” cultural relativism less persuasive. Taking Moral Action A more likely description is that there is some finite set of values or dimensions of valuing that are framed by evolution or the constraints of social interaction and that individuals and societies make choices within this limited space. 4. Moral diversity within and across cultures is both a problem and a solution. Moral diversity and disagreement can be found within every culture and across cultures.15 This has usually been approached as a problem. From a philosophical standpoint, it looks too much like support for unthinking relativism. From a political and religious standpoint, it seems the nexus of a great deal of societal conflict and uncertainty. However, Lawrence Kohlberg’s work and that of many others reviewed in this and other chapters (Chapters 7, 8, and 9) make the clear point that this diversity serves as a resource for cultural critique. The shared structure and values within and across cultures make conversations possible across these value divides. They serve as resources for arguments that appeal to common expes rience, value, and intuition in the face of disagreement. This diversity may indeed be seen as similar in importance to genetic diversity in evolutionary processes: of without the existing diversity, change would be impossible. 5. One can approach morality as a design issue. Because (im)moral decisions are imbedded in the structures of relationships, families, organizations, and cultures, one can think of ways to change those relationro ships so that they are more likely to result in moral behavior. This approach connects current research on moral action to ancient traditions of moral thought from Greece, India, and China. Philosophers have long thought about how to structure society. This thought tradition makes it clear that the “design problem” lP approach has no easy solution, nor does it guarantee moral outcomes. But current work in moral psychology helps us discern some structure to the design problem that is based in the psychological capacities and motivations of people. 6. Recognition of diversity within and across cultures does not require radical relativism. The existence of cultural difference is indisputable, as are the patterns of those difna ferences across cultures: cultures agree on which principles they disagree about, and these disagreements have patterns (e.g. values that tend to be endorsed or sanctioned in cultures cluster together, see Schwartz, 2010). These differences may have their origins in evolutionary patterns required for successful group living (Tomasello & Vaish, 2012) and so to that extent they are objective in terms of Fi embodying what is needed for flourishing for the species (Flanagan, 1991; Flanagan et al., 2008). Thus, recognition of these patterns of cultural difference does not require acceptance of cultural relativism or an “anything goes as long as a group endorses it” approach (Flanagan et al., 2008; Taylor, 1982). It is at least compatible with a suitably complex pluralism, a recognition that there are in the human condition multiple foundational values and that different cultures come to different solutions about the appropriate balance among them. A pluralistic approach like this may help in guarding against the sort of moral objectivism (Goodwin & Darley, 2008, 2009, 2010, 2012) that associates a person’s culture’s judgments and actions unequivocally with the good, and demonizes those who disagree (Kekes, 1993). 15 My thanks to Jessica Salvatore, one of the reviewers of this text, for this insight. Moral Ecology 77 7. Humans are not passive recipients of influence in culture, but active co-­creators of it. In almost every section of this chapter we saw humans being influenced by culture, organization, leaders, friends, etc. However, we also saw multiple examples of people changing organizations, influencing each other, and taking action to support other people taking moral action. We provide links to some models of how this happens (e.g. Markus & Kitayama, 2010) but more work is needed. 3.6.2 Application The story of Nathaniel Borenstein’s decision presented in the Introduction is a story of conflicting and overlapping moral ecologies. In it we have a happy incident in which we see multiple moral ecologies influencing an actor to disregard his principles and thereby achieve a moral outcome. Borenstein is a computer scientist and pacifist with s a long history in the peace movement. His perception of the moral ecology of the military was that it was indifferent if not hostile to his concerns about the safety of nuclear of weapons systems. But that very system recruited him to help it critique its own performance on safety. He was motivated to help the military in its self-­critique despite his firm personal value commitment to not consulting for the military. As he began his collaboration, he discovered that the value conflict was more that some actors in the ro private consulting sector were unconcerned with safety if they could sell a contract. His action in altering military perception and policy about certain computer systems is an example of committed individuals taking moral action to change moral ecologies. The NATO lieutenant commander who persistently recruited Borenstein was a pivotal lP player, as was Borenstein himself. Each had different psychologies, goals, and moral influences, but they shared significant overlap that helped to produce conversation and change. The story is also an example of one moral ecology (NATO) using a representative of another moral ecology (the peace movement) to influence a third moral ecology (the military consulting industry). That these very different moral ecologies na had something to say to each other is evidence of the cross-­cultural similarities in the structure of values and an example of how differences are negotiated."
3,3.6,"Discussion Fi This review of the ways that moral ecology can influence moral action, and be influenced by it, is admittedly spotty. The point is not to make a comprehensive review of moral psychology as influenced by friendship, families, groups, organizations, and culture.14 It is more to show the wide variety of ways that moral action can be supported or led astray by the social surround, and the ways that the social environment can be influenced so it is more supportive of moral action. If the review provides windows into the processes of moral ecology and some idea of its variety and importance, then it has been successful. Still, there are some tentative conclusions we can make from the work reviewed so far. 14 This would be a book in itself and we know of no volume attempting this. Moral Ecology 75 3.6.1 Conclusion The range of moral ecologies is wide, but they share characteristics across their v­ ariety. The extent to which these characteristics are shared across all levels is a matter for empirical investigation, so these conclusions should be taken as tentative. Some conclusions (e.g. Section 3.6.1.1) share an evidence base from other chapters and can be thought of as more established: 1. Moral psychology is also the psychology of evil. Many of the moral ecology processes we have covered have a complex relationship to the content of the moral action they support or hinder. Designing institutional processes to support particular valued employee and executive actions might be a way to support either corruption or ethical action. The limits of the Michelangelo s phenomenon have yet to be explored but it seems reasonable that it would work for one partner to help another to obtain an ideal self that might harm the self (e.g. of anorexia) or others (e.g. terrorism). We may find some processes in moral psychology that are more likely to result in immoral rather than moral action. For instance, the moral disengagement strategy of minimizing harm is pervasive in justifications of aggression. Still, surgeons and doctors may need to psychologically minimize ro the harm they do to allow themselves permission to do surgery (Collins & Pinch, 2005). And soldiers in combat need to objectivize the enemy to do their job (Grossman, 1996). In this way, moral psychology is likely to be immoral psychology, and the psychology of moral exemplars also becomes the psychology of lP evil. 2. Moral ecologies can support domain limits in moral judgment and action, making integrity across situations difficult. A specific moral ecology can provide domain-­limited morally relevant information (Is this a moral issue? Are these people I should care about?). It can also prime na particular moral emotions and skills and thereby make certain kinds of (im)moral action more relevant and/or likely. Cultural institutions, values, activities, organizational procedures, domains of concern in volunteer organizations, and the moral support of close others can define particular issues as important or irrelevant to the moral self. It can even make some individuals subject to compassion and others Fi subject to attack (Hart, 2005). Some moral principles (e.g. group loyalty, Haidt & Joseph, 2004) have this domain limitation as an integral part of their structure. This may be a more general problem about the limitation of human resources: focus on anything requires one to remove focus from something else. 3. There is a structure to the moral differences both across and within cultures. Our catalog of moral differences within and across cultures is already quite long even in this short review. But what is often missed is that these cultural differences have a structure to them that allows one to see a larger pattern to the agreement and disagreement within and across cultures. There are still multiple ways to describe the dimensions in these differences, and it may take some time to determine the best empirical solutions to a description. But there is agreement that there is indeed a structure and that cultures and individuals do not simply randomly choose to value some things (e.g. the color blue) and not others. This makes the empirical case for radical “anything goes” cultural relativism less persuasive. Taking Moral Action A more likely description is that there is some finite set of values or dimensions of valuing that are framed by evolution or the constraints of social interaction and that individuals and societies make choices within this limited space. 4. Moral diversity within and across cultures is both a problem and a solution. Moral diversity and disagreement can be found within every culture and across cultures.15 This has usually been approached as a problem. From a philosophical standpoint, it looks too much like support for unthinking relativism. From a political and religious standpoint, it seems the nexus of a great deal of societal conflict and uncertainty. However, Lawrence Kohlberg’s work and that of many others reviewed in this and other chapters (Chapters 7, 8, and 9) make the clear point that this diversity serves as a resource for cultural critique. The shared structure and values within and across cultures make conversations possible across these value divides. They serve as resources for arguments that appeal to common expes rience, value, and intuition in the face of disagreement. This diversity may indeed be seen as similar in importance to genetic diversity in evolutionary processes: of without the existing diversity, change would be impossible. 5. One can approach morality as a design issue. Because (im)moral decisions are imbedded in the structures of relationships, families, organizations, and cultures, one can think of ways to change those relationro ships so that they are more likely to result in moral behavior. This approach connects current research on moral action to ancient traditions of moral thought from Greece, India, and China. Philosophers have long thought about how to structure society. This thought tradition makes it clear that the “design problem” lP approach has no easy solution, nor does it guarantee moral outcomes. But current work in moral psychology helps us discern some structure to the design problem that is based in the psychological capacities and motivations of people. 6. Recognition of diversity within and across cultures does not require radical relativism. The existence of cultural difference is indisputable, as are the patterns of those difna ferences across cultures: cultures agree on which principles they disagree about, and these disagreements have patterns (e.g. values that tend to be endorsed or sanctioned in cultures cluster together, see Schwartz, 2010). These differences may have their origins in evolutionary patterns required for successful group living (Tomasello & Vaish, 2012) and so to that extent they are objective in terms of Fi embodying what is needed for flourishing for the species (Flanagan, 1991; Flanagan et al., 2008). Thus, recognition of these patterns of cultural difference does not require acceptance of cultural relativism or an “anything goes as long as a group endorses it” approach (Flanagan et al., 2008; Taylor, 1982). It is at least compatible with a suitably complex pluralism, a recognition that there are in the human condition multiple foundational values and that different cultures come to different solutions about the appropriate balance among them. A pluralistic approach like this may help in guarding against the sort of moral objectivism (Goodwin & Darley, 2008, 2009, 2010, 2012) that associates a person’s culture’s judgments and actions unequivocally with the good, and demonizes those who disagree (Kekes, 1993). 15 My thanks to Jessica Salvatore, one of the reviewers of this text, for this insight. Moral Ecology 77 7. Humans are not passive recipients of influence in culture, but active co-­creators of it. In almost every section of this chapter we saw humans being influenced by culture, organization, leaders, friends, etc. However, we also saw multiple examples of people changing organizations, influencing each other, and taking action to support other people taking moral action. We provide links to some models of how this happens (e.g. Markus & Kitayama, 2010) but more work is needed. 3.6.2 Application The story of Nathaniel Borenstein’s decision presented in the Introduction is a story of conflicting and overlapping moral ecologies. In it we have a happy incident in which we see multiple moral ecologies influencing an actor to disregard his principles and thereby achieve a moral outcome. Borenstein is a computer scientist and pacifist with s a long history in the peace movement. His perception of the moral ecology of the military was that it was indifferent if not hostile to his concerns about the safety of nuclear of weapons systems. But that very system recruited him to help it critique its own performance on safety. He was motivated to help the military in its self-­critique despite his firm personal value commitment to not consulting for the military. As he began his collaboration, he discovered that the value conflict was more that some actors in the ro private consulting sector were unconcerned with safety if they could sell a contract. His action in altering military perception and policy about certain computer systems is an example of committed individuals taking moral action to change moral ecologies. The NATO lieutenant commander who persistently recruited Borenstein was a pivotal lP player, as was Borenstein himself. Each had different psychologies, goals, and moral influences, but they shared significant overlap that helped to produce conversation and change. The story is also an example of one moral ecology (NATO) using a representative of another moral ecology (the peace movement) to influence a third moral ecology (the military consulting industry). That these very different moral ecologies na had something to say to each other is evidence of the cross-­cultural similarities in the structure of values and an example of how differences are negotiated. 3.6.3 Open Questions Fi In this chapter, we have focused on the mutual influence that people and their surrounding moral ecologies exert on each other. This has led us to consider the complexities of how the various levels of moral ecology interact with each other. Most of these complexities are just beginning to be investigated. 1. Our knowledge of how groups take moral action is fragmented. Addressing this may move us from thinking of virtuous individuals to virtuous ecologies, or the interaction of these, as the source of effective virtue. Work on morality in groups is often isolated from work in moral psychology. In this chapter, we have mostly talked about moral ecology from the perspective of the individual moral actor and his or her role in the moral ecology. But it is possible to move to a group level of analysis. We need better conceptualizations of the group processes involved in moral awareness, judgment, motivation, and action that can help drive research at this level. Some of the work mentioned earlier in leadership Taking Moral Action (Section 3.5.4) might be a source from which to begin theorizing. We have specifically called for work in moral exemplars to start to account for this systemic level of exemplary action. With moral exemplars, one might focus on continued exemplary action (rather than just the single actor) and ask what systems support and hinder it. This might move the conceptual balance of moral character to seeing the “dynamic cocreational process among leaders, followers, and environments” (Thoroughgood et al., 2016, p. 627) as a source of effective virtue. 2. How do moral actors actively grapple with moral diversity? Clearly, cultures, organizations, and even friendships are not homogenous. It is at least clear that the reaction to moral diversity at all these levels is often negative: we judge those who have moral disagreements with us harshly. We need to know more about how people think about, support, or tolerate the diversity of moral judgments and goals in a moral ecology. How do people handle moral tradeoffs s when diverse values are in play? How do choice processes lead to different moral goals at these different levels? How do individuals lobby to turn optional moral of goals into mandatory goals? There are surely even more questions than these. 3. How do the different levels of a moral ecology interact with each other? Markus and Kitayama (2010) have given a beginning conceptualization of how self and culture mutually constitute each other, and their model involves interacro tions at all the levels we have reviewed in this chapter. They include internal representations of the moral ecology, for instance, how daily routines (e.g. hygiene) should be structured, or pervasive moral ideas such as how dependent or interdependent people should be with others. However, their model does not yet seem lP specific enough to drive programs of research in morality (e.g. the word moral only occurs twice in the article). We also do not know enough about the consistency of the structure of value differences across different levels of a moral ecology: Are self-­transcendence and self-­enhancement always viewed as in conflict in all cultures at all levels of a moral na ecology? Nor do we know much about how the larger moral ecology structures the relationships of its constituent units: Why are there such large differences in the frequency of volunteerism across cultures? 4. How does the active construction of identity interact with the various levels of moral ecology? We know from Chapter 5 that how (and whether) people think of themselves in Fi moral terms is of crucial importance. And we know that one cannot be a self by oneself. What does this mean for how a moral ecology helps to constitute the moral identities of those within it? We know there are significant moral differences within moral ecologies. How are moral identities related to those differences, and how do they construe the differences in the ecology?"
3,3.7,"Further Readings These suggested reading are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. • Ashforth and Anand (2003). “The normalization of corruption in organizations.” A literature review and a model of how organizations shape immoral behavior. Moral Ecology 79 • Epley and Tannenbaum (2017). “Treating ethics as a design problem.” A proposal that ethical issues in organizations can be treated as a design issue for them, making the point that an organization can shape the ethical behavior of its members. • Heine (2010). “Cultural psychology.” A readable overview of the work on psychological differences across culture. • Markus and Kitayama (2010). “Cultures and selves: A cycle of mutual constitution.” This proposes a multilayered model of how culture influences the self and how the self influences culture. • Nisbett and Ross (1980). Human Inference: Strategies and Shortcoming of Social Judgment. The classic early statement of the primacy of situational influence on judgment and decision-­making. • Sagiv and Schwartz (2022). “Personal values across cultures.” A comprehensive review of current work on values, focusing on Schwartz’s theory of values. It s explores cross-­cultural variation and similarity and the interlinking of cognitive representations, emotions, and motivational goals."
4,4.1,"Beyond Character as Traits Our approach to moral personality is adaptive in that it recognizes that personality adapts to the context in which the person lives. It is pluralistic in that, unlike earlier approaches (Colby & Kohlberg, 1987), there is no single definitive “moral character” or even set of virtues. It is integrative in that aspects of the other influences (moral identity and skills and knowledge) need to be incorporated into our understanding of personality. In this way, personality is not a separate influence on moral action but in some way an integration of the other two influences. 4.1.1 Personality as Adaptive s The “character as trait” model that early psychologists used might lead one to expect what statisticians would call strong main effects for personality characteristics: that character should primarily determine behavior and that this effect should not be of affected by changes in the situation (or in any other variable). However, most researchers now agree that one should not expect such straightforward effects: the effect of personality dispositions should be complicated by, at the least, situational ro and role constraints and social norms (Penner & Orom, 2010, p. 17). This means we should look for those things that structure the interaction between (1) the character of the individual and (2) the situation in which character is (or is not) expressed. Penner and Orum (2010) suggest that to the extent that the moral decision process is more thoughtful and planned, personal dispositions (though not lP necessarily reason) are more likely to influence decisions to engage in pro-­social behavior. Work in self-­regulation (e.g. Hofmann, Friese, & Strack, 2009) also shows that impulsive action is more under the control of the situation than planned action but that even impulsive action can be influenced by the individual taking precautions to remind themselves of their commitments (Gollwitzer et al., 2011). na Still, even very strong situations do not always swamp dispositional characteristics. Coverage of Milgram’s famous (1963) obedience experiments often focuses on the two-­thirds of subjects who showed obedience.2 But Milgram was just as interested (if not more) in the one-­third that managed to avoid the power of the situation, and he included detailed interviews with these individuals in his (1974) book. Penner and Fi Orum (2010) provide another example of a strong situation that fails to influence many who might be disposed to nurturing behavior: parents’ sympathy for their sick children. They provide evidence that non-­empathic parents show less empathy and social support for their children when the children are undergoing cancer care. This surely counts as a strong situation that should overwhelm personal dispositions, but the dispositional tendencies show an effect despite the situation. 2 And if you read Milgram’s (1963, 1974) descriptions more carefully, even the obedience was not mere passive submission. For most, it was suffused with protest, negotiation, reluctance, covert sabotage, and regret. For some it was stoic persistence in the face of a difficult task. For (some few) others, it was ready agreement. See Browning’s (1992) historical study of a German police battalion during the Holocaust for a similar range of responses to a very strong situation. c04.indd 90 07-20-2023 16:29:19 Personality 91 Matsuba, Hart, and Atkins (2007) present a mediational model that suggests that the effects of personality3 on volunteering are mediated by two factors: the moral identity of the individual (do they think of themselves as helpful?) and the opportunity available to them (are they in contact with organizations and people who can connect them to volunteering possibilities?). They found that under-­and over-­controlled individuals had less salient helping identities, and these individuals were not very affected by the presence of opportunities to volunteer, in comparison to those resilient individuals whose volunteering was influenced by opportunity. So here we have a situation (volunteering opportunity) that is weak in influencing behavior, except when there is some match between the personality of the individual and what the situation calls for. Mediational models like this have led us to think that some way of combining the dispositions of the individual with their experience of the situation should help us s better understand the dynamics that lead individuals to see a particular situation as one that calls for them to behave in a particular way.4 Models like these have emerged of in at least three unconnected literatures. Walter Mischel, the prototypical personality iconoclast, has developed a research program that shows that one can find consistency in behavior if one looks for consistency in the pattern (or “behavioral signature”) of how the individual responds to situations they construe as relevant (Mischel, 2004; ro Shoda, Mischel, & Wright, 1994). We will review this work in Section 4.1.3.2. Weber, Koppelman, and Messick (2004) have reviewed the literature on how people make choices in social dilemmas (where one individual’s private interests are pitted against shared interests). They too have found that individuals respond as though they had lP asked “What does a person like me do in a situation like this?” – a question that integrates personality and situation (Weber et al., 2004, p. 281). Gustafson and Mumford (1995) conducted a study with leaders in the US Navy that shows an even more complex personality–situation interaction. An individual’s pattern across several personality variables (called personal style) could be matched with five different empirina cally derived patterns of situation to predict the leader’s success in those situations. This is another case, in an independent area of research, of how one can find consistency if one takes both the personality and the situation into account. It also suggests that there is no single type of “best leader,” but multiple types. Indeed, current models of leadership see it as a “dynamic cocreational process among leaders, followers, Fi and environments” (Thoroughgood et al., 2016, p. 627). We cover this approach to leadership in a bit more detail in Chapter 3. We will find a similar personality pluralism in the literature on moral psychology, leading to the conclusion that there is no single “best character.” It is apparent that cultures, organizations, and even friendships are not homogenous. Diversity of goals, values, personality characteristics, skills, etc. has long been recognized in research, but 3 In their case measured as resilient vs. under-­and over-­controlled personality. Resilient personality was measured in children aged eight to ten years before volunteerism was measured (Atkins, Hart, & Donnelly, 2005). In children, a resilient personality means they are compliant, socially skillful, and have positive emotional tone. Under-­controlled children have low levels of impulse control and trouble maintaining relationships. Over-­ controlled children are shy, timid, anxious, and have trouble maintaining relationships. 4 See also Chapter 5 for another way to think of this match-­to-­situation. c04.indd 91 07-20-2023 16:29:19 92 Taking Moral Action rarely investigated on its own terms. It is at least clear that the reaction to moral diversity is often negative, and we judge harshly those who have moral disagreements with us. We need to know more about how people think about the diversity of moral judgments and goals in a moral ecology. What levels and kinds of moral diversity are people willing to tolerate? How do people handle moral tradeoffs when diverse values are in play? How do people choose the moral goals they strive to achieve? How do individuals lobby to turn optional moral goals into mandatory goals? There are surely even more questions than these. 4.1.2 Personality as Pluralistic In his 1991 exploration of the varieties of moral personality, the philosopher Owen Flanagan uses a short catalog of Christian saints as an example of one sort of morally s exemplary person. He then shows that even this somewhat limited category of moral excellence contains multitudes. Saints are introverted and extraverted, patient, irasciof ble, thoughtful, simple, impulsive, warriors, poets, scholars, poor, rich, etc. The saints Flanagan refers to have in common the requirements of the Roman Catholic Church but very little else.5 From this example, one could expect that psychological research on moral excellence will also find multiple models. ro In their review of the implications of personality psychology for moral psychology, Hill and Roberts (2010, p. 380) include as their first proposition that “A singular moral personality does not exist.” One would expect this from the example of Roman Catholic saints, and research bears it out. Work on moral personality often proceeds lP along the lines of identifying individuals who are remarkable for their moral commitment and then attempting to learn something from their histories and personality profiles. This tradition begins with the work of Oliner and Oliner (1988) who studied individuals who participated in rescue attempts of victims of the Holocaust. They found na three primary motivations for rescuers: those who participated because of their connection to groups who encouraged it (called “normative,” 52% of the rescuers), those who responded to empathy for particular individuals (“empathic,” 37%), and those who participated because of principled decision (“principled,” 11%). Colby and Damon (1992) also sought out moral exemplars but in the field of social service in Fi the United States. Their extensive nomination method resulted in interviews with twenty-­three moral exemplars who differed widely in education and the targeted goal of their service (e.g. medical service for the poor, entrepreneurship, civil rights, urban poverty, etc.) They noted that the individuals they interviewed tended to specialize in one of two types of work: social reform or direct helping of those in need. In a study of moral exemplars in the field of computing, Huff and Barnard (2009) documented a similar specialization, with some engaging in societal reform and others using their skill to help others directly. Walker and colleagues (Matsuba & Walker, 2004; Reimer, DeWitt Goudelock, & Walker, 2009; Walker & Frimer, 2007; Walker, Frimer, & 5 The Roman Catholic Church canonizes saints who are recognized for “heroic virtue” (Beccari, 1907), those “whose virtues and good works greatly outdistance those of ordinary good people.” c04.indd 92 07-20-2023 16:29:19 Personality 93 Dunlop, 2010) have done the most definitive work in looking for varieties of moral personality among exemplars. They constructed a sample from winners of two humanitarian prizes in Canada, one for heroic action and one for influential long-­ term volunteer work, and identified at least three types: just, brave, and caring. If, in the quest for some unifying principle of morality, one moves to catalogs of virtues, one confronts a similar pluralism. Kohlberg and Mayer (1972) have complained that lists of virtues tend to be arbitrary and have only little common overlap. In addition, some of the virtues seem to be at least in tension with one another, e.g. justice and charity. Cross-­cultural work on values by Schwartz (2006, 2010) provides some structure to the tension in the domain of values, with a circular model that shows each value in tension with some other value on the other side of the circumplex.6 Thus, it seems that in moral personality, motivation, goal, virtue, and value we are s faced with a pluralism that is difficult to reconcile with insistence on the unity of the virtues (Walker et al., 2010). The personality of moral exemplars, their motivations, of and their goals seem to be widely variable. 4.1.3 Personality as Integrative ro We now have an outline of moral personality as adaptive and pluralistic. What about integrative? It is in response to the complexities listed so far that psychologists have begun constructing integrative models of personality. These systems are usually based in a wide review of the empirical personality literature and then constructed with the lP express purpose of explaining how the individual maintains a sense of coherence and efficacy in their world. 4.1.3.1 Idiographic vs. Nomothetic Approaches All the models we will review in this na section are idiographic: they look at psychological processes as they occur at an individual level – how each person answers the question “What does a person like me do in a situation like this?” This is in contrast to a standard psychological nomothetical approach that looks at aggregates of individuals (e.g. do extraverts on average tend to volunteer more?7). Fi Nomothetic approaches, like those associated with the five-­factor model of personality (McCrae & Costa, 1997), look at differences between individuals, averaged over many people, and the relationship of those differences to other things of interest, such as volunteering. These patterns say something about the behavior of abstract groups that are constituted statistically, but it is not immediately obvious how the patterns translate into the functioning of the individual. The distinction between nomothetic differences measured at the group level and individual, idiographic personality architecture is a difficult one; but one with important implications for the conversation about what character (and virtue) is and how it 6 See Chapter 3 for a detailed explanation of this work. We argue in Chapter 9 that this tension is part of the basic human condition, and that learning to operate within it is part of what becoming moral is about. 7 Yes. See Ozer and Benet-­Martínez (2006) for evidence of this relationship. c04.indd 93 07-20-2023 16:29:19 94 Taking Moral Action functions. It is certainly too simplistic to say, with Socrates and Protagoras, that “temperance makes men temperate.” And it is too simplistic to say that extraversion or conscientiousness – as defined by current personality inventories (e.g. Costa & McCrae 1997) – is a property one can have. Nor can one easily say that this property causes behavior in any straightforward way. This critique is fully elaborated in Cervone (2004), with the significant implication that one cannot, without empirical evidence, talk about extraversion or conscientiousness as psychological constructs that an individual “has” in the same way one “has” a superego in Freudian approaches (if anyone indeed has a superego). Conscientiousness (as measured by most personality inventories) could, theoretically, be part of an internal psychological system that influences behavior, and some theorists speak about it this way (McCrae & Costa, 1997). But the evidence in fact, seems to lean against this (Borsboom, Mellenbergh, & van Heerden, 2003; Cervone s & Tripathi, 2009). Even though the Big Five personality characteristics (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience) are useful of in explaining differences between individuals in the aggregate, attempts to show they have the same psychological function at the individual level have been, at best, equivocal. Two individuals, for instance, may be much more honest than the general population and both may tend to tell the truth across many situations. Still, those situations ro will be different for each person and each individual may be motivated to be honest for different reasons in the different contexts (sometimes having nothing to do with a desire for truth). This distinction is relevant to the current debate in philosophical virtue theory lP about the existence of character (Doris, 2002; Snow, 2010). A conceptual virtue such as honesty or generosity may well describe the differences among groups of people but describe neither the reasons or patterns of honesty in any individual person nor the complexity and interdependence of that virtue with another virtue, for that person. And thus, our naïve psychology that honesty is a thing one “has” na may mislead us to expect a kind of consistency where, for good reason, there should be none. The nomothetic approach may be correctly answering the question of how people, in the aggregate, are different from each other, but not giving us an answer about how individuals, as they go about their lives in the world, constitute those differences. Fi Both Mischel (2004) and Cervone and Tripathi (2009) ask this latter question. How does the individual as a whole act in the world? Both approach individual functioning by calling on psychological systems of cognition and emotion that underlie and help to produce the individual’s characteristic responses. Thus, according to Cervone (2004, p. 430), “… an intraindividual focus does not indicate disinterest in individual d ­ ifferences. Instead, it represents a strategy for understanding them: a bottom-­up ­strategy …” that articulates how each person is honest in the characteristic way he or she is.8 8 A cynical, but partially true, implication of this is that the entire personality-­situation controversy that has roiled psychology and philosophy can be reduced to a measurement issue (top down vs. bottom up). There have been amazing advances in measurement at the idiographic level (Beck & Jackson, 2020). But more reasonably considered, it has been a long standing theoretical and empirical puzzle that we are only now beginning to unravel. c04.indd 94 07-20-2023 16:29:20 Personality 95 Because they focus on the psychological processes that support the adaptiveness and coherence of individual action, the models we review here are particularly relevant to thinking about how people act morally. It is interesting, and perhaps useful for recruiting purposes, to know that an identifiable type of person (e.g. extraverts) ­volunteers more often. This is the nomothetic level. But if we want to understand how and why each one volunteers, the structure and functioning of individual character, we need to look to psychological models of the individual, idiographic “springs of action.”9 4.1.3.2 The Cognitive-­ Affective Processing System Mischel and colleagues’ (Mischel, 2004; Shoda et al., 1994) work on personality signatures, or individual patterns of responding, is primarily designed to try to understand how individuals s navigate different situations with a sense of coherence. They offer a powerful and empirically well-­supported answer, and all the other integrative models mostly of propose parallel answers in response to this central puzzle of personality. They begin with noting the two types of personality theory that we have just covered.10 They then set for themselves the task of determining how to measure idiographic consistency based on “intraindividual patterns of variability” (Mischel, 2004, p. 9, italics added), ro the distinct pattern each individual shows in response to perceived situations. Shoda, Mischel, and Wright’s (1994) work, based in detailed tracking of children at a summer camp, provides evidence that one can collect data to construct these behavioral signatures and that these signatures have predictive value. They followed lP aggression and self-­regulation in 84 children across the 6 weeks of the summer camp, with an average of 160 hours of behavioral observation of each child over that time. They collected videotaped social interactions and coded them, coded the children’s activities within each hour for behaviors like whining, compliance, and physical and verbal aggression, and asked camp counselors to give global personalna ity judgments for each child. This required a team of 77 adult observers, with each child observed by between 14 and 28 observers over their time at camp. This produced an enormous and complicated database of each child’s actions in strategically selected situations. They were able to show striking stability in the behavior profile of each child across Fi five different types of situations (peer tease, peer approach, adult praise, adult warn, adult punish). Thus, individuals who might on average seem similarly aggressive, nevertheless showed clear differences across the situations that called forth that ­aggression. Some children showed clear stability in these differential reactions to each situation, while others were more variable. One child, for instance was only aggressive in response to adult punishment, while another was most aggressive to peers when they initiated positive contact (peer approach). 9 The origin of this phrase comes from the philosopher Jeremy Bentham’s 32-­page pamphlet Table of the Springs of Action (1817). It consists of 14 tables showing the origins of motivations, accompanied by copious notes. 10 Mischel (2004) calls nomothetic consistency “Type 1” and idiographic consistency “Type 2.” c04.indd 95 07-20-2023 16:29:20 96 Taking Moral Action They conclude that the individuals showed more or less11 stable patterns of variability in their behavior across different types of situations. Mischel (2004) explains these patterns, or personality signatures, with a model of a cognitive-­affective processing system (CAPS). This model suggests that individuals differ in their mental representations of “self, people, and situations, enduring goals, expectations-­beliefs, and feeling states, as well as memories of people and past events” (p. 11). These representations are not isolated, but are organized in interaction with each other, and in characteristic patterns of emotion and cognition. Everyone’s unique patterns of behavior are produced by these unique representations, processed in characteristic ways by the individual. They have tested the model with computer simulations (Shoda, LeeTiernan, & Mischel, 2002), and shown that it can produce both nomothetic (on average) and idiographic consistency. It is important at this point to remember that we are so far not talking about moral s consistency. The consistency in personality does not need to be one of moral consistency. There are a variety of identity themes (McGregor & Little, 1998), or personal of projects, that individuals construct to organize their lives, including being a meaningful part of a community, achieving status or success, or simply having fun. Indeed, in a study by McGregor & Little (1998) that asked over 300 college students about their personal projects, moral ideals did not emerge as a major theme among any ro significant subset of the respondents. One is not guaranteed that the consistencies in life will be moral ones. Commitment to simple hedonism, achievement, or group loyalty may even result in one being labeled a moral wanton (Frankfurt, 1971) but not, perhaps, a wanton in respect to one’s constructed identity theme (e.g. having fun lP or being dominant). One need not be labeled immoral because one does not take morality as a central aspect of the self. See the chapter on Self for the complexities of how we construct moral identities. We expect minimal commitments to moral principles in order to construct a habitable society (Haidt, 2008a; Haidt & Joseph, 2004; Tomasello & Vaish, 2012), and can stay within these lines without having morality at na the center of one’s identity. To conclude, Mischel and colleagues’ work (Mischel, 1968, 2004; Shoda et al., 2002; Shoda et al., 1994) has provided a paradigmatic solution to what has been called the “personality paradox”12 and helps us understand how a person might be empathic and helpful in one situation but not in another. But there is Fi more to the role of personality in moral action than the personality paradox. Individuals strive to become better over time (or not). They try, for instance, to become more patient in their relationships or more courageous in their work life. Individuals’ behavioral signatures show consistency (or lack thereof) depending in part on their self-­regulatory skill. They resist (or not) the temptation to make a snarky comment and they resist (or not) the desire to impress others by embellishing a personal story. They construct personal narratives that support a career of helping or personal narratives that undermine it. In response to events in the 11 Some would show stability for one behavior (e.g. aggression) across situations, but not for another (e.g. whining). The complications here are immense, but one can find pattern in them. 12 This is the lack of relationship between what a “personality characteristics as traits” approach would expect in behavior consistency, and what we actually find. c04.indd 96 07-20-2023 16:29:20 Personality 97 world, they construct worldviews that emphasize cynicism or charity. In addition to making CAPS-­like movements to resolve the personality paradox, the personality systems we review next also try to address the broad spectrum of personality’s influence on moral action. 4.1.3.3 Personality Architecture (KAPA) Daniel Cervone and his colleagues (Cervone, 2004; Cervone & Tripathi, 2009) provide an alternative model with similar characteristics to CAPS. They refer to their theoretical system as “architecture” to distinguish it from the nomothetic approach so prevalent in recent personality psychology. Cervone’s (2004) Knowledge and Appraisal Personality Architecture (KAPA) model is similar to Mischel’s in that both refer to the ways individuals construe their world and react to it. Cervone’s model helpfully connects this to a s large literature in emotion13 that helps us understand emotions as mixtures of cognition (appraisals) and reactions to those cognitions. Because individuals have of different conceptions of who they are, of who their friends and enemies are, and of what harm or help mean, they will have different reactions to what might objectively look like the same action. The research on emotional appraisal (Lazarus, 1991) helps us to understand, from the bottom-­up, these different reactions, and the KAPA ro system (Cervone, 2004, 2021; Cervone & Bartoszek, 2013) helps us to see the characteristic ways of reacting as a part of our personalities, and how they might change over time. lP 4.1.3.4 The Neo-­ Analytic Model (NSAM) Roberts and Wood (2006) Socio-­ propose an integrative model that, like those of Shoda and Mischel (1994) and Cervone (2004), uses an idiographic approach to resolve the personality paradox, but reaches much further in its integration and in its goals. It is a complicated model that considers influences ranging from genetic mechanisms to society and na culture.14 For our purposes, we will emphasize several similarities between this comprehensive model and the approach taken in this book. Like the framework in this book, the NSAM sees the social surround of the individual as crucial in shaping the individual’s pattern of response. We cover this aspect in Chapter 3. Roberts and Wood’s (2006) model also, like this book, emphasizes the role of Fi abilities, skill, and knowledge in shaping the characteristic ways the individual as a whole acts in the world based on the intersecting influences of the many parts of the model.15 The resulting model is more comprehensive than others, but also more cumbersome. Hill and Roberts (2010, p. 382) use this model to make specific claims about moral psychology and personality, among them the claim 13 For a detailed discussion of emotion, see Chapter 8, along with discussions of emotional regulation in Chapters 6 and 9. 14 The complete list of influences consists of the following: genes, physiological mechanisms, Big Seven personality traits, positive and negative affect, attachment styles, motives, values, goals, interests, life tasks, abilities, general intelligence, verbal and spatial ability, quantitative skill, stories, significant memories, scripts, ideological settings, identity, reputation, social roles, and social and cultural influence. 15 See also Matthews (2008) for another approach that emphasizes skills. c04.indd 97 07-20-2023 16:29:20 98 Taking Moral Action common to all the models we have reviewed here: “Studies of moral personality development must go beyond just traits.” Recently one aspect of the model has been specified in more detail: how short term, situational processes can produce longer term personality change (Wrzus & Roberts, 2017). We review this advancement in Chapter 6. 4.1.3.5 A Three-­level Approach to Personality Systems The final approach to personality we present here is more of a framework than a theoretical model of individual personality processes. But the framework organizes a broad swath of literatures and suggests how they might relate to each other. McAdams (2009, p. 12) proposes that personality consists of “(1) an individual’s unique variation on the general evolutionary design for human nature, expressed as a developing pattern of (2) dispositional traits, s (3) characteristic adaptations, and (4) self-­defining life narratives, complexly and differentially situated in (5) culture and social context.” Note that this approach of centers, again, on the individual, and like Roberts & Wood (2006) encompasses biological roots and cultural surround. The three main parts are conceived of as levels of increasing specificity for the individual, with each level providing a more nuanced understanding of the individual. Personality traits are things like extraversion, ro dominance, and emotional reactivity, and they account for some broad consistency of individuals across time and situation.16 Characteristic adaptations fill in the details of the individual’s reactions in situations. This level includes the schemas and emotional appraisals one finds in Mischel’s (2004) and Cervone’s (2004) systems, along with lP things like motives, goals, strivings, values, coping strategies etc. This level of description helps provide articulation to the broad patterns outlined at the level of personality traits. In the same way that people vary on traits like extraversion, one can arrange people into groups based on their values (Graham, Haidt, & Nosek, 2009; Graham et al., 2011; Haidt, Graham, & Joseph, 2009; Schwartz, 2006, 2010) or na motivations (Snyder & Clary, 2000). The most specific level of personality is that of the individual’s narrative of their past and expected future. These narratives are, of course, unique, though one can find some shared structure in them. For instance, when they tell stories about their life, some people tell stories whose theme is often about how good outcomes flow from bad occurrences, e.g. how losing a job led to a Fi new step in life. The tendency to tell stories with these “redemption” themes has implications for one’s moral profile. 4.2 Personality Influences on Moral Action The remainder of this chapter uses this three-­level framework by McAdams and Pals (2006) to organize a review of how each level is related to moral action. As you read, remember to keep the nomothetic vs. idiographic distinction in mind: is the pattern 16 They “account for” this consistency in that they point out patterns of consistency, but they may not be the actual “springs of action” that produce the consistency in any individual (Cervone, 2004). c04.indd 98 07-20-2023 16:29:20 Personality 99 the research describes just based on abstract categories, or are the categories things that one might expect to find having real influence at the individual level? 4.2.1 Dispositional Moral Traits The early work of Hartshorne and May (1928) and the conclusions of Mischel (1968) have bolstered the claims in philosophical circles (Doris, 2002; Doris & Stich, 2005) that large-­scale personality traits such as the Big Five do not help us understand moral action. But recent work has, in fact, found reliable effects of these characteristics in areas such as helping, cooperation, criminal behavior, and espoused moral values. In this section we review this work and conclude with Dovidio et al. (1991, p. 101) that “despite the pessimism of earlier reviews in this area, a growing body of literature suggests the importance of individual differences in helping.” These effect sizes are s generally small, but this is what one would expect in a science where there is massive interaction among the causal variables (Götz, Gosling, & Rentfrow, 2022). The secof tion begins with a review of the correlates of each of the Big Five personality traits, then notes the involvement of moral themes in alternative six-­or seven-­dimensional formulations, and finally notes some cross-­cultural attempts to present virtues as personality-­style traits. ro 4.2.1.1 Moral Correlates of the Big Five The Big Five is the standard name for the five-­ dimensional outcome of a particular approach to personality traits. These lP psychological constructs do a remarkably good job of covering the broadest span of applicable personality traits (John & Srivastava, 1999; Roccas et al., 2002). There is, of course, continuing conversation about their comprehensiveness, their causal and ontological status, and their structure (Cervone, 2004; John & Srivastava, 1999). The dimensions have been shown to replicate reasonably well in Western cultures and na moderately well (with informative exceptions) in non-­Western cultures (McCrae & Costa, 1999; McCrae et al., 1998). They are usually conceived as consisting of five dimensions (e.g. introversion–extraversion), with each dimension being a broad level summary of more specific traits (e.g. for extraversion, sociability and dominance). Thus, as one tries to parse the relationships of each dimension to morality, it is good Fi to keep in mind that it may be one aspect of a dimension (e.g. dominance) that is pulling the weight in a correlation (with e.g. brave moral action). Extraversion–introversion: People differ in the extent to which, across a broad range of situations, they tend to be socially outgoing or dominant. These differences are part of a pattern of interaction with the social world that includes interaction that we would call moral. In their study of moral exemplars who won Canadian prizes for bravery or social service, Walker et al. (2010) found that the brave exemplars were more likely to score highly on social dominance (an aspect of extraversion), while the caring exemplars tended to score more highly on nurturance (an aspect of agreeableness).17 Huff and Barnard (2009) found that, among the moral 17 See Chapter 9 for a detailed presentation of this research. c04.indd 99 07-20-2023 16:29:20 100 Taking Moral Action exemplars in computing they studied, the more extraverted exemplars were ­ inclined to be involved in social change movements, while some of the more introverted exemplars tended to use their craft to help individuals. Extraversion is also associated with community involvement and volunteerism (Ozer & Benet-­ Martínez, 2006), although Matsuba et al. (2007) have shown that this relationship can be a complicated combination of motivation and opportunity. Aspects of introversion are also related to how easily one learns the moral structures of one’s childhood. Kochanska and colleagues (Kochanska & Aksan, 2006; Kochanska & Murray, 2000; Kochanska et al., 2010) have shown that shy, fearful children are more readily socialized, particularly with regard to the development of feelings of guilt. Thus, the dimension of introversion–extraversion has a complicated relationship to morality, and it might be best to say the dimension may more describe the different ways that individuals are moral: individuals on different ends of this s dimension can be “differently moral” rather than more moral. Agreeableness–disagreeableness: This dimension of personality has variously been called of social adaptability, likability, friendly compliance, and love (John & Srivastava, 1999). These different names for the dimension give some idea that its core is about positive social interaction, including aspects of cooperation and empathy for others. Those who score high on this dimension are more cooperative with others, volunro teer more (Dovidio et al., 2006) and donate to charities more (John & Srivastava, 1999), while low agreeableness is associated with criminal behavior (Ozer & Benet-­ Martínez, 2006). Individuals high on agreeableness tend to endorse the values of benevolence and tradition, and to reject power as a value lP (Roccas et al., 2002). One might conclude that this is a dimension with a moral loading, that is, that as individuals increase in their score on agreeableness, they are also likely to increase in morality. But this would be too hasty. At the extremes of criminal behavior this may work, but one can certainly call to mind famously grumpy and uncooperative saints (Flanagan, 1991) and social action often involves na being uncooperative to the point of lawbreaking (Colby & Damon, 1992). Agreeableness may well itself contain two different kinds of morality since Hirsh et al. (2010) have found that the compassion aspect of agreeableness correlates with politically liberal values, while the politeness aspect is associated with conservative values. Fi Conscientiousness–unconscientiousness: High scores on this dimension are reliably related to success in work environment and career, to impulse control and delay of gratification, and to school and college grades (John & Srivastava, 1999). The orderliness aspect of conscientiousness correlates with what Haidt and colleagues (Haidt & Joseph, 2004) have called the “binding factors” of morality: dedication to in-­group loyalty, recognition of authority, and honor of sacred things (Hirsh et al., 2010). Low conscientiousness is associated with criminal behavior (Ozer & Benet-­Martínez, 2006) and high scorers are more likely to endorse the values of achievement and conformity (Roccas et al., 2002). Neuroticism–emotional stability: Neuroticism is the awkward label for the dimension describing an individual’s negative emotional reactivity. It is associated with a host of negative outcomes in life, including negative family and work satisfaction, lack of financial security, failure in the workplace, and conflict in romantic relationships. High scores on this dimension are also associated with criminal behavior. Those c04.indd 100 07-20-2023 16:29:20 Personality 101 who are high in extraversion and low on neuroticism are less emotionally responsive to negative feedback, and more likely to look on the bright side of things. Not surprisingly, low neuroticism is related to better emotional regulation. All these relationships are reviewed by Ozer and Benet-­Martínez (2006). Openness–closedness: Openness to experience is the tendency to seek new experience, to be tolerant of and welcoming to other views (Ozer & Benet-­Martínez, 2006). In his review of the moral personality, McAdams (2009) notes that high openness tends to correlate with post-­conventional moral reasoning, and low openness with authoritarianism; and on this basis suggests that openness may “be most closely associated with moral reasoning and thought” (p. 15). The empirical relationships are clearly there, but one should be wary of concluding too much about the dispositional nature of morality from them. Haidt and colleagues’ (Graham et al., 2009; Haidt, 2007, 2008a, 2008b; Haidt & Graham, 2007; Haidt s et al., 2009; Haidt & Hersh, 2001) work on the dimensional nature of moral cognition suggests that openness is only tracking those two (justice and care) moral of dimensions that are accepted by political liberals, and that it leaves conservatives’ moral commitments (more related to group loyalty, obedience, and sacredness) out of the domain of the moral. Some evidence for this assertion comes from the negative correlation openness shows with Schwartz values of conformity, security, ro and tradition, items one would expect to be related to conservative values (Roccas et al., 2002). Thus, the dimension tracks moral disagreement on which values are more important. lP Alternatives to the Big Five: There are several alternatives to the Big Five that use the same dimensional approach but find that six or seven dimensions better fit the way traits cluster together. The approaches we mention here differ from the Big Five in how they handle issues of morality. Both add explicitly moral dimensions to the standard dimensional analysis. One approach (Ashton & Lee, 2007) shows six dimenna sions that slightly reshuffle aspects of some dimensions (e.g. moving angry emotionality from the neuroticism dimension to the agreeableness dimension). The largest difference is the appearance of a sixth dimension called Honesty/Humility that captures differences based on sincerity, fairness, honesty, humility, and lack of greed. The original Big Five themselves have some moral tone (e.g. conscientiousness, agreeableFi ness) and it is interesting that the additional dimension that arises in this approach is an explicitly moral one. Saucier (2003) reports on a seven-­dimensional approach, and again, one of the added dimensions is explicitly moral: Social (Un)acceptability (e.g. rude, greedy, corrupt vs. loyal, dependable, honest). These additional explicitly moral dimensions lead one to think one might map the virtues themselves as traits, and there are researchers who have done so. 4.2.1.2 Mapping the Virtues as Traits One of the difficulties with talking about the virtues is that generated lists of virtues are inevitably idiosyncratic, often non-­ overlapping, and difficult to harmonize (see Lapsley & Narvaez, 2006 for a review of this difficulty). One approach to this problem is to empirically establish groupings of virtues from some suitably large set. Both Cawley (Cawley III, 1997; Cawley III, Martin, & Johnson, 2000) and De Raad (De Raad & Van Oudenhoven, 2011) have c04.indd 101 07-20-2023 16:29:20 102 Taking Moral Action generated extensive lists of virtue relevant trait words, and asked people to rate themselves and others on these traits.18 The approach, then, is very much like those that have generated the Big Five personality dimensions and its variants. Thus, they tend to find dimensions on which the virtues themselves vary (e.g. virtues rank high or low in the extent to which they involve empathy), rather than give us a comprehensive set of virtues. The methodology asks the question: “In what pattern do these traits hang together in people’s self-­ reports?” Cawley et al. (2000) found a four-­ dimensional pattern in American English speakers (empathy, order, resourcefulness, and serenity), while De Raad and Van Oudenhoven (2011) found six dimensions in Dutch speakers (sociability, achievement, respectfulness, vigor, altruism, and prudence). Both patterns showed clear relationships to the Big Five personality characteristics and some convergence on shared dimensions (De Raad & Van Oudenhoven, 2011). For instance, individuals high on the virtue dimension s “order” in Cawley’s (1997) system, tend to score high on De Raad and Van Oudenhoven’s (2011) achievement virtue dimension, and also generally score high of on the Big five characteristic of conscientiousness. A more classic approach is that of Peterson and Seligman (2004) who produce a catalog of important virtues and their supporting strengths. They survey a wide range of cultural, philosophical, and psychological approaches and argue that ro their list of six virtues (wisdom, courage, humanity, justice, temperance, and transcendence) is at least implicit in the approaches they survey. They argue, for example, that though humanity is never explicitly mentioned in Plato’s or Aristotle’s account of the virtues, “notions of shared humanity … are scattered lP across both works” (Peterson & Seligman, 2004, p. 47).19 Most of the effort is expended on the construction of a set of “strengths” that support each virtue. The virtue of humanity, for example, is composed of the strengths of love, kindness, and social intelligence. This conceptual framework is the basis for an extensive psychometric effort to produce self-­r eport and observational scales for each na of the twenty-­five strengths they catalog. Lapsley and Lasky (2001) take a cognitive approach to untangling the puzzle of the structure of the virtues. They propose that our understanding of the virtues is a “prototype,” a cognitive network with links based on similarity among the items. Walker and Hennig (2004) base their research into folk conceptions of morality on Fi this cognitive network approach, and in places Peterson and Seligman seem to do so as well (Peterson & Seligman, 2004, p. 16). As one might by now expect, Lapsley and Lasky (2001) generated a large list of character-­relevant traits, and had people rate how much each applied to someone “of good character.”20 They then 18 For instance, De Raad and Van Oudenhoven (2011) started with 1,203 trait descriptive words in Dutch. 19 They do not mention that both Aristotle and Plato had quite limited views of how widely full humanity was shared: women, slaves, foreigners (barbarians), etc. were excluded (see Nussbaum, 1996, for a valuable and nuanced discussion of virtue in Helenistic philosophy). 20 They began with 175 traits generated by subjects. At the end, the top five character-­ relevant traits were honest, trustworthy, genuine, loving, and dependable. The bottom five, least character-­relevant traits were well-­noticed, provocative, shy, popular, and lucky. c04.indd 102 07-20-2023 16:29:20 Personality 103 showed that one could produce the expected cognitive effects that indicated the traits were organized as a prototype. For instance, in a task where they first read trait words associated with a person, and were then asked to recognize those words, they falsely remembered character-­relevant words that had not been shown. This and other effects suggest these character-­based traits are part of a cognitive network based on similarity, with some traits being more central to the network and others more peripheral. 4.2.1.3 Some Conclusions About Traits The most obvious outcome from this overview of large-­scale personality traits is in harmony with the conclusion by Hill and Roberts (2010) that there is no singular “moral personality.” There are many different personality traits that are related to morality and moral action, and there s seems to be no clear unity to them. In Chapter 7 we will review evidence (Schwartz, 2010) that the values that underlie many of the moral aspects of of personality may even have a structure that pits them against each other, with any unity lying more in a sense of appropriate balance for the situation than with clear compatibility of the values or personality traits that support them. Thus, some version of value pluralism reigns in the domain of moral personality. ro There are many types of moral exemplars and multiple personality profiles that can each legitimately be called moral. No particular dimension of the Big Five captures the variety of ways people are moral. When one views virtues as though they are traits, these traits do not naturally cohere, and no single virtue trait captures the variety of lP ways people are virtuous. But this state of affairs is exactly what one would expect if moral personality is adaptive to its surroundings, pluralistic in its possible forms, and integrative of a variety of influences. Effects at the individual trait level should be small and interactive with many other variables (Götz et al., 2022). na Finally, the psychological status of traits or virtues is unclear. Certainly, people use trait/virtue words to describe themselves and others, and a large literature exists that shows some structure in the ways these descriptions cohere within a limited set of dimensions. But it seems unlikely that these dimensions refer to specific psychological entities (in the way that motives, values, goals, memories, Fi scripts, self-­concept, emotions, intuitions, etc. do). It is likely that some combination of the entities just listed influence the behavior that we then label with trait/ virtue words. These labels are likely based in prototypes, cognitive networks of descriptors whose links are based on similarity. Our experience of others’ behavior, and our culture and language, are the basis of our folk conception of the virtues. This conception is then manifest in our prototypes of patterns of moral action (Lapsley & Lasky, 2001; Walker & Hennig, 2004). Current models of virtue (Fowers et al., 2020) or character (Narvaez, 2010) have incorporated the adaptive, pluralistic, and integrative nature of moral action and provide an initial structure to grasp the complexity. To understand how we become moral, learn the virtues, and take moral action, we will need to look more carefully at the “springs of action” that produce these patterns. Some of these springs flow from McAdams and Pals’s (2006) second level of personality, characteristic adaptations. c04.indd 103 07-20-2023 16:29:20 104 Taking Moral Action 4.2.2 Characteristic Moral Adaptations This level consists of the characteristic ways that an individual adapts to his or her environment(s). To say “his or her” already suggests that there is likely more than one way of adaptation, and more than one kind of environment. As in the more basic level traits, multiplicity and pluralism will be the rule here. These aspects of personality differ from the broad trait aspects mentioned earlier in that they are more: • closely linked to motivation and cognition • easily influenced by environment and culture • likely to change over time (through therapy, practice, or environmental influence) Roberts and Wood (2006) suggest that these lower-­level aspects have more clear s implications for situational action and might therefore be the mechanisms that produce the patterns of characteristic action at the higher levels (see also Little, 1999; of McAdams & Pals, 2006). There is no canonical list of these aspects, but they are at least motivational (e.g. life goals and projects), cognitive (e.g. self-­perceptions), and emotional (e.g. dispositional empathy). All likely involve some combination of these. For instance, life goals include some cognitive conception of the good, self-­perceptions ro include motivational aspects, and empathy requires knowledge and motivation. Many of the items that might be listed in this section of the text are covered in other chapters, in part because the literatures group more easily that way. McAdams (2009), for instance, lists the content of moral beliefs and values and the structure of moral lP reasoning as two aspects at this level. We review these aspects in detail in Chapters 7 and 8 since these aspects play such an important part in each process. What follows is an incomplete listing of some of these lower-­level aspects of personality. na 4.2.2.1 Pro-­Social Personality There is a long and productive research program in what has been called “pro-­social personality” (for reviews, see Dovidio et al., 2006; Penner et al., 2005; Penner & Orom, 2010; Schroeder & Graziano, 2015). This “cluster of interrelated dispositions” (Penner & Orom, 2010, p. 60) is a reliable predictor of ongoing involvement in pro-­ social behavior, including long-­ term volunteering, spontaneous helping during accidents and other incidents (in lab Fi studies and in real life), help to friends, organizational citizenship, and parent’s empathic response to their sick children (Matsuba et al., 2007; Penner & Orom, 2010). The multidimensional nature of the cluster suggests, again, that there is more than one single aspect to moral action. The most recent versions of this approach (Penner & Orom, 2010) present a two-­dimensional picture, with one dimension of other-­ oriented empathy and a second of helpfulness. Other-­oriented empathy consists of pro-­ social thoughts and feelings, including thoughts and feelings of social responsibility, empathic concern, affective and cognitive empathy, and other-­ oriented moral reasoning. This first dimension correlates moderately with the Big Five dimension of agreeableness and with a nurturant or communal interpersonal style (Penner & Orom, 2010). The helpfulness dimension consists of a reported history of helping, and a tendency to not experience personal, egocentric distress in response to the distress of others. This later dimension thus includes a positive inclination toward helping and the removal or absence of what might be a barrier to helping others, c04.indd 104 07-20-2023 16:29:20 Personality 105 one’s own egocentric distress. This second dimension correlates positively with agency or dominance, and with feelings of self-­efficacy and personal control (Penner & Orom, 2010). The two dimensions correlate with each other, but not strongly, and it is the ­combination of the two dimensions, empathy and an action orientation, that predicts helpfulness. Thus, the two dimensions combine to describe those people who experience empathy for others and engage in moral reasoning about their obligations, but who are also socially dominant enough to have opportunities for and the expectation of success in helping (Penner & Orom, 2010 p. 63). Phrasing the two dimensions in this way makes the interaction of personal characteristics with situational aspects obvious. 4.2.2.2 Cynicism It is not surprising that someone who has a negative attitude toward s others and suspects them of dealing selfishly and dishonestly will be unlikely to engage in helping those individuals. Cynicism has been most extensively studied in the of organizational literature (Dean, Brandes, & Dharwadkar, 1998) but has recently made an appearance in work on ethics in science (De Vries, Anderson, & Martinson, 2006; Mumford et al., 2007). In both literatures cynicism is a reaction to perceived inequity and unfairness, and the source of a disposition not to help others. ro In science, Mumford (2007) has tracked the exposure of graduate students to ethical violations, and shown that this exposure produces cynicism, which in turn is expressed as a willingness to skirt the rules in self-­defense. De Vries et al. (2006) have shown a similar pattern in interviews with funded scientists. Similarly in organizations, cynicism lP is often a response to poor organizational performance, excessive executive compensation, and harsh layoff policies (Dean et al., 1998). It seems possible that cynicism can be domain specific, limited, for instance, to one’s workplace. There is some evidence that it is unrelated to any of the Big Five traits (Haas, 2002). na 4.2.2.3 Optimism and Positivity These have been cited as characteristic of moral exemplars (Oliner & Oliner, 1988). Colby and Damon (1992) note this among the exemplars they interview, but also point out some significant exceptions of angry, disappointed individuals struggling for social change. As the Colby and Damon exceptions might lead us to expect, the relationship of optimism and positivity to Fi moral action has a spotty record of replication (Walker & Frimer, 2007). 4.2.2.4 Internal Locus of Control and Self-­Efficacy These are both characteristics that have been mentioned as a part of the action-­oriented helpfulness dimension in pro-­ social personality research. Locus of control is the general feeling that one has control in one’s life. Self-­efficacy is a more domain-­specific sense that one can be effective in action in a particular area. Both are tendencies that might urge one to act or keep one from acting. Both are related to the willingness to take action in relevant situations (Midlarsky et al., 2005; Penner & Orom, 2010; Treviño, Weaver, & Reynolds, 2006). 4.2.2.5 Generativity Generativity was defined by Erikson (1963) as having a concern for promoting the well-­being of future generations. But the concept has been widened to a more general concern for society (de St. Aubin, McAdams, & Kim, 2004). There c04.indd 105 07-20-2023 16:29:20 106 Taking Moral Action is a developmental arc of adaptation that shows increases in goals related to generativity in mid-­life. (McAdams, 2009). One does not have to think of generativity as simply future-­generation oriented (Snyder & Clary, 2004), though volunteerism is often present oriented, it does not rule out, and often seeks, future benefit. Generativity is usually construed in positive terms, but it can also be about agency, narcissism, and self-­replication (Snyder & Clary, 2004, p. 232). Still, the positive aspect of this goal orientation has been associated with a wide range of pro-­social action, including involvement in children’s education, responsible parenting, participation in politics and in religion, and in volunteer work for the poor (for reviews, see de St. Aubin et al., 2004). 4.2.3 Narrative Identity s Narrative consists in the way the individual arranges his or her story about who they are, have been, and will become. This provides the unity and coherence to one’s view of of oneself and one’s life (McAdams, 2009). Narrative is, then, how the individual construes the story of the self, the story of identity.21 In one of the most careful studies of moral exemplars, Walker et al. (2007) did extensive interviews with those who had been nominated in Canada for national ro prizes for heroic rescue or for sustained social service. They also interviewed a matched sample of individuals. They coded the interviews for how they structured their life narratives (McAdams et al., 2001). The moral exemplars did not differ very much in terms of Big Five trait characteristics or even lower-­level characteristic adaptations, lP but they did differ markedly on how they told the stories of their lives. In comparison to the non-­exemplars, their stories emphasized early secure attachment to parental figures, lack of early enemies, and presence of early support. Their narratives had more positive affective tone, they spoke more positively about communication, and were more likely to emphasize the needs of others. Finally, the stories they told also na tended to see good coming out of bad occurrences, something McAdams calls a “redemptive” theme (McAdams et al., 2001). These strong differences at the narrative level suggest that this aspect or organization of identity is a central aspect of the moral self. We will see much more of this when we turn to Chapter 5. Fi 4.3 Discussion 4.3.1 Conclusion 1. Virtues are not what make us virtuous. Unlike Socrates and Protagoras, virtues do not seem to be useful constructs to use in psychological models of moral action. Ironically, virtue may not be a central psychologically active construct in a virtue-­oriented moral psychology. Or, in the language we have used in this chapter, virtue may not be among the “springs of action.” Virtue, like the Big Five traits, may describe the characteristic ways that individuals differ in acting, across a variety of situations (that is, at the nomothetic 21 For a broader discussion of this aspect of moral identity see Chapters 5 and 9. c04.indd 106 07-20-2023 16:29:20 Personality 107 level).22 But virtue names (honesty, courage, compassion) may not identify the psychological springs of action that organize and motivate each person’s behavior. One needs instead to look at the fine-­grained appraisal patterns, personal commitments, values, skills, life projects, and narrative identity across the lifespan to discover how people come to act honestly, courageously, or compassionately in certain domains. It will be these springs of action that generate the very human (in)consistency we show in living. 2. There is no singular moral personality. Moral exemplars and saints (Colby & Damon, 1992; Flanagan, 1991), people who act in accordance with long and sustained commitments to moral goals, are only similar to each other at a very high level of abstraction (e.g. their life narratives often share a similar structure of optimism though they share no personality traits). The particular moral commitments they have and the characteristic ways each pers son has of achieving those commitments vary widely (Hill & Roberts, 2010). Thus, the empirical evidence for moral pluralism, even among the highly moral, is of undeniable, at the levels of both characteristic adaptations (e.g. values) and narrative identity. Exemplars and saints are similar in that they are committed to the particular goods they are seeking. They vary widely in the moral goals they seek and in the ways they seek those goals. ro 4.3.2 Application What does a person like me do in a situation like this? In the Introduction, we prelP sented a bar fight that was handled in an unusual way by the justice system. One point of restorative justice programs is to provide psychological leverage to change the personality of offenders so that they will be less likely to re-­offend upon release. The perpetrator in the bar fight assaulted someone wearing a yarmulke, though he did so in the presence of his friend who was Jewish. He was therefore confused when he was na charged with a hate crime. The court procedure allowed the assaulter, the victim, and others to come together, after preparation, and tell their different stories. The victim was able to ask the assaulter, “What if I had not been wearing a yarmulke? Would you still have assaulted me?” This question, in the formal situation, brought some new perspective to the offender, who admitted his prejudice. As a result, the victim asked Fi for a lesser sentence and the judge altered that reduced sentence to allow him to keep his job (two concessions that might induce gratitude). There are individuals who have dedicated their professional lives to the success of restorative justice programs. The setting of the restorative justice hearing is itself “a situation like this” that influences the thinking and behavior of the participants. And that behavior then influences the perceptions of the participants and their later 22 Or one might be able to conceive of virtue as some integration of the pattern of behavior across all three levels of personality. This might match with some version of Aristotle’s description of virtuous action: “Any one can get angry – that is easy – or give or spend money; but to do this to the right person, to the right extent, at the right time, with the right motive, and in the right way, that is not for every one, nor is it easy” (Aristotle, 340 BCE/1941, Book II, 1109a27). Virtue as integration might serve well as a psychologically active construct. c04.indd 107 07-20-2023 16:29:20 108 Taking Moral Action ­decisions (and commitments to action). Thus, each person in the hearing may have been calling on a slightly different “person like me” that was made relevant by the setting of the hearing. Throughout the process, the offender is invited to consider what “a person like me should do in a situation like this.” And the decisions that result from it, at least in this case, seem tailored to reduce cynicism on the offender’s part. In addition, it is likely there was change in the “situation like this” at the bar, in an attempt to change its reputation as a setting for bar fights. In this description we can see the complex interplay of personality and situation that is tracked by the most current personality approaches. Enduring ways of interacting with the world are altered by, and alter, the world in a way that usually provides a sense of coherence and consistency to actors. s 4.3.3 Open Questions 1. Only some consistency is moral consistency. of Surely a sense of coherence and consistency in character is important to us. Also, most people want to think of themselves as moral. But this does not imply that the central consistency and coherence for every person is about morality. It is important for a functioning society that almost everyone have some minimal commitro ment to morality. But there are many other themes than morality that individuals construct to organize their lives, including being a meaningful part of a community or family, achieving status or success, or simply having fun. In Chapter 5, we will see that people vary on the extent to which they place morality as central to lP their identity. It is only the very few for whom moral projects are the center of their identity. 2. What is the relationship of morality to our life themes/projects/stories? Since morality is not so often the central theme of individuals’ lives, what then is the relationship of morality to those other life themes, and how does this influence na moral action? It may be that, to the extent that a life theme is moralized (construed as a moral enterprise), moral consideration and action will be limited to the domains within that theme. But the relationship may be more complex than that, and there is very little empirical investigation of these interactions to help us decide. It might depend, for instance, on the dimension of morality that is integrated into the theme Fi (e.g. loyal achievement of success vs. sacred achievement of success). Or it may have more complex interactions depending on other personality variables (e.g. attachment schemas). We know enough to ask the question, but not to give answers. Another question in this vein is whether those who have morality deeply integrated into a life theme act differently than those who do not. Chapter 5 will suggest that this is so, but we do not yet know enough to give details of those differences or to say how they come about. 3. How does integration of morality into the personality happen? The perpetrator in the bar fight is one example of an intervention that might help someone integrate moral considerations into their life themes. But this is only one window on a longer process of rehabilitation for the perpetrator and even the more general process may vary greatly from one individual to the next. Chapter 9 will address this question and provide a range of models and processes. And just the range of the models will suggest how much work there is yet to do. c04.indd 108 07-20-2023 16:29:20 Personality 109 4.4 Further Readings These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. • Beck and Jackson (2020). “Idiographic traits: A return to Allportian approaches to personality.” An introduction to recently developed statistical methods that allow us to track the individual and their personality profile across time. • Fowers et al. (2020). “The emerging science of virtue.” A theoretical model of the virtuous personality that decomposes virtue into four major components: knowledge, behavior, emotion/motivation, and disposition. s • Hill and Roberts (2010). “Propositions for the study of moral personality development.” An application of principles of personality psychology to moral psychology. of • Nisbett and Ross (1980). Human Inference: Strategies and Shortcoming of Social Judgment. A classic early statement and overview of the primacy of situational influence on judgment and decision making. ro • Penner and Orom (2010). “Enduring goodness: A person-­by-­situation perspective on prosocial behavior.” A useful review of the literature in the domain of pro-­social behavior that integrates the interaction of the person with the situation. • The following four models all share a view of personality as adaptive, pluralistic and lP integrative: ◦◦ Cervone and Tripathi (2009). “The moral functioning of the person as a whole: On moral psychology and personality science.” ◦◦ McAdams and Pals (2006). “A new Big Five: Fundamental principles for an integrative science of personality.” ◦◦ Mischel (2004). “Toward an integrative science of the person.” na ◦◦ Roberts and Wood (2006). “Personality development in the context of the neo-­ socioanalytic model of personality.”"
4,4.2,"Personality Influences on Moral Action The remainder of this chapter uses this three-­level framework by McAdams and Pals (2006) to organize a review of how each level is related to moral action. As you read, remember to keep the nomothetic vs. idiographic distinction in mind: is the pattern 16 They “account for” this consistency in that they point out patterns of consistency, but they may not be the actual “springs of action” that produce the consistency in any individual (Cervone, 2004). c04.indd 98 07-20-2023 16:29:20 Personality 99 the research describes just based on abstract categories, or are the categories things that one might expect to find having real influence at the individual level? 4.2.1 Dispositional Moral Traits The early work of Hartshorne and May (1928) and the conclusions of Mischel (1968) have bolstered the claims in philosophical circles (Doris, 2002; Doris & Stich, 2005) that large-­scale personality traits such as the Big Five do not help us understand moral action. But recent work has, in fact, found reliable effects of these characteristics in areas such as helping, cooperation, criminal behavior, and espoused moral values. In this section we review this work and conclude with Dovidio et al. (1991, p. 101) that “despite the pessimism of earlier reviews in this area, a growing body of literature suggests the importance of individual differences in helping.” These effect sizes are s generally small, but this is what one would expect in a science where there is massive interaction among the causal variables (Götz, Gosling, & Rentfrow, 2022). The secof tion begins with a review of the correlates of each of the Big Five personality traits, then notes the involvement of moral themes in alternative six-­or seven-­dimensional formulations, and finally notes some cross-­cultural attempts to present virtues as personality-­style traits. ro 4.2.1.1 Moral Correlates of the Big Five The Big Five is the standard name for the five-­ dimensional outcome of a particular approach to personality traits. These lP psychological constructs do a remarkably good job of covering the broadest span of applicable personality traits (John & Srivastava, 1999; Roccas et al., 2002). There is, of course, continuing conversation about their comprehensiveness, their causal and ontological status, and their structure (Cervone, 2004; John & Srivastava, 1999). The dimensions have been shown to replicate reasonably well in Western cultures and na moderately well (with informative exceptions) in non-­Western cultures (McCrae & Costa, 1999; McCrae et al., 1998). They are usually conceived as consisting of five dimensions (e.g. introversion–extraversion), with each dimension being a broad level summary of more specific traits (e.g. for extraversion, sociability and dominance). Thus, as one tries to parse the relationships of each dimension to morality, it is good Fi to keep in mind that it may be one aspect of a dimension (e.g. dominance) that is pulling the weight in a correlation (with e.g. brave moral action). Extraversion–introversion: People differ in the extent to which, across a broad range of situations, they tend to be socially outgoing or dominant. These differences are part of a pattern of interaction with the social world that includes interaction that we would call moral. In their study of moral exemplars who won Canadian prizes for bravery or social service, Walker et al. (2010) found that the brave exemplars were more likely to score highly on social dominance (an aspect of extraversion), while the caring exemplars tended to score more highly on nurturance (an aspect of agreeableness).17 Huff and Barnard (2009) found that, among the moral 17 See Chapter 9 for a detailed presentation of this research. c04.indd 99 07-20-2023 16:29:20 100 Taking Moral Action exemplars in computing they studied, the more extraverted exemplars were ­ inclined to be involved in social change movements, while some of the more introverted exemplars tended to use their craft to help individuals. Extraversion is also associated with community involvement and volunteerism (Ozer & Benet-­ Martínez, 2006), although Matsuba et al. (2007) have shown that this relationship can be a complicated combination of motivation and opportunity. Aspects of introversion are also related to how easily one learns the moral structures of one’s childhood. Kochanska and colleagues (Kochanska & Aksan, 2006; Kochanska & Murray, 2000; Kochanska et al., 2010) have shown that shy, fearful children are more readily socialized, particularly with regard to the development of feelings of guilt. Thus, the dimension of introversion–extraversion has a complicated relationship to morality, and it might be best to say the dimension may more describe the different ways that individuals are moral: individuals on different ends of this s dimension can be “differently moral” rather than more moral. Agreeableness–disagreeableness: This dimension of personality has variously been called of social adaptability, likability, friendly compliance, and love (John & Srivastava, 1999). These different names for the dimension give some idea that its core is about positive social interaction, including aspects of cooperation and empathy for others. Those who score high on this dimension are more cooperative with others, volunro teer more (Dovidio et al., 2006) and donate to charities more (John & Srivastava, 1999), while low agreeableness is associated with criminal behavior (Ozer & Benet-­ Martínez, 2006). Individuals high on agreeableness tend to endorse the values of benevolence and tradition, and to reject power as a value lP (Roccas et al., 2002). One might conclude that this is a dimension with a moral loading, that is, that as individuals increase in their score on agreeableness, they are also likely to increase in morality. But this would be too hasty. At the extremes of criminal behavior this may work, but one can certainly call to mind famously grumpy and uncooperative saints (Flanagan, 1991) and social action often involves na being uncooperative to the point of lawbreaking (Colby & Damon, 1992). Agreeableness may well itself contain two different kinds of morality since Hirsh et al. (2010) have found that the compassion aspect of agreeableness correlates with politically liberal values, while the politeness aspect is associated with conservative values. Fi Conscientiousness–unconscientiousness: High scores on this dimension are reliably related to success in work environment and career, to impulse control and delay of gratification, and to school and college grades (John & Srivastava, 1999). The orderliness aspect of conscientiousness correlates with what Haidt and colleagues (Haidt & Joseph, 2004) have called the “binding factors” of morality: dedication to in-­group loyalty, recognition of authority, and honor of sacred things (Hirsh et al., 2010). Low conscientiousness is associated with criminal behavior (Ozer & Benet-­Martínez, 2006) and high scorers are more likely to endorse the values of achievement and conformity (Roccas et al., 2002). Neuroticism–emotional stability: Neuroticism is the awkward label for the dimension describing an individual’s negative emotional reactivity. It is associated with a host of negative outcomes in life, including negative family and work satisfaction, lack of financial security, failure in the workplace, and conflict in romantic relationships. High scores on this dimension are also associated with criminal behavior. Those c04.indd 100 07-20-2023 16:29:20 Personality 101 who are high in extraversion and low on neuroticism are less emotionally responsive to negative feedback, and more likely to look on the bright side of things. Not surprisingly, low neuroticism is related to better emotional regulation. All these relationships are reviewed by Ozer and Benet-­Martínez (2006). Openness–closedness: Openness to experience is the tendency to seek new experience, to be tolerant of and welcoming to other views (Ozer & Benet-­Martínez, 2006). In his review of the moral personality, McAdams (2009) notes that high openness tends to correlate with post-­conventional moral reasoning, and low openness with authoritarianism; and on this basis suggests that openness may “be most closely associated with moral reasoning and thought” (p. 15). The empirical relationships are clearly there, but one should be wary of concluding too much about the dispositional nature of morality from them. Haidt and colleagues’ (Graham et al., 2009; Haidt, 2007, 2008a, 2008b; Haidt & Graham, 2007; Haidt s et al., 2009; Haidt & Hersh, 2001) work on the dimensional nature of moral cognition suggests that openness is only tracking those two (justice and care) moral of dimensions that are accepted by political liberals, and that it leaves conservatives’ moral commitments (more related to group loyalty, obedience, and sacredness) out of the domain of the moral. Some evidence for this assertion comes from the negative correlation openness shows with Schwartz values of conformity, security, ro and tradition, items one would expect to be related to conservative values (Roccas et al., 2002). Thus, the dimension tracks moral disagreement on which values are more important. lP Alternatives to the Big Five: There are several alternatives to the Big Five that use the same dimensional approach but find that six or seven dimensions better fit the way traits cluster together. The approaches we mention here differ from the Big Five in how they handle issues of morality. Both add explicitly moral dimensions to the standard dimensional analysis. One approach (Ashton & Lee, 2007) shows six dimenna sions that slightly reshuffle aspects of some dimensions (e.g. moving angry emotionality from the neuroticism dimension to the agreeableness dimension). The largest difference is the appearance of a sixth dimension called Honesty/Humility that captures differences based on sincerity, fairness, honesty, humility, and lack of greed. The original Big Five themselves have some moral tone (e.g. conscientiousness, agreeableFi ness) and it is interesting that the additional dimension that arises in this approach is an explicitly moral one. Saucier (2003) reports on a seven-­dimensional approach, and again, one of the added dimensions is explicitly moral: Social (Un)acceptability (e.g. rude, greedy, corrupt vs. loyal, dependable, honest). These additional explicitly moral dimensions lead one to think one might map the virtues themselves as traits, and there are researchers who have done so. 4.2.1.2 Mapping the Virtues as Traits One of the difficulties with talking about the virtues is that generated lists of virtues are inevitably idiosyncratic, often non-­ overlapping, and difficult to harmonize (see Lapsley & Narvaez, 2006 for a review of this difficulty). One approach to this problem is to empirically establish groupings of virtues from some suitably large set. Both Cawley (Cawley III, 1997; Cawley III, Martin, & Johnson, 2000) and De Raad (De Raad & Van Oudenhoven, 2011) have c04.indd 101 07-20-2023 16:29:20 102 Taking Moral Action generated extensive lists of virtue relevant trait words, and asked people to rate themselves and others on these traits.18 The approach, then, is very much like those that have generated the Big Five personality dimensions and its variants. Thus, they tend to find dimensions on which the virtues themselves vary (e.g. virtues rank high or low in the extent to which they involve empathy), rather than give us a comprehensive set of virtues. The methodology asks the question: “In what pattern do these traits hang together in people’s self-­ reports?” Cawley et al. (2000) found a four-­ dimensional pattern in American English speakers (empathy, order, resourcefulness, and serenity), while De Raad and Van Oudenhoven (2011) found six dimensions in Dutch speakers (sociability, achievement, respectfulness, vigor, altruism, and prudence). Both patterns showed clear relationships to the Big Five personality characteristics and some convergence on shared dimensions (De Raad & Van Oudenhoven, 2011). For instance, individuals high on the virtue dimension s “order” in Cawley’s (1997) system, tend to score high on De Raad and Van Oudenhoven’s (2011) achievement virtue dimension, and also generally score high of on the Big five characteristic of conscientiousness. A more classic approach is that of Peterson and Seligman (2004) who produce a catalog of important virtues and their supporting strengths. They survey a wide range of cultural, philosophical, and psychological approaches and argue that ro their list of six virtues (wisdom, courage, humanity, justice, temperance, and transcendence) is at least implicit in the approaches they survey. They argue, for example, that though humanity is never explicitly mentioned in Plato’s or Aristotle’s account of the virtues, “notions of shared humanity … are scattered lP across both works” (Peterson & Seligman, 2004, p. 47).19 Most of the effort is expended on the construction of a set of “strengths” that support each virtue. The virtue of humanity, for example, is composed of the strengths of love, kindness, and social intelligence. This conceptual framework is the basis for an extensive psychometric effort to produce self-­r eport and observational scales for each na of the twenty-­five strengths they catalog. Lapsley and Lasky (2001) take a cognitive approach to untangling the puzzle of the structure of the virtues. They propose that our understanding of the virtues is a “prototype,” a cognitive network with links based on similarity among the items. Walker and Hennig (2004) base their research into folk conceptions of morality on Fi this cognitive network approach, and in places Peterson and Seligman seem to do so as well (Peterson & Seligman, 2004, p. 16). As one might by now expect, Lapsley and Lasky (2001) generated a large list of character-­relevant traits, and had people rate how much each applied to someone “of good character.”20 They then 18 For instance, De Raad and Van Oudenhoven (2011) started with 1,203 trait descriptive words in Dutch. 19 They do not mention that both Aristotle and Plato had quite limited views of how widely full humanity was shared: women, slaves, foreigners (barbarians), etc. were excluded (see Nussbaum, 1996, for a valuable and nuanced discussion of virtue in Helenistic philosophy). 20 They began with 175 traits generated by subjects. At the end, the top five character-­ relevant traits were honest, trustworthy, genuine, loving, and dependable. The bottom five, least character-­relevant traits were well-­noticed, provocative, shy, popular, and lucky. c04.indd 102 07-20-2023 16:29:20 Personality 103 showed that one could produce the expected cognitive effects that indicated the traits were organized as a prototype. For instance, in a task where they first read trait words associated with a person, and were then asked to recognize those words, they falsely remembered character-­relevant words that had not been shown. This and other effects suggest these character-­based traits are part of a cognitive network based on similarity, with some traits being more central to the network and others more peripheral. 4.2.1.3 Some Conclusions About Traits The most obvious outcome from this overview of large-­scale personality traits is in harmony with the conclusion by Hill and Roberts (2010) that there is no singular “moral personality.” There are many different personality traits that are related to morality and moral action, and there s seems to be no clear unity to them. In Chapter 7 we will review evidence (Schwartz, 2010) that the values that underlie many of the moral aspects of of personality may even have a structure that pits them against each other, with any unity lying more in a sense of appropriate balance for the situation than with clear compatibility of the values or personality traits that support them. Thus, some version of value pluralism reigns in the domain of moral personality. ro There are many types of moral exemplars and multiple personality profiles that can each legitimately be called moral. No particular dimension of the Big Five captures the variety of ways people are moral. When one views virtues as though they are traits, these traits do not naturally cohere, and no single virtue trait captures the variety of lP ways people are virtuous. But this state of affairs is exactly what one would expect if moral personality is adaptive to its surroundings, pluralistic in its possible forms, and integrative of a variety of influences. Effects at the individual trait level should be small and interactive with many other variables (Götz et al., 2022). na Finally, the psychological status of traits or virtues is unclear. Certainly, people use trait/virtue words to describe themselves and others, and a large literature exists that shows some structure in the ways these descriptions cohere within a limited set of dimensions. But it seems unlikely that these dimensions refer to specific psychological entities (in the way that motives, values, goals, memories, Fi scripts, self-­concept, emotions, intuitions, etc. do). It is likely that some combination of the entities just listed influence the behavior that we then label with trait/ virtue words. These labels are likely based in prototypes, cognitive networks of descriptors whose links are based on similarity. Our experience of others’ behavior, and our culture and language, are the basis of our folk conception of the virtues. This conception is then manifest in our prototypes of patterns of moral action (Lapsley & Lasky, 2001; Walker & Hennig, 2004). Current models of virtue (Fowers et al., 2020) or character (Narvaez, 2010) have incorporated the adaptive, pluralistic, and integrative nature of moral action and provide an initial structure to grasp the complexity. To understand how we become moral, learn the virtues, and take moral action, we will need to look more carefully at the “springs of action” that produce these patterns. Some of these springs flow from McAdams and Pals’s (2006) second level of personality, characteristic adaptations. c04.indd 103 07-20-2023 16:29:20 104 Taking Moral Action 4.2.2 Characteristic Moral Adaptations This level consists of the characteristic ways that an individual adapts to his or her environment(s). To say “his or her” already suggests that there is likely more than one way of adaptation, and more than one kind of environment. As in the more basic level traits, multiplicity and pluralism will be the rule here. These aspects of personality differ from the broad trait aspects mentioned earlier in that they are more: • closely linked to motivation and cognition • easily influenced by environment and culture • likely to change over time (through therapy, practice, or environmental influence) Roberts and Wood (2006) suggest that these lower-­level aspects have more clear s implications for situational action and might therefore be the mechanisms that produce the patterns of characteristic action at the higher levels (see also Little, 1999; of McAdams & Pals, 2006). There is no canonical list of these aspects, but they are at least motivational (e.g. life goals and projects), cognitive (e.g. self-­perceptions), and emotional (e.g. dispositional empathy). All likely involve some combination of these. For instance, life goals include some cognitive conception of the good, self-­perceptions ro include motivational aspects, and empathy requires knowledge and motivation. Many of the items that might be listed in this section of the text are covered in other chapters, in part because the literatures group more easily that way. McAdams (2009), for instance, lists the content of moral beliefs and values and the structure of moral lP reasoning as two aspects at this level. We review these aspects in detail in Chapters 7 and 8 since these aspects play such an important part in each process. What follows is an incomplete listing of some of these lower-­level aspects of personality. na 4.2.2.1 Pro-­Social Personality There is a long and productive research program in what has been called “pro-­social personality” (for reviews, see Dovidio et al., 2006; Penner et al., 2005; Penner & Orom, 2010; Schroeder & Graziano, 2015). This “cluster of interrelated dispositions” (Penner & Orom, 2010, p. 60) is a reliable predictor of ongoing involvement in pro-­ social behavior, including long-­ term volunteering, spontaneous helping during accidents and other incidents (in lab Fi studies and in real life), help to friends, organizational citizenship, and parent’s empathic response to their sick children (Matsuba et al., 2007; Penner & Orom, 2010). The multidimensional nature of the cluster suggests, again, that there is more than one single aspect to moral action. The most recent versions of this approach (Penner & Orom, 2010) present a two-­dimensional picture, with one dimension of other-­ oriented empathy and a second of helpfulness. Other-­oriented empathy consists of pro-­ social thoughts and feelings, including thoughts and feelings of social responsibility, empathic concern, affective and cognitive empathy, and other-­ oriented moral reasoning. This first dimension correlates moderately with the Big Five dimension of agreeableness and with a nurturant or communal interpersonal style (Penner & Orom, 2010). The helpfulness dimension consists of a reported history of helping, and a tendency to not experience personal, egocentric distress in response to the distress of others. This later dimension thus includes a positive inclination toward helping and the removal or absence of what might be a barrier to helping others, c04.indd 104 07-20-2023 16:29:20 Personality 105 one’s own egocentric distress. This second dimension correlates positively with agency or dominance, and with feelings of self-­efficacy and personal control (Penner & Orom, 2010). The two dimensions correlate with each other, but not strongly, and it is the ­combination of the two dimensions, empathy and an action orientation, that predicts helpfulness. Thus, the two dimensions combine to describe those people who experience empathy for others and engage in moral reasoning about their obligations, but who are also socially dominant enough to have opportunities for and the expectation of success in helping (Penner & Orom, 2010 p. 63). Phrasing the two dimensions in this way makes the interaction of personal characteristics with situational aspects obvious. 4.2.2.2 Cynicism It is not surprising that someone who has a negative attitude toward s others and suspects them of dealing selfishly and dishonestly will be unlikely to engage in helping those individuals. Cynicism has been most extensively studied in the of organizational literature (Dean, Brandes, & Dharwadkar, 1998) but has recently made an appearance in work on ethics in science (De Vries, Anderson, & Martinson, 2006; Mumford et al., 2007). In both literatures cynicism is a reaction to perceived inequity and unfairness, and the source of a disposition not to help others. ro In science, Mumford (2007) has tracked the exposure of graduate students to ethical violations, and shown that this exposure produces cynicism, which in turn is expressed as a willingness to skirt the rules in self-­defense. De Vries et al. (2006) have shown a similar pattern in interviews with funded scientists. Similarly in organizations, cynicism lP is often a response to poor organizational performance, excessive executive compensation, and harsh layoff policies (Dean et al., 1998). It seems possible that cynicism can be domain specific, limited, for instance, to one’s workplace. There is some evidence that it is unrelated to any of the Big Five traits (Haas, 2002). na 4.2.2.3 Optimism and Positivity These have been cited as characteristic of moral exemplars (Oliner & Oliner, 1988). Colby and Damon (1992) note this among the exemplars they interview, but also point out some significant exceptions of angry, disappointed individuals struggling for social change. As the Colby and Damon exceptions might lead us to expect, the relationship of optimism and positivity to Fi moral action has a spotty record of replication (Walker & Frimer, 2007). 4.2.2.4 Internal Locus of Control and Self-­Efficacy These are both characteristics that have been mentioned as a part of the action-­oriented helpfulness dimension in pro-­ social personality research. Locus of control is the general feeling that one has control in one’s life. Self-­efficacy is a more domain-­specific sense that one can be effective in action in a particular area. Both are tendencies that might urge one to act or keep one from acting. Both are related to the willingness to take action in relevant situations (Midlarsky et al., 2005; Penner & Orom, 2010; Treviño, Weaver, & Reynolds, 2006). 4.2.2.5 Generativity Generativity was defined by Erikson (1963) as having a concern for promoting the well-­being of future generations. But the concept has been widened to a more general concern for society (de St. Aubin, McAdams, & Kim, 2004). There c04.indd 105 07-20-2023 16:29:20 106 Taking Moral Action is a developmental arc of adaptation that shows increases in goals related to generativity in mid-­life. (McAdams, 2009). One does not have to think of generativity as simply future-­generation oriented (Snyder & Clary, 2004), though volunteerism is often present oriented, it does not rule out, and often seeks, future benefit. Generativity is usually construed in positive terms, but it can also be about agency, narcissism, and self-­replication (Snyder & Clary, 2004, p. 232). Still, the positive aspect of this goal orientation has been associated with a wide range of pro-­social action, including involvement in children’s education, responsible parenting, participation in politics and in religion, and in volunteer work for the poor (for reviews, see de St. Aubin et al., 2004). 4.2.3 Narrative Identity s Narrative consists in the way the individual arranges his or her story about who they are, have been, and will become. This provides the unity and coherence to one’s view of of oneself and one’s life (McAdams, 2009). Narrative is, then, how the individual construes the story of the self, the story of identity.21 In one of the most careful studies of moral exemplars, Walker et al. (2007) did extensive interviews with those who had been nominated in Canada for national ro prizes for heroic rescue or for sustained social service. They also interviewed a matched sample of individuals. They coded the interviews for how they structured their life narratives (McAdams et al., 2001). The moral exemplars did not differ very much in terms of Big Five trait characteristics or even lower-­level characteristic adaptations, lP but they did differ markedly on how they told the stories of their lives. In comparison to the non-­exemplars, their stories emphasized early secure attachment to parental figures, lack of early enemies, and presence of early support. Their narratives had more positive affective tone, they spoke more positively about communication, and were more likely to emphasize the needs of others. Finally, the stories they told also na tended to see good coming out of bad occurrences, something McAdams calls a “redemptive” theme (McAdams et al., 2001). These strong differences at the narrative level suggest that this aspect or organization of identity is a central aspect of the moral self. We will see much more of this when we turn to Chapter 5. Fi 4.3 Discussion 4.3.1 Conclusion 1. Virtues are not what make us virtuous. Unlike Socrates and Protagoras, virtues do not seem to be useful constructs to use in psychological models of moral action. Ironically, virtue may not be a central psychologically active construct in a virtue-­oriented moral psychology. Or, in the language we have used in this chapter, virtue may not be among the “springs of action.” Virtue, like the Big Five traits, may describe the characteristic ways that individuals differ in acting, across a variety of situations (that is, at the nomothetic 21 For a broader discussion of this aspect of moral identity see Chapters 5 and 9. c04.indd 106 07-20-2023 16:29:20 Personality 107 level).22 But virtue names (honesty, courage, compassion) may not identify the psychological springs of action that organize and motivate each person’s behavior. One needs instead to look at the fine-­grained appraisal patterns, personal commitments, values, skills, life projects, and narrative identity across the lifespan to discover how people come to act honestly, courageously, or compassionately in certain domains. It will be these springs of action that generate the very human (in)consistency we show in living. 2. There is no singular moral personality. Moral exemplars and saints (Colby & Damon, 1992; Flanagan, 1991), people who act in accordance with long and sustained commitments to moral goals, are only similar to each other at a very high level of abstraction (e.g. their life narratives often share a similar structure of optimism though they share no personality traits). The particular moral commitments they have and the characteristic ways each pers son has of achieving those commitments vary widely (Hill & Roberts, 2010). Thus, the empirical evidence for moral pluralism, even among the highly moral, is of undeniable, at the levels of both characteristic adaptations (e.g. values) and narrative identity. Exemplars and saints are similar in that they are committed to the particular goods they are seeking. They vary widely in the moral goals they seek and in the ways they seek those goals. ro 4.3.2 Application What does a person like me do in a situation like this? In the Introduction, we prelP sented a bar fight that was handled in an unusual way by the justice system. One point of restorative justice programs is to provide psychological leverage to change the personality of offenders so that they will be less likely to re-­offend upon release. The perpetrator in the bar fight assaulted someone wearing a yarmulke, though he did so in the presence of his friend who was Jewish. He was therefore confused when he was na charged with a hate crime. The court procedure allowed the assaulter, the victim, and others to come together, after preparation, and tell their different stories. The victim was able to ask the assaulter, “What if I had not been wearing a yarmulke? Would you still have assaulted me?” This question, in the formal situation, brought some new perspective to the offender, who admitted his prejudice. As a result, the victim asked Fi for a lesser sentence and the judge altered that reduced sentence to allow him to keep his job (two concessions that might induce gratitude). There are individuals who have dedicated their professional lives to the success of restorative justice programs. The setting of the restorative justice hearing is itself “a situation like this” that influences the thinking and behavior of the participants. And that behavior then influences the perceptions of the participants and their later 22 Or one might be able to conceive of virtue as some integration of the pattern of behavior across all three levels of personality. This might match with some version of Aristotle’s description of virtuous action: “Any one can get angry – that is easy – or give or spend money; but to do this to the right person, to the right extent, at the right time, with the right motive, and in the right way, that is not for every one, nor is it easy” (Aristotle, 340 BCE/1941, Book II, 1109a27). Virtue as integration might serve well as a psychologically active construct. c04.indd 107 07-20-2023 16:29:20 108 Taking Moral Action ­decisions (and commitments to action). Thus, each person in the hearing may have been calling on a slightly different “person like me” that was made relevant by the setting of the hearing. Throughout the process, the offender is invited to consider what “a person like me should do in a situation like this.” And the decisions that result from it, at least in this case, seem tailored to reduce cynicism on the offender’s part. In addition, it is likely there was change in the “situation like this” at the bar, in an attempt to change its reputation as a setting for bar fights. In this description we can see the complex interplay of personality and situation that is tracked by the most current personality approaches. Enduring ways of interacting with the world are altered by, and alter, the world in a way that usually provides a sense of coherence and consistency to actors. s"
4,4.3,"Discussion 4.3.1 Conclusion 1. Virtues are not what make us virtuous. Unlike Socrates and Protagoras, virtues do not seem to be useful constructs to use in psychological models of moral action. Ironically, virtue may not be a central psychologically active construct in a virtue-­oriented moral psychology. Or, in the language we have used in this chapter, virtue may not be among the “springs of action.” Virtue, like the Big Five traits, may describe the characteristic ways that individuals differ in acting, across a variety of situations (that is, at the nomothetic 21 For a broader discussion of this aspect of moral identity see Chapters 5 and 9. c04.indd 106 07-20-2023 16:29:20 Personality 107 level).22 But virtue names (honesty, courage, compassion) may not identify the psychological springs of action that organize and motivate each person’s behavior. One needs instead to look at the fine-­grained appraisal patterns, personal commitments, values, skills, life projects, and narrative identity across the lifespan to discover how people come to act honestly, courageously, or compassionately in certain domains. It will be these springs of action that generate the very human (in)consistency we show in living. 2. There is no singular moral personality. Moral exemplars and saints (Colby & Damon, 1992; Flanagan, 1991), people who act in accordance with long and sustained commitments to moral goals, are only similar to each other at a very high level of abstraction (e.g. their life narratives often share a similar structure of optimism though they share no personality traits). The particular moral commitments they have and the characteristic ways each pers son has of achieving those commitments vary widely (Hill & Roberts, 2010). Thus, the empirical evidence for moral pluralism, even among the highly moral, is of undeniable, at the levels of both characteristic adaptations (e.g. values) and narrative identity. Exemplars and saints are similar in that they are committed to the particular goods they are seeking. They vary widely in the moral goals they seek and in the ways they seek those goals. ro 4.3.2 Application What does a person like me do in a situation like this? In the Introduction, we prelP sented a bar fight that was handled in an unusual way by the justice system. One point of restorative justice programs is to provide psychological leverage to change the personality of offenders so that they will be less likely to re-­offend upon release. The perpetrator in the bar fight assaulted someone wearing a yarmulke, though he did so in the presence of his friend who was Jewish. He was therefore confused when he was na charged with a hate crime. The court procedure allowed the assaulter, the victim, and others to come together, after preparation, and tell their different stories. The victim was able to ask the assaulter, “What if I had not been wearing a yarmulke? Would you still have assaulted me?” This question, in the formal situation, brought some new perspective to the offender, who admitted his prejudice. As a result, the victim asked Fi for a lesser sentence and the judge altered that reduced sentence to allow him to keep his job (two concessions that might induce gratitude). There are individuals who have dedicated their professional lives to the success of restorative justice programs. The setting of the restorative justice hearing is itself “a situation like this” that influences the thinking and behavior of the participants. And that behavior then influences the perceptions of the participants and their later 22 Or one might be able to conceive of virtue as some integration of the pattern of behavior across all three levels of personality. This might match with some version of Aristotle’s description of virtuous action: “Any one can get angry – that is easy – or give or spend money; but to do this to the right person, to the right extent, at the right time, with the right motive, and in the right way, that is not for every one, nor is it easy” (Aristotle, 340 BCE/1941, Book II, 1109a27). Virtue as integration might serve well as a psychologically active construct. c04.indd 107 07-20-2023 16:29:20 108 Taking Moral Action ­decisions (and commitments to action). Thus, each person in the hearing may have been calling on a slightly different “person like me” that was made relevant by the setting of the hearing. Throughout the process, the offender is invited to consider what “a person like me should do in a situation like this.” And the decisions that result from it, at least in this case, seem tailored to reduce cynicism on the offender’s part. In addition, it is likely there was change in the “situation like this” at the bar, in an attempt to change its reputation as a setting for bar fights. In this description we can see the complex interplay of personality and situation that is tracked by the most current personality approaches. Enduring ways of interacting with the world are altered by, and alter, the world in a way that usually provides a sense of coherence and consistency to actors. s 4.3.3 Open Questions 1. Only some consistency is moral consistency. of Surely a sense of coherence and consistency in character is important to us. Also, most people want to think of themselves as moral. But this does not imply that the central consistency and coherence for every person is about morality. It is important for a functioning society that almost everyone have some minimal commitro ment to morality. But there are many other themes than morality that individuals construct to organize their lives, including being a meaningful part of a community or family, achieving status or success, or simply having fun. In Chapter 5, we will see that people vary on the extent to which they place morality as central to lP their identity. It is only the very few for whom moral projects are the center of their identity. 2. What is the relationship of morality to our life themes/projects/stories? Since morality is not so often the central theme of individuals’ lives, what then is the relationship of morality to those other life themes, and how does this influence na moral action? It may be that, to the extent that a life theme is moralized (construed as a moral enterprise), moral consideration and action will be limited to the domains within that theme. But the relationship may be more complex than that, and there is very little empirical investigation of these interactions to help us decide. It might depend, for instance, on the dimension of morality that is integrated into the theme Fi (e.g. loyal achievement of success vs. sacred achievement of success). Or it may have more complex interactions depending on other personality variables (e.g. attachment schemas). We know enough to ask the question, but not to give answers. Another question in this vein is whether those who have morality deeply integrated into a life theme act differently than those who do not. Chapter 5 will suggest that this is so, but we do not yet know enough to give details of those differences or to say how they come about. 3. How does integration of morality into the personality happen? The perpetrator in the bar fight is one example of an intervention that might help someone integrate moral considerations into their life themes. But this is only one window on a longer process of rehabilitation for the perpetrator and even the more general process may vary greatly from one individual to the next. Chapter 9 will address this question and provide a range of models and processes. And just the range of the models will suggest how much work there is yet to do. c04.indd 108 07-20-2023 16:29:20 Personality 109"
4,4.4,"Further Readings These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. • Beck and Jackson (2020). “Idiographic traits: A return to Allportian approaches to personality.” An introduction to recently developed statistical methods that allow us to track the individual and their personality profile across time. • Fowers et al. (2020). “The emerging science of virtue.” A theoretical model of the virtuous personality that decomposes virtue into four major components: knowledge, behavior, emotion/motivation, and disposition. s • Hill and Roberts (2010). “Propositions for the study of moral personality development.” An application of principles of personality psychology to moral psychology. of • Nisbett and Ross (1980). Human Inference: Strategies and Shortcoming of Social Judgment. A classic early statement and overview of the primacy of situational influence on judgment and decision making. ro • Penner and Orom (2010). “Enduring goodness: A person-­by-­situation perspective on prosocial behavior.” A useful review of the literature in the domain of pro-­social behavior that integrates the interaction of the person with the situation. • The following four models all share a view of personality as adaptive, pluralistic and lP integrative: ◦◦ Cervone and Tripathi (2009). “The moral functioning of the person as a whole: On moral psychology and personality science.” ◦◦ McAdams and Pals (2006). “A new Big Five: Fundamental principles for an integrative science of personality.” ◦◦ Mischel (2004). “Toward an integrative science of the person.” na ◦◦ Roberts and Wood (2006). “Personality development in the context of the neo-­ socioanalytic model of personality.”"
5,5.1,"From the Judgment–Action Gap to Moral Identity The revival of research on the self and moral psychology was fueled by the widespread recognition that even when people are capable of making careful and mature moral judgments, this ability does not often result in moral action. The idea is at least as old as the writings of the Apostle Paul. Simply knowing the right/good/moral thing to do is not the same as wanting to do it, which is again different from a final translation s into action.4 Hartshorne and May (1928) were among the first psychologists to empirically document this. With the children they tested, honesty in one situation had of little to no predictive value for honesty in dissimilar situations. This pattern (or lack of a pattern) held for many other supposedly character-­like attributes they tested. In 1968, Mischel reviewed the cumulative failure of psychologists to find cross-­situational consistency for personality characteristics and famously proposed that there were no ro simple personality traits that were broadly predictive of behavior. A decade later, Blasi (1980) cataloged the consistently small correlations5 that were obtained between increases in Kohlberg’s moral stages and taking corresponding moral action.6 He labeled this disappointing state of affairs the judgment–action gap,7 and proposed lP moral identity as the motivational factor needed to bridge it. For Blasi, moral identity is the possession of a particular kind of self-­concept (Blasi, 1984), a self-­concept with high, even central, regard for issues of moral obligation, responsibility, and the good. We will analyze moral identity as a multidimensional aspect of the self-­concept and follow the implications of this dimensionality for the judgment–action gap.8 na The judgment–action gap is most problematic for those approaches, like Kohlberg’s, that have conscious moral judgment as the central aspect of the model (Frimer & Walker, 2008). These models depend upon psychological consistency pressures as the main engine to bridge the gap between knowing and doing. If one judges something to be the moral thing to do, it is uncomfortable to think that one has not done it.9 Fi For Kohlberg, this uncomfortable consistency pressure comes from holding a 3 How this commitment comes about is the subject of Chapter 9. 4 The relationship among these three things is part of the philosophical puzzle called “weakness of the will.” See Stroud (2019) for a review of the long philosophical history of this problem. 5 Both words in the phrase “consistently small” are important to note. There is a very consistent correlation (about 0.33) between moral cognition and moral action, but this consistency is at best “somewhat modest” (Walker, 2004, p. 2). 6 See Chapter 7 for a presentation and critique of Kohlberg’s approach. 7 Note that this formulation presumes the judgment comes (or ought to come) before the action. 8 Chapter 9 is where we will explore how a person comes to have a strong moral identity. 9 See Heider (1958) and Festinger (1957) for early versions of this motivational urging that is associated with thinking inconsistent thoughts. Moral Identity and the Self 117 principle (e.g. justice) and is thus about consistency with the principle.10 Blasi’s moral identity (1980) approach is still centered on judgment, and so it too is powered by cognitive consistency. But it is consistent with the moral self (one aspect of the multidimensional self that has moral goals, etc.). Thus, for Kohlberg, immoral action is betrayal of a principle, but for Blasi, it is betrayal of the self, with presumably more motivating power (see Lapsley, 2008, for a review).11 The judgment–action gap is more easily bridged in models of the self that actively include emotions and automatic evaluations as central players (Bandura, 1986; Mischel, 2004; Narvaez, 2010b).12 Well-­practiced emotions lead us to righteous anger or pity, and contain within them a motivation to act (see Chapter 8 for this). These approaches bridge the gap naturally (at least in theory) because they contain an action impulse as an integral part of the automatic response. Automatic, non-­ conscious evaluations (Haidt & Kesebir, 2010; Narvaez, 2010a) and emotions are s combinations of cognitive judgment, self-­and other-­relevant emotion, and action orientation (Haidt, 2003; Lazarus, 1991b). The massive interconnectivity of emoof tional and judgment areas in the brain (Pessoa, 2008) attest to this blending of cognition, emotion, and action, and Moll et al. (2006) refer to (and also track over time) “cognitive-­emotional” complexes in moral judgments. The cognitive appraisals in these models include reference to the implications of the situation for the self ro and it goals (Lazarus, 1991a, 1991b). Thus, these automatic/emotional approaches also have the self as a core component – not a meager, cognitive self but a richly complex one that includes motivational commitments and automatic tendencies toward action. lP 5.2 The Varieties of Self: Or What is Moral Identity? In this section, we will consider the variety of psychological models of the self, conna sidered under three propositions: that the self is multidimensional, variable over time and context, and often domain specific. In the process, these general characteristics of the self will be shown to be true also of the moral self or moral identity, which we define as those aspects of the self that are relevant to moral action. As moral identity Fi 10 Kohlberg founded his psychological system in part on Kantian models of reason as the source of moral judgment (Frimer & Walker, 2008; Lapsley & Narvaez, 2005). However, he mistakes the complexity of Kant’s moral psychology when he claims reason alone should be the source of moral action. In a well-­known footnote in Kant’s (1785/2011, pp. 30–31) Groundwork for the Metaphysics of Morals, Kant bridges the gap between thought and feeling/motivation by treating the feeling of respect or reverence (Achtung) for a principle as both a cognitive and a motivational construct, so that the internal feeling comes not as outside influence but “through a motivation self-­wrought by a rational concept” (durch einen Vernunftbegriff selbstgewirktes Gefühl). Note that “Vernunftbegriff” would be literally translated as “term of reason.” In contrast, Kohlberg sees all emotion as bias and ignores Kant’s subtle moral psychology in favor of a simple rational actor model. 11 This self-­betrayal is analyzed by Sartre (1943/1984) under the label of acting in bad faith. 12 There are models of automatic moral cognition that do not include reference to the self, motivation, or emotion (Sunstein, 2005) and these have a similar judgment–action gap to bridge. Taking Moral Action is used in much of the literature in moral psychology, this is the term we will use interchangeably with the moral self or moral self-­concept.13 5.2.1 The Self is Multidimensional Before the dawn of academic psychology, the Danish theologian Søren Kierkegaard pioneered the phenomenological study of the self. He portrayed the self as a threefold relationship that holds together the physiological, psychological, and theological/normative aspects of a person’s life. Thus, the self is not a thing, or some shadowy substance, or a possession one might have. Instead, it is what one does, an ongoing narrative with which one stitches together past and future, being and becoming, conditions and possibilities. Such a self is seen as an agent of one’s becoming, navigating a continuous and continuously revised set of relations, some imposed by the constraints and tensions of s being human, others freely chosen as a response to those tensions, and all embedded within, or resting on, a narrative about ultimate meaning (Davenport, 2013; Garff, 2013). of In recent personality and social psychology literature, the self has been understood using the more limited metaphor of a cognitive network. This self-­system is a multidimensional network that includes cognitive representations and evaluations of the actual, possible, ideal, future, etc. self (Cervone, 2004; Heatherton, 2011; ro Leary, 2007; Mischel, 2004). Critics of cognitive network approaches have complained that this cognitive bias in models of the self makes them inadequate for understanding our deeply motivating, complex, and evolving self-­representations of who we are (Nucci, 2000, 2004). At one level, this complaint is telling. The rich lP experience of deeply meaningful activity (Colby & Damon, 1992), of social threats to our self-­esteem (DeWall, 2009; Heatherton, 2011), and of personal crises of meaning (Koole, Greenberg, & Pyszczynski, 2006) cannot easily be modeled by a simple network of nodes linking traits that we think apply to us (Aquino & Reed, 2002). However, most approaches do not see self-­networks as such spare furniture in our na psyche. Many approaches link our self-­systems to self-­reflections of competence and esteem (Bandura, 1986; Bandura & Locke, 2003; Heatherton, 2011; Leary, 2007) and thus implicitly or explicitly evoke the emotional commitments that come with a sense of self. Many systems explicitly include emotion in self-­systems: Mischel and colleagues (Mischel, 2004; Shoda, LeeTiernan, & Mischel, 2002; Shoda, Mischel, & Fi Wright, 1994) refer to the “cognitive-­ affective” processing system and Cervone (2004) explores the linkage of knowledge and emotional appraisal in judgments about the self. Other approaches to the moral self see aspects of skilled action (e.g. offering specific kinds of help to others) as highly automatized, scripted, and central to the self (Lapsley & Hill, 2008). Still other approaches see the themes that emerge from public and private narratives of the self as defining of the moral self (Colby & Damon, 1992; Huff, Barnard, & Frey, 2008a, 2008b; McAdams, 2009). All models agree that the networks that make up our moral selves are multidimensional and include cultural and social influence, cognition, emotion, and intuition. And because they are action-­ oriented, they include highly practiced skill 13 One can split many hairs over the differences between these terms. We do not have the space to do so; and we think avoiding it is worth any minor conceptual confusion it might create. Moral Identity and the Self 119 Affiliations & Roles, life tasks, relationships & possible selves Personal contexts Motives & strivings Beliefs, attitudes, Stories & s & values defining memories of Traits & Past behaviors & competencies experiences ro Figure 5.1 A model of some of the components of the self. Source: Adapted from McGregor & Little (1998). lP (McConnell, 2010). It follows that there will be a variety of ways that ideals, values, morality, and moral goals will be integrated into the self. Figure 5.1 is a good example of the variety of ways that self can be constructed. It proposes a set of ways that themes, including moral themes, may be integrated into the self-­concept (to answer the question “What is a person like me?”).14 This “diverse array” (McGregor & Little, 1998, p. 496) of elements includes at least sixteen differna ent types of items ranging from memories of the past to hopes (and fears) for the future, from skills to attitudes to social roles. Items, of course, overlap and it is unlikely that the list is complete. But each of them suggests ways that morally relevant influences might be integrated into the self. For any single individual, a moral commitment to integrity might be experienced as, and be represented in, multiple things. For Fi example, a computer scientist that Huff and Barnard (2009) interviewed in a study on moral expertise spoke of his architect father as an important role model. He noted that his father’s moral integrity was “incredibly influential” in his life.15 As interviewers we were confronted with a host of questions: How shall we talk about or represent this important aspect of this person’s life? We could conceptualize this as a value of 14 We are using “moral identity,” “moral self-­concept,” and “moral self” as synonyms in this chapter. These are aspects of the larger self. Indeed, when people are asked to rate what aspects of the self would most drastically change identity, the moral self appears to be the most important part of the self, surpassing even autobiographical memory (Strohminger & Nichols, 2014). 15 This is from a study of moral exemplars in computing, individuals who were widely known for their commitment to moral causes in the field of computing, selected by a panel of computer scientists and philosophers. Taking Moral Action “integrity,” or as a motivating story about his father’s struggles in a system that was sometimes unfair? Or as a boyhood memory of Saturdays at the office with his father, or as a possible self that is like his father, or as the skill/virtue of courage he practiced in emulation of his father? Or all these together? Or of some at one time, and others at other times? There is evidence in the interview for all of these. Each of these conceptions would likely tap something about the importance of his father, about the role his father played in his life and his particular moral self-­concept. Some aspects might be more relevant than others, depending on the idiosyncratic way the exemplar thought about his father’s influence. And the best way to conceive of the father’s influence for this exemplar may not work at all for some other person with some other influence from some other family member. This is a theme we visited regarding trait and virtue theory in Chapter 4. Conceptions of moral identity or other variables that work well across a range of people are tapping something similar and s work to predict behavior because of it. But they are likely not describing the particular way each individual experiences the world or thinks and feels about moral issues. of Most of those who do work in moral identity recognize this richness, and see their conceptualizations and measurement instruments as useful tools to tap something about moral identity, but not as definitive of all the ways moral identity operates or is experienced by the individual (e.g. Aquino & Reed, 2002, p. 1424; Narvaez et al., 2006, p. 982).16 ro 5.2.2 The Self is Variable Over Time lP There is great complexity within the web of self-­relevant memories, descriptions, scripts, roles, etc. of how we represent our selves to ourselves. This multiplicity of self-­identity is likely gradually developed over childhood, increasing in complexity as the child’s social world expands (Amiot et al., 2007). In this process, the self-­concept becomes more and more multidimensional as its cognitive and emotional capacities to represent and interact na with this complexity develop (Amiot et al., 2007). This differentiation of the (moral) self is influenced by, at least, parenting style (Hardy et al., 2010) and community context (Hart, 2005a; Hart & Carlo, 2005). As they develop, the multiple aspects of the self become more complex, varying in their interdependence, and in their overlapping attributes, narratives, themes, and emotional resonance (McConnell, 2010). Fi Coherence or consistency is often (though not always) imposed by the life narrative into which the individual retrospectively incorporates past, present, and possible future selves (McAdams, 2006). And these narratives themselves have implications for desired future behavior. But the expected consistencies may be limited. In our interviews of moral exemplars in computing we found some respondents insisted on integrating their family life into their stories, and others were perfectly willing to speak of their professional activity as though it was entirely independent of other aspects of their life (Huff & Barnard, 2009). 16 See Frimer and Walker (2008) and Lapsley (2008) for reviews of how the moral self is measured. Though it does appear that each of the many measures is predictive of moral action, there is not yet enough in common among them to determine what is important and what is peripheral in these approaches and their concomitant measures. This is perhaps because the ways that morality can be integrated into the self-­concept are legion. Moral Identity and the Self 121 5.2.3 The Self is Often Domain Specific Situational influence can make some aspects of this web of meaning more relevant at one time than another. And though there are internal pressures for consistency, our sense of self is “highly differentiated and domain specific” (Lapsley, 2008, p. 46) and significantly influenced by our social surroundings (McConnell, 2010). Thus, the self we show up with in any situation may be slightly different depending upon the significance of that situation for us and upon the centrality of internal pressures for consistency in the moral domain, across situations. But we are not simply trapped by the situation: the influence is reciprocal. We often choose the situations we are in, in order to match our sense of self, and we can choose to influence those situations if there is some mismatch (Huff et al., 2008b; Killen & Dahl, 2021; Lapsley & Narvaez, 2004; McConnell, 2010). s One type of situational variation in the self that has received significant attention is variation based on social relations and community. We interact with many different of individuals over time, and each sees a slightly different aspect of who we are (Andersen & Chen, 2002). Simply put, we show different selves, or different aspects of the self, to different others. We are, at various times, mother, teacher, friend, mentor, child, team member. Our interactions, or imagined interactions, with others can call out ro different interpersonal patterns of affect, belief, motivation, self-­reflection, and self-­ regulation (Aquino, McFerran, & Laven, 2011; McConnell, 2010; Rusbult et al., 2009). This psychological grounding in schemas based on past experience in relationships is in fact what Bowlby and Ainsworth had originally proposed as the lP central mechanism in attachment (Bretherton, 1992). However, we need not limit the dimensional variation in our selves to individual relations. We know that even in an individualistic culture, people vary in the extent to which they see their connections with others as significant aspects of the self and that seeing one’s self as socially connected influences compassion and socially responsible na behavior (Cojuharenco, Cornelissen, & Karelaia, 2016; Cross, Bacon, & Morris, 2000; Day & Impett, 2018; Vignoles, 2017). Snyder and Omoto (2008) note the importance of simple group membership in supporting volunteering, and how motivation for helping can change depending upon whether one is helping in-­group or out-­ group members. For instance, in a series of studies, Stürmer and Snyder (2010) Fi showed that individuals helped members of in-­groups because of empathy but they helped members of out-­groups because they were attractive or had some social value. There is evidence that moral identity can widen one’s “circle of moral regard” (Aquino et al., 2006; Reed & Aquino, 2003). This is reminiscent of the work of the Oliners (Oliner & Oliner, 1988) who showed that those who helped Jews and others escape the Holocaust had a much wider view of who “us” was, a view that included those being victimized. We show a different moral face to those who are “them” than we do to those who are “us.” One might have great integrity about justice and care for those we include in the deserving community, while being callous and uncaring for those “other people.” Susan Opotow explores this dynamic under the label “moral inclusion/exclusion.” She has reviewed how moral exclusion is constructed in a moral ecology (Opotow, 2001) and how programs stressing moral inclusion can have their effects in reducing violence and injustice (Opotow, 2005). Moral tightening and loosening describes the ways these impulses can change in a culture over time in response to Taking Moral Action challenges like scarcity or external threat (Gelfand, 2021). This moral exclusion is one of the crucial steps in the staircase to terrorism (Moghaddam, 2005; Moghaddam, Warren, & Love, 2014). Our moral ecology interacts with our moral identity in other ways than the us– them dynamic of moral inclusion. Participation within a community actually helps to construct our sense of self. In a longitudinal study of high school students, Pratt et al. (2003) found that self-­ideal (measured by self-­report of traits one strives for, such as being a good citizen, fair, just, caring) predicted community involvement, but over time it was community involvement that led to increases of these self-­ideal traits. Thus, active participation in community can produce a virtuous cycle of self-­ascription of traits, followed by further community service. Hart (2005a, p. 260) argues: “If the notion of identity is to contribute to an understanding of moral functioning, then it must be a construct with deep roots in a social world.” These roots will need to be s both deep and specific to each individual and his or her personal history and moral ecology. Piliavin and colleagues (Grube & Piliavin, 2000; Piliavin & Callero, 1991) of have shown the importance of “specific role identity” (as, e.g. a blood donor or a cancer society volunteer) in supporting volunteer activity. Rule and Bebeau (2005) and Huff and Barnard (2009) have also tracked the importance of specific identity themes in professions. ro So, the “deep social roots” of the self, and thus of the moral self, may well be quite specific, not easily susceptible to consistency pressures across domains, and may not reach across roles or domains to influence moral behavior in other contexts. In this way, the specificity and multidimensionality of the self can become a threat to preslP sures of consistency across domains; or what in moral language is often called integrity. To investigate this issue, we will need to ask how consistency pressures, or pressures toward integrity, operate in the multidimensional self. na 5.3 How Does the Moral Self-­Concept Influence Action? Supposedly, moral identity influences moral action in that the more that moral ideals/ values/models/narratives/etc. are integrated into the self-­concept, the more individuals’ moral actions are motivated and structured by that moral identity. Chapter 9 traces Fi this integration. We mention it here to remind us that these moral identity models are designed to solve the problem of the judgment–action gap discussed earlier. One important thing to note is that the empirical gap is less broad than often thought. Blasi’s (1980) review and several subsequent ones (Frimer & Walker, 2008; Jennings, Mitchell, & Hannah, 2015; Lapsley, 2008; Lapsley & Narvaez, 2005) have established a moderate relationship between moral identity and action, particularly when the action is seen as self-­relevant (Reynolds & Ceranic, 2007). This helps us to see the judgment–action gap as something that, from the perspective of the self, is only consequential when the judgment and the action conflict with each other in ways the self judges to be relevant.17 17 One can, of course, disagree with someone about whether an action is relevant, and even question one’s own actions or integrity. This process makes judgments of relevance central to understanding integrity. Moral Identity and the Self 123 Still, the self that is supposed to drive moral action has been revealed to be multidimensional, variable, and domain specific. One can see this as fragmentation of the self (Gergen, 2000), which makes the gap wider, or at least deprives the actor of a strong incentive toward unity of judgment and action. When judgments of relevance can splinter along lines of domain, situation, and aspects of the self, there seems to be little in the model that pushes for unity or integrity. The unity of the moral self might thus dissolve into a postmodern mash of singular, conveniently changed, isolated hopes, urges, and defenses (Frimer & Walker, 2008, p. 344) with no central organizing principle to provide internal consistency or integrity. Alternatively, one can see the multidimensionality as authentic adaptation to the complexity of life, in which aspects of the moral self cleave the social world based on its different moral ecologies. In this view, some variation in response to situational s difference might be respectable and even expected (Shoda et al., 2002). Domain limitations on moral action may well be the result of what existentialists call the need of to reconcile life’s unavoidable contradictions. And it may be that a well-­developed moral identity allows for thoughtful movement between moral ecologies, or the careful integration of values one might think are opposed (see the concept of integration in Section 5.3.1.1 and the concept of self-­transcendence in Chapter 9). One ro might then think of moral identity as less a moral straitjacket and more a well-­ coordinated wardrobe of clothes. It may best be thought of as integrating the moral tensions we experience in the many domains of our life rather than simply serving as a bulwark against failure. lP This review of the multidimensionality of the (moral) self should lead us to be careful in framing any demand for moral consistency, integrity, or unity. There are at least two issues here: when we speak of a drive toward consistency what items need to be consistent with each other, and how (in what way) are these items consistent? na 5.3.1 Two Forms of Moral Integrity What are the aspects of our self that we are longing to have consistent or to show integrity? Blasi (2005) provides a suggestion by outlining two kinds of self-­integrity: identity integrity (internal coherence among ideals, principles, values, and other Fi aspects of self-­conception) and behavioral integrity (coherence of external behavior with internal conceptions). 5.3.1.1 Identity Integrity Identity integrity is the postmodern puzzle we have been reviewing. To what extent is the conception of self across domains and values integrated? We have seen that there is ample evidence that most individuals’ self-­ conception varies across domains and with situations. There is evidence from Schwartz’s (2016, 1987) cross-­cultural work in values that there is even a fundamental incompatibility built into the structure of the way we think about values. In his well-­ validated circumplex model, values are arranged in a circle, with proximity on the circle representing how compatible they are in terms of the extent to which people report adherence to them. For instance, the values of benevolence and universalism lie next to each other, while power assertion and individual achievement lie next to each other on the opposite side of the circle (see Figure 3.1 in Chapter 3). This Taking Moral Action opposition of values to each other suggests that integrity among one’s values will be a difficult achievement. However, Walker, Frimer, and colleagues (Frimer & Walker, 2008; Frimer et al., 2011; Walker & Frimer, 2015) provide evidence that it is the integration of some of these supposedly opposing values that especially marks moral identity integrity and that also predicts moral behavior. In their reconciliation model, they identify people for whom agency (an individualistic value) and communion (a moral value of benevolence and universalism) co-­occur. These peoples’ agency is centered on communion with others, thus reconciling the supposed tension between them. Their defining moral goals are both agentic and centered on others. Here is an example they provide from an interview (Frimer & Walker, 2009, p. 1678): In any action we take, in any choice we make, we can have a positive or negative impact on the world … In terms of good habits, treating all people with dignity and respect regardless s of their situation in life or how similar or different they may be of This dedication of the (agentic) choosing self to (communal) others, provides a theme of unity in the moral self that can guide moral behavior. We review the evidence for this unity in Chapter 9, Section 9.3.1.1. ro 5.3.1.2 Behavioral Integrity: Or How to Overcome the Judgment–Action Gap The judgment–action gap we have documented in this and other chapters is precisely the issue of behavioral integrity: the extent to which external behavior coheres with lP internal commitments (Blasi, 1980). We know this gap exists and can document some of the processes that narrow it. But where can we find an impetus toward more behavioral integrity? There needs to be some perceived inconsistency between one’s behavior and something internal for there to be some motivation to reduce it. What is the internal aspect that serves as a reference point? We present here a variety of na candidates, and each one may, under some circumstances, be the aspect that drives the perception of consistency or inconsistency in behavior: • Principle. Consistency with a principle was proposed as the motivating factor by Kohlberg (1958, 1971). Whether this is one all-­encompassing principle or a set of Fi principles is unclear, even in later versions of the theory (Kohlberg, Levine, & Hewer, 1983). However, it reappears in our discussion in Chapter 9 of the idea of a higher goal or telos that reorganizes our values.18 • Self-­concept or identity. Blasi’s (1980, 1984, 2005) influential work suggests that what gives a perception of consistency-­motivating force is when the behavior is seen as consistent or not with one’s understanding of who one is, one’s moral self-­ concept. We have reviewed this literature in this chapter. • Self-­within-­context. Several authors have argued that a sense of responsibility or obligation does not arise out of a simple consistency pressure of behavior with self-­ concept, but from self-­concept within social systems that constitute one’s social 18 We should note that this higher goal need not appear phenomenologically to the moral actor as a principle. It could show up in any of a variety of guises. In Section 5.2.1 we give an example of how the influence of a father might be integrated into the moral self in many ways. Moral Identity and the Self 125 and cultural relations (Haidt, 2001; Hart, Atkins, & Southerland, 2006; Hart & Matsuba, 2009; Markus & Kitayama, 2010; Power, 2004). Cultural meanings and social surround help to identify those aspects of the self that are the most relevant to determining behavioral integrity in any context. This is an expansive definition of the self, and one that challenges the simple dichotomy of person vs. situation. • Emotion. An emotion has a natural action tendency (Arnold, 1960; Ellsworth, 2013), hence an action or a lack of action can be inconsistent with this action tendency.19 A variety of researchers have identified moral emotions as containing the kind of motivational power that can drive behavioral integrity (Haidt, 2001, 2003; Oliner & Oliner, 1988; Tangney, Stuewig, & Mashek, 2007). This is in part because the process of “having” an emotion involves a judgment of the relevance of some occurrence to the self. So, one can treat emotions as a separate source of behavioral integrity or as one process through which judgments of self-­relevance have their s effect. of There is empirical support for all four of these reference points to serve as the contrasting pole that produces pressures for behavioral consistency, or behavioral integrity. Rather than being alternative explanations, it may well be that they act ro independently or in concert. There is simply not enough theory or data to allow more than speculation about when or how each might have influence. 5.3.2 How Are These Aspects Consistent? lP What do we mean when we say that some action is inconsistent with some standard? What kind of comparison for consistency are we making? In almost all the psychological literature, the default understanding of consistency has been logical consistency. Logical entailment has been used as the measure of moral consistency in part because it is most suited to the project of finding a logically consistent and unquestionable na foundation for our sense of right and wrong.20 In our later list of “ways of being ­consistent”, logical consistency stands out because it seems simultaneously to answer questions about how we make moral judgments and whether those judgments are ultimately justified. It was for this reason that Kohlberg (1958) adopted the logical consistency criterion (Lapsley & Narvaez, 2005). Fi None of the other kinds of consistency are “foundational” in this way. They are much more attempts to simply describe how people make consistency judgments, or “feel” that things are inconsistent. Though they cannot offer a logical connection to a principled position, they can still differentiate among better and worse or more and less in the amount of consistency. And so, they can still provide for some motivation to increase consistency. 19 See Chapter 8 for more detail. 20 See Rudd (2007) on narrative consistency not being logical consistency or suitable for a foundationalist approach. See also Chapter 7 for Lawrence Kohlberg’s long, foundationalist battle against relativism. Taking Moral Action • Logical entailment.21 Consistency defined as logical entailment seems to set up a dimension on which more is always better. Colby and Damon (1992) talk about their moral exemplars often striving to broaden and deepen their moral commitments over the life span. Frimer and Walker (2008, p. 349) suggest that the attainment of complete logical consistency of moral motives within and across all domains and action is “a practical impossibility.”22 It may even be paradoxical, not least because it can itself distract from the goal of striving for the good. • Moral ledger. But there is a less demanding interpretation proposed by Nisan (1991) as a “moral ledger.” Nisan provides evidence that people trade off moral credits and debits and seem satisfied when the overall balance is above some positive threshold. This relaxed approach allows, of course, for its own kind of abuse in moral licensing, the belief that having done something good can then entitle one to be more lax in other areas (Conway & Peetz, 2012; Monin & Miller, 2001). s • Emotional consistency. Emotional experiences such as elevation (Algoe & Haidt, 2009; Haidt, 2000; Vianello, Galliani, & Haidt, 2010), empathy (Oliner & of Oliner, 1988; Preston & de Waal, 2002; Tangney et al., 2007), and compassion (Goetz, Keltner, & Simon-­Thomas, 2010; Oveis, Horberg, & Keltner, 2010; Stellar & Keltner, 2014) produce motivations to do good. We will explore the nature of these motivations in Chapter 8, but they can be signals that something is ro out of balance and needs to be corrected or is approaching balance and should be pursued. In addition, they can be cultivated: one can learn to be more (or less) emotionally sensitive (Weng et al., 2013; Wong, 2015) and can make this emotional development a goal (Koole, 2009; Koole & Veenstra, 2015; Kuhl & lP Koole, 2004). • Social consistency. We have already reviewed the work on the self as embedded in culture and situation. Rather than simply viewing this as a corrupting influence (from the perspective of logical entailment) one can also see it as social influence toward consistency and integrity. Colby and Damon (1992) recount numerous na instances in which it was social influence that led their exemplars into deeper ­commitment to causes, or to widen the horizon of their concern. The consistency pressures here can be thought of as mutual social influence in a way that greatly enhances the social aspect of Haidt’s (2001) social intuitionist model. By sharing their moral reactions, people mutually influence each other’s intuitions about the good. Fi • Instrumental consistency. Work on moral exemplars (Colby & Damon, 1992; Huff & Barnard, 2009; Plaisance, 2014) suggests that many view their commitments as moral projects, and evaluate their actions based, at least in part, on how they are compatible with achieving their moral goal. This has the problematic aspect that one might choose immoral methods to attain a moral goal (Hart, 2005b; 21 We use “logical entailment” here to mean what philosophers Beall and Restall (2019) refer to as “the relation between premises and conclusions in valid arguments” and call “logical consequence.” Exactly what this means is, of course, a matter of dispute and Beall and Restall review that dispute. 22 This practical impossibility in the face of the demand for complete consistency is related to the sense of inadequacy in the face of the infinite ideal (e.g. the highest good) that has been puzzled over from ancient times to Kierkegaard and beyond. It is also found in Reinhold Niebuhr’s reflections on the “impossible possibility” (Niebuhr, 1935, chapter 7). Moral Identity and the Self 127 Skitka, 2010; Skitka & Mullen, 2002). Not all examples of this expediency are negative. The theologian Bonhoffer’s participation in a plot to assassinate Hitler and Nathaniel Borenstein’s decision to consult for the military are two examples that are arguably positive. But it may nonetheless describe the nature of the motivational process behind many goal-­driven moral actions. It seems quite similar to what we call in Chapter 9 self-­transcendence, when the self transcends not only one’s goals but also ethical convictions toward a higher calling in a certain place and time. • Narrative consistency. Many theorists are now exploring the role of narrative in psychological functioning. Narratives have a structure and unity that is not univocal, in the way that logical entailment must be, but is instead “polyphonic” (McAdams, 2006, 2009), with multiple threads sometimes competing, sometimes cooperating. The telling of narratives serves a variety of purposes, some of s them centrally moral (McAdams, 2009; McAdams & Pals, 2006; Tappan & Brown, 1989). All people tell narratives for social-­bonding purposes, but people of also tell stories to direct and guide their future behavior and to establish and maintain self-­continuity (Bluck et al., 2005; De Silveira & Habermas, 2011; Habermas, 2011; Rasmussen & Habermas, 2011). These latter two purposes are both in part moral and can be thought of as relating to behavioral integrity and ro identity integrity respectively. Frimer and Walker (2009) have shown that it is just this kind of narrative unity between the opposing themes of benevolence/ universalism and power assertion/achievement that predict successful moral action. Thus, narrative consistency can provide a sense of continuity, psychologilP cal pressures to consistency, and motivation to act, while being more flexible than simple logical entailment consistency. We now have a quite complex picture of what it might mean to say one has integrity within one’s moral identity by achieving consistency between some moral referna ence point and one’s (im)moral behavior. Table 5.1 gives a picture of that complexity.23 Rows show various kinds of reference points (e.g. a principle) and columns show how each might be compared with an action. There are four different kinds of reference points and a variety of modes of consistency.24 The cells contain interpretations of what might psychologically be happening to produce consistency pressure in an actor Fi within that cell.25 For instance, where self-­in-­context and emotional consistency intersect, an actor might ask, “Is my emotion/motivation for this action consistent with my role as a doctor/daughter/feminist?” Or where principle and emotional consistency intersect, they might ask, “Is my emotion/motivation for this action consistent 23 Cervone (2021) provides a somewhat simpler overview of five ways one can construe personality coherence: (1) belief-­based; (2) goal-­based; (3) evaluative standards-­based; (4) intra-­psychic (interrelations among personality systems); and (5) phenomenological. These could be used to add even more (and perhaps fatal) complexity to this approach. 24 More or fewer might be imagined. See Cervone (2021) for a recent parallel proposal of different aspects of thinking about personality consistency. 25 We leave filling in the cells, and offering alternative interpretations of what a cell might mean, as an exercise for the reader. The rows and columns are not comprehensive and may need to be tailored to reflect the particular background of any individual. Taking Moral Action with a principle of respect for others?” One can easily take advantage of this large array of possible self-­reflections to find the most convenient comparison for one’s purposes, or one could take the time and resources to look for a more global kind of consistency. Consistency among the rows in Table 5.1 might be called identity integrity. But bridging the gap, or behavioral consistency is what happens in each cell. A person who feels no pressure for consistency among the various kinds of judgments in the cells, or chooses them based on convenience, can be what the philosopher Frankfurt (1971, p. 11) calls a “wanton.” How much consistency is enough? The philosopher Schwitzgebel (2019) makes a data-­based case that something like a B+ is the criterion most well intentioned people have. However, there is little research on this and how it might be modified by ­culture, domain, moral identity, etc. It is likely that moral exemplars, at least in the s relevant domain, have a higher standard. And it is possible also to dissociate some particular performance of, say, dishonesty, in a domain as a role-­excused “free trait” of that does not count against overall feelings of personal integrity (Schmidt & Poole, 2020). Doing this well, of course, requires skills like self-­reflection, emotional regulation, and moral imagination, which we cover in Chapter 6. It also requires appropriate, or ro at least a modest, commitment to some values or norms as discussed in Chapter 9, Section 9.3. And with the appropriate skills, norms, etc. one can reflectively assess the various consistencies in Table 5.1 to approach a social–emotional reflective equilibrium26 that we describe in Chapter 8. Here lies the trap described at the beginning of lP the chapter by the Apostle Paul: there are many ways to fall off the path. Many of these approaches to moral consistency come with a price: they open the process up to other motives (Cervone & Tripathi, 2009; Frimer & Walker, 2008) than the balanced consistency we describe as social–emotional reflective equilibrium. Many authors view this as a serious liability (Blasi, 1999, 2009; Kohlberg, 1963; na Walker & Frimer, 2009). If consistency with moral principles is only one of many possible motives for moral action, then one is faced with diluting the drive to unity and the value of integrity, and we may be left with a fragmented moral sense. Whether the moral sense is – in fact and in lived experience – fragmented and cobbled together or carefully constructed as a polyphonic narrative is in the end an empirical question – Fi but one with significant implications for judgments about morality. 5.3.3 If Moral Evaluation is So Complex, Can We Ever Hold Each Other Accountable? A robust societal morality requires that we be able to hold each other responsible for our actions. The seductive call of logical consistency accounts is that they provide us with firm ground on which to make judgments of accountability. But one does not 26 One can easily imagine what social–emotional reflective equilibrium consists of by simply scanning the types of consistency in Table 5.1. We describe it in other chapters as a process for mature, or expert, moral action. This is what might count as a more global kind of consistency, integrating the table. .INDD 129 Fi Table 5.1 The variety of moral consistencies. Mode of Comparison: In what way is the action being compared with the reference point? na Logical Moral Ledger Emotional Social Instrumental Narrative Reference Point: What is being compared with Principle/ Action Emotion of action Action matches Action achieves Value matches is based in values of valued goal? principle? principle? others/roles? Moral Action changes Action matches Action matches Action fits in lP Identity positive balance personal professional story of moral of identity? character based identity? identity? the action? on others/roles? Self-­in-­ Action changes Emotion of action Action matches Action achieves Action fits in Moral Identity and the Self Context positive balance matches important important moral goal shared story of self in of identity in others/roles? others/roles? with others or of context? ro context? role? Emotion Emotion of Action matches Action achieves Action fits with action current emotion? emotional goal? emotional tone matches of personal of preferred narrative? emotion? s 129 07-13-2023 10:01:55 130 Taking Moral Action need strict logical consistency in interpersonal relationships to have influence. We can still hold each other accountable for our actions “so long as there exists an agentic, unifying process [that] attempt[s] to mend inconsistency and [has] some (incomplete) success” (Frimer & Walker, 2008, p. 346).27 Each of the modes of comparison in Table 5.1 have ways of evaluating consistency, and all are subject to dispute. But they all share at least a modest impulse to consistency between the reference point and the action and some shared ground for recognizing and debating that impulse. Where might this drive for unity come from? First, there is a kind of logic within each mode of evaluation. Second, we review in Chapter 3 ways that the social surround might support the internal logic in each mode. Third, Weinstein, Przybylski, and Ryan (2013) propose three integrative characteristics of self-­ regulation that ­support the unifying processes: (1) conscious access to one’s emotions, motivations and values; (2) taking responsibility for one’s emotions, decisions, and thoughts; and s (3) non-­defensiveness in response to challenge. None of these sound (or are) easy, since they often involve an honest response to failure. But they involve skills that can of be learned (as we discuss in Chapter 6). 5.4 Critiques of the Moral Self ro There is a clear case to be made for the importance of moral identity in moral action. But the concept is not without its critics. We have mentioned earlier the complaint of Nucci (2004) that many models of moral identity are too simplistic, and we have seen lP that there are multidimensional models that respond to this complaint (Amiot et al., 2007; Hart & Carlo, 2005; McConnell, 2010; Reed & Bolton, 2005). But in his wide-­ranging critique of the moral self-­construct, Nucci (2004) is also worried that some models of moral identity essentially reduce morality to a sort of moral egoism: “I do it because I want to.” Frimer and Walker (2008, p. 352) aptly respond that na this is only a problem to the extent that the moral identity is conceived to be the only operating factor. There is evidence, for instance, of a variety of influences on volunteering, including wanting to have a particular experience or collect a line on one’s vita (Snyder & Omoto, 2008). But this is rarely the only influence, and even when it is, it might over time be transformed into other motivations (Hart & Matsuba, 2007). Fi Once one includes moral reasoning, moral emotion, embeddedness in a moral ecology, or other influences, then we are back to a model of balancing influences. In addition, if moral exemplars’ moral identities are centered on helping others, one must accuse them of a particularly complex and cynical sort of egoism that includes helping others as a façade for mere self-­enhancement (Badhwar, 1993). There seems little evidence to support this contorted critique. 27 It is this issue of whether our moral psychology allows us to insist on accountability or responsibility that is the central motivation behind Kohlberg’s and others’ insistence on a non-­relativist moral psychology (Blasi, 2009; Kohlberg, 1958). The approach in this chapter certainly could be relativist, but the “modest drive to unity” is, we think, at least equally compatible with an approach called pluralism (Flanagan, Sarkissian, & Wong, 2008), which avoids the radical relativist abandonment of any standard. Moral Identity and the Self 131 A more problematic critique is that the role of individual moral identity may vary dramatically by culture (Cervone & Tripathi, 2009; Miller, Goyal, & Wice, 2017). The self is constituted differently in different cultures (Markus & Kitayama, 2010) and even at different levels of social status in the United States (Bowman, Kitayama, & Nisbett, 2009). Individuals in India, for instance, view not helping others as a moral failing regardless of the relationship with the other, while Americans see this as a moral issue only for close others (Miller, Bersoff, & Harwood, 1990) – a distinction that maps onto cultural differences in how embedded the self in each culture is in social networks (Markus & Kitayama, 2010). In reviewing three decades of research on the self and culture, Markus and Kitayama (2010, p. 421) note that “the study of culture and self has led to the realization that people and their sociocultural worlds are not separate from one another. Instead they require each other and complete one another… . one cannot be a self by one’s self.” This makes it clear that the issue is s not whether the self is involved in moral action in Indian or other collectivist cultures but how the self is differently construed and constructed, and how it contributes to of moral action in different cultures. Thus, this criticism of the cultural inconsistency of moral identity effects can be recast as an invitation to explore the different ways that moral identity acts in different cultures, depending on how the self is construed in those cultures. ro Another critique of the self as a key aspect of moral action comes from work by those who claim the self’s primary function in the psyche is to “facilitate people’s social interactions and relationships” (Leary, 2007, p. 317).28 This might be viewed as a “selfish” motivation of self-­enhancement or social accommodation: The self lP experiences “moral” emotions and acts on them merely to achieve social status or success. But this is a narrow view of Leary’s sociometer approach and it does not take into account the seemingly other-­ centered focus of moral emotions (Aktipis & Kurzban, 2004). It also confuses two levels of explanation, the ultimate (evolutionary) and the proximate (motivational) (Preston & de Waal, 2002) – it is one thing to na say that the self supports moral behavior “to facilitate relationships” at an evolutionary level, and quite another to claim that the experience of the motivation to be moral is primarily based in the desire to have better relationships. A final critique stems from the cross-­cultural finding that traditional approaches to spiritual growth almost uniformly speak of denying the self, or the death of, or Fi ­non-­existence of the self as a necessary (and continual) aspect of becoming a whole, or virtuous, person (see Augustine, 1986 for an analysis in Christian, Buddhist, and Hindu monasticism). The Christian monastic Merton (2009) suggests that moral formation has to do with a life-­long transformation of the self, which does not leave the self fully behind but rather transforms it from a mere egocentric self to what he calls the “true self.” This claim has a long religious, and specifically monastic, history (Merton, 2009) and can be found across many religious expressions (Shulman & Stroumsa, 2002). On its face, this emphasis on self-­denial seems a direct contradiction to the sense of self as the motivator of action that we have found in this chapter. 28 Note that in Table 5.1, there is a column that is primarily driven by consistency pressures from important others and social roles. The table thus incorporates this critique as a kind of consistency. Taking Moral Action If, as monastic language would have it, one must become detached from the self, how can this motivate moral action? There are two clues in psychological theory that may help us here. First, among his later theoretical formulations of the hierarchy of needs, Maslow differentiated the highest level of self-­actualization into two parts: self-­actualization and self-­transcendence. Self-­ transcendence involves “seek[ing] a benefit beyond the purely personal and seek[ing] communion with the transcendent … com[ing] to identify with something greater than the purely individual self, often engaging in service to others” (Koltko-­Rivera, 2006, p. 306). Thus, in self-­ transcendence, one seeks something beyond self-­interest, and this becomes more important than, or possibly identified with, self-­interest. One might find this happening in several of the examples with which we began this book: The Munsons moved from taking in disabled foster children to founding a social service facility for disabled children; the Mothers of the Plaza de Mayo moving from concern for their child to s larger social and political goals; and Thomas Merton seeking to transform the self in search of God and thereby becoming a peace advocate.29 of A second approach that shares the pattern of de-­emphasizing the self comes from the research program of Walker and Frimer (2015). They and their colleagues have done extensive work on moral exemplars using both quantitative and qualitative methods. They describe their moral exemplars as having connected the good of othro ers, or of some ideal, to the central moral concern of self and view this as an integration of two values, with one (self-­agency) becoming an instrumental path to achieving the other (communion).30 We should be careful not to assume a harmony among these approaches. The lP monastic approach emphasizes more detachment from the self than do the other two models, and it includes vast variation among different monastic traditions in different religions as well as non-­religious forms of spirituality. Maslow seems to find self-­ transcendence attaching to a wide range of transcendent objects, as opposed to the other two approaches. And Walker and Frimer (2015) seem to view the process as a na natural developmental path for most people, while for Maslow and the monastic approach this achievement seems more exceptional, in some traditions only truly achieved as a rare form of enlightenment. But all agree that there is a path to moral action that involves some form of decentering or transforming the self. We will explore this path in detail in Chapter 9. Fi 5.5 Discussion 5.5.1 Conclusion 1. The integration of morality into the self is important in moral action. Many research programs and theoretical models point to the importance of moral identity, the integration of morality into the self, as serving an important role in 29 There is a dark side to self-­transcendence (Koltko-­Rivera, 2006; Skitka & Mullen, 2002) so that simple self-­transcendence cannot serve as a marker of morality per se. 30 Again, see Chapter 9 for an introduction to the Walker and Frimer (2015) research program and a reprise of this discussion. Moral Identity and the Self 133 the springs of moral action. There are regular, moderate-­to-­strong effects of moral identity in shaping moral behavior, particularly when one matches the situation and behavior to the specific commitments of moral identity. The importance of matching the situation and behavior to specific commitments is parallel in structure to the patterns we found in Chapter 4. Indeed, they are likely the same findings, as the measures used in personality are probably tapping aspects of moral identity. There is, then, mounting and converging evidence that moral identity plays a crucial part in the processes that initiate, regulate, and maintain (or derail, degrade, and misdirect) moral action. Moral identity is not, of course, all that influences moral action, as the other chapters in this text will attest. There are likely kinds of moral action that are somewhat unrelated to moral identity (e.g. habitual action – see Chapter 6). But moral identity is a prime candidate for playing a central role in much moral action. s 2. The moral self is multidimensional and variable over time and domains. The multidimensionality of the moral self suggests that there is no single “bridge” of across a single “gap.” As the table of moral consistencies (Table 5.1) shows, there are multiple reference points (rows) against which one might judge a moral action, and then multiple modes (columns) in which this action might be interpreted in light of the reference point. The bridge and gap metaphor portrays an isolated ro individual vainly straining to overcome a gap between ideals and action, a gap that should not be there but constantly haunts the reflective actor (as the Apostle Paul was haunted). But it is far more complicated than this, and perhaps less dire. There is not one single value but a pluralism of values. And the values may be represented lP in a variety of ways in the complexity of the self and its representations of the moral ecology. Different aspects of the self become relevant as one navigates the moral ecology, and the self develops and changes over time as a result of these interactions and the ways they are evaluated. Finally, self-­reflection, the skill of evaluating the fit of one’s action to one’s moral identity is itself legion in its modes. In this na complex landscape, one should not be haunted by gaps but instead encouraged by woven networks of consistency that endure across the complexities of the moral ecology, of the self, and of self-­reflection (see Chapters 6 and 9). 3. Self-­reflection as a guide for moral action is very flexible. From the standpoint of behavioral integrity, this is both a feature and a bug. Fi The multitude of reference points and modes of comparison make the self-­ reflection process very flexible: a positive feature given the complexity of our moral ecologies and of how we think of our selves. It provides for coherence balanced by flexibility in how we adapt our selves to the complexities of human life. However, one can see this flexibility as providing too many opportunities for self-­serving interpretations of one’s actions. Chapter 7 provides an overview of some of the ways we use reason to construct consistencies that allow us to excuse or support immorality. What then supports the impetus for consistency in moral action that comes from self-­reflection? We argue in this text that many influences (moral ecology, personality, skill) can do so. There is clear evidence that moral identity does not need to act alone. One person’s fragile network of self-­reflections in the table might spin apart as a result of a moral ecology of corruption. Or one can imagine the web of consistencies beginning to come together in a moral ecology that favors particular consistencies, such as restorative justice hearings. Of course, most moral Taking Moral Action ecologies contain both integrative and disintegrative influences (e.g. the complexity of a NATO study panel on nuclear technology). Still, one can likely cobble together a modest drive to unity from a wide variety of both internal and external influences. This is likely how most friendships, families, organizations, and societies survive. 4. A modest drive to unity may be enough to support consistent moral action. Moral identity is an important, and even crucial, influence on moral action. But it is rarely the moral hero standing alone in the gap. It provides internal resources for moral action when, because of its relevance in the situation, and sometimes despite the situation, it is called upon by individuals. But it is not always called upon, or it may often be called upon in different forms: the moral identity one has at work may be different from the one most prominent at home. Is consistency among this complexity a vain hope? We think not. There is ample evidence s of moral exemplars in a wide range of areas who are thoughtful and mostly consistent in moral action. Moral identity seems to play a central role in their action. of We have also reviewed here evidence that variation in moral identity is clearly associated with variations in moral action. So, the mere complexity of the task facing us is not cause for despair. As Frimer and Walker (2008, p. 346) argue, even a modest drive to unity, aided by self-­reflection, may be all we need. But the ro complexity is a caution that we need a better understanding of the task before us. We might instead, reconfigure the metaphor of “bridging the gap” into one of maintaining an ever-­changing network or weave of moral commitments and action. Who is the weaver? In Chapter 9, we argue that it is an active but not lP omnipotent moral self, navigating the world in response to a range of needs, constraints, and moral goals. 5.5.2 Application na “All I knew was that I wanted grace, and that I needed prayer, and that I was helpless without God, and that I wanted to do everything that people did to keep close to him” (Merton, 1948/1998, p. 329). This quote comes from Merton’s autobiography and is included in the first chapter of this book. It is a very personal description of his reasons for joining a monastic order. At least from this report, the entire self is Fi focused on the search for closeness to God. Nothing else matters. Yet Merton became a central figure in the peace movement in the United States in the 1960s. His overwhelming preference was to be a hermit, yet he was rarely allowed this luxury. Instead, he was told by his Abbot to write, since his writing was of such a high quality and so widely sought after. He was so deeply steeped in Christian monastic tradition and practice that even his turn toward those justice issues that were raging at the time (e.g. race and peace) was suffused with symbolism and language from that tradition. In a famous vision he had in 1958, at the center of the Louisville KY shopping district on the corner of Fourth and Walnut, he saw that everyone in the crowd of shoppers had the spark of God in them. “If only everybody could realize this!” he later wrote of this experience, “But it cannot be explained. There is no way of telling people that they are all walking around shining like the sun” (Merton, 1966, pp. 153–154). This mystical language has nothing of human rights or justice language in it, and yet it marks a turning point in Merton’s writing toward issues of justice, race, and ­opposition Moral Identity and the Self 135 to war. It is a complicated matter to explain how this strange language of people “walking around shining like the sun” connects to these moral issues and to Merton’s social activism. But it is at least clear that Merton’s moral action has different roots than a moral identity centered on principled justice reasoning. These roots are uniquely grounded in a specific tradition of language, narrative, and worldview where reform of the self, otherworldly desire for God, and social activism are often closely intertwined. There are consistency pressures within this moral ecology, but they are (often) not ones that valorize the self. One can multiply examples like this endlessly, showing that moral action is connected with a view of “a person like me in a situation like this” but that, from one actor to the next, this view is rarely the same in specific motivation and structure. And yet, at an abstract level, we will find things in this chapter that help us understand Merton’s moral action (e.g. Maslow and self-­transcendence). s 5.5.3 Open Questions of 1. How do people navigate the multiplicities of consistency that the literature suggests? We have concluded that the moral self is multidimensional and variable over time and domains, and that there are many dimensions on which individuals can evaluro ate their own and each other’s behavior. We have also suggested, as in some idiographic personality models, that people will establish complex patterns of moral commitment and moral self-­reflection that will vary within these dimensions of the self and the moral ecology. It is these patterns that should have some modest relalP tionship to moral action. But how do people navigate this complex inner and outer landscape? Do some navigate it better than others? What does consistency look like in this complex landscape – a straitjacket for action or something necessarily more flexible? Are some moral ecologies better at supporting appropriate navigation? What skills and dispositions might help in getting better at navigation? And how na does this navigation relate to moral action? It is in the end an empirical question whether the moral sense is a fragmented collection with no center or a complex weave designed to fit a complex self and environment. 2. What are the different roles of the self in taking moral action in different moral ecologies? Fi How the moral self is constructed and construed, how it relates to cultural values, and how it is evaluated both by the self and others may all vary depending on the moral ecology. The larger cultural surround, organizational culture, and patterns of friendship may interact with each other in shaping moral action and its evaluation. We are beginning to get models of this interactivity of self and cultural surround, but these models have yet to connect to the models and approaches on moral identity, cognition, or emotion in moral psychology. 3. To what extent is the moral self active in maintaining webs of commitment and action? We have suggested it is time to reconfigure the metaphor of “bridging the gap” into one of maintaining an ever-­changing network or web of commitments, self-­ reflection, and action. This reintroduces the self as an active agent in its own moral behavior, thought, and feeling. And it allows us to ask how this activity acts together with the constraints placed upon us given our biological heritage and personality, our skills and habits, and the constraints and opportunities provided Taking Moral Action by our moral ecology. This interaction might have them at one time working together (choosing to follow organizational guidance), working in opposition (choosing to reform or subvert unjust laws), or acting in some complex dialectic (advocating that some praiseworthy voluntary action should be made into a requirement). We sometimes use the metaphor of navigation to think about the complexity here, a metaphor borrowed from Aristotle. When and how do actors monitor the interacting currents and winds of consistency? When and how do they, wittingly or unwittingly, modify their ship or steer against the wind? Are they only sailing alone? 4. How is moral failure integrated into the moral self in a corrective way? We have proposed that there is, indeed, some modest drive to unity in self-­reflection. But it is crucial that this modest drive responds to situations of inconsistency and moral failure. Weinstein et al. (2013) helpfully propose three integrative characters istics of self-­regulation that might support appropriate reflection on moral failure: (1) conscious access to one’s emotions, motivations and values; (2) taking responof sibility for one’s emotions, decisions, and thoughts; and (3) non-­defensiveness in response to challenge. As important as these are, they still leave the moral self isolated in its reflection. In Chapters 3, 6, 8, and 9, we have presented other influences and processes that might be helpful in understanding responses to moral ro failure and in designing small and large environments that are supportive of self-­ reflective response to moral failure. But we need systematic research in response to moral failure to bring the process into sharp focus. lP 5.6 Further Readings These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and na recent work. Complete citations are provided in the references section. • Blasi (1980). “Bridging moral cognition and moral action: A critical review of the literature.” The classic review of the problem of the judgment–action gap and the integration of the self as a helpful solution. Fi • Cervone (2021). “Five paths to personality coherence.” A parallel attempt to construct different aspects of how one evaluates personality coherence, and their interactions with situational context. It suggests the available resources and constraints as individuals search for authenticity. • Frimer and Walker (2009). “Reconciling the self and morality: an empirical model of moral centrality development.” An empirical paper that provides evidence that the relationship between the self’s interests and moral concerns ideally transforms from one of mutual competition to one of synergy. • Weinstein et al. (2013). “The integrative process: New research and future directions.” A guide to aspects of self-­regulation (awareness, ownership, nondefensiveness) that might help in maintaining integrity in evaluation of the self. • Three models of the self that are multidimensional: ◦◦ McGregor and Little (1998). “Personal projects, happiness, and meaning: On doing well and being yourself.” Moral Identity and the Self 137 ◦◦ McConnell (2010). “The multiple self-­ aspects framework: Self-­ concept ­representation and its implications.” ◦◦ Markus and Kitayama (2010) “Cultures and selves: A cycle of mutual constitution.”"
5,5.2,"The Varieties of Self: Or What is Moral Identity? In this section, we will consider the variety of psychological models of the self, conna sidered under three propositions: that the self is multidimensional, variable over time and context, and often domain specific. In the process, these general characteristics of the self will be shown to be true also of the moral self or moral identity, which we define as those aspects of the self that are relevant to moral action. As moral identity Fi 10 Kohlberg founded his psychological system in part on Kantian models of reason as the source of moral judgment (Frimer & Walker, 2008; Lapsley & Narvaez, 2005). However, he mistakes the complexity of Kant’s moral psychology when he claims reason alone should be the source of moral action. In a well-­known footnote in Kant’s (1785/2011, pp. 30–31) Groundwork for the Metaphysics of Morals, Kant bridges the gap between thought and feeling/motivation by treating the feeling of respect or reverence (Achtung) for a principle as both a cognitive and a motivational construct, so that the internal feeling comes not as outside influence but “through a motivation self-­wrought by a rational concept” (durch einen Vernunftbegriff selbstgewirktes Gefühl). Note that “Vernunftbegriff” would be literally translated as “term of reason.” In contrast, Kohlberg sees all emotion as bias and ignores Kant’s subtle moral psychology in favor of a simple rational actor model. 11 This self-­betrayal is analyzed by Sartre (1943/1984) under the label of acting in bad faith. 12 There are models of automatic moral cognition that do not include reference to the self, motivation, or emotion (Sunstein, 2005) and these have a similar judgment–action gap to bridge. Taking Moral Action is used in much of the literature in moral psychology, this is the term we will use interchangeably with the moral self or moral self-­concept.13 5.2.1 The Self is Multidimensional Before the dawn of academic psychology, the Danish theologian Søren Kierkegaard pioneered the phenomenological study of the self. He portrayed the self as a threefold relationship that holds together the physiological, psychological, and theological/normative aspects of a person’s life. Thus, the self is not a thing, or some shadowy substance, or a possession one might have. Instead, it is what one does, an ongoing narrative with which one stitches together past and future, being and becoming, conditions and possibilities. Such a self is seen as an agent of one’s becoming, navigating a continuous and continuously revised set of relations, some imposed by the constraints and tensions of s being human, others freely chosen as a response to those tensions, and all embedded within, or resting on, a narrative about ultimate meaning (Davenport, 2013; Garff, 2013). of In recent personality and social psychology literature, the self has been understood using the more limited metaphor of a cognitive network. This self-­system is a multidimensional network that includes cognitive representations and evaluations of the actual, possible, ideal, future, etc. self (Cervone, 2004; Heatherton, 2011; ro Leary, 2007; Mischel, 2004). Critics of cognitive network approaches have complained that this cognitive bias in models of the self makes them inadequate for understanding our deeply motivating, complex, and evolving self-­representations of who we are (Nucci, 2000, 2004). At one level, this complaint is telling. The rich lP experience of deeply meaningful activity (Colby & Damon, 1992), of social threats to our self-­esteem (DeWall, 2009; Heatherton, 2011), and of personal crises of meaning (Koole, Greenberg, & Pyszczynski, 2006) cannot easily be modeled by a simple network of nodes linking traits that we think apply to us (Aquino & Reed, 2002). However, most approaches do not see self-­networks as such spare furniture in our na psyche. Many approaches link our self-­systems to self-­reflections of competence and esteem (Bandura, 1986; Bandura & Locke, 2003; Heatherton, 2011; Leary, 2007) and thus implicitly or explicitly evoke the emotional commitments that come with a sense of self. Many systems explicitly include emotion in self-­systems: Mischel and colleagues (Mischel, 2004; Shoda, LeeTiernan, & Mischel, 2002; Shoda, Mischel, & Fi Wright, 1994) refer to the “cognitive-­ affective” processing system and Cervone (2004) explores the linkage of knowledge and emotional appraisal in judgments about the self. Other approaches to the moral self see aspects of skilled action (e.g. offering specific kinds of help to others) as highly automatized, scripted, and central to the self (Lapsley & Hill, 2008). Still other approaches see the themes that emerge from public and private narratives of the self as defining of the moral self (Colby & Damon, 1992; Huff, Barnard, & Frey, 2008a, 2008b; McAdams, 2009). All models agree that the networks that make up our moral selves are multidimensional and include cultural and social influence, cognition, emotion, and intuition. And because they are action-­ oriented, they include highly practiced skill 13 One can split many hairs over the differences between these terms. We do not have the space to do so; and we think avoiding it is worth any minor conceptual confusion it might create. Moral Identity and the Self 119 Affiliations & Roles, life tasks, relationships & possible selves Personal contexts Motives & strivings Beliefs, attitudes, Stories & s & values defining memories of Traits & Past behaviors & competencies experiences ro Figure 5.1 A model of some of the components of the self. Source: Adapted from McGregor & Little (1998). lP (McConnell, 2010). It follows that there will be a variety of ways that ideals, values, morality, and moral goals will be integrated into the self. Figure 5.1 is a good example of the variety of ways that self can be constructed. It proposes a set of ways that themes, including moral themes, may be integrated into the self-­concept (to answer the question “What is a person like me?”).14 This “diverse array” (McGregor & Little, 1998, p. 496) of elements includes at least sixteen differna ent types of items ranging from memories of the past to hopes (and fears) for the future, from skills to attitudes to social roles. Items, of course, overlap and it is unlikely that the list is complete. But each of them suggests ways that morally relevant influences might be integrated into the self. For any single individual, a moral commitment to integrity might be experienced as, and be represented in, multiple things. For Fi example, a computer scientist that Huff and Barnard (2009) interviewed in a study on moral expertise spoke of his architect father as an important role model. He noted that his father’s moral integrity was “incredibly influential” in his life.15 As interviewers we were confronted with a host of questions: How shall we talk about or represent this important aspect of this person’s life? We could conceptualize this as a value of 14 We are using “moral identity,” “moral self-­concept,” and “moral self” as synonyms in this chapter. These are aspects of the larger self. Indeed, when people are asked to rate what aspects of the self would most drastically change identity, the moral self appears to be the most important part of the self, surpassing even autobiographical memory (Strohminger & Nichols, 2014). 15 This is from a study of moral exemplars in computing, individuals who were widely known for their commitment to moral causes in the field of computing, selected by a panel of computer scientists and philosophers. Taking Moral Action “integrity,” or as a motivating story about his father’s struggles in a system that was sometimes unfair? Or as a boyhood memory of Saturdays at the office with his father, or as a possible self that is like his father, or as the skill/virtue of courage he practiced in emulation of his father? Or all these together? Or of some at one time, and others at other times? There is evidence in the interview for all of these. Each of these conceptions would likely tap something about the importance of his father, about the role his father played in his life and his particular moral self-­concept. Some aspects might be more relevant than others, depending on the idiosyncratic way the exemplar thought about his father’s influence. And the best way to conceive of the father’s influence for this exemplar may not work at all for some other person with some other influence from some other family member. This is a theme we visited regarding trait and virtue theory in Chapter 4. Conceptions of moral identity or other variables that work well across a range of people are tapping something similar and s work to predict behavior because of it. But they are likely not describing the particular way each individual experiences the world or thinks and feels about moral issues. of Most of those who do work in moral identity recognize this richness, and see their conceptualizations and measurement instruments as useful tools to tap something about moral identity, but not as definitive of all the ways moral identity operates or is experienced by the individual (e.g. Aquino & Reed, 2002, p. 1424; Narvaez et al., 2006, p. 982).16 ro 5.2.2 The Self is Variable Over Time lP There is great complexity within the web of self-­relevant memories, descriptions, scripts, roles, etc. of how we represent our selves to ourselves. This multiplicity of self-­identity is likely gradually developed over childhood, increasing in complexity as the child’s social world expands (Amiot et al., 2007). In this process, the self-­concept becomes more and more multidimensional as its cognitive and emotional capacities to represent and interact na with this complexity develop (Amiot et al., 2007). This differentiation of the (moral) self is influenced by, at least, parenting style (Hardy et al., 2010) and community context (Hart, 2005a; Hart & Carlo, 2005). As they develop, the multiple aspects of the self become more complex, varying in their interdependence, and in their overlapping attributes, narratives, themes, and emotional resonance (McConnell, 2010). Fi Coherence or consistency is often (though not always) imposed by the life narrative into which the individual retrospectively incorporates past, present, and possible future selves (McAdams, 2006). And these narratives themselves have implications for desired future behavior. But the expected consistencies may be limited. In our interviews of moral exemplars in computing we found some respondents insisted on integrating their family life into their stories, and others were perfectly willing to speak of their professional activity as though it was entirely independent of other aspects of their life (Huff & Barnard, 2009). 16 See Frimer and Walker (2008) and Lapsley (2008) for reviews of how the moral self is measured. Though it does appear that each of the many measures is predictive of moral action, there is not yet enough in common among them to determine what is important and what is peripheral in these approaches and their concomitant measures. This is perhaps because the ways that morality can be integrated into the self-­concept are legion. Moral Identity and the Self 121 5.2.3 The Self is Often Domain Specific Situational influence can make some aspects of this web of meaning more relevant at one time than another. And though there are internal pressures for consistency, our sense of self is “highly differentiated and domain specific” (Lapsley, 2008, p. 46) and significantly influenced by our social surroundings (McConnell, 2010). Thus, the self we show up with in any situation may be slightly different depending upon the significance of that situation for us and upon the centrality of internal pressures for consistency in the moral domain, across situations. But we are not simply trapped by the situation: the influence is reciprocal. We often choose the situations we are in, in order to match our sense of self, and we can choose to influence those situations if there is some mismatch (Huff et al., 2008b; Killen & Dahl, 2021; Lapsley & Narvaez, 2004; McConnell, 2010). s One type of situational variation in the self that has received significant attention is variation based on social relations and community. We interact with many different of individuals over time, and each sees a slightly different aspect of who we are (Andersen & Chen, 2002). Simply put, we show different selves, or different aspects of the self, to different others. We are, at various times, mother, teacher, friend, mentor, child, team member. Our interactions, or imagined interactions, with others can call out ro different interpersonal patterns of affect, belief, motivation, self-­reflection, and self-­ regulation (Aquino, McFerran, & Laven, 2011; McConnell, 2010; Rusbult et al., 2009). This psychological grounding in schemas based on past experience in relationships is in fact what Bowlby and Ainsworth had originally proposed as the lP central mechanism in attachment (Bretherton, 1992). However, we need not limit the dimensional variation in our selves to individual relations. We know that even in an individualistic culture, people vary in the extent to which they see their connections with others as significant aspects of the self and that seeing one’s self as socially connected influences compassion and socially responsible na behavior (Cojuharenco, Cornelissen, & Karelaia, 2016; Cross, Bacon, & Morris, 2000; Day & Impett, 2018; Vignoles, 2017). Snyder and Omoto (2008) note the importance of simple group membership in supporting volunteering, and how motivation for helping can change depending upon whether one is helping in-­group or out-­ group members. For instance, in a series of studies, Stürmer and Snyder (2010) Fi showed that individuals helped members of in-­groups because of empathy but they helped members of out-­groups because they were attractive or had some social value. There is evidence that moral identity can widen one’s “circle of moral regard” (Aquino et al., 2006; Reed & Aquino, 2003). This is reminiscent of the work of the Oliners (Oliner & Oliner, 1988) who showed that those who helped Jews and others escape the Holocaust had a much wider view of who “us” was, a view that included those being victimized. We show a different moral face to those who are “them” than we do to those who are “us.” One might have great integrity about justice and care for those we include in the deserving community, while being callous and uncaring for those “other people.” Susan Opotow explores this dynamic under the label “moral inclusion/exclusion.” She has reviewed how moral exclusion is constructed in a moral ecology (Opotow, 2001) and how programs stressing moral inclusion can have their effects in reducing violence and injustice (Opotow, 2005). Moral tightening and loosening describes the ways these impulses can change in a culture over time in response to Taking Moral Action challenges like scarcity or external threat (Gelfand, 2021). This moral exclusion is one of the crucial steps in the staircase to terrorism (Moghaddam, 2005; Moghaddam, Warren, & Love, 2014). Our moral ecology interacts with our moral identity in other ways than the us– them dynamic of moral inclusion. Participation within a community actually helps to construct our sense of self. In a longitudinal study of high school students, Pratt et al. (2003) found that self-­ideal (measured by self-­report of traits one strives for, such as being a good citizen, fair, just, caring) predicted community involvement, but over time it was community involvement that led to increases of these self-­ideal traits. Thus, active participation in community can produce a virtuous cycle of self-­ascription of traits, followed by further community service. Hart (2005a, p. 260) argues: “If the notion of identity is to contribute to an understanding of moral functioning, then it must be a construct with deep roots in a social world.” These roots will need to be s both deep and specific to each individual and his or her personal history and moral ecology. Piliavin and colleagues (Grube & Piliavin, 2000; Piliavin & Callero, 1991) of have shown the importance of “specific role identity” (as, e.g. a blood donor or a cancer society volunteer) in supporting volunteer activity. Rule and Bebeau (2005) and Huff and Barnard (2009) have also tracked the importance of specific identity themes in professions. ro So, the “deep social roots” of the self, and thus of the moral self, may well be quite specific, not easily susceptible to consistency pressures across domains, and may not reach across roles or domains to influence moral behavior in other contexts. In this way, the specificity and multidimensionality of the self can become a threat to preslP sures of consistency across domains; or what in moral language is often called integrity. To investigate this issue, we will need to ask how consistency pressures, or pressures toward integrity, operate in the multidimensional self. na 5.3 How Does the Moral Self-­Concept Influence Action? Supposedly, moral identity influences moral action in that the more that moral ideals/ values/models/narratives/etc. are integrated into the self-­concept, the more individuals’ moral actions are motivated and structured by that moral identity. Chapter 9 traces Fi this integration. We mention it here to remind us that these moral identity models are designed to solve the problem of the judgment–action gap discussed earlier. One important thing to note is that the empirical gap is less broad than often thought. Blasi’s (1980) review and several subsequent ones (Frimer & Walker, 2008; Jennings, Mitchell, & Hannah, 2015; Lapsley, 2008; Lapsley & Narvaez, 2005) have established a moderate relationship between moral identity and action, particularly when the action is seen as self-­relevant (Reynolds & Ceranic, 2007). This helps us to see the judgment–action gap as something that, from the perspective of the self, is only consequential when the judgment and the action conflict with each other in ways the self judges to be relevant.17 17 One can, of course, disagree with someone about whether an action is relevant, and even question one’s own actions or integrity. This process makes judgments of relevance central to understanding integrity. Moral Identity and the Self 123 Still, the self that is supposed to drive moral action has been revealed to be multidimensional, variable, and domain specific. One can see this as fragmentation of the self (Gergen, 2000), which makes the gap wider, or at least deprives the actor of a strong incentive toward unity of judgment and action. When judgments of relevance can splinter along lines of domain, situation, and aspects of the self, there seems to be little in the model that pushes for unity or integrity. The unity of the moral self might thus dissolve into a postmodern mash of singular, conveniently changed, isolated hopes, urges, and defenses (Frimer & Walker, 2008, p. 344) with no central organizing principle to provide internal consistency or integrity. Alternatively, one can see the multidimensionality as authentic adaptation to the complexity of life, in which aspects of the moral self cleave the social world based on its different moral ecologies. In this view, some variation in response to situational s difference might be respectable and even expected (Shoda et al., 2002). Domain limitations on moral action may well be the result of what existentialists call the need of to reconcile life’s unavoidable contradictions. And it may be that a well-­developed moral identity allows for thoughtful movement between moral ecologies, or the careful integration of values one might think are opposed (see the concept of integration in Section 5.3.1.1 and the concept of self-­transcendence in Chapter 9). One ro might then think of moral identity as less a moral straitjacket and more a well-­ coordinated wardrobe of clothes. It may best be thought of as integrating the moral tensions we experience in the many domains of our life rather than simply serving as a bulwark against failure. lP This review of the multidimensionality of the (moral) self should lead us to be careful in framing any demand for moral consistency, integrity, or unity. There are at least two issues here: when we speak of a drive toward consistency what items need to be consistent with each other, and how (in what way) are these items consistent? na 5.3.1 Two Forms of Moral Integrity What are the aspects of our self that we are longing to have consistent or to show integrity? Blasi (2005) provides a suggestion by outlining two kinds of self-­integrity: identity integrity (internal coherence among ideals, principles, values, and other Fi aspects of self-­conception) and behavioral integrity (coherence of external behavior with internal conceptions). 5.3.1.1 Identity Integrity Identity integrity is the postmodern puzzle we have been reviewing. To what extent is the conception of self across domains and values integrated? We have seen that there is ample evidence that most individuals’ self-­ conception varies across domains and with situations. There is evidence from Schwartz’s (2016, 1987) cross-­cultural work in values that there is even a fundamental incompatibility built into the structure of the way we think about values. In his well-­ validated circumplex model, values are arranged in a circle, with proximity on the circle representing how compatible they are in terms of the extent to which people report adherence to them. For instance, the values of benevolence and universalism lie next to each other, while power assertion and individual achievement lie next to each other on the opposite side of the circle (see Figure 3.1 in Chapter 3). This Taking Moral Action opposition of values to each other suggests that integrity among one’s values will be a difficult achievement. However, Walker, Frimer, and colleagues (Frimer & Walker, 2008; Frimer et al., 2011; Walker & Frimer, 2015) provide evidence that it is the integration of some of these supposedly opposing values that especially marks moral identity integrity and that also predicts moral behavior. In their reconciliation model, they identify people for whom agency (an individualistic value) and communion (a moral value of benevolence and universalism) co-­occur. These peoples’ agency is centered on communion with others, thus reconciling the supposed tension between them. Their defining moral goals are both agentic and centered on others. Here is an example they provide from an interview (Frimer & Walker, 2009, p. 1678): In any action we take, in any choice we make, we can have a positive or negative impact on the world … In terms of good habits, treating all people with dignity and respect regardless s of their situation in life or how similar or different they may be of This dedication of the (agentic) choosing self to (communal) others, provides a theme of unity in the moral self that can guide moral behavior. We review the evidence for this unity in Chapter 9, Section 9.3.1.1. ro 5.3.1.2 Behavioral Integrity: Or How to Overcome the Judgment–Action Gap The judgment–action gap we have documented in this and other chapters is precisely the issue of behavioral integrity: the extent to which external behavior coheres with lP internal commitments (Blasi, 1980). We know this gap exists and can document some of the processes that narrow it. But where can we find an impetus toward more behavioral integrity? There needs to be some perceived inconsistency between one’s behavior and something internal for there to be some motivation to reduce it. What is the internal aspect that serves as a reference point? We present here a variety of na candidates, and each one may, under some circumstances, be the aspect that drives the perception of consistency or inconsistency in behavior: • Principle. Consistency with a principle was proposed as the motivating factor by Kohlberg (1958, 1971). Whether this is one all-­encompassing principle or a set of Fi principles is unclear, even in later versions of the theory (Kohlberg, Levine, & Hewer, 1983). However, it reappears in our discussion in Chapter 9 of the idea of a higher goal or telos that reorganizes our values.18 • Self-­concept or identity. Blasi’s (1980, 1984, 2005) influential work suggests that what gives a perception of consistency-­motivating force is when the behavior is seen as consistent or not with one’s understanding of who one is, one’s moral self-­ concept. We have reviewed this literature in this chapter. • Self-­within-­context. Several authors have argued that a sense of responsibility or obligation does not arise out of a simple consistency pressure of behavior with self-­ concept, but from self-­concept within social systems that constitute one’s social 18 We should note that this higher goal need not appear phenomenologically to the moral actor as a principle. It could show up in any of a variety of guises. In Section 5.2.1 we give an example of how the influence of a father might be integrated into the moral self in many ways. Moral Identity and the Self 125 and cultural relations (Haidt, 2001; Hart, Atkins, & Southerland, 2006; Hart & Matsuba, 2009; Markus & Kitayama, 2010; Power, 2004). Cultural meanings and social surround help to identify those aspects of the self that are the most relevant to determining behavioral integrity in any context. This is an expansive definition of the self, and one that challenges the simple dichotomy of person vs. situation. • Emotion. An emotion has a natural action tendency (Arnold, 1960; Ellsworth, 2013), hence an action or a lack of action can be inconsistent with this action tendency.19 A variety of researchers have identified moral emotions as containing the kind of motivational power that can drive behavioral integrity (Haidt, 2001, 2003; Oliner & Oliner, 1988; Tangney, Stuewig, & Mashek, 2007). This is in part because the process of “having” an emotion involves a judgment of the relevance of some occurrence to the self. So, one can treat emotions as a separate source of behavioral integrity or as one process through which judgments of self-­relevance have their s effect. of There is empirical support for all four of these reference points to serve as the contrasting pole that produces pressures for behavioral consistency, or behavioral integrity. Rather than being alternative explanations, it may well be that they act ro independently or in concert. There is simply not enough theory or data to allow more than speculation about when or how each might have influence. 5.3.2 How Are These Aspects Consistent? lP What do we mean when we say that some action is inconsistent with some standard? What kind of comparison for consistency are we making? In almost all the psychological literature, the default understanding of consistency has been logical consistency. Logical entailment has been used as the measure of moral consistency in part because it is most suited to the project of finding a logically consistent and unquestionable na foundation for our sense of right and wrong.20 In our later list of “ways of being ­consistent”, logical consistency stands out because it seems simultaneously to answer questions about how we make moral judgments and whether those judgments are ultimately justified. It was for this reason that Kohlberg (1958) adopted the logical consistency criterion (Lapsley & Narvaez, 2005). Fi None of the other kinds of consistency are “foundational” in this way. They are much more attempts to simply describe how people make consistency judgments, or “feel” that things are inconsistent. Though they cannot offer a logical connection to a principled position, they can still differentiate among better and worse or more and less in the amount of consistency. And so, they can still provide for some motivation to increase consistency. 19 See Chapter 8 for more detail. 20 See Rudd (2007) on narrative consistency not being logical consistency or suitable for a foundationalist approach. See also Chapter 7 for Lawrence Kohlberg’s long, foundationalist battle against relativism. Taking Moral Action • Logical entailment.21 Consistency defined as logical entailment seems to set up a dimension on which more is always better. Colby and Damon (1992) talk about their moral exemplars often striving to broaden and deepen their moral commitments over the life span. Frimer and Walker (2008, p. 349) suggest that the attainment of complete logical consistency of moral motives within and across all domains and action is “a practical impossibility.”22 It may even be paradoxical, not least because it can itself distract from the goal of striving for the good. • Moral ledger. But there is a less demanding interpretation proposed by Nisan (1991) as a “moral ledger.” Nisan provides evidence that people trade off moral credits and debits and seem satisfied when the overall balance is above some positive threshold. This relaxed approach allows, of course, for its own kind of abuse in moral licensing, the belief that having done something good can then entitle one to be more lax in other areas (Conway & Peetz, 2012; Monin & Miller, 2001). s • Emotional consistency. Emotional experiences such as elevation (Algoe & Haidt, 2009; Haidt, 2000; Vianello, Galliani, & Haidt, 2010), empathy (Oliner & of Oliner, 1988; Preston & de Waal, 2002; Tangney et al., 2007), and compassion (Goetz, Keltner, & Simon-­Thomas, 2010; Oveis, Horberg, & Keltner, 2010; Stellar & Keltner, 2014) produce motivations to do good. We will explore the nature of these motivations in Chapter 8, but they can be signals that something is ro out of balance and needs to be corrected or is approaching balance and should be pursued. In addition, they can be cultivated: one can learn to be more (or less) emotionally sensitive (Weng et al., 2013; Wong, 2015) and can make this emotional development a goal (Koole, 2009; Koole & Veenstra, 2015; Kuhl & lP Koole, 2004). • Social consistency. We have already reviewed the work on the self as embedded in culture and situation. Rather than simply viewing this as a corrupting influence (from the perspective of logical entailment) one can also see it as social influence toward consistency and integrity. Colby and Damon (1992) recount numerous na instances in which it was social influence that led their exemplars into deeper ­commitment to causes, or to widen the horizon of their concern. The consistency pressures here can be thought of as mutual social influence in a way that greatly enhances the social aspect of Haidt’s (2001) social intuitionist model. By sharing their moral reactions, people mutually influence each other’s intuitions about the good. Fi • Instrumental consistency. Work on moral exemplars (Colby & Damon, 1992; Huff & Barnard, 2009; Plaisance, 2014) suggests that many view their commitments as moral projects, and evaluate their actions based, at least in part, on how they are compatible with achieving their moral goal. This has the problematic aspect that one might choose immoral methods to attain a moral goal (Hart, 2005b; 21 We use “logical entailment” here to mean what philosophers Beall and Restall (2019) refer to as “the relation between premises and conclusions in valid arguments” and call “logical consequence.” Exactly what this means is, of course, a matter of dispute and Beall and Restall review that dispute. 22 This practical impossibility in the face of the demand for complete consistency is related to the sense of inadequacy in the face of the infinite ideal (e.g. the highest good) that has been puzzled over from ancient times to Kierkegaard and beyond. It is also found in Reinhold Niebuhr’s reflections on the “impossible possibility” (Niebuhr, 1935, chapter 7). Moral Identity and the Self 127 Skitka, 2010; Skitka & Mullen, 2002). Not all examples of this expediency are negative. The theologian Bonhoffer’s participation in a plot to assassinate Hitler and Nathaniel Borenstein’s decision to consult for the military are two examples that are arguably positive. But it may nonetheless describe the nature of the motivational process behind many goal-­driven moral actions. It seems quite similar to what we call in Chapter 9 self-­transcendence, when the self transcends not only one’s goals but also ethical convictions toward a higher calling in a certain place and time. • Narrative consistency. Many theorists are now exploring the role of narrative in psychological functioning. Narratives have a structure and unity that is not univocal, in the way that logical entailment must be, but is instead “polyphonic” (McAdams, 2006, 2009), with multiple threads sometimes competing, sometimes cooperating. The telling of narratives serves a variety of purposes, some of s them centrally moral (McAdams, 2009; McAdams & Pals, 2006; Tappan & Brown, 1989). All people tell narratives for social-­bonding purposes, but people of also tell stories to direct and guide their future behavior and to establish and maintain self-­continuity (Bluck et al., 2005; De Silveira & Habermas, 2011; Habermas, 2011; Rasmussen & Habermas, 2011). These latter two purposes are both in part moral and can be thought of as relating to behavioral integrity and ro identity integrity respectively. Frimer and Walker (2009) have shown that it is just this kind of narrative unity between the opposing themes of benevolence/ universalism and power assertion/achievement that predict successful moral action. Thus, narrative consistency can provide a sense of continuity, psychologilP cal pressures to consistency, and motivation to act, while being more flexible than simple logical entailment consistency. We now have a quite complex picture of what it might mean to say one has integrity within one’s moral identity by achieving consistency between some moral referna ence point and one’s (im)moral behavior. Table 5.1 gives a picture of that complexity.23 Rows show various kinds of reference points (e.g. a principle) and columns show how each might be compared with an action. There are four different kinds of reference points and a variety of modes of consistency.24 The cells contain interpretations of what might psychologically be happening to produce consistency pressure in an actor Fi within that cell.25 For instance, where self-­in-­context and emotional consistency intersect, an actor might ask, “Is my emotion/motivation for this action consistent with my role as a doctor/daughter/feminist?” Or where principle and emotional consistency intersect, they might ask, “Is my emotion/motivation for this action consistent 23 Cervone (2021) provides a somewhat simpler overview of five ways one can construe personality coherence: (1) belief-­based; (2) goal-­based; (3) evaluative standards-­based; (4) intra-­psychic (interrelations among personality systems); and (5) phenomenological. These could be used to add even more (and perhaps fatal) complexity to this approach. 24 More or fewer might be imagined. See Cervone (2021) for a recent parallel proposal of different aspects of thinking about personality consistency. 25 We leave filling in the cells, and offering alternative interpretations of what a cell might mean, as an exercise for the reader. The rows and columns are not comprehensive and may need to be tailored to reflect the particular background of any individual. Taking Moral Action with a principle of respect for others?” One can easily take advantage of this large array of possible self-­reflections to find the most convenient comparison for one’s purposes, or one could take the time and resources to look for a more global kind of consistency. Consistency among the rows in Table 5.1 might be called identity integrity. But bridging the gap, or behavioral consistency is what happens in each cell. A person who feels no pressure for consistency among the various kinds of judgments in the cells, or chooses them based on convenience, can be what the philosopher Frankfurt (1971, p. 11) calls a “wanton.” How much consistency is enough? The philosopher Schwitzgebel (2019) makes a data-­based case that something like a B+ is the criterion most well intentioned people have. However, there is little research on this and how it might be modified by ­culture, domain, moral identity, etc. It is likely that moral exemplars, at least in the s relevant domain, have a higher standard. And it is possible also to dissociate some particular performance of, say, dishonesty, in a domain as a role-­excused “free trait” of that does not count against overall feelings of personal integrity (Schmidt & Poole, 2020). Doing this well, of course, requires skills like self-­reflection, emotional regulation, and moral imagination, which we cover in Chapter 6. It also requires appropriate, or ro at least a modest, commitment to some values or norms as discussed in Chapter 9, Section 9.3. And with the appropriate skills, norms, etc. one can reflectively assess the various consistencies in Table 5.1 to approach a social–emotional reflective equilibrium26 that we describe in Chapter 8. Here lies the trap described at the beginning of lP the chapter by the Apostle Paul: there are many ways to fall off the path. Many of these approaches to moral consistency come with a price: they open the process up to other motives (Cervone & Tripathi, 2009; Frimer & Walker, 2008) than the balanced consistency we describe as social–emotional reflective equilibrium. Many authors view this as a serious liability (Blasi, 1999, 2009; Kohlberg, 1963; na Walker & Frimer, 2009). If consistency with moral principles is only one of many possible motives for moral action, then one is faced with diluting the drive to unity and the value of integrity, and we may be left with a fragmented moral sense. Whether the moral sense is – in fact and in lived experience – fragmented and cobbled together or carefully constructed as a polyphonic narrative is in the end an empirical question – Fi but one with significant implications for judgments about morality. 5.3.3 If Moral Evaluation is So Complex, Can We Ever Hold Each Other Accountable? A robust societal morality requires that we be able to hold each other responsible for our actions. The seductive call of logical consistency accounts is that they provide us with firm ground on which to make judgments of accountability. But one does not 26 One can easily imagine what social–emotional reflective equilibrium consists of by simply scanning the types of consistency in Table 5.1. We describe it in other chapters as a process for mature, or expert, moral action. This is what might count as a more global kind of consistency, integrating the table. .INDD 129 Fi Table 5.1 The variety of moral consistencies. Mode of Comparison: In what way is the action being compared with the reference point? na Logical Moral Ledger Emotional Social Instrumental Narrative Reference Point: What is being compared with Principle/ Action Emotion of action Action matches Action achieves Value matches is based in values of valued goal? principle? principle? others/roles? Moral Action changes Action matches Action matches Action fits in lP Identity positive balance personal professional story of moral of identity? character based identity? identity? the action? on others/roles? Self-­in-­ Action changes Emotion of action Action matches Action achieves Action fits in Moral Identity and the Self Context positive balance matches important important moral goal shared story of self in of identity in others/roles? others/roles? with others or of context? ro context? role? Emotion Emotion of Action matches Action achieves Action fits with action current emotion? emotional goal? emotional tone matches of personal of preferred narrative? emotion? s 129 07-13-2023 10:01:55 130 Taking Moral Action need strict logical consistency in interpersonal relationships to have influence. We can still hold each other accountable for our actions “so long as there exists an agentic, unifying process [that] attempt[s] to mend inconsistency and [has] some (incomplete) success” (Frimer & Walker, 2008, p. 346).27 Each of the modes of comparison in Table 5.1 have ways of evaluating consistency, and all are subject to dispute. But they all share at least a modest impulse to consistency between the reference point and the action and some shared ground for recognizing and debating that impulse. Where might this drive for unity come from? First, there is a kind of logic within each mode of evaluation. Second, we review in Chapter 3 ways that the social surround might support the internal logic in each mode. Third, Weinstein, Przybylski, and Ryan (2013) propose three integrative characteristics of self-­ regulation that ­support the unifying processes: (1) conscious access to one’s emotions, motivations and values; (2) taking responsibility for one’s emotions, decisions, and thoughts; and s (3) non-­defensiveness in response to challenge. None of these sound (or are) easy, since they often involve an honest response to failure. But they involve skills that can of be learned (as we discuss in Chapter 6). 5.4 Critiques of the Moral Self ro There is a clear case to be made for the importance of moral identity in moral action. But the concept is not without its critics. We have mentioned earlier the complaint of Nucci (2004) that many models of moral identity are too simplistic, and we have seen lP that there are multidimensional models that respond to this complaint (Amiot et al., 2007; Hart & Carlo, 2005; McConnell, 2010; Reed & Bolton, 2005). But in his wide-­ranging critique of the moral self-­construct, Nucci (2004) is also worried that some models of moral identity essentially reduce morality to a sort of moral egoism: “I do it because I want to.” Frimer and Walker (2008, p. 352) aptly respond that na this is only a problem to the extent that the moral identity is conceived to be the only operating factor. There is evidence, for instance, of a variety of influences on volunteering, including wanting to have a particular experience or collect a line on one’s vita (Snyder & Omoto, 2008). But this is rarely the only influence, and even when it is, it might over time be transformed into other motivations (Hart & Matsuba, 2007). Fi Once one includes moral reasoning, moral emotion, embeddedness in a moral ecology, or other influences, then we are back to a model of balancing influences. In addition, if moral exemplars’ moral identities are centered on helping others, one must accuse them of a particularly complex and cynical sort of egoism that includes helping others as a façade for mere self-­enhancement (Badhwar, 1993). There seems little evidence to support this contorted critique. 27 It is this issue of whether our moral psychology allows us to insist on accountability or responsibility that is the central motivation behind Kohlberg’s and others’ insistence on a non-­relativist moral psychology (Blasi, 2009; Kohlberg, 1958). The approach in this chapter certainly could be relativist, but the “modest drive to unity” is, we think, at least equally compatible with an approach called pluralism (Flanagan, Sarkissian, & Wong, 2008), which avoids the radical relativist abandonment of any standard. Moral Identity and the Self 131 A more problematic critique is that the role of individual moral identity may vary dramatically by culture (Cervone & Tripathi, 2009; Miller, Goyal, & Wice, 2017). The self is constituted differently in different cultures (Markus & Kitayama, 2010) and even at different levels of social status in the United States (Bowman, Kitayama, & Nisbett, 2009). Individuals in India, for instance, view not helping others as a moral failing regardless of the relationship with the other, while Americans see this as a moral issue only for close others (Miller, Bersoff, & Harwood, 1990) – a distinction that maps onto cultural differences in how embedded the self in each culture is in social networks (Markus & Kitayama, 2010). In reviewing three decades of research on the self and culture, Markus and Kitayama (2010, p. 421) note that “the study of culture and self has led to the realization that people and their sociocultural worlds are not separate from one another. Instead they require each other and complete one another… . one cannot be a self by one’s self.” This makes it clear that the issue is s not whether the self is involved in moral action in Indian or other collectivist cultures but how the self is differently construed and constructed, and how it contributes to of moral action in different cultures. Thus, this criticism of the cultural inconsistency of moral identity effects can be recast as an invitation to explore the different ways that moral identity acts in different cultures, depending on how the self is construed in those cultures. ro Another critique of the self as a key aspect of moral action comes from work by those who claim the self’s primary function in the psyche is to “facilitate people’s social interactions and relationships” (Leary, 2007, p. 317).28 This might be viewed as a “selfish” motivation of self-­enhancement or social accommodation: The self lP experiences “moral” emotions and acts on them merely to achieve social status or success. But this is a narrow view of Leary’s sociometer approach and it does not take into account the seemingly other-­ centered focus of moral emotions (Aktipis & Kurzban, 2004). It also confuses two levels of explanation, the ultimate (evolutionary) and the proximate (motivational) (Preston & de Waal, 2002) – it is one thing to na say that the self supports moral behavior “to facilitate relationships” at an evolutionary level, and quite another to claim that the experience of the motivation to be moral is primarily based in the desire to have better relationships. A final critique stems from the cross-­cultural finding that traditional approaches to spiritual growth almost uniformly speak of denying the self, or the death of, or Fi ­non-­existence of the self as a necessary (and continual) aspect of becoming a whole, or virtuous, person (see Augustine, 1986 for an analysis in Christian, Buddhist, and Hindu monasticism). The Christian monastic Merton (2009) suggests that moral formation has to do with a life-­long transformation of the self, which does not leave the self fully behind but rather transforms it from a mere egocentric self to what he calls the “true self.” This claim has a long religious, and specifically monastic, history (Merton, 2009) and can be found across many religious expressions (Shulman & Stroumsa, 2002). On its face, this emphasis on self-­denial seems a direct contradiction to the sense of self as the motivator of action that we have found in this chapter. 28 Note that in Table 5.1, there is a column that is primarily driven by consistency pressures from important others and social roles. The table thus incorporates this critique as a kind of consistency. Taking Moral Action If, as monastic language would have it, one must become detached from the self, how can this motivate moral action? There are two clues in psychological theory that may help us here. First, among his later theoretical formulations of the hierarchy of needs, Maslow differentiated the highest level of self-­actualization into two parts: self-­actualization and self-­transcendence. Self-­ transcendence involves “seek[ing] a benefit beyond the purely personal and seek[ing] communion with the transcendent … com[ing] to identify with something greater than the purely individual self, often engaging in service to others” (Koltko-­Rivera, 2006, p. 306). Thus, in self-­ transcendence, one seeks something beyond self-­interest, and this becomes more important than, or possibly identified with, self-­interest. One might find this happening in several of the examples with which we began this book: The Munsons moved from taking in disabled foster children to founding a social service facility for disabled children; the Mothers of the Plaza de Mayo moving from concern for their child to s larger social and political goals; and Thomas Merton seeking to transform the self in search of God and thereby becoming a peace advocate.29 of A second approach that shares the pattern of de-­emphasizing the self comes from the research program of Walker and Frimer (2015). They and their colleagues have done extensive work on moral exemplars using both quantitative and qualitative methods. They describe their moral exemplars as having connected the good of othro ers, or of some ideal, to the central moral concern of self and view this as an integration of two values, with one (self-­agency) becoming an instrumental path to achieving the other (communion).30 We should be careful not to assume a harmony among these approaches. The lP monastic approach emphasizes more detachment from the self than do the other two models, and it includes vast variation among different monastic traditions in different religions as well as non-­religious forms of spirituality. Maslow seems to find self-­ transcendence attaching to a wide range of transcendent objects, as opposed to the other two approaches. And Walker and Frimer (2015) seem to view the process as a na natural developmental path for most people, while for Maslow and the monastic approach this achievement seems more exceptional, in some traditions only truly achieved as a rare form of enlightenment. But all agree that there is a path to moral action that involves some form of decentering or transforming the self. We will explore this path in detail in Chapter 9. Fi 5.5 Discussion 5.5.1 Conclusion 1. The integration of morality into the self is important in moral action. Many research programs and theoretical models point to the importance of moral identity, the integration of morality into the self, as serving an important role in 29 There is a dark side to self-­transcendence (Koltko-­Rivera, 2006; Skitka & Mullen, 2002) so that simple self-­transcendence cannot serve as a marker of morality per se. 30 Again, see Chapter 9 for an introduction to the Walker and Frimer (2015) research program and a reprise of this discussion. Moral Identity and the Self 133 the springs of moral action. There are regular, moderate-­to-­strong effects of moral identity in shaping moral behavior, particularly when one matches the situation and behavior to the specific commitments of moral identity. The importance of matching the situation and behavior to specific commitments is parallel in structure to the patterns we found in Chapter 4. Indeed, they are likely the same findings, as the measures used in personality are probably tapping aspects of moral identity. There is, then, mounting and converging evidence that moral identity plays a crucial part in the processes that initiate, regulate, and maintain (or derail, degrade, and misdirect) moral action. Moral identity is not, of course, all that influences moral action, as the other chapters in this text will attest. There are likely kinds of moral action that are somewhat unrelated to moral identity (e.g. habitual action – see Chapter 6). But moral identity is a prime candidate for playing a central role in much moral action. s 2. The moral self is multidimensional and variable over time and domains. The multidimensionality of the moral self suggests that there is no single “bridge” of across a single “gap.” As the table of moral consistencies (Table 5.1) shows, there are multiple reference points (rows) against which one might judge a moral action, and then multiple modes (columns) in which this action might be interpreted in light of the reference point. The bridge and gap metaphor portrays an isolated ro individual vainly straining to overcome a gap between ideals and action, a gap that should not be there but constantly haunts the reflective actor (as the Apostle Paul was haunted). But it is far more complicated than this, and perhaps less dire. There is not one single value but a pluralism of values. And the values may be represented lP in a variety of ways in the complexity of the self and its representations of the moral ecology. Different aspects of the self become relevant as one navigates the moral ecology, and the self develops and changes over time as a result of these interactions and the ways they are evaluated. Finally, self-­reflection, the skill of evaluating the fit of one’s action to one’s moral identity is itself legion in its modes. In this na complex landscape, one should not be haunted by gaps but instead encouraged by woven networks of consistency that endure across the complexities of the moral ecology, of the self, and of self-­reflection (see Chapters 6 and 9). 3. Self-­reflection as a guide for moral action is very flexible. From the standpoint of behavioral integrity, this is both a feature and a bug. Fi The multitude of reference points and modes of comparison make the self-­ reflection process very flexible: a positive feature given the complexity of our moral ecologies and of how we think of our selves. It provides for coherence balanced by flexibility in how we adapt our selves to the complexities of human life. However, one can see this flexibility as providing too many opportunities for self-­serving interpretations of one’s actions. Chapter 7 provides an overview of some of the ways we use reason to construct consistencies that allow us to excuse or support immorality. What then supports the impetus for consistency in moral action that comes from self-­reflection? We argue in this text that many influences (moral ecology, personality, skill) can do so. There is clear evidence that moral identity does not need to act alone. One person’s fragile network of self-­reflections in the table might spin apart as a result of a moral ecology of corruption. Or one can imagine the web of consistencies beginning to come together in a moral ecology that favors particular consistencies, such as restorative justice hearings. Of course, most moral Taking Moral Action ecologies contain both integrative and disintegrative influences (e.g. the complexity of a NATO study panel on nuclear technology). Still, one can likely cobble together a modest drive to unity from a wide variety of both internal and external influences. This is likely how most friendships, families, organizations, and societies survive. 4. A modest drive to unity may be enough to support consistent moral action. Moral identity is an important, and even crucial, influence on moral action. But it is rarely the moral hero standing alone in the gap. It provides internal resources for moral action when, because of its relevance in the situation, and sometimes despite the situation, it is called upon by individuals. But it is not always called upon, or it may often be called upon in different forms: the moral identity one has at work may be different from the one most prominent at home. Is consistency among this complexity a vain hope? We think not. There is ample evidence s of moral exemplars in a wide range of areas who are thoughtful and mostly consistent in moral action. Moral identity seems to play a central role in their action. of We have also reviewed here evidence that variation in moral identity is clearly associated with variations in moral action. So, the mere complexity of the task facing us is not cause for despair. As Frimer and Walker (2008, p. 346) argue, even a modest drive to unity, aided by self-­reflection, may be all we need. But the ro complexity is a caution that we need a better understanding of the task before us. We might instead, reconfigure the metaphor of “bridging the gap” into one of maintaining an ever-­changing network or weave of moral commitments and action. Who is the weaver? In Chapter 9, we argue that it is an active but not lP omnipotent moral self, navigating the world in response to a range of needs, constraints, and moral goals. 5.5.2 Application na “All I knew was that I wanted grace, and that I needed prayer, and that I was helpless without God, and that I wanted to do everything that people did to keep close to him” (Merton, 1948/1998, p. 329). This quote comes from Merton’s autobiography and is included in the first chapter of this book. It is a very personal description of his reasons for joining a monastic order. At least from this report, the entire self is Fi focused on the search for closeness to God. Nothing else matters. Yet Merton became a central figure in the peace movement in the United States in the 1960s. His overwhelming preference was to be a hermit, yet he was rarely allowed this luxury. Instead, he was told by his Abbot to write, since his writing was of such a high quality and so widely sought after. He was so deeply steeped in Christian monastic tradition and practice that even his turn toward those justice issues that were raging at the time (e.g. race and peace) was suffused with symbolism and language from that tradition. In a famous vision he had in 1958, at the center of the Louisville KY shopping district on the corner of Fourth and Walnut, he saw that everyone in the crowd of shoppers had the spark of God in them. “If only everybody could realize this!” he later wrote of this experience, “But it cannot be explained. There is no way of telling people that they are all walking around shining like the sun” (Merton, 1966, pp. 153–154). This mystical language has nothing of human rights or justice language in it, and yet it marks a turning point in Merton’s writing toward issues of justice, race, and ­opposition Moral Identity and the Self 135 to war. It is a complicated matter to explain how this strange language of people “walking around shining like the sun” connects to these moral issues and to Merton’s social activism. But it is at least clear that Merton’s moral action has different roots than a moral identity centered on principled justice reasoning. These roots are uniquely grounded in a specific tradition of language, narrative, and worldview where reform of the self, otherworldly desire for God, and social activism are often closely intertwined. There are consistency pressures within this moral ecology, but they are (often) not ones that valorize the self. One can multiply examples like this endlessly, showing that moral action is connected with a view of “a person like me in a situation like this” but that, from one actor to the next, this view is rarely the same in specific motivation and structure. And yet, at an abstract level, we will find things in this chapter that help us understand Merton’s moral action (e.g. Maslow and self-­transcendence). s 5."
5,5.3,"How Does the Moral Self-­Concept Influence Action? Supposedly, moral identity influences moral action in that the more that moral ideals/ values/models/narratives/etc. are integrated into the self-­concept, the more individuals’ moral actions are motivated and structured by that moral identity. Chapter 9 traces Fi this integration. We mention it here to remind us that these moral identity models are designed to solve the problem of the judgment–action gap discussed earlier. One important thing to note is that the empirical gap is less broad than often thought. Blasi’s (1980) review and several subsequent ones (Frimer & Walker, 2008; Jennings, Mitchell, & Hannah, 2015; Lapsley, 2008; Lapsley & Narvaez, 2005) have established a moderate relationship between moral identity and action, particularly when the action is seen as self-­relevant (Reynolds & Ceranic, 2007). This helps us to see the judgment–action gap as something that, from the perspective of the self, is only consequential when the judgment and the action conflict with each other in ways the self judges to be relevant.17 17 One can, of course, disagree with someone about whether an action is relevant, and even question one’s own actions or integrity. This process makes judgments of relevance central to understanding integrity. Moral Identity and the Self 123 Still, the self that is supposed to drive moral action has been revealed to be multidimensional, variable, and domain specific. One can see this as fragmentation of the self (Gergen, 2000), which makes the gap wider, or at least deprives the actor of a strong incentive toward unity of judgment and action. When judgments of relevance can splinter along lines of domain, situation, and aspects of the self, there seems to be little in the model that pushes for unity or integrity. The unity of the moral self might thus dissolve into a postmodern mash of singular, conveniently changed, isolated hopes, urges, and defenses (Frimer & Walker, 2008, p. 344) with no central organizing principle to provide internal consistency or integrity. Alternatively, one can see the multidimensionality as authentic adaptation to the complexity of life, in which aspects of the moral self cleave the social world based on its different moral ecologies. In this view, some variation in response to situational s difference might be respectable and even expected (Shoda et al., 2002). Domain limitations on moral action may well be the result of what existentialists call the need of to reconcile life’s unavoidable contradictions. And it may be that a well-­developed moral identity allows for thoughtful movement between moral ecologies, or the careful integration of values one might think are opposed (see the concept of integration in Section 5.3.1.1 and the concept of self-­transcendence in Chapter 9). One ro might then think of moral identity as less a moral straitjacket and more a well-­ coordinated wardrobe of clothes. It may best be thought of as integrating the moral tensions we experience in the many domains of our life rather than simply serving as a bulwark against failure. lP This review of the multidimensionality of the (moral) self should lead us to be careful in framing any demand for moral consistency, integrity, or unity. There are at least two issues here: when we speak of a drive toward consistency what items need to be consistent with each other, and how (in what way) are these items consistent? na 5.3.1 Two Forms of Moral Integrity What are the aspects of our self that we are longing to have consistent or to show integrity? Blasi (2005) provides a suggestion by outlining two kinds of self-­integrity: identity integrity (internal coherence among ideals, principles, values, and other Fi aspects of self-­conception) and behavioral integrity (coherence of external behavior with internal conceptions). 5.3.1.1 Identity Integrity Identity integrity is the postmodern puzzle we have been reviewing. To what extent is the conception of self across domains and values integrated? We have seen that there is ample evidence that most individuals’ self-­ conception varies across domains and with situations. There is evidence from Schwartz’s (2016, 1987) cross-­cultural work in values that there is even a fundamental incompatibility built into the structure of the way we think about values. In his well-­ validated circumplex model, values are arranged in a circle, with proximity on the circle representing how compatible they are in terms of the extent to which people report adherence to them. For instance, the values of benevolence and universalism lie next to each other, while power assertion and individual achievement lie next to each other on the opposite side of the circle (see Figure 3.1 in Chapter 3). This Taking Moral Action opposition of values to each other suggests that integrity among one’s values will be a difficult achievement. However, Walker, Frimer, and colleagues (Frimer & Walker, 2008; Frimer et al., 2011; Walker & Frimer, 2015) provide evidence that it is the integration of some of these supposedly opposing values that especially marks moral identity integrity and that also predicts moral behavior. In their reconciliation model, they identify people for whom agency (an individualistic value) and communion (a moral value of benevolence and universalism) co-­occur. These peoples’ agency is centered on communion with others, thus reconciling the supposed tension between them. Their defining moral goals are both agentic and centered on others. Here is an example they provide from an interview (Frimer & Walker, 2009, p. 1678): In any action we take, in any choice we make, we can have a positive or negative impact on the world … In terms of good habits, treating all people with dignity and respect regardless s of their situation in life or how similar or different they may be of This dedication of the (agentic) choosing self to (communal) others, provides a theme of unity in the moral self that can guide moral behavior. We review the evidence for this unity in Chapter 9, Section 9.3.1.1. ro 5.3.1.2 Behavioral Integrity: Or How to Overcome the Judgment–Action Gap The judgment–action gap we have documented in this and other chapters is precisely the issue of behavioral integrity: the extent to which external behavior coheres with lP internal commitments (Blasi, 1980). We know this gap exists and can document some of the processes that narrow it. But where can we find an impetus toward more behavioral integrity? There needs to be some perceived inconsistency between one’s behavior and something internal for there to be some motivation to reduce it. What is the internal aspect that serves as a reference point? We present here a variety of na candidates, and each one may, under some circumstances, be the aspect that drives the perception of consistency or inconsistency in behavior: • Principle. Consistency with a principle was proposed as the motivating factor by Kohlberg (1958, 1971). Whether this is one all-­encompassing principle or a set of Fi principles is unclear, even in later versions of the theory (Kohlberg, Levine, & Hewer, 1983). However, it reappears in our discussion in Chapter 9 of the idea of a higher goal or telos that reorganizes our values.18 • Self-­concept or identity. Blasi’s (1980, 1984, 2005) influential work suggests that what gives a perception of consistency-­motivating force is when the behavior is seen as consistent or not with one’s understanding of who one is, one’s moral self-­ concept. We have reviewed this literature in this chapter. • Self-­within-­context. Several authors have argued that a sense of responsibility or obligation does not arise out of a simple consistency pressure of behavior with self-­ concept, but from self-­concept within social systems that constitute one’s social 18 We should note that this higher goal need not appear phenomenologically to the moral actor as a principle. It could show up in any of a variety of guises. In Section 5.2.1 we give an example of how the influence of a father might be integrated into the moral self in many ways. Moral Identity and the Self 125 and cultural relations (Haidt, 2001; Hart, Atkins, & Southerland, 2006; Hart & Matsuba, 2009; Markus & Kitayama, 2010; Power, 2004). Cultural meanings and social surround help to identify those aspects of the self that are the most relevant to determining behavioral integrity in any context. This is an expansive definition of the self, and one that challenges the simple dichotomy of person vs. situation. • Emotion. An emotion has a natural action tendency (Arnold, 1960; Ellsworth, 2013), hence an action or a lack of action can be inconsistent with this action tendency.19 A variety of researchers have identified moral emotions as containing the kind of motivational power that can drive behavioral integrity (Haidt, 2001, 2003; Oliner & Oliner, 1988; Tangney, Stuewig, & Mashek, 2007). This is in part because the process of “having” an emotion involves a judgment of the relevance of some occurrence to the self. So, one can treat emotions as a separate source of behavioral integrity or as one process through which judgments of self-­relevance have their s effect. of There is empirical support for all four of these reference points to serve as the contrasting pole that produces pressures for behavioral consistency, or behavioral integrity. Rather than being alternative explanations, it may well be that they act ro independently or in concert. There is simply not enough theory or data to allow more than speculation about when or how each might have influence. 5.3.2 How Are These Aspects Consistent? lP What do we mean when we say that some action is inconsistent with some standard? What kind of comparison for consistency are we making? In almost all the psychological literature, the default understanding of consistency has been logical consistency. Logical entailment has been used as the measure of moral consistency in part because it is most suited to the project of finding a logically consistent and unquestionable na foundation for our sense of right and wrong.20 In our later list of “ways of being ­consistent”, logical consistency stands out because it seems simultaneously to answer questions about how we make moral judgments and whether those judgments are ultimately justified. It was for this reason that Kohlberg (1958) adopted the logical consistency criterion (Lapsley & Narvaez, 2005). Fi None of the other kinds of consistency are “foundational” in this way. They are much more attempts to simply describe how people make consistency judgments, or “feel” that things are inconsistent. Though they cannot offer a logical connection to a principled position, they can still differentiate among better and worse or more and less in the amount of consistency. And so, they can still provide for some motivation to increase consistency. 19 See Chapter 8 for more detail. 20 See Rudd (2007) on narrative consistency not being logical consistency or suitable for a foundationalist approach. See also Chapter 7 for Lawrence Kohlberg’s long, foundationalist battle against relativism. Taking Moral Action • Logical entailment.21 Consistency defined as logical entailment seems to set up a dimension on which more is always better. Colby and Damon (1992) talk about their moral exemplars often striving to broaden and deepen their moral commitments over the life span. Frimer and Walker (2008, p. 349) suggest that the attainment of complete logical consistency of moral motives within and across all domains and action is “a practical impossibility.”22 It may even be paradoxical, not least because it can itself distract from the goal of striving for the good. • Moral ledger. But there is a less demanding interpretation proposed by Nisan (1991) as a “moral ledger.” Nisan provides evidence that people trade off moral credits and debits and seem satisfied when the overall balance is above some positive threshold. This relaxed approach allows, of course, for its own kind of abuse in moral licensing, the belief that having done something good can then entitle one to be more lax in other areas (Conway & Peetz, 2012; Monin & Miller, 2001). s • Emotional consistency. Emotional experiences such as elevation (Algoe & Haidt, 2009; Haidt, 2000; Vianello, Galliani, & Haidt, 2010), empathy (Oliner & of Oliner, 1988; Preston & de Waal, 2002; Tangney et al., 2007), and compassion (Goetz, Keltner, & Simon-­Thomas, 2010; Oveis, Horberg, & Keltner, 2010; Stellar & Keltner, 2014) produce motivations to do good. We will explore the nature of these motivations in Chapter 8, but they can be signals that something is ro out of balance and needs to be corrected or is approaching balance and should be pursued. In addition, they can be cultivated: one can learn to be more (or less) emotionally sensitive (Weng et al., 2013; Wong, 2015) and can make this emotional development a goal (Koole, 2009; Koole & Veenstra, 2015; Kuhl & lP Koole, 2004). • Social consistency. We have already reviewed the work on the self as embedded in culture and situation. Rather than simply viewing this as a corrupting influence (from the perspective of logical entailment) one can also see it as social influence toward consistency and integrity. Colby and Damon (1992) recount numerous na instances in which it was social influence that led their exemplars into deeper ­commitment to causes, or to widen the horizon of their concern. The consistency pressures here can be thought of as mutual social influence in a way that greatly enhances the social aspect of Haidt’s (2001) social intuitionist model. By sharing their moral reactions, people mutually influence each other’s intuitions about the good. Fi • Instrumental consistency. Work on moral exemplars (Colby & Damon, 1992; Huff & Barnard, 2009; Plaisance, 2014) suggests that many view their commitments as moral projects, and evaluate their actions based, at least in part, on how they are compatible with achieving their moral goal. This has the problematic aspect that one might choose immoral methods to attain a moral goal (Hart, 2005b; 21 We use “logical entailment” here to mean what philosophers Beall and Restall (2019) refer to as “the relation between premises and conclusions in valid arguments” and call “logical consequence.” Exactly what this means is, of course, a matter of dispute and Beall and Restall review that dispute. 22 This practical impossibility in the face of the demand for complete consistency is related to the sense of inadequacy in the face of the infinite ideal (e.g. the highest good) that has been puzzled over from ancient times to Kierkegaard and beyond. It is also found in Reinhold Niebuhr’s reflections on the “impossible possibility” (Niebuhr, 1935, chapter 7). Moral Identity and the Self 127 Skitka, 2010; Skitka & Mullen, 2002). Not all examples of this expediency are negative. The theologian Bonhoffer’s participation in a plot to assassinate Hitler and Nathaniel Borenstein’s decision to consult for the military are two examples that are arguably positive. But it may nonetheless describe the nature of the motivational process behind many goal-­driven moral actions. It seems quite similar to what we call in Chapter 9 self-­transcendence, when the self transcends not only one’s goals but also ethical convictions toward a higher calling in a certain place and time. • Narrative consistency. Many theorists are now exploring the role of narrative in psychological functioning. Narratives have a structure and unity that is not univocal, in the way that logical entailment must be, but is instead “polyphonic” (McAdams, 2006, 2009), with multiple threads sometimes competing, sometimes cooperating. The telling of narratives serves a variety of purposes, some of s them centrally moral (McAdams, 2009; McAdams & Pals, 2006; Tappan & Brown, 1989). All people tell narratives for social-­bonding purposes, but people of also tell stories to direct and guide their future behavior and to establish and maintain self-­continuity (Bluck et al., 2005; De Silveira & Habermas, 2011; Habermas, 2011; Rasmussen & Habermas, 2011). These latter two purposes are both in part moral and can be thought of as relating to behavioral integrity and ro identity integrity respectively. Frimer and Walker (2009) have shown that it is just this kind of narrative unity between the opposing themes of benevolence/ universalism and power assertion/achievement that predict successful moral action. Thus, narrative consistency can provide a sense of continuity, psychologilP cal pressures to consistency, and motivation to act, while being more flexible than simple logical entailment consistency. We now have a quite complex picture of what it might mean to say one has integrity within one’s moral identity by achieving consistency between some moral referna ence point and one’s (im)moral behavior. Table 5.1 gives a picture of that complexity.23 Rows show various kinds of reference points (e.g. a principle) and columns show how each might be compared with an action. There are four different kinds of reference points and a variety of modes of consistency.24 The cells contain interpretations of what might psychologically be happening to produce consistency pressure in an actor Fi within that cell.25 For instance, where self-­in-­context and emotional consistency intersect, an actor might ask, “Is my emotion/motivation for this action consistent with my role as a doctor/daughter/feminist?” Or where principle and emotional consistency intersect, they might ask, “Is my emotion/motivation for this action consistent 23 Cervone (2021) provides a somewhat simpler overview of five ways one can construe personality coherence: (1) belief-­based; (2) goal-­based; (3) evaluative standards-­based; (4) intra-­psychic (interrelations among personality systems); and (5) phenomenological. These could be used to add even more (and perhaps fatal) complexity to this approach. 24 More or fewer might be imagined. See Cervone (2021) for a recent parallel proposal of different aspects of thinking about personality consistency. 25 We leave filling in the cells, and offering alternative interpretations of what a cell might mean, as an exercise for the reader. The rows and columns are not comprehensive and may need to be tailored to reflect the particular background of any individual. Taking Moral Action with a principle of respect for others?” One can easily take advantage of this large array of possible self-­reflections to find the most convenient comparison for one’s purposes, or one could take the time and resources to look for a more global kind of consistency. Consistency among the rows in Table 5.1 might be called identity integrity. But bridging the gap, or behavioral consistency is what happens in each cell. A person who feels no pressure for consistency among the various kinds of judgments in the cells, or chooses them based on convenience, can be what the philosopher Frankfurt (1971, p. 11) calls a “wanton.” How much consistency is enough? The philosopher Schwitzgebel (2019) makes a data-­based case that something like a B+ is the criterion most well intentioned people have. However, there is little research on this and how it might be modified by ­culture, domain, moral identity, etc. It is likely that moral exemplars, at least in the s relevant domain, have a higher standard. And it is possible also to dissociate some particular performance of, say, dishonesty, in a domain as a role-­excused “free trait” of that does not count against overall feelings of personal integrity (Schmidt & Poole, 2020). Doing this well, of course, requires skills like self-­reflection, emotional regulation, and moral imagination, which we cover in Chapter 6. It also requires appropriate, or ro at least a modest, commitment to some values or norms as discussed in Chapter 9, Section 9.3. And with the appropriate skills, norms, etc. one can reflectively assess the various consistencies in Table 5.1 to approach a social–emotional reflective equilibrium26 that we describe in Chapter 8. Here lies the trap described at the beginning of lP the chapter by the Apostle Paul: there are many ways to fall off the path. Many of these approaches to moral consistency come with a price: they open the process up to other motives (Cervone & Tripathi, 2009; Frimer & Walker, 2008) than the balanced consistency we describe as social–emotional reflective equilibrium. Many authors view this as a serious liability (Blasi, 1999, 2009; Kohlberg, 1963; na Walker & Frimer, 2009). If consistency with moral principles is only one of many possible motives for moral action, then one is faced with diluting the drive to unity and the value of integrity, and we may be left with a fragmented moral sense. Whether the moral sense is – in fact and in lived experience – fragmented and cobbled together or carefully constructed as a polyphonic narrative is in the end an empirical question – Fi but one with significant implications for judgments about morality. 5.3.3 If Moral Evaluation is So Complex, Can We Ever Hold Each Other Accountable? A robust societal morality requires that we be able to hold each other responsible for our actions. The seductive call of logical consistency accounts is that they provide us with firm ground on which to make judgments of accountability. But one does not 26 One can easily imagine what social–emotional reflective equilibrium consists of by simply scanning the types of consistency in Table 5.1. We describe it in other chapters as a process for mature, or expert, moral action. This is what might count as a more global kind of consistency, integrating the table. .INDD 129 Fi Table 5.1 The variety of moral consistencies. Mode of Comparison: In what way is the action being compared with the reference point? na Logical Moral Ledger Emotional Social Instrumental Narrative Reference Point: What is being compared with Principle/ Action Emotion of action Action matches Action achieves Value matches is based in values of valued goal? principle? principle? others/roles? Moral Action changes Action matches Action matches Action fits in lP Identity positive balance personal professional story of moral of identity? character based identity? identity? the action? on others/roles? Self-­in-­ Action changes Emotion of action Action matches Action achieves Action fits in Moral Identity and the Self Context positive balance matches important important moral goal shared story of self in of identity in others/roles? others/roles? with others or of context? ro context? role? Emotion Emotion of Action matches Action achieves Action fits with action current emotion? emotional goal? emotional tone matches of personal of preferred narrative? emotion? s 129 07-13-2023 10:01:55 130 Taking Moral Action need strict logical consistency in interpersonal relationships to have influence. We can still hold each other accountable for our actions “so long as there exists an agentic, unifying process [that] attempt[s] to mend inconsistency and [has] some (incomplete) success” (Frimer & Walker, 2008, p. 346).27 Each of the modes of comparison in Table 5.1 have ways of evaluating consistency, and all are subject to dispute. But they all share at least a modest impulse to consistency between the reference point and the action and some shared ground for recognizing and debating that impulse. Where might this drive for unity come from? First, there is a kind of logic within each mode of evaluation. Second, we review in Chapter 3 ways that the social surround might support the internal logic in each mode. Third, Weinstein, Przybylski, and Ryan (2013) propose three integrative characteristics of self-­ regulation that ­support the unifying processes: (1) conscious access to one’s emotions, motivations and values; (2) taking responsibility for one’s emotions, decisions, and thoughts; and s (3) non-­defensiveness in response to challenge. None of these sound (or are) easy, since they often involve an honest response to failure. But they involve skills that can of be learned (as we discuss in Chapter 6)."
5,5.4,"Critiques of the Moral Self ro There is a clear case to be made for the importance of moral identity in moral action. But the concept is not without its critics. We have mentioned earlier the complaint of Nucci (2004) that many models of moral identity are too simplistic, and we have seen lP that there are multidimensional models that respond to this complaint (Amiot et al., 2007; Hart & Carlo, 2005; McConnell, 2010; Reed & Bolton, 2005). But in his wide-­ranging critique of the moral self-­construct, Nucci (2004) is also worried that some models of moral identity essentially reduce morality to a sort of moral egoism: “I do it because I want to.” Frimer and Walker (2008, p. 352) aptly respond that na this is only a problem to the extent that the moral identity is conceived to be the only operating factor. There is evidence, for instance, of a variety of influences on volunteering, including wanting to have a particular experience or collect a line on one’s vita (Snyder & Omoto, 2008). But this is rarely the only influence, and even when it is, it might over time be transformed into other motivations (Hart & Matsuba, 2007). Fi Once one includes moral reasoning, moral emotion, embeddedness in a moral ecology, or other influences, then we are back to a model of balancing influences. In addition, if moral exemplars’ moral identities are centered on helping others, one must accuse them of a particularly complex and cynical sort of egoism that includes helping others as a façade for mere self-­enhancement (Badhwar, 1993). There seems little evidence to support this contorted critique. 27 It is this issue of whether our moral psychology allows us to insist on accountability or responsibility that is the central motivation behind Kohlberg’s and others’ insistence on a non-­relativist moral psychology (Blasi, 2009; Kohlberg, 1958). The approach in this chapter certainly could be relativist, but the “modest drive to unity” is, we think, at least equally compatible with an approach called pluralism (Flanagan, Sarkissian, & Wong, 2008), which avoids the radical relativist abandonment of any standard. Moral Identity and the Self 131 A more problematic critique is that the role of individual moral identity may vary dramatically by culture (Cervone & Tripathi, 2009; Miller, Goyal, & Wice, 2017). The self is constituted differently in different cultures (Markus & Kitayama, 2010) and even at different levels of social status in the United States (Bowman, Kitayama, & Nisbett, 2009). Individuals in India, for instance, view not helping others as a moral failing regardless of the relationship with the other, while Americans see this as a moral issue only for close others (Miller, Bersoff, & Harwood, 1990) – a distinction that maps onto cultural differences in how embedded the self in each culture is in social networks (Markus & Kitayama, 2010). In reviewing three decades of research on the self and culture, Markus and Kitayama (2010, p. 421) note that “the study of culture and self has led to the realization that people and their sociocultural worlds are not separate from one another. Instead they require each other and complete one another… . one cannot be a self by one’s self.” This makes it clear that the issue is s not whether the self is involved in moral action in Indian or other collectivist cultures but how the self is differently construed and constructed, and how it contributes to of moral action in different cultures. Thus, this criticism of the cultural inconsistency of moral identity effects can be recast as an invitation to explore the different ways that moral identity acts in different cultures, depending on how the self is construed in those cultures. ro Another critique of the self as a key aspect of moral action comes from work by those who claim the self’s primary function in the psyche is to “facilitate people’s social interactions and relationships” (Leary, 2007, p. 317).28 This might be viewed as a “selfish” motivation of self-­enhancement or social accommodation: The self lP experiences “moral” emotions and acts on them merely to achieve social status or success. But this is a narrow view of Leary’s sociometer approach and it does not take into account the seemingly other-­ centered focus of moral emotions (Aktipis & Kurzban, 2004). It also confuses two levels of explanation, the ultimate (evolutionary) and the proximate (motivational) (Preston & de Waal, 2002) – it is one thing to na say that the self supports moral behavior “to facilitate relationships” at an evolutionary level, and quite another to claim that the experience of the motivation to be moral is primarily based in the desire to have better relationships. A final critique stems from the cross-­cultural finding that traditional approaches to spiritual growth almost uniformly speak of denying the self, or the death of, or Fi ­non-­existence of the self as a necessary (and continual) aspect of becoming a whole, or virtuous, person (see Augustine, 1986 for an analysis in Christian, Buddhist, and Hindu monasticism). The Christian monastic Merton (2009) suggests that moral formation has to do with a life-­long transformation of the self, which does not leave the self fully behind but rather transforms it from a mere egocentric self to what he calls the “true self.” This claim has a long religious, and specifically monastic, history (Merton, 2009) and can be found across many religious expressions (Shulman & Stroumsa, 2002). On its face, this emphasis on self-­denial seems a direct contradiction to the sense of self as the motivator of action that we have found in this chapter. 28 Note that in Table 5.1, there is a column that is primarily driven by consistency pressures from important others and social roles. The table thus incorporates this critique as a kind of consistency. Taking Moral Action If, as monastic language would have it, one must become detached from the self, how can this motivate moral action? There are two clues in psychological theory that may help us here. First, among his later theoretical formulations of the hierarchy of needs, Maslow differentiated the highest level of self-­actualization into two parts: self-­actualization and self-­transcendence. Self-­ transcendence involves “seek[ing] a benefit beyond the purely personal and seek[ing] communion with the transcendent … com[ing] to identify with something greater than the purely individual self, often engaging in service to others” (Koltko-­Rivera, 2006, p. 306). Thus, in self-­ transcendence, one seeks something beyond self-­interest, and this becomes more important than, or possibly identified with, self-­interest. One might find this happening in several of the examples with which we began this book: The Munsons moved from taking in disabled foster children to founding a social service facility for disabled children; the Mothers of the Plaza de Mayo moving from concern for their child to s larger social and political goals; and Thomas Merton seeking to transform the self in search of God and thereby becoming a peace advocate.29 of A second approach that shares the pattern of de-­emphasizing the self comes from the research program of Walker and Frimer (2015). They and their colleagues have done extensive work on moral exemplars using both quantitative and qualitative methods. They describe their moral exemplars as having connected the good of othro ers, or of some ideal, to the central moral concern of self and view this as an integration of two values, with one (self-­agency) becoming an instrumental path to achieving the other (communion).30 We should be careful not to assume a harmony among these approaches. The lP monastic approach emphasizes more detachment from the self than do the other two models, and it includes vast variation among different monastic traditions in different religions as well as non-­religious forms of spirituality. Maslow seems to find self-­ transcendence attaching to a wide range of transcendent objects, as opposed to the other two approaches. And Walker and Frimer (2015) seem to view the process as a na natural developmental path for most people, while for Maslow and the monastic approach this achievement seems more exceptional, in some traditions only truly achieved as a rare form of enlightenment. But all agree that there is a path to moral action that involves some form of decentering or transforming the self. We will explore this path in detail in Chapter 9. Fi 5.5 Discussion 5.5.1 Conclusion 1. The integration of morality into the self is important in moral action. Many research programs and theoretical models point to the importance of moral identity, the integration of morality into the self, as serving an important role in 29 There is a dark side to self-­transcendence (Koltko-­Rivera, 2006; Skitka & Mullen, 2002) so that simple self-­transcendence cannot serve as a marker of morality per se. 30 Again, see Chapter 9 for an introduction to the Walker and Frimer (2015) research program and a reprise of this discussion. Moral Identity and the Self 133 the springs of moral action. There are regular, moderate-­to-­strong effects of moral identity in shaping moral behavior, particularly when one matches the situation and behavior to the specific commitments of moral identity. The importance of matching the situation and behavior to specific commitments is parallel in structure to the patterns we found in Chapter 4. Indeed, they are likely the same findings, as the measures used in personality are probably tapping aspects of moral identity. There is, then, mounting and converging evidence that moral identity plays a crucial part in the processes that initiate, regulate, and maintain (or derail, degrade, and misdirect) moral action. Moral identity is not, of course, all that influences moral action, as the other chapters in this text will attest. There are likely kinds of moral action that are somewhat unrelated to moral identity (e.g. habitual action – see Chapter 6). But moral identity is a prime candidate for playing a central role in much moral action. s 2. The moral self is multidimensional and variable over time and domains. The multidimensionality of the moral self suggests that there is no single “bridge” of across a single “gap.” As the table of moral consistencies (Table 5.1) shows, there are multiple reference points (rows) against which one might judge a moral action, and then multiple modes (columns) in which this action might be interpreted in light of the reference point. The bridge and gap metaphor portrays an isolated ro individual vainly straining to overcome a gap between ideals and action, a gap that should not be there but constantly haunts the reflective actor (as the Apostle Paul was haunted). But it is far more complicated than this, and perhaps less dire. There is not one single value but a pluralism of values. And the values may be represented lP in a variety of ways in the complexity of the self and its representations of the moral ecology. Different aspects of the self become relevant as one navigates the moral ecology, and the self develops and changes over time as a result of these interactions and the ways they are evaluated. Finally, self-­reflection, the skill of evaluating the fit of one’s action to one’s moral identity is itself legion in its modes. In this na complex landscape, one should not be haunted by gaps but instead encouraged by woven networks of consistency that endure across the complexities of the moral ecology, of the self, and of self-­reflection (see Chapters 6 and 9). 3. Self-­reflection as a guide for moral action is very flexible. From the standpoint of behavioral integrity, this is both a feature and a bug. Fi The multitude of reference points and modes of comparison make the self-­ reflection process very flexible: a positive feature given the complexity of our moral ecologies and of how we think of our selves. It provides for coherence balanced by flexibility in how we adapt our selves to the complexities of human life. However, one can see this flexibility as providing too many opportunities for self-­serving interpretations of one’s actions. Chapter 7 provides an overview of some of the ways we use reason to construct consistencies that allow us to excuse or support immorality. What then supports the impetus for consistency in moral action that comes from self-­reflection? We argue in this text that many influences (moral ecology, personality, skill) can do so. There is clear evidence that moral identity does not need to act alone. One person’s fragile network of self-­reflections in the table might spin apart as a result of a moral ecology of corruption. Or one can imagine the web of consistencies beginning to come together in a moral ecology that favors particular consistencies, such as restorative justice hearings. Of course, most moral Taking Moral Action ecologies contain both integrative and disintegrative influences (e.g. the complexity of a NATO study panel on nuclear technology). Still, one can likely cobble together a modest drive to unity from a wide variety of both internal and external influences. This is likely how most friendships, families, organizations, and societies survive. 4. A modest drive to unity may be enough to support consistent moral action. Moral identity is an important, and even crucial, influence on moral action. But it is rarely the moral hero standing alone in the gap. It provides internal resources for moral action when, because of its relevance in the situation, and sometimes despite the situation, it is called upon by individuals. But it is not always called upon, or it may often be called upon in different forms: the moral identity one has at work may be different from the one most prominent at home. Is consistency among this complexity a vain hope? We think not. There is ample evidence s of moral exemplars in a wide range of areas who are thoughtful and mostly consistent in moral action. Moral identity seems to play a central role in their action. of We have also reviewed here evidence that variation in moral identity is clearly associated with variations in moral action. So, the mere complexity of the task facing us is not cause for despair. As Frimer and Walker (2008, p. 346) argue, even a modest drive to unity, aided by self-­reflection, may be all we need. But the ro complexity is a caution that we need a better understanding of the task before us. We might instead, reconfigure the metaphor of “bridging the gap” into one of maintaining an ever-­changing network or weave of moral commitments and action. Who is the weaver? In Chapter 9, we argue that it is an active but not lP omnipotent moral self, navigating the world in response to a range of needs, constraints, and moral goals. 5.5.2 Application na “All I knew was that I wanted grace, and that I needed prayer, and that I was helpless without God, and that I wanted to do everything that people did to keep close to him” (Merton, 1948/1998, p. 329). This quote comes from Merton’s autobiography and is included in the first chapter of this book. It is a very personal description of his reasons for joining a monastic order. At least from this report, the entire self is Fi focused on the search for closeness to God. Nothing else matters. Yet Merton became a central figure in the peace movement in the United States in the 1960s. His overwhelming preference was to be a hermit, yet he was rarely allowed this luxury. Instead, he was told by his Abbot to write, since his writing was of such a high quality and so widely sought after. He was so deeply steeped in Christian monastic tradition and practice that even his turn toward those justice issues that were raging at the time (e.g. race and peace) was suffused with symbolism and language from that tradition. In a famous vision he had in 1958, at the center of the Louisville KY shopping district on the corner of Fourth and Walnut, he saw that everyone in the crowd of shoppers had the spark of God in them. “If only everybody could realize this!” he later wrote of this experience, “But it cannot be explained. There is no way of telling people that they are all walking around shining like the sun” (Merton, 1966, pp. 153–154). This mystical language has nothing of human rights or justice language in it, and yet it marks a turning point in Merton’s writing toward issues of justice, race, and ­opposition Moral Identity and the Self 135 to war. It is a complicated matter to explain how this strange language of people “walking around shining like the sun” connects to these moral issues and to Merton’s social activism. But it is at least clear that Merton’s moral action has different roots than a moral identity centered on principled justice reasoning. These roots are uniquely grounded in a specific tradition of language, narrative, and worldview where reform of the self, otherworldly desire for God, and social activism are often closely intertwined. There are consistency pressures within this moral ecology, but they are (often) not ones that valorize the self. One can multiply examples like this endlessly, showing that moral action is connected with a view of “a person like me in a situation like this” but that, from one actor to the next, this view is rarely the same in specific motivation and structure. And yet, at an abstract level, we will find things in this chapter that help us understand Merton’s moral action (e.g. Maslow and self-­transcendence). s"
5,5.5,"Discussion 5.5.1 Conclusion 1. The integration of morality into the self is important in moral action. Many research programs and theoretical models point to the importance of moral identity, the integration of morality into the self, as serving an important role in 29 There is a dark side to self-­transcendence (Koltko-­Rivera, 2006; Skitka & Mullen, 2002) so that simple self-­transcendence cannot serve as a marker of morality per se. 30 Again, see Chapter 9 for an introduction to the Walker and Frimer (2015) research program and a reprise of this discussion. Moral Identity and the Self 133 the springs of moral action. There are regular, moderate-­to-­strong effects of moral identity in shaping moral behavior, particularly when one matches the situation and behavior to the specific commitments of moral identity. The importance of matching the situation and behavior to specific commitments is parallel in structure to the patterns we found in Chapter 4. Indeed, they are likely the same findings, as the measures used in personality are probably tapping aspects of moral identity. There is, then, mounting and converging evidence that moral identity plays a crucial part in the processes that initiate, regulate, and maintain (or derail, degrade, and misdirect) moral action. Moral identity is not, of course, all that influences moral action, as the other chapters in this text will attest. There are likely kinds of moral action that are somewhat unrelated to moral identity (e.g. habitual action – see Chapter 6). But moral identity is a prime candidate for playing a central role in much moral action. s 2. The moral self is multidimensional and variable over time and domains. The multidimensionality of the moral self suggests that there is no single “bridge” of across a single “gap.” As the table of moral consistencies (Table 5.1) shows, there are multiple reference points (rows) against which one might judge a moral action, and then multiple modes (columns) in which this action might be interpreted in light of the reference point. The bridge and gap metaphor portrays an isolated ro individual vainly straining to overcome a gap between ideals and action, a gap that should not be there but constantly haunts the reflective actor (as the Apostle Paul was haunted). But it is far more complicated than this, and perhaps less dire. There is not one single value but a pluralism of values. And the values may be represented lP in a variety of ways in the complexity of the self and its representations of the moral ecology. Different aspects of the self become relevant as one navigates the moral ecology, and the self develops and changes over time as a result of these interactions and the ways they are evaluated. Finally, self-­reflection, the skill of evaluating the fit of one’s action to one’s moral identity is itself legion in its modes. In this na complex landscape, one should not be haunted by gaps but instead encouraged by woven networks of consistency that endure across the complexities of the moral ecology, of the self, and of self-­reflection (see Chapters 6 and 9). 3. Self-­reflection as a guide for moral action is very flexible. From the standpoint of behavioral integrity, this is both a feature and a bug. Fi The multitude of reference points and modes of comparison make the self-­ reflection process very flexible: a positive feature given the complexity of our moral ecologies and of how we think of our selves. It provides for coherence balanced by flexibility in how we adapt our selves to the complexities of human life. However, one can see this flexibility as providing too many opportunities for self-­serving interpretations of one’s actions. Chapter 7 provides an overview of some of the ways we use reason to construct consistencies that allow us to excuse or support immorality. What then supports the impetus for consistency in moral action that comes from self-­reflection? We argue in this text that many influences (moral ecology, personality, skill) can do so. There is clear evidence that moral identity does not need to act alone. One person’s fragile network of self-­reflections in the table might spin apart as a result of a moral ecology of corruption. Or one can imagine the web of consistencies beginning to come together in a moral ecology that favors particular consistencies, such as restorative justice hearings. Of course, most moral Taking Moral Action ecologies contain both integrative and disintegrative influences (e.g. the complexity of a NATO study panel on nuclear technology). Still, one can likely cobble together a modest drive to unity from a wide variety of both internal and external influences. This is likely how most friendships, families, organizations, and societies survive. 4. A modest drive to unity may be enough to support consistent moral action. Moral identity is an important, and even crucial, influence on moral action. But it is rarely the moral hero standing alone in the gap. It provides internal resources for moral action when, because of its relevance in the situation, and sometimes despite the situation, it is called upon by individuals. But it is not always called upon, or it may often be called upon in different forms: the moral identity one has at work may be different from the one most prominent at home. Is consistency among this complexity a vain hope? We think not. There is ample evidence s of moral exemplars in a wide range of areas who are thoughtful and mostly consistent in moral action. Moral identity seems to play a central role in their action. of We have also reviewed here evidence that variation in moral identity is clearly associated with variations in moral action. So, the mere complexity of the task facing us is not cause for despair. As Frimer and Walker (2008, p. 346) argue, even a modest drive to unity, aided by self-­reflection, may be all we need. But the ro complexity is a caution that we need a better understanding of the task before us. We might instead, reconfigure the metaphor of “bridging the gap” into one of maintaining an ever-­changing network or weave of moral commitments and action. Who is the weaver? In Chapter 9, we argue that it is an active but not lP omnipotent moral self, navigating the world in response to a range of needs, constraints, and moral goals. 5.5.2 Application na “All I knew was that I wanted grace, and that I needed prayer, and that I was helpless without God, and that I wanted to do everything that people did to keep close to him” (Merton, 1948/1998, p. 329). This quote comes from Merton’s autobiography and is included in the first chapter of this book. It is a very personal description of his reasons for joining a monastic order. At least from this report, the entire self is Fi focused on the search for closeness to God. Nothing else matters. Yet Merton became a central figure in the peace movement in the United States in the 1960s. His overwhelming preference was to be a hermit, yet he was rarely allowed this luxury. Instead, he was told by his Abbot to write, since his writing was of such a high quality and so widely sought after. He was so deeply steeped in Christian monastic tradition and practice that even his turn toward those justice issues that were raging at the time (e.g. race and peace) was suffused with symbolism and language from that tradition. In a famous vision he had in 1958, at the center of the Louisville KY shopping district on the corner of Fourth and Walnut, he saw that everyone in the crowd of shoppers had the spark of God in them. “If only everybody could realize this!” he later wrote of this experience, “But it cannot be explained. There is no way of telling people that they are all walking around shining like the sun” (Merton, 1966, pp. 153–154). This mystical language has nothing of human rights or justice language in it, and yet it marks a turning point in Merton’s writing toward issues of justice, race, and ­opposition Moral Identity and the Self 135 to war. It is a complicated matter to explain how this strange language of people “walking around shining like the sun” connects to these moral issues and to Merton’s social activism. But it is at least clear that Merton’s moral action has different roots than a moral identity centered on principled justice reasoning. These roots are uniquely grounded in a specific tradition of language, narrative, and worldview where reform of the self, otherworldly desire for God, and social activism are often closely intertwined. There are consistency pressures within this moral ecology, but they are (often) not ones that valorize the self. One can multiply examples like this endlessly, showing that moral action is connected with a view of “a person like me in a situation like this” but that, from one actor to the next, this view is rarely the same in specific motivation and structure. And yet, at an abstract level, we will find things in this chapter that help us understand Merton’s moral action (e.g. Maslow and self-­transcendence). s 5.5.3 Open Questions of 1. How do people navigate the multiplicities of consistency that the literature suggests? We have concluded that the moral self is multidimensional and variable over time and domains, and that there are many dimensions on which individuals can evaluro ate their own and each other’s behavior. We have also suggested, as in some idiographic personality models, that people will establish complex patterns of moral commitment and moral self-­reflection that will vary within these dimensions of the self and the moral ecology. It is these patterns that should have some modest relalP tionship to moral action. But how do people navigate this complex inner and outer landscape? Do some navigate it better than others? What does consistency look like in this complex landscape – a straitjacket for action or something necessarily more flexible? Are some moral ecologies better at supporting appropriate navigation? What skills and dispositions might help in getting better at navigation? And how na does this navigation relate to moral action? It is in the end an empirical question whether the moral sense is a fragmented collection with no center or a complex weave designed to fit a complex self and environment. 2. What are the different roles of the self in taking moral action in different moral ecologies? Fi How the moral self is constructed and construed, how it relates to cultural values, and how it is evaluated both by the self and others may all vary depending on the moral ecology. The larger cultural surround, organizational culture, and patterns of friendship may interact with each other in shaping moral action and its evaluation. We are beginning to get models of this interactivity of self and cultural surround, but these models have yet to connect to the models and approaches on moral identity, cognition, or emotion in moral psychology. 3. To what extent is the moral self active in maintaining webs of commitment and action? We have suggested it is time to reconfigure the metaphor of “bridging the gap” into one of maintaining an ever-­changing network or web of commitments, self-­ reflection, and action. This reintroduces the self as an active agent in its own moral behavior, thought, and feeling. And it allows us to ask how this activity acts together with the constraints placed upon us given our biological heritage and personality, our skills and habits, and the constraints and opportunities provided Taking Moral Action by our moral ecology. This interaction might have them at one time working together (choosing to follow organizational guidance), working in opposition (choosing to reform or subvert unjust laws), or acting in some complex dialectic (advocating that some praiseworthy voluntary action should be made into a requirement). We sometimes use the metaphor of navigation to think about the complexity here, a metaphor borrowed from Aristotle. When and how do actors monitor the interacting currents and winds of consistency? When and how do they, wittingly or unwittingly, modify their ship or steer against the wind? Are they only sailing alone? 4. How is moral failure integrated into the moral self in a corrective way? We have proposed that there is, indeed, some modest drive to unity in self-­reflection. But it is crucial that this modest drive responds to situations of inconsistency and moral failure. Weinstein et al. (2013) helpfully propose three integrative characters istics of self-­regulation that might support appropriate reflection on moral failure: (1) conscious access to one’s emotions, motivations and values; (2) taking responof sibility for one’s emotions, decisions, and thoughts; and (3) non-­defensiveness in response to challenge. As important as these are, they still leave the moral self isolated in its reflection. In Chapters 3, 6, 8, and 9, we have presented other influences and processes that might be helpful in understanding responses to moral ro failure and in designing small and large environments that are supportive of self-­ reflective response to moral failure. But we need systematic research in response to moral failure to bring the process into sharp focus. lP"
5,5.6,"Further Readings These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and na recent work. Complete citations are provided in the references section. • Blasi (1980). “Bridging moral cognition and moral action: A critical review of the literature.” The classic review of the problem of the judgment–action gap and the integration of the self as a helpful solution. Fi • Cervone (2021). “Five paths to personality coherence.” A parallel attempt to construct different aspects of how one evaluates personality coherence, and their interactions with situational context. It suggests the available resources and constraints as individuals search for authenticity. • Frimer and Walker (2009). “Reconciling the self and morality: an empirical model of moral centrality development.” An empirical paper that provides evidence that the relationship between the self’s interests and moral concerns ideally transforms from one of mutual competition to one of synergy. • Weinstein et al. (2013). “The integrative process: New research and future directions.” A guide to aspects of self-­regulation (awareness, ownership, nondefensiveness) that might help in maintaining integrity in evaluation of the self. • Three models of the self that are multidimensional: ◦◦ McGregor and Little (1998). “Personal projects, happiness, and meaning: On doing well and being yourself.” Moral Identity and the Self 137 ◦◦ McConnell (2010). “The multiple self-­ aspects framework: Self-­ concept ­representation and its implications.” ◦◦ Markus and Kitayama (2010) “Cultures and selves: A cycle of mutual constitution.”"
6,6.1,"General Skills s The skills associated with moral action can span the entire range from perception to judgment, planning, action implementation, and reflection. Most work in psychology of has been done on those skills relevant to moral judgment. We will look at this literature in Chapter 7. Here, we look at other general skills, including self-­reflection, self-­ regulation, and moral attentiveness. These are skills that are assumed to underlie all moral action. Finally, we look at the special skills and knowledge that belong to moral action in specific domains. ro We are interested in more than what is covered by the field of self-­regulation. But even if we were to limit ourselves to the traditional topics in self-­regulation, we face a distinct challenge. After more than a century of investigation of self-­ regulation, lP beginning with Freud’s (1895/2000) models of internal processes,3 “the self-­ regulation literature commonly is said to lack theoretical order” (Cervone et al., 2006, p. 333). In a short chapter, we cannot pretend to impose that order. Instead, we present here only a selective review most relevant to moral action.4 We have already noted that these skills of moral action need to be understood on na various levels. A common mistake is to focus primarily on conscious self-­control. Such approaches assume a central executive system that consciously guides thought, emotion, and behavior. But there is too much to do in everyday living for us to regulate it all consciously: “filtering, organizing, and integrating the vast array of different feelings, thoughts, needs, motivations, goals, norms, expectations, etc.” on an ongoFi ing basis, and also being reflective about those processes (Kuhl & Koole, 2004, p. 415). And even “executive function” is actually a diverse set of functions each of which develop in domain-­dependent ways dependent on “knowledge, beliefs, norms, 2 And this narrowing of the literature has in turn been supported by the structuralist foundations of Piagetian and Kohlbergian moral psychology (Narvaez, 2005). This old foundation assumes that the conceptual development that supports all morality is separable and unique from other forms of learning, such as expertise. This assumption is no longer widely accepted (Hatano & Inagaki, 2000, p. 267). Rethinking morality as skill will require a rethinking of these Piagetian foundations of moral psychology. 3 For modern explanations of what is now called self-­regulation, one can arguably go back even further than Freud, at least to Søren Kierkegaard (1849/2004) and his investigation of “inner movements.” More ancient distinctions go back to the stoics (Nussbaum, 1996). 4 See Vohs and Baumeister (2016) for a more comprehensive review of this literature. Skills and Knowledge 147 values and preferences” (Doebel, 2020). A set of theoretical approaches that take this complexity into account is “self-­organizing dynamic systems” (Carver & Scheier, 2002). Instead of assuming a hierarchical, conscious system, these approaches envision multiple psychological systems operating semi-­independently and interactively, at both conscious and nonconscious levels, both competing and cooperating.5 Integration among these systems is crucial to proper operation of all of the skills (including even the specific domain-­ relevant skills) we discuss in this chapter (Benita, 2020; Weinstein, Przybylski, & Ryan, 2013). We cover aspects of integration in Chapters 4, 5, and 9. There is a clear commonality here with the two-­process systems we cover in Chapter 7, though the number of systems is multiplied. In this chapter, instead of concentrating on cognition, we are primarily looking at how the skills of self-­regulation influence and guide our moral action.6 s 6.1.1 Self-­Reflection of By moral self-­reflection we mean the (mostly) conscious reflection and evaluation of the self and its skills, knowledge, emotions, values, goals, etc. that is done in the service of becoming a different kind of person or of maintaining consistency within one’s self.7 Narvaez (2010) calls this aspect moral metacognition, and treats it as essential ro to the high-­level monitoring needed to plan and sustain moral action (see also Kuhl & Koole, 2004; Walker & Frimer, 2009). As the “meta” suggests, these are about higher processes that are more conscious, controlled, and based in reasoning and reflection. This does not rule out an emotional aspect to evaluation, nor does it suglP gest that some evaluations (e.g. automatic reappraisal of emotions) might be so well practiced that they become automatic.8 In the longstanding person–situation debate, a simplistic view is to ask whether the situation or internal processes of the person has more control over behavior.9 A more sophisticated approach is to ask when, or under what conditions, the situation or na the person is more in control. Impulsive, intuitive action is often more controlled by the situation (Hofmann, Friese, & Strack, 2009). But this can be somewhat regulated by individuals taking precaution to remind themselves of prior commitments (Gollwitzer et al., 2011). Indeed, this is often what happens in the reappraisal of emotion: an initial emotional reaction is tempered by further reflection (Feinberg Fi et al., 2012). For our purpose, one may think of it as reappraisal focused particularly on self-­reflective emotional responses (e.g. Am I being proud in the right way?). Chapter 5 provides us with an idea of the structure and complexity of this process of self-­reflection. Table 5.1 in that chapter provides a multidimensional approach to 5 This approach sometimes seems quite Freudian, and prone to the same difficulties of ­taking proposed theoretical mechanisms and making them more real than they deserve. 6 See John Davenport’s excellent (2007) book on the will for a philosophical approach to this area. 7 We list self-­reflection independently of the self-­regulation category because its clearly conscious status – at least within the Kuhl and Koole (2004) taxonomy we are using – likely excludes it from lists of self-­regulation skills. 8 See Chapters 7 and 8 for suggestions about how this might happen. 9 See Chapter 4 for this debate. Taking Moral Action how one might evaluate one’s actions in the light of various standards. Thus, what one might think is a simple issue of evaluation (Is my action moral?) can in fact become quite psychologically complicated. Wrzus and Roberts (2017) provide a systematic way to understand how reflection on current experience can be transformed into personality change (Wrzus & Roberts, 2017). The core of the model is the transformation of immediate evaluative reactions to one’s behavior (e.g. I was not kind) into desired expectancies for behavior (I should be more kind) in similar situations in the future. This transformation is accomplished at both an explicit and an implicit level. At the explicit level, individuals consciously reflect on the triggering situation, cognitive and emotional state, and immediate reaction in a particular incident, or they later remember that situation and consciously reflect on it. I might, for instance, remember an action, be proud, and resolve to repeat it. Or when I fail to repeat it under relevant circumstances, I might s immediately feel guilt that motivates evaluative thought. In each of these examples, I might at the same time implicitly be forming associations of emotions, judgments, of and perceptions that can build up over time as I attempt to maintain consistency in my behavior. This change (or stability) in my evaluative and learning processes then shapes my expectation for the next occurrence of a relevant triggering situation, which in turn ro shapes my state and behavioral expression of that state. Over time, and many repeated cycles of these evaluative and learning processes, this may result in the shaping (formation) of my behavioral expressions and immediate reactions to them. This long-­term cyclical process can thus produce personality/character change. lP An important point about this model is that many “exit points” from the evaluative process exist in each daily experience. Each exit point allows for the individual to simply confirm that their expectations and reactions do not need to change. To confirm that they do not need to become more moral. Suppose I want to become a more generous person. Even if that is my intention, there are many ways for me to fail to achieve it. In na my daily (less generous) life, situations that unequivocally push for a change in my generosity may arise too rarely to help me practice the appropriate ­reactions and judgments and to reflect on that practice. Even when they do arise, I might not notice that a situation is relevant to my generosity. Or for a variety of reasons (available excuses, match to my expectations, etc.) I may not experience any of the moral emotions or judgments Fi that might lead to generosity, or I could notice the situation, react to it, and judge my reaction adequate or at least excusable (thus not leading me to form an expectation that I should be more generous later, in similar situations). Because of these many exit points, it is easier to maintain current personality characteristics than it is to change them: the accumulation of the exit points works toward maintaining stability.10 But persistent, systematic changes in the situation or consistent practice of the expectations or evaluations can produce personality change. Thus, substantial change in moral formation can occur, even in middle and late adulthood, if (1) enough opportunities occur that challenge existing frameworks; (2) the person 10 This model of many exit points is reminiscent of the Latane and Darley (1970) model of the numerous reasons that a bystander may not help in an emergency situation: not noticing, interpreting it wrongly, etc. Skills and Knowledge 149 Triggering Situation Expectancy State/State Expression s Reaction of Explicit, Evaluative Processes ro Implicit, Associative Learning Figure 6.1 A vastly simplified version of the Wrzus and Roberts (2017) model. lP experiences the states as novel and calling for self-­reflection; and (3) this happens frequently enough to become engrained (Wrzus & Roberts, 2017).11 This framework suggests how, in daily living (see Figure 6.1), consistent practice of shaping actual reactions and expectations in the image of one’s desired reactions can na shape moral formation.12 It recognizes that this change occurs at both the explicit, conscious level (e.g. using self-­reflection to alter goals, expectations, reactions) and on an implicit, nonconscious level (e.g. in learned associations or trained skills). And it proposes a set of conditions that lead to the most effective and lasting change. The impetus for such change can come from a variety of influences. It can come from Fi consistent personal intention to change, from consistent social pressure, or from life events that exert consistent pressure on the person or some combination of these and other influences. Indeed, the model is so open to different kinds of influences and changes, that it is somewhat unclear exactly what is changing over time. This may be the necessary price we pay for such multidimensional models: what is changing may differ from time to time and person to person. Tracking this complexity will require equally complex ­idiographic personality models like those we cover in Chapter 4. 11 We will suggest in Chapter 9 that some traditional approaches to moral formation try to produce moral ecologies that meet these criteria (see e.g. Chapter 9, Section 9.1.3 on Monastic Formation and Section 9.1.1 on Bildung). 12 Note that underlying this process are many of the skills of self-­reflection, self-­regulation, emotion regulation, moral sensitivity, etc. that we cover in this chapter. Taking Moral Action One can find similar but domain limited psychological models of evaluative moral formation in clinical psychology (Norcross, Krebs, & Prochaska, 2011), religious conversion (Rambo, 1995), and volunteerism (Snyder & Omoto, 2008). These alternative models provide suggestions for the richness and variation of the processes in different domains. The Wrzus and Roberts (2017) model is directed at the most abstract level of the processes and one may find the processes change dramatically in different moral ecologies (e.g. in more wicked or kind environments, see Section 6.3.1). 6.1.2 Self-­Regulation s The Mothers of the Plaza de Mayo were focused on calling attention to the plight of their missing children in Argentina.13 Even in the face of severe repression (several founders were themselves disappeared), they brought their cause to internaof tional attention and played a significant part in the eventual change of government. This is a story of extraordinary courage but also extraordinary skill (Thalhammer et al., 2007). None of this could have happened if the founders and their followers ro had not been able to organize themselves, plan and execute complex schemes, and adapt to disappointment, fear, and changing conditions. In addition to skill associated with community organizing, many of these skills are more basic strategies of self-­regulation. lP A comprehensive review of self-­regulation could fill a book (and has, Boekarts, Pintrich, & Zeidner, 2005). Suffice it to say that ability in each of these aspects is predictive (or perhaps constitutive) of mature functioning in life (Frimer & Walker, 2008; Mischel, Shoda, & Rodriguez, 1989) and can be increased through practice (Baumeister, Gailliot, & Tice, 2009; Förster & Jostmann, 2012; Lord et al. 2009). We use the term self-­regulation to gather together a set of explicit and na implicit skills in guiding the self in daily tasks.14 We will focus on three different aspects of this set of skills: • The self-­control system, that set of skills and associated standards, personality traits, etc. that help the person to focus on the task at hand, and to avoid distraction and Fi temptation (Kuhl & Koole, 2004). 13 See the Introduction for an overview of this movement. 14 There are numerous other models of self-­regulation. Some are, like Kuhl and Koole (2004), more friendly to the idea of some complicated version of “free will” while others are more mechanistic. But almost all reside within the domain of what philosophers call compatibilism, the idea that free will can be compatible with deterministic causality in human action. That is, most recognize deterministic limits on what can be “free” about free will, but also recruit deterministic processes (e.g. habit formation) in interaction with planned action to explain how free will is implemented in human (and perhaps other animal) action. See Kuhl, Quirin, and Koole (2021) for a recent overview in humans. See de Waal (2009) and Chapter 1 for the argument that extends these processes to some other animals. Skills and Knowledge 151 • The self-­maintenance system, that set of skills and associated standards that help direct the person in daily life to take action toward goals, standards, and values that matter to them (Kuhl & Koole, 2004).15 • Emotional self-­regulation, a set of skills that overlaps significantly with each of the first two systems and helps to motivate and structure the interaction between them and other aspects of moral life, such as self-­reflection and self-­formation. 6.1.2.1 Self-­Control The self-­control system has the function of inhibiting impulsive action and focusing on currently active goals. It is often reduced to what is misleadingly called “willpower.” The “willpower” metaphor suggests what has been called the ego-­depletion hypothesis: that there is a limited reserve of such power, that it operates the same in all domains, that it always involves conscious focus and effort, that some people have more of it, and that practice can help improve it s (Baumeister et al., 2009; Baumeister & Tierney, 2011; Weir, 2012). The effect is in dispute (Friese et al., 2019; Vohs et al., 2021) but may survive in some altered of form (Lin et al., 2020). Still, ego-­depletion (and willpower) is not all there is to self-­ control. Calling it the self-­ control system opens consideration for other processes that ­operate differently but serve the same function. For instance, in a meta-­analysis of 120 studies on self-­control, de Ridder et al. ro (2012) found dramatic differences in the effectiveness of self-­control in different domains. Self-­control’s effects on eating and weight were quite small, its influence on work and school were strong, and its effects on interpersonal goals (e.g. relationship commitment, parental supportiveness) were in between.16 They also found that peolP ple who are better at self-­control are not, by and large, better at resisting temptation (the classic willpower task) but more skilled at forming and breaking habits. For these people, self-­control is operating at the interface between system 1 and system 2 activity, between habitual, automatic action and conscious guided action.17 Thus, successful self-­control is strongly linked to using this skill to avoid temptation, rather than to na resist it (Ent, Baumeister, & Tice, 2015), and this may better be accomplished at the implicit, nonconscious, habitual level, guided by conscious efforts to cultivate (and weed) 15 For organizational purposes, we use the Kuhl and Koole (2004) distinction between Fi a system that is primarily about avoidance of distraction and temptation (self-­control) vs. a system that is primarily about achieving goals. We do not follow their theoretical approach in all its complexity but do adopt their suggestion that affect regulation is central in moderating among the various systems. One reason to use their approach is its openness to nonconscious ways of regulating emotion. We also emphasize various conscious meta-­ reflective aspects in this picture. These distinctions are shared among many theorists and are at least useful in bringing some order to the theoretical thickets of work in this area.There are many alternatives to the Kuhl and Koole (2004) approach. One advantage in adopting it in a book that uses virtue as a model is that it takes the notion of will seriously and does so in a way that allows for nonconscious volitional action. For alternative approaches, see Cervone et al. (2006); Shoda, LeeTiernan, and Mischel (2002); Ryan and Deci (2003); or Hofmann et al. (2009). 16 It is unclear where morality would fall in this set of domains. 17 Remember that system 1 is the one in which habit, implicit judgment, and nonconscious control of action are occurring, while system 2 involves conscious, effortful, reasoning, planning and implementation. See Chapter 7 for a review of these systems. Taking Moral Action one’s profile of habits.18 This is the origin of the standard advice that consistent weight loss is best effected by lifestyle change (the change of habits, surroundings, shopping, etc.) rather than by simple willpower (only eating very small portions of the cake and pastries that fill the refrigerator) (Rothman, Sheeran, & Wood, 2009). Thus, at its best, self-­control functions to avoid distraction and inhibit impulsive action. But it is most successful when it operates to avoid temptation (rather than to resist it); when it avoids the need to exercise willpower. One establishes eating habits that avoid certain foods, habits of friendship that avoid opportunities to practice racial prejudice, habits of association that encourage compassion, or habits of giving that encourage generosity. This strategic habit formation is not easy to do, and it is hedged around with the difficulties of situational pressure, opportunity, and available skill. However, deployed with the appropriate guidance of self-­reflection, it helps the individual to avoid distraction and to focus on desired activities and outcomes. It merges the s task-­focus of self-­control with the goal-­focus of self-­maintenance. of 6.1.2.2 Self-­Maintenance The self-­maintenance aspects of self-­regulation help focus the person on activities that are intrinsically rewarding or “congruent with a multitude of the person’s inner values and autobiographical experiences” (Kuhl & Koole, 2004, p. 416). It is less concerned with not doing (self-­ control’s domain) and more ro concerned with acting in the service of chosen goals, values, narratives, etc. It is positive doing. In our example of the Mothers of the Plaza de Mayo, it is less about resisting fear and more about engaging the community in action, or pursuing the goals of the movement. The difficulty, of course, is that there is indeed a multitude of lP such goals, including social disagreement about them. And many of these disagreements are deeply emotional and central to group identity and intergroup relations (Goldenberg et al., 2020; Porat et al., 2020; E. R. Smith & Mackie, 2008). The self-­maintenance aspect of self-­regulation must negotiate its way among these goals and around the numerous obstacles in the way (Duckworth et al., 2007). It is na the process of everyday negotiation of action in the service of multiple goals that constitutes self-­maintenance. The self-­maintenance system operates by integrating multiple aspects from cognitive and affective subsystems to support the intuitive control of goal-­directed behavior, control that is purposeful but usually not conscious. It is partly conscious in Fi making short-­term plans, but the cognitive structures that need to be accessed even in a normal conversation with friends (ideas, goals, values, expectations, norms, ­situational knowledge, etc.) are too extensive to be completely contained within conscious experience. If one were to constantly monitor these during conversation, one would become lost in thought. Conversation or other daily tasks only work because these networks are subconsciously explored and, if possible, integrated when there are conflicts. Thus, the self-­maintenance system helps to guide, shape, and maintain the engagement of the person in his or her daily life tasks. So, we have self-­control aspects of self-­regulation that focus on active suppression of action (e.g. not interrupting in the conversation) and self-­maintenance aspects that 18 Long practice of particular actions in religious contexts may make the burden of moral commitment lighter than it might otherwise be (Koole et al., 2010) Skills and Knowledge 153 guide action (e.g. listening carefully to another person).19 Then there are conscious self-­reflective aspects that focus on how one is meeting goals and standards. Do all these aspects run in parallel or do we switch among them? We really do not have enough data or theory to know. In some domains, like conversation, there may be some parallelism, but in others, such as skilled musical or surgical performance, the systems may be distinct. But one thing that does seem to be true is that emotion (and thus the emotion-­regulation system) is involved in signaling and negotiating the need to switch among systems and strategies (Alter et al., 2007). 6.1.2.3 Emotion Regulation When, while performing some action, it seems things are not going right, not on track to meet the goal, one often has a negative emotional experience. This emotion serves as a signal that something is not working in one’s action plans and performance (Alter et al., 2007). It signals the need to search for s options about why the uncomfortable feeling of “it is not working” has surfaced. It acts as an internal signal that something needs adjusting in order to obtain goals. of Thus, our emotional life and its regulation are central in helping us to become better at attaining our goals, and among them, our moral goals. But emotion regulation is a broader set of processes than simply those that serve us in pursuing our goals. We regulate our emotions whenever we find that we want to ro redirect the spontaneous flow of our emotions.20 Emotion regulation in the moral domain, then, at the least involves attempting to increase or decrease any of the moral emotions we list in Chapter 8. We might want to increase feelings of compassion to help us become a better person; or decrease feelings of compassion because they make lP us so uncomfortable. We may want to increase feelings of anger to make an impression in a protest against injustice; or decrease anger to facilitate our interaction with coworkers or family. And we do this for various reasons and using a range of strategies. Thus, there will be a range of motivations and strategies for regulating moral emotion. In an attempt to systematize the complexity here, Koole (2009) proposes na three different functions that emotion regulation can serve: goal achievement, hedonic need fulfillment, and personal balance maintenance. Focused, appropriate, 19 These two examples provide a nice picture of how the two “systems” can be distinFi guished. The phenomenological experience of trying not to interrupt is one of refraining from acting, even though one wants to. The intentionality is one of not doing something. The emotional concomitants may include frustration, and even a longing concentration on the forbidden desire. The experience of listening intently may also inhibit interruption, or at least transform it into backchannel expressions like “yes, uh-­huh” that focus both speaker and listener on the conversation. The phenomenological experience is also different. Not interrupting is consciously frustrating, while listening intently may be one of engagement or even flow. 20 One should be suspicious of thinking that emotions are spontaneous things that simply happen to us. Deeply ingrained patterns of emotional responding can feel spontaneous and still be both learned and changeable with practice. But talk about “regulating” assumes there is some process in which we want to intervene. These prior processes that produce or anticipate emotion are often called emotional sensitivity (Koole, 2009) or in the moral domain, moral imagination, ethical sensitivity, or habituated empathic concern (Narvaez, 2010). Thus, those “spontaneous” emotions can themselves be trained, as can the regulation of the spontaneous emotions as they arise. Taking Moral Action and balanced emotions are central to each of these functions. Regulation is achieved for each function by means of three different systems – guided attention, knowledge (reasoning and reappraisal), and body systems (manipulating food intake, exercise, attention to emotion expression) – that are engaged in that regulation. This produces a relatively complex grid of three functions crossed with the three systems that serve each function. And as always, the actual processes may not allow for such complex and clear distinctions to be made: systems and functions overlap.21 Meditation and mindfulness training can target the attention, knowledge, or body systems depending upon the form (Garland et al., 2015; Hölzel et al., 2011; Kok & Singer, 2017). There is some evidence that mindfulness practice leads to increases in compassion (Hölzel et al., 2011) or what Narvaez (2010) calls “habituated empathy” with changes, again, in all three systems: one becomes more aware, thoughtful, and responsive in those emotions associated with compassion. s Mindfulness training also brings awareness of subjective experience (again in all three systems) that can drive behavior change by producing a change in how one of perceives, values, and reacts to one’s habits, enhancing the likelihood of desirable change (Ludwig, Brown, & Brewer, 2020). Van Gordon, Sapthiang, and Shonin (2021) provide a review of the successes and controversies of meditation including concern over “McMindfulness,” and possible adverse effects. Some of these diffiro culties come from separating religiously and socially embedded practices from the practices and stances that originally surrounded and supported them (Condon & Makransky, 2020). Though this presentation of types and systems seems to provide clear guidelines for lP separating concepts, it is, as always, difficult to make the distinctions in the everyday world of moral action. Several of the strategies target multiple systems, and the types show conceptual and practical overlap. The categories also miss the social nature of emotion-­regulation: People often proactively control emotion by creating, modifying, or avoiding particular situations, thus intervening in the process before it has a na chance to begin. Or they spend time talking with others, regulating their emotion by sharing it in conversation (Wagner et al., 2015). Two final points about the skill of emotional regulation: First, changes toward more flexible and appropriate emotional regulation are clearly possible in adulthood. It has been shown that clinical psychological approaches like emotion-­focused therFi apy (EFT) can produce better emotional responding from clients with a range of emotional difficulties (Angus et al., 2015). Mindfulness and meditation programs show improvements in emotional functioning (Kok & Singer, 2017), gratitude training (Bono, Emmons, & McCullough, 2012), and various political consciousness-­ raising groups (Keane, 2015) all show the processes through which adults can change the ways they emotionally respond to moral issues. Second, as many of the examples show, this kind of emotional development does not simply mean restricting one’s emotional range. It can also mean deepening it so that one responds with more ­complexity and skill to situations (Frijda & Sundararajan, 2007). 21 See Koole (2009, p. 11 ff.) for an overview of these difficulties and detailed examples and research on the functions and systems. Skills and Knowledge 155 Self-­ regulation is a complex and ever-­ changing dance among self-­ control, ­self-­maintenance, and various strategies of emotional regulation. All these aspects of self-­regulation, in all their complexity, are skills that contribute to success in a variety of domains, and thus they can be practiced and improved over time with guided practice. We simply do not know enough yet to say which sets of skills are more easily improved, or how this relates to the moral domain in which they might be exercised. 6.1.3 Moral Attentiveness There is a skill involved in being regularly aware of and ready to respond to morally relevant situations. Narvaez (2010) calls this cognitive chronicity, taking the concept from the social cognition literature about mental models that are complex, detailed, and chronically accessible (Higgins, King, & Mavin, 1982). This is a skill aspect of s what, in Chapter 5, we call moral identity. Two of the defining characteristics of having a moral identity are that: one has a detailed and complex knowledge of the of domain;22 and this knowledge affects the sensitivity of the individual to relevant issues in their environment.23 Acquiring such skills is obviously part of the task of growing up (Eisenberg, 2005) and some adults clearly excel in this (e.g. Colby & Damon, 1992). In work on leadership in the military, Hanna and Avolio (2010) ro have called this cluster of skills and knowledge moral potency and shown its relationship to ethical values and behavior among soldiers. In work on organizational teamwork, Reynolds (2008) has used a similar concept, moral attentiveness, and shown its relation to recall of moral action, moral awareness, and moral behavior in teamwork lP as rated by teammates. The research on this skill is still somewhat scattered, but the cognitive chronicity approach of Narvaez (2010) provides a useful way of identifying its components and developmental trajectory. 6.1.4 Moral Imagination na Moral imagination is the skill needed to imagine alternatives after one has noticed that there is some moral choice to be made. It is a term used more in business ethics (Preti, 2014; I. H. Smith et al., 2023) and technology ethics (Crowell, Narvaez, & Gomberg, 2004; Friedman & Hendry, 2019; Pritchard, 2001) than in psychology, Fi where the idea is fragmented into theory of mind (Gray, Young, & Waytz, 2012; Hudac & Sommerville, 2020; Wellman, 2018), empathy (Decety, 2021; Depow, Frances, & Inzlicht, 2021; Fowler, Law, & Gaesser, 2021), and option choice and evaluation in decision-­making (Galotti, 2007; Morris et al., 2021). It is limited by goal and motivation, as we characterize it in Chapter 9, Section 9.3.1.3 (Opotow, 2010). Part of the point of moral exclusion is the removal of the need to exercise moral imagination on their behalf. Moral imagination is also quite bounded 22 But remember that domain can be quite limited. Morality (and moral identity) may be limited to only one aspect of an individual’s life, and this can result in inconsistencies between domains, such as work, charity, and family (Colby & Damon, 1992). 23 The third aspect of moral identity is that it is closely linked to the individual’s view of the self (Lapsley, 2008). Taking Moral Action by knowledge and expertise in the specific culture, domain, or situation as we discuss in the next section. 6.2 Domain-­Specific Skills The skills covered so far seem relevant in a wide variety of situations and domains. But there is ample evidence that these skills alone are not sufficient when one is participating in a particular domain of life. One needs skills relevant to each domain. It is possible that the general moral skills may be prerequisites for, or lead individuals to more quickly acquire, the domain-­relevant skills.24 Obviously, domain-­r elevant skills will be particular to each domain, and since the domains are legion in number, so too would be the skills. Generalizing s across domains, one might find similarities in these skills, but these similarities would need to occur at a higher level of abstraction, and the skill may not be of able to be taught at this level of abstraction. This is interesting speculation, but there is very little work even on domain-­r elevant skills to support it. There are some particular examples of what we might mean by domain-­r elevant skills. For instance, when the philosopher Michael Pritchard interviewed moral exemplars ro in the engineering professions, he found that the virtues they listed contained some standard suspects (e.g. honesty, courage) but also quite specific skills, such as “a habit of documenting work” (Pritchard, 1998, 2001). Moral exemplars in computing make little distinction among moral, social, and technical lP skills, often claiming that all were interrelated (Huff & Barnard, 2009). And experts in the ethical issues of computing use domain related knowledge (e.g. data privacy) far more than novices do (Keefer & Ashley, 2001). One presumes that expertise consists in part of having these intermediate knowledge structures available and ready to use. Work in addiction recovery (Bernheim, 2004) na shows that specific skills of understanding and managing susceptibility to relapse are crucial in recovery. Skills like social networking and negotiating are what Thalhammer et al. (2007) refer to as internal resources in their model of what influences the action of courageous resistors, such as those who sheltered victims of the holocaust. Snyder and colleagues’ model of volunteering sugFi gests that one of the reasons people volunteer is to learn skills they might not find elsewhere (Snyder & Clary, 2000; Snyder & Omoto, 2008) and have a chance to practice them to increase expertise. Thus, there is something special about the domain-­specific knowledge that experts bring to a (moral) task that matters. In Section 6.3, we try to uncover what that is. 24 This is similar to Aristotle’s thought when he says that one must have had the right kind of upbringing before one can learn the virtues (Aristotle, 1941, NE 10.9 1179b4-­31). But we do not know of any research that would document this. Skills and Knowledge 157 6.3 Expert Performance We can think of excellence in moral acting as the achievement of expertise in a domain (Dreyfus & Dreyfus, 2004; Narvaez, 2005, 2010). The model of moral action as expertise conforms well to the recently resurgent idea of moral action consisting of the exercising of the virtues (Annas, 2006; Anscombe, 1958; MacIntyre, 1981). Like virtue, expertise is a characteristic of the individual and can be held at various levels of excellence. Like virtue, expertise consists of habitual and even automatic ways of performing certain tasks, and these ways can be acquired through practice. It is likely that descriptions of an individual as “having” a virtue (e.g. honesty) are actually descriptions of a characteristic way of acting well (acting in an expert manner in regard to being honest), rather than descriptions of a characteristic the individual “has” that s causes virtuous action.25 The expertise model of morality thus sees consistent moral action as the use of skills to strive for excellence with regard to particular (moral) goals in a particular of domain. The caveat regarding the nature of goals is important here. It has been shown, for instance, that mentoring in service of exclusively success-­oriented goals can lead young scientists to actually care less about moral issues, and be less moral ro in their practice of science (Anderson et al., 2007). As discussed in Chapter 5, one can have many other goals than moral ones, including enjoyment, sociality, and achievement (McGregor & Little, 1998). All people, even psychopaths (Skeem et al., 2011), have some of the skills associated with achieving moral goals, and lP need them in order to navigate our shared social life. But moral exemplars, individuals recognized for excellence in striving after moral goals, have achieved high levels of expertise in these skills. Narvaez (2010) makes the analogy with music. Everyone appreciates and participates in music to some extent, but few of us have extensively practiced both the appreciation and performance of music: these are experts. The literature on expertise na presents some consensus on the differences between novices and experts who: 1. Have more and better organized domain knowledge (declarative, procedural and conditional). 2. Perceive and react to the world differently, noticing detail, risk, and opportunity. Fi 3. Act in the domain in an automatic and effortless way, when things are normal. Common to all the models is the idea that expertise can be learned over time, with practice and appropriate feedback (Dane, 2010). This learning arc was noticed long ago by Zeami (Motokio, 1400/1984) who cataloged the developmental progression of expertise in his medieval treatises on Japanese Noh theater. According to Zeami, 25 Hulsey and Hampson (2014) have proposed a model of virtue as composed of habits and expert skills. They combine these under the idea of Habitus, borrowing from both Thomas Aquinas and the early emotion researcher Magda Arnold (Arnold, 1960) who based much of her theorizing on Aquinas’ Habitus. Their model is consistent with much of what is presented in this text. Taking Moral Action the rules that the beginner obeys (Shu) are “beautiful fictions,” and with practice the novice can advance to the stage where the practitioner can detach (Ha) from the rules and break them intentionally in the right circumstances. True experts transcend (Ri) the rules, and even though they may seem to violate them, their action can propose the modification of the rules (Murata, 2010). This Shu–Ha–Ri progression has been taken up in the martial arts and in computer science (Boehm & Turner, 2003) to describe levels of mastery. But can we really speak of expertise in the moral domain? Narvaez (1998) compared moral experts and non-­experts and showed the experts behaved like experts in other well-­studied domains (e.g. chess). Given complex moral narratives to read, they gave more explanation and total expressions, showed deeper understanding and engagement in texts, disagreed with the narrative of text more often, and had more and better organized logic. Following the chronicity metaphor of expertise, Narvaez s et al. (2006) showed that moral “chronics” respond faster and make more dispositional inferences when making judgments about morally relevant stories.26 Similarly, people of with higher moral reasoning scores showed a better recall of moral arguments in texts, and particularly better recall of more complex moral arguments (Narvaez & Gleason, 1995). This research program makes the case that at least some aspects of moral skill and knowledge follow the patterns one would expect from the expertise ro literature. And the use of expertise models in applied domains with clear moral relevance (Dane, 2010; Moulton et al., 2007) shows that others find the model a useful way to think about morally relevant action. Box 6.1 shows the model of “mature moral functioning” Narvaez (2010) has lP developed from her research program. The complete model of moral expertise depicts moral experts as different in perception, cognition, action, metacognition, and meta-­ action. This kind of comprehensive expertise is based in extensive practice within a domain of morality (e.g. within a profession or calling). This facilitates the expert’s ability to be a more sensitive perceiver of ethically relevant occurrences, a more creana tive proposer of action plans, a better implementer of those plans, and a more thoughtful planner and networker in shaping the moral ecology. This expansive, and even ideal, model of moral expertise is still limited by the recognition that moral expertise is typically developed within a domain. Even these highly skilled moral experts are limited in their expertise to those aspects of their Fi world to which they have dedicated themselves. The work on moral exemplars seems to support this segmentation of moral expertise. People recognized for high moral achievement in social service or in a profession are often not such high achievers in other domains of their lives (e.g. their families are regularly negatively affected). It is unclear whether this neglect comes from inevitable competition for limited resources, lack of ethical commitment to domains other than the chosen one, or lack of some skill in the less well-­practiced domain (Lapsley & Narvaez, 2006, p. 253). One difficulty of the model of expertise provided here is that at times it seems to locate the action of expertise almost entirely in automatized responses to the 26 The term “chronics” is taken from the social cognition literature to refer to individuals whose mental models for a particular domain are most complex, detailed, and chronically accessible (Higgins et al., 1982). Skills and Knowledge 159 Box 6.1 According to Narvaez (2010, p. 172), mature moral ­functioning involves: • Basic socialization generally expected of adults (e.g. emotion regulation) • Basic habits and disposition conducive to self-­development • Moral imagination • Ethical expertise in a particular domain (e.g. a profession, or community service). Including • greater skills in ethical sensitivity • ethical judgment • ethical focus s • flexible adaptation within networks of relationships • individual capacities for: of ◦◦ habituated empathic concern (targeted feelings of compassion combined with a sense of responsibility and propensity to act) ◦◦ moral metacognition (manage and complete tasks, monitor progress, adapt plans and strategy), including moral locus of control, moral self-­ ro monitoring, and moral self-­reflection • collective capacities for: ◦◦ moral dialogue, commitment to and skill at initiating and supporting community dialogue about moral action lP ◦◦ moral institutions, the construction, maintenance and reform of social institutions This expertise looks different in every individual, and any particular moral expert cannot serve as the model for how all should operate. Note also that Narvaez (2010) conceives of moral expertise as occurring within domains, na rather than being a more general, cross-­domain expertise. ­environment.27 This may be because the model is based on the work on expertise by Dreyfus & Dreyfus (2004). Their model sees expertise as consisting primarily of highly Fi practiced perception–judgment–action routines that develop over time. In the Drefus & Dreyfus (2004) model, these routines are seen as flexible and working under most circumstances. But what happens when they do not work?28 We will look in detail at this issue in Section 6.4. For now we should note that the ability to be aware of the situation and to recognize when ordinary, practiced, expert routines are not working is itself a part of expertise, as is the ability to be reflective about the breakdown and to do appropriate puzzle-­solving when normal solutions do not work (Moulton et al., 2007). 27 Though Narvaez (2010) is very explicit about the roles for thoughtful, conscious guidance of action. 28 Dreyfus and Dreyfus (2004, p. 256) do note that “in familiar but problematic situations, the expert deliberates about the appropriateness of his or her intuitions.” They do not give much explanation about how this deliberation works but they admit that “expert deliberation is not inferior to intuition” (p. 255). Still, to say that it is “not inferior” is small praise. Taking Moral Action 6.3.1 The Development of Expertise Dreyfus and Dreyfus (2004) propose a five-­stage model of skill acquisition. They begin their analysis with two morally neutral skills, driving and chess, and go on to consider the pattern of acquisition in the domain of morality.29 The five steps along the continuum of expertise they describe are: 1. Novice: action is guided by context-­free situational features and rules for determining actions based on those features of the situation. This simplistic approach fails in complex contexts. 2. Advanced beginner: guidance for action begins to be based in recognition of aspects of the context. At this level, maxims (e.g. make things as simple as possible) replace context-­free rules. s 3. Competence: the multiplicity of features and aspects that one must consider, even given maxims to help sort them, begins to overwhelm judgment because of comof binatorial explosion. Hierarchical structures based on an individual’s goals for that situation are imposed to limit the complexity. Goal choice is emotionally fraught because there is a lack of clear rules at this meta level. 4. Proficiency: action is guided by the adoption of a perspective that guides choices ro among higher-­level goals. Flow in the task become continuous but is still punctuated by conscious planning and effort. 5. Expertise: “Normally an expert does not deliberate. He or she neither reasons nor acts deliberately. He or she simply spontaneously does what has normally worked lP and … it normally works” (Dreyfus & Dreyfus, 2004, p. 253, ellipsis in original). The stages are not discontinuous, and in appropriate environments, this development of expertise proceeds in tandem with appropriate practice. One can, for instance, see advances in expertise in the processing of moral discourse develop across c­ hildhood na (Eisenberg, 2005; Narvaez & Gleason, 1995). Kind environments (Hogarth, 2001) provide support for the development of such expertise. Weather forecasting and sports are such environments, providing unambiguous, rapid feedback of success or error, and giving rise to internally consistent and externally valid mental models and intuition. When coupled with coaching in both practice and theory, these environFi ments can support rapid expertise development. Wicked environments, on the other hand, do not provide the feedback needed because, for instance, definitions of success are malleable and feedback is ambiguous, difficult to recognize, or easy to reinterpret.30 This makes it difficult to get (and easy to avoid) the feedback that can inform expert performance. Given a kind environment, deliberate practice is necessary but not sufficient to achieve expert level performance. Campitelli and Gobet (2011) suggest it requires approximately 3,000 hours of deliberate practice, but this number varies tremendously (e.g. from hundreds to more than 20,000 hours to achieve master levels in 29 But virtue ethics suggests that even these skills in a domain of practice are not morally neutral. 30 This leads to the interesting and ironic hypothesis that the domain of morality may be wicked in this technical sense. Skills and Knowledge 161 chess). This wide variability may be explained by individual differences in ability, sensitive periods for development (Campitelli & Gobet, 2011), and coaching ­ (Hogarth, 2001). These numbers are likely to also vary widely by domain, and expertise may well not be a linear function of hours of deliberate practice (Campitelli & Gobet, 2011). One skill might be easy to learn at rudimentary levels (e.g. English) but difficult to excel at, while another may pose difficulties from the very beginning (e.g. Chinese). Where does morality stand in this? We do not know. The idea of morality as an expertise is still too young for these questions to have been investigated. 6.3.2 Automaticity in Expertise There appears to be an odd irony in the Dreyfus and Dreyfus (2004) presentation of s this progression in expertise. At the highest levels, automaticity rules performance, and the expert seems to do best when thinking least. This is a provocative idea, but of there is some evidence to support it. Hassin and Bargh (2009) provide evidence that automatic processes do not need to be rigid and inflexible. Automatic-­level goals can facilitate flexible action to achieve them, and automatic-­level routines can even help resolve self-­regulation dilemmas. One advantage of the automatic level of processing ro and action guidance is that it uses less energy, and thus frees the actor to concentrate on other things (Schmeichel, Vohs, & Baumeister, 2003). There is still controversy on the ways that goals and automated skills interact (Kruglanski & Szumowska, 2020; Mamede et al., 2010; Wood, Mazar, & Neal, 2021) but it lies with an agreement that lP a goal-­flexible, adaptive automaticity could underlie expert negotiation of difficult tasks (and thus difficult moral tasks). In Section 6.4 we will look at another model of expertise that makes knowing when to drop out of automatic processing into deliberative processing a central aspect of expertise. na 6.3.3 What Knowledge and Skill? What kinds of skills and knowledge does one learn as one becomes more morally expert? The traditional Piagetian approach (Hatano & Inagaki, 2000; Narvaez, 2005) saw advancement driven by cognitive capability in foundational logical-­mathematical Fi operations. Advance in these operations supposedly produced advances across all domains of thought and action. This hierarchical structure is no longer viewed as valid in most circles (Hatano & Inagaki, 2000; Lapsley & Narvaez, 2006).31 Most work on conceptual development now sees it as similar to expertise in a domain, within the multiple domains of knowledge and action in our lives.32 So, the first broad answer to the question is that it will be knowledge and skill relevant to the domain of morality, and perhaps with regard to morality within a specific domain of action, such as a profession or one’s family of origin. This does not seem like a remarkable statement unless one reflects on the short history of developmental theory outlined here. 31 This change is one reason behind the move to the “neo-­Kohlberg” theory that depends on concepts like schemas and expertise (Narvaez, 2005). 32 We should note that there is some dispute among philosophers about whether knowledge is a necessary component of a virtue (Winter, 2011). Taking Moral Action Beyond this quite vague description, can we specify what kind of knowledge is involved in expertise? Narvaez (2005) uses schema theory taken from Marshall (1995) to construct a model of moral skills and knowledge for the purpose of teaching them. She lists four types of knowledge: 1. Identification: knowledge of essential elements of the domain so that one can identify them. 2. Elaboration: knowledge that enables creation of a situational mental model. 3. Planning: knowledge of how to combine what is known to form expectations and make plans. 4. Execution: knowledge to guide the execution of plans and their revision when things go wrong. s Can one obtain reasonably valid descriptions of the relevant skills and knowledge in a domain? Much research in organizational psychology shows we can get reasonaof bly valid descriptions of the skills involved in particular jobs (Fleishman & Mumford, 1991; Fleishman et al., 1991). In the domain of morality, attempts have been made to catalog and validate skills involved in moral judgment (Wainryb & Brehl, 2006) and moral behavior among school children (Narvaez, 2006). Lists of ro moral skills and knowledge have been developed for various professions, including computing professionals (Huff & Martin, 1995), dentistry (Bebeau, 1994), and medicine (Pinijphon, 2009). How do these skills and knowledge differ between novices and experts? Keefer and lP Ashley (2001) asked experts in engineering ethics and undergraduate students in engineering to write responses to complex cases in engineering ethics. They found that expert ethical thinkers in this domain were more likely to: • appeal to middle-­level principles that identify role-­specific obligations (e.g. due na diligence in safety inspections) • make greater use of professional knowledge in order to recognize moral issues and relevant facts (e.g. knowledge about interactions among safety aspects of particular systems) • employ more contextually sensitive reasoning strategies when crafting resolutions Fi including: ◦◦ identifying alternative moral issues ◦◦ assessing the moral implications of actions ◦◦ providing “alternative practical resolutions” One surprising aspect of the findings is that novices in the domain tended to use the more abstract, “philosophical” reasoning strategies, while domain experts (many of whom were philosophers) used middle-­level concepts and role-­specific obligation to identify problems and think about the cases. The discussion so far makes it seem as though the skills and knowledge outlined here are entirely the work of the isolated individual. But at least some of the skill one has in identifying moral issues comes from knowing how to interact with others to investigate and understand their perspectives. Similar social skills can be found in each of the categories listed earlier. Chapter 3 makes this point in detail. Skills and Knowledge 163 6.3.4 Domain Specificity We have already noted that expertise is domain specific. This is in part what one means when one speaks of expertise – expertise is always expertise-­in-­something. The virtues that moral exemplars in engineering listed for other engineers include more general items such as integrity and courage, but also domain-­specific items like “habit of documenting work” and “competence” (Pritchard, 1998, 2001). One of the computing moral exemplars that one author (CH) interviewed commented that technical and creative incompetence can produce additional ethical temptation to cut corners and to do sub-­par, unethical work (Huff & Barnard, 2009). Others have noted that moral exemplars in social service often find themselves regretting the ways they have treated their families. Colby and Damon (1992) speculate that this is not a simple case of not having concern for their families, but more s likely a result of conflict among moral goals given limited resources. They base this hypothesis on the ways their exemplars spoke about valuing their families’ welfare, of feeling compelled to spend time on their other moral commitments, and feeling guilt and distress over the neglect this produced. Given the inevitable limited resources individuals have, it seems reasonable there might actually be competition among domains (Lapsley & Narvaez, 2006). So, at least in this case, it may not be a lack of ro skill in the domain of the family that produces the neglect. But if resource limitations lead to less practice in one domain (e.g. family) it may lead to less knowledge about that domain and less skill in practicing in that domain. Thus, those led to neglect a domain may find themselves less able to practice in it when they do finally find the lP time; and they may find their well-­honed skills in other domains less successful than they might hope. 6.4 Habits na When one speaks of habits, the term is often modified by an implied “bad.” But in his Nichomachean Ethics, Aristotle suggests that the virtuous person was prepared (or “cultivated”) for virtue by learning good habits (Aristotle, 340 BCE/1941, NE 10.9 1179b4-­31). The importance of habits for moral behavior can be seen from how Fi much of our overall behavior they control. In experience sampling studies, habitual actions comprise 45% of everyday activity (Neal, Wood, & Quinn, 2006). In the psychological literature, habits are “automated response dispositions that are cued by aspects of the performance context” (Neal et al., 2006, p. 198) and in terms of value may be good, bad, or indifferent. Habits can be simple aspects of our daily routine (e.g. how we squeeze the toothpaste tube) or they can be relatively complex parts of an expert routine (e.g. an engineer checking for safety in the interactions of components). But to count as habitual, they must operate primarily automatically and be controlled by cues in the individual’s context. They are learned by repetition in a similar context so that procedural memory – that aspect of memory that stores and controls action sequences – is “cognitively tuned” to both the context and the response. This suggests their relationship to expertise: those parts of expertise that can be described as “automated response dispositions” can be thought of as habits. But as we will see, expertise is more than a collection of habits. Taking Moral Action Still, even habits are not simple chains of stimulus–response links without representations of the environment or goals. There are roles for consciousness, goals, and motivational states in habits (Neal et al., 2006). At the simple habit level, Rothman, Sheeran, and Wood (2009) propose a model of habit change that includes both automatic and controlled processes that regulate eating behavior at different times in the behavior change process. Some habits are controlled almost entirely by performance context cues. Others are not always performed in a particular context but their performance can be triggered, without conscious intervention, by particular goals in the appropriate context. The more a habit is under the control of environmental cues, and the more highly practiced it is, the more difficult it is to intentionally alter (Neal, Wood, Labrecque, & Lally, 2012).33 When a particular action only occurs rarely, or is performed in complex interaction with goals and contexts, it may require a great deal of practice to become s habitual (Neal et al., 2012). This helps to make sense of the long practice times required to cultivate expertise, which will consist of a multitude of habits that are of integrated with both goals and contexts. One advantage of the mostly automatic nature of habits is that they do not require much in the way of cognitive resources (Neal et al., 2006). In complex or stressful contexts, this leaves the actor with the cognitive resources to concentrate on other ro aspects of performance. Of course, if the habit is not appropriately sensitive to context changes, it may be performed at inappropriate times. Expertise may consist in part of tuning habits so that they are expressed only in the appropriate contexts. The lack of such tuning is called “cognitive entrenchment” in the organizational literature lP (Dane, 2010).34 6.4.1 How Are Habits Regulated? na The appropriate integration of habits into expertise requires that they be sensitive to goals and contexts, even if they are so well learned that they are automatic in activation and execution. Neal, Wood, and Quin (2006, p. 200) call this process of integration Fi 33 In the habit literature, habits that are always performed in a particular context are termed “strong” habits while those that are deployed depending on the goal and the context are called “moderate strength” habits. This language is one of the last vestiges of the behaviorist interest in habits, and it can be misleading. It considers habits as isolated units that are stronger or weaker, rather than as possibly integrated units in a larger expertise in a domain. One might easily call habits that are activated only in the appropriate context “flexible habits,” or even “strong habits,” because they are tightly integrated into expertise. 34 This detachment of habits from context has the ironic effect of making habits feel unconnected to the sense of self. Thus, people think their non-­habitual actions are more informative about who they are (Neal et al., 2006, p. 201). This is perhaps because the self is autobiographical and more dependent on declarative, narrative memory. This disconnection of habit from the self could be one reason for the “humility” shown in exemplars. It might also help us understand why we think our judgment in difficult (non-­automatic) situations is the marker of our moral character rather than the developed automatized skills of moral expertise. Skills and Knowledge 165 self-­regulation,35 and note that it consists of “monitoring and adjusting responses in the service of the self.” But if habits are automatic, how can this kind of self-­regulation interact with them? One suggestion is that the perception of some metacognitive difficulty or disfluency in the process is a cue for conscious intervention (Alter et al., 2007; Moulton et al., 2007; Neal et al., 2006). For instance, when an individual has multiple goals, these can conflict with each other and activate competing responses. When complex contexts activate competing habits, this too may cause disfluency. Or when a goal is blocked (perhaps by some conflict with the context, such as a pattern of data that does not fit with a medical diagnosis) disfluency may be experienced. Thus, experts need to use markers of disfluency (Moulton et al., 2007) to break out of automatic routines and respond consciously to these difficulties. Moulton et al. (2007) have a model of “slowing down when you should” and their model of s expertise showcases the ability to switch back and forth from automatic to controlled processes. Their work is based in research on medical expertise, and they draw from of a model of expertise by Schön (1984) taken from engineering, architecture, management, psychotherapy, and town planning. In contrast to the Dreyfus and Dreyfus (2004) model mentioned earlier of “doing what normally works,” they ask how expertise copes in extraordinary circumstances. They mark the ability to switch back ro and forth from automatic to controlled process as the critical skill needed for expertise in extraordinary circumstances. This ability to self-­ regulate is facilitated by awareness of the situation that allows detection of disfluency, the connection of that disfluency to situational parameters, and the initiation of appropriate corrective lP action (Alter et al., 2007). The expert then has a well-­practiced controlled process to search for alternative solutions to the issue, both naming the difficulty and framing it, placing it in the larger picture of the situation and goals (Schön, 1984).36 Some of the psychological processes underlying this flexibility of automatic action have been described by De Neys (2012, 2021), though again there is disagreement over how na the processes play out (Kruglanski & Szumowska, 2020; Mamede et al., 2010; Wood et al., 2021). Another sort of disfluency can come from recognition that one’s performance in different domains is differentially successful. One barrier to the sort of integrity that is achieved from cross-­domain consistency is competition between domains. Fi Competition can arise from simple conflicts for limited resources (e.g. time) or from more complex conflicts when the goals associated with different cultural or personal domains are in conflict (Schwartz, 2010). When we speak of moral integrity (Mumford et al., 2001; Paine, 1994; Pritchard, 2006), we often refer to consistency in value commitments or consistency of behavior with a particular value commitment (see Chapter 5). But if we think of moral action in the context of domain dependent expertise, it becomes clear that one might have commitment to a domain but not the requisite level of expertise in it. And one can thus speak of 35 Note that this is a different use of the term than what we have used in Section 6.1.2. It is not unusual for such terms to be treated slight differently by different authors (see, e.g. the table of definitions for moral psychology in the Introduction). 36 This process is reminiscent of the hermeneutic framework that Gadamer (1996) provides in his work on medical practice. Taking Moral Action lack of skill as a threat to integrity. Integrity can be threatened by the inevitable competition for limited resources, or from a lack of ethical commitment to domains other than the chosen one, or from a lack of some skill in a less well-­practiced domain. Restoring integrity, then, involves the skill of recognizing the disfluency and moving to address it. The expert has the cognitive capacity to be aware of disfluency and situational context in part because the automatized habits require little capacity to run. Habits are thus a two edged sword: they can both free the expert to respond flexibly to the extraordinary (Moulton et al., 2007) and trap the expert into routines that are not appropriate to the context (Dane, 2010). s 6.5 Skills Go Awry of Finally, we must make a comment about the moral in the phrase moral skill. What is peculiarly moral about these skills? Psychopaths can exhibit significant self-­ regulation skills in the service of their goals, but still show “feckless disregard” and meanness toward others (Skeem et al., 2011, p. 107). This seems to be based ro in the facet of psychopathy associated with sensitivity to norms (Luke, Neumann, & Gawronski, 2021). The classic work on German police participation in the final solution describes at least one subset of the most efficient “Jew-­ hunters” as having particular emotional regulation skills that allowed them to dislP tance themselves from their work (Browning, 1992, p. 127) and thus to participate willingly in mass murder. Thus, the relationship between morality and the skills and expertise we outline here is at the very least complex, if not contradictory and dialectical.37 Skills and knowledge can be separated from morality and can indeed serve immoral ends. As we have na seen in the various models of moral exemplars (e.g. Colby & Damon, 1992; Walker & Hennig, 2004), moral action and its influences are characterized by equifinality – the same moral action can come about in many different ways. And any particular influence (e.g. a skill, a personality characteristic, etc.) is multi-­final – it can support or contribute to a range of both moral and immoral action. But in most instances, Fi absent moral luck (Nagel, 1979; Williams, 1981), moral actors must have some skills to successfully obtain their goals. Thus, if we want to understand, and ultimately to help develop, successful moral action, we will want to understand the role that skill plays in it. A final thing to note regarding the moral reach of skills is their seeming domain specificity. Even more general skills, such as emotion regulation, can manifest differently in different life domains (Harley et al., 2019). And one can easily imagine that things like moral attentiveness, the ability to recognize moral issues, would depend on knowledge and skill in the particular domain in question (e.g. Nathaniel Borenstein’s recognition of the dangers of particular military software). 37 See the discussion on this in Chapter 9. Skills and Knowledge 167 6.6 Discussion When we include taking action in the domain of morality, expertise based in knowledge, skill, and habit becomes immediately relevant. This approach is both a description of how one operates in a domain and a description of an ideal state toward which one constantly strives. How might this change our picture of moral action? 6.6.1 Conclusion 1. Principled decision making is likely not the primary path to taking moral action. Moral judgment and moral decision-­making may be important skills when operating in difficult situations, but much skilled moral action is not consciously guided. s From the perspective of skill, expertise, and habit, conscious moral judgment and decision-­making of the sort that is measured in moral reasoning tests is likely an exceptional occurrence. Moral acting in everyday life may more often consist of of automatically or habitually pursuing a moral goal rather than constantly deliberating about moral dilemmas. Principled decision-­making may not be primary in terms of being learned first, or in ro terms of being foundational. It is probably one necessary but not sufficient ingredient in the ongoing behavior stream of expertise. It may be most likely to be called upon when some disfluency occurs in action that needs resolution, but even then it may involve intermediate level knowledge in a domain rather than any return to foundational ethical principles. The only way you can claim that principled decision-­making is lP the primary path to moral action is to define moral action as action that occurs based on principled decision-­making. And to do this leaves out a great deal of moral action. 2. Many of the skills and habits that support moral action are domain limited. Expertise is always expertise in some domain. To discover this, one needs only to venture outside that domain (e.g. attempt casual conversation or humanitarian na assistance in another culture). Noticing and responding to a moral issue in one’s family requires different skills and knowledge than doing so at work. Moral exemplars in social service often find themselves regretting the ways they have treated their families. There are more general level skills, such as emotion regulation, that underlie moral action across domains, but even these are likely to have domain Fi limitations. It may well be that this domain specificity of skills contributes to the problem of behavioral integrity that we review in Chapter 5. 3. By designing kind environments, we can leverage the learning of moral expertise in a domain. If we treat moral action as a design problem (see Chapter 3), we can better support the acquisition of moral expertise in new domains. We can identify and teach skills that are automatized in moral action and problem-­solving skills that operate consciously when disfluency in automatic action requires it. Concentrating exclusively on moral judgment will not be enough to support expertise in moral action. When possible, we can provide unambiguous, rapid feedback that supports the development of internally consistent and externally valid mental models and intuition that can underlie automated moral action. Some domains will be more conducive to this approach than others. Value conflicts in some domains will make it harder, and some disfluency in moral action may be due to these conflicts (rather than character). Taking Moral Action 6."
6,6.2,"Domain-­Specific Skills The skills covered so far seem relevant in a wide variety of situations and domains. But there is ample evidence that these skills alone are not sufficient when one is participating in a particular domain of life. One needs skills relevant to each domain. It is possible that the general moral skills may be prerequisites for, or lead individuals to more quickly acquire, the domain-­relevant skills.24 Obviously, domain-­r elevant skills will be particular to each domain, and since the domains are legion in number, so too would be the skills. Generalizing s across domains, one might find similarities in these skills, but these similarities would need to occur at a higher level of abstraction, and the skill may not be of able to be taught at this level of abstraction. This is interesting speculation, but there is very little work even on domain-­r elevant skills to support it. There are some particular examples of what we might mean by domain-­r elevant skills. For instance, when the philosopher Michael Pritchard interviewed moral exemplars ro in the engineering professions, he found that the virtues they listed contained some standard suspects (e.g. honesty, courage) but also quite specific skills, such as “a habit of documenting work” (Pritchard, 1998, 2001). Moral exemplars in computing make little distinction among moral, social, and technical lP skills, often claiming that all were interrelated (Huff & Barnard, 2009). And experts in the ethical issues of computing use domain related knowledge (e.g. data privacy) far more than novices do (Keefer & Ashley, 2001). One presumes that expertise consists in part of having these intermediate knowledge structures available and ready to use. Work in addiction recovery (Bernheim, 2004) na shows that specific skills of understanding and managing susceptibility to relapse are crucial in recovery. Skills like social networking and negotiating are what Thalhammer et al. (2007) refer to as internal resources in their model of what influences the action of courageous resistors, such as those who sheltered victims of the holocaust. Snyder and colleagues’ model of volunteering sugFi gests that one of the reasons people volunteer is to learn skills they might not find elsewhere (Snyder & Clary, 2000; Snyder & Omoto, 2008) and have a chance to practice them to increase expertise. Thus, there is something special about the domain-­specific knowledge that experts bring to a (moral) task that matters. In Section 6.3, we try to uncover what that is. 24 This is similar to Aristotle’s thought when he says that one must have had the right kind of upbringing before one can learn the virtues (Aristotle, 1941, NE 10.9 1179b4-­31). But we do not know of any research that would document this. Skills and Knowledge 157 6.3 Expert Performance We can think of excellence in moral acting as the achievement of expertise in a domain (Dreyfus & Dreyfus, 2004; Narvaez, 2005, 2010). The model of moral action as expertise conforms well to the recently resurgent idea of moral action consisting of the exercising of the virtues (Annas, 2006; Anscombe, 1958; MacIntyre, 1981). Like virtue, expertise is a characteristic of the individual and can be held at various levels of excellence. Like virtue, expertise consists of habitual and even automatic ways of performing certain tasks, and these ways can be acquired through practice. It is likely that descriptions of an individual as “having” a virtue (e.g. honesty) are actually descriptions of a characteristic way of acting well (acting in an expert manner in regard to being honest), rather than descriptions of a characteristic the individual “has” that s causes virtuous action.25 The expertise model of morality thus sees consistent moral action as the use of skills to strive for excellence with regard to particular (moral) goals in a particular of domain. The caveat regarding the nature of goals is important here. It has been shown, for instance, that mentoring in service of exclusively success-­oriented goals can lead young scientists to actually care less about moral issues, and be less moral ro in their practice of science (Anderson et al., 2007). As discussed in Chapter 5, one can have many other goals than moral ones, including enjoyment, sociality, and achievement (McGregor & Little, 1998). All people, even psychopaths (Skeem et al., 2011), have some of the skills associated with achieving moral goals, and lP need them in order to navigate our shared social life. But moral exemplars, individuals recognized for excellence in striving after moral goals, have achieved high levels of expertise in these skills. Narvaez (2010) makes the analogy with music. Everyone appreciates and participates in music to some extent, but few of us have extensively practiced both the appreciation and performance of music: these are experts. The literature on expertise na presents some consensus on the differences between novices and experts who: 1. Have more and better organized domain knowledge (declarative, procedural and conditional). 2. Perceive and react to the world differently, noticing detail, risk, and opportunity. Fi 3. Act in the domain in an automatic and effortless way, when things are normal. Common to all the models is the idea that expertise can be learned over time, with practice and appropriate feedback (Dane, 2010). This learning arc was noticed long ago by Zeami (Motokio, 1400/1984) who cataloged the developmental progression of expertise in his medieval treatises on Japanese Noh theater. According to Zeami, 25 Hulsey and Hampson (2014) have proposed a model of virtue as composed of habits and expert skills. They combine these under the idea of Habitus, borrowing from both Thomas Aquinas and the early emotion researcher Magda Arnold (Arnold, 1960) who based much of her theorizing on Aquinas’ Habitus. Their model is consistent with much of what is presented in this text. Taking Moral Action the rules that the beginner obeys (Shu) are “beautiful fictions,” and with practice the novice can advance to the stage where the practitioner can detach (Ha) from the rules and break them intentionally in the right circumstances. True experts transcend (Ri) the rules, and even though they may seem to violate them, their action can propose the modification of the rules (Murata, 2010). This Shu–Ha–Ri progression has been taken up in the martial arts and in computer science (Boehm & Turner, 2003) to describe levels of mastery. But can we really speak of expertise in the moral domain? Narvaez (1998) compared moral experts and non-­experts and showed the experts behaved like experts in other well-­studied domains (e.g. chess). Given complex moral narratives to read, they gave more explanation and total expressions, showed deeper understanding and engagement in texts, disagreed with the narrative of text more often, and had more and better organized logic. Following the chronicity metaphor of expertise, Narvaez s et al. (2006) showed that moral “chronics” respond faster and make more dispositional inferences when making judgments about morally relevant stories.26 Similarly, people of with higher moral reasoning scores showed a better recall of moral arguments in texts, and particularly better recall of more complex moral arguments (Narvaez & Gleason, 1995). This research program makes the case that at least some aspects of moral skill and knowledge follow the patterns one would expect from the expertise ro literature. And the use of expertise models in applied domains with clear moral relevance (Dane, 2010; Moulton et al., 2007) shows that others find the model a useful way to think about morally relevant action. Box 6.1 shows the model of “mature moral functioning” Narvaez (2010) has lP developed from her research program. The complete model of moral expertise depicts moral experts as different in perception, cognition, action, metacognition, and meta-­ action. This kind of comprehensive expertise is based in extensive practice within a domain of morality (e.g. within a profession or calling). This facilitates the expert’s ability to be a more sensitive perceiver of ethically relevant occurrences, a more creana tive proposer of action plans, a better implementer of those plans, and a more thoughtful planner and networker in shaping the moral ecology. This expansive, and even ideal, model of moral expertise is still limited by the recognition that moral expertise is typically developed within a domain. Even these highly skilled moral experts are limited in their expertise to those aspects of their Fi world to which they have dedicated themselves. The work on moral exemplars seems to support this segmentation of moral expertise. People recognized for high moral achievement in social service or in a profession are often not such high achievers in other domains of their lives (e.g. their families are regularly negatively affected). It is unclear whether this neglect comes from inevitable competition for limited resources, lack of ethical commitment to domains other than the chosen one, or lack of some skill in the less well-­practiced domain (Lapsley & Narvaez, 2006, p. 253). One difficulty of the model of expertise provided here is that at times it seems to locate the action of expertise almost entirely in automatized responses to the 26 The term “chronics” is taken from the social cognition literature to refer to individuals whose mental models for a particular domain are most complex, detailed, and chronically accessible (Higgins et al., 1982). Skills and Knowledge 159 Box 6.1 According to Narvaez (2010, p. 172), mature moral ­functioning involves: • Basic socialization generally expected of adults (e.g. emotion regulation) • Basic habits and disposition conducive to self-­development • Moral imagination • Ethical expertise in a particular domain (e.g. a profession, or community service). Including • greater skills in ethical sensitivity • ethical judgment • ethical focus s • flexible adaptation within networks of relationships • individual capacities for: of ◦◦ habituated empathic concern (targeted feelings of compassion combined with a sense of responsibility and propensity to act) ◦◦ moral metacognition (manage and complete tasks, monitor progress, adapt plans and strategy), including moral locus of control, moral self-­ ro monitoring, and moral self-­reflection • collective capacities for: ◦◦ moral dialogue, commitment to and skill at initiating and supporting community dialogue about moral action lP ◦◦ moral institutions, the construction, maintenance and reform of social institutions This expertise looks different in every individual, and any particular moral expert cannot serve as the model for how all should operate. Note also that Narvaez (2010) conceives of moral expertise as occurring within domains, na rather than being a more general, cross-­domain expertise. ­environment.27 This may be because the model is based on the work on expertise by Dreyfus & Dreyfus (2004). Their model sees expertise as consisting primarily of highly Fi practiced perception–judgment–action routines that develop over time. In the Drefus & Dreyfus (2004) model, these routines are seen as flexible and working under most circumstances. But what happens when they do not work?28 We will look in detail at this issue in Section 6.4. For now we should note that the ability to be aware of the situation and to recognize when ordinary, practiced, expert routines are not working is itself a part of expertise, as is the ability to be reflective about the breakdown and to do appropriate puzzle-­solving when normal solutions do not work (Moulton et al., 2007). 27 Though Narvaez (2010) is very explicit about the roles for thoughtful, conscious guidance of action. 28 Dreyfus and Dreyfus (2004, p. 256) do note that “in familiar but problematic situations, the expert deliberates about the appropriateness of his or her intuitions.” They do not give much explanation about how this deliberation works but they admit that “expert deliberation is not inferior to intuition” (p. 255). Still, to say that it is “not inferior” is small praise. Taking Moral Action 6.3.1 The Development of Expertise Dreyfus and Dreyfus (2004) propose a five-­stage model of skill acquisition. They begin their analysis with two morally neutral skills, driving and chess, and go on to consider the pattern of acquisition in the domain of morality.29 The five steps along the continuum of expertise they describe are: 1. Novice: action is guided by context-­free situational features and rules for determining actions based on those features of the situation. This simplistic approach fails in complex contexts. 2. Advanced beginner: guidance for action begins to be based in recognition of aspects of the context. At this level, maxims (e.g. make things as simple as possible) replace context-­free rules. s 3. Competence: the multiplicity of features and aspects that one must consider, even given maxims to help sort them, begins to overwhelm judgment because of comof binatorial explosion. Hierarchical structures based on an individual’s goals for that situation are imposed to limit the complexity. Goal choice is emotionally fraught because there is a lack of clear rules at this meta level. 4. Proficiency: action is guided by the adoption of a perspective that guides choices ro among higher-­level goals. Flow in the task become continuous but is still punctuated by conscious planning and effort. 5. Expertise: “Normally an expert does not deliberate. He or she neither reasons nor acts deliberately. He or she simply spontaneously does what has normally worked lP and … it normally works” (Dreyfus & Dreyfus, 2004, p. 253, ellipsis in original). The stages are not discontinuous, and in appropriate environments, this development of expertise proceeds in tandem with appropriate practice. One can, for instance, see advances in expertise in the processing of moral discourse develop across c­ hildhood na (Eisenberg, 2005; Narvaez & Gleason, 1995). Kind environments (Hogarth, 2001) provide support for the development of such expertise. Weather forecasting and sports are such environments, providing unambiguous, rapid feedback of success or error, and giving rise to internally consistent and externally valid mental models and intuition. When coupled with coaching in both practice and theory, these environFi ments can support rapid expertise development. Wicked environments, on the other hand, do not provide the feedback needed because, for instance, definitions of success are malleable and feedback is ambiguous, difficult to recognize, or easy to reinterpret.30 This makes it difficult to get (and easy to avoid) the feedback that can inform expert performance. Given a kind environment, deliberate practice is necessary but not sufficient to achieve expert level performance. Campitelli and Gobet (2011) suggest it requires approximately 3,000 hours of deliberate practice, but this number varies tremendously (e.g. from hundreds to more than 20,000 hours to achieve master levels in 29 But virtue ethics suggests that even these skills in a domain of practice are not morally neutral. 30 This leads to the interesting and ironic hypothesis that the domain of morality may be wicked in this technical sense. Skills and Knowledge 161 chess). This wide variability may be explained by individual differences in ability, sensitive periods for development (Campitelli & Gobet, 2011), and coaching ­ (Hogarth, 2001). These numbers are likely to also vary widely by domain, and expertise may well not be a linear function of hours of deliberate practice (Campitelli & Gobet, 2011). One skill might be easy to learn at rudimentary levels (e.g. English) but difficult to excel at, while another may pose difficulties from the very beginning (e.g. Chinese). Where does morality stand in this? We do not know. The idea of morality as an expertise is still too young for these questions to have been investigated. 6.3.2 Automaticity in Expertise There appears to be an odd irony in the Dreyfus and Dreyfus (2004) presentation of s this progression in expertise. At the highest levels, automaticity rules performance, and the expert seems to do best when thinking least. This is a provocative idea, but of there is some evidence to support it. Hassin and Bargh (2009) provide evidence that automatic processes do not need to be rigid and inflexible. Automatic-­level goals can facilitate flexible action to achieve them, and automatic-­level routines can even help resolve self-­regulation dilemmas. One advantage of the automatic level of processing ro and action guidance is that it uses less energy, and thus frees the actor to concentrate on other things (Schmeichel, Vohs, & Baumeister, 2003). There is still controversy on the ways that goals and automated skills interact (Kruglanski & Szumowska, 2020; Mamede et al., 2010; Wood, Mazar, & Neal, 2021) but it lies with an agreement that lP a goal-­flexible, adaptive automaticity could underlie expert negotiation of difficult tasks (and thus difficult moral tasks). In Section 6.4 we will look at another model of expertise that makes knowing when to drop out of automatic processing into deliberative processing a central aspect of expertise. na 6.3.3 What Knowledge and Skill? What kinds of skills and knowledge does one learn as one becomes more morally expert? The traditional Piagetian approach (Hatano & Inagaki, 2000; Narvaez, 2005) saw advancement driven by cognitive capability in foundational logical-­mathematical Fi operations. Advance in these operations supposedly produced advances across all domains of thought and action. This hierarchical structure is no longer viewed as valid in most circles (Hatano & Inagaki, 2000; Lapsley & Narvaez, 2006).31 Most work on conceptual development now sees it as similar to expertise in a domain, within the multiple domains of knowledge and action in our lives.32 So, the first broad answer to the question is that it will be knowledge and skill relevant to the domain of morality, and perhaps with regard to morality within a specific domain of action, such as a profession or one’s family of origin. This does not seem like a remarkable statement unless one reflects on the short history of developmental theory outlined here. 31 This change is one reason behind the move to the “neo-­Kohlberg” theory that depends on concepts like schemas and expertise (Narvaez, 2005). 32 We should note that there is some dispute among philosophers about whether knowledge is a necessary component of a virtue (Winter, 2011). Taking Moral Action Beyond this quite vague description, can we specify what kind of knowledge is involved in expertise? Narvaez (2005) uses schema theory taken from Marshall (1995) to construct a model of moral skills and knowledge for the purpose of teaching them. She lists four types of knowledge: 1. Identification: knowledge of essential elements of the domain so that one can identify them. 2. Elaboration: knowledge that enables creation of a situational mental model. 3. Planning: knowledge of how to combine what is known to form expectations and make plans. 4. Execution: knowledge to guide the execution of plans and their revision when things go wrong. s Can one obtain reasonably valid descriptions of the relevant skills and knowledge in a domain? Much research in organizational psychology shows we can get reasonaof bly valid descriptions of the skills involved in particular jobs (Fleishman & Mumford, 1991; Fleishman et al., 1991). In the domain of morality, attempts have been made to catalog and validate skills involved in moral judgment (Wainryb & Brehl, 2006) and moral behavior among school children (Narvaez, 2006). Lists of ro moral skills and knowledge have been developed for various professions, including computing professionals (Huff & Martin, 1995), dentistry (Bebeau, 1994), and medicine (Pinijphon, 2009). How do these skills and knowledge differ between novices and experts? Keefer and lP Ashley (2001) asked experts in engineering ethics and undergraduate students in engineering to write responses to complex cases in engineering ethics. They found that expert ethical thinkers in this domain were more likely to: • appeal to middle-­level principles that identify role-­specific obligations (e.g. due na diligence in safety inspections) • make greater use of professional knowledge in order to recognize moral issues and relevant facts (e.g. knowledge about interactions among safety aspects of particular systems) • employ more contextually sensitive reasoning strategies when crafting resolutions Fi including: ◦◦ identifying alternative moral issues ◦◦ assessing the moral implications of actions ◦◦ providing “alternative practical resolutions” One surprising aspect of the findings is that novices in the domain tended to use the more abstract, “philosophical” reasoning strategies, while domain experts (many of whom were philosophers) used middle-­level concepts and role-­specific obligation to identify problems and think about the cases. The discussion so far makes it seem as though the skills and knowledge outlined here are entirely the work of the isolated individual. But at least some of the skill one has in identifying moral issues comes from knowing how to interact with others to investigate and understand their perspectives. Similar social skills can be found in each of the categories listed earlier. Chapter 3 makes this point in detail. Skills and Knowledge 163 6.3.4 Domain Specificity We have already noted that expertise is domain specific. This is in part what one means when one speaks of expertise – expertise is always expertise-­in-­something. The virtues that moral exemplars in engineering listed for other engineers include more general items such as integrity and courage, but also domain-­specific items like “habit of documenting work” and “competence” (Pritchard, 1998, 2001). One of the computing moral exemplars that one author (CH) interviewed commented that technical and creative incompetence can produce additional ethical temptation to cut corners and to do sub-­par, unethical work (Huff & Barnard, 2009). Others have noted that moral exemplars in social service often find themselves regretting the ways they have treated their families. Colby and Damon (1992) speculate that this is not a simple case of not having concern for their families, but more s likely a result of conflict among moral goals given limited resources. They base this hypothesis on the ways their exemplars spoke about valuing their families’ welfare, of feeling compelled to spend time on their other moral commitments, and feeling guilt and distress over the neglect this produced. Given the inevitable limited resources individuals have, it seems reasonable there might actually be competition among domains (Lapsley & Narvaez, 2006). So, at least in this case, it may not be a lack of ro skill in the domain of the family that produces the neglect. But if resource limitations lead to less practice in one domain (e.g. family) it may lead to less knowledge about that domain and less skill in practicing in that domain. Thus, those led to neglect a domain may find themselves less able to practice in it when they do finally find the lP time; and they may find their well-­honed skills in other domains less successful than they might hope. 6.4 Habits na When one speaks of habits, the term is often modified by an implied “bad.” But in his Nichomachean Ethics, Aristotle suggests that the virtuous person was prepared (or “cultivated”) for virtue by learning good habits (Aristotle, 340 BCE/1941, NE 10.9 1179b4-­31). The importance of habits for moral behavior can be seen from how Fi much of our overall behavior they control. In experience sampling studies, habitual actions comprise 45% of everyday activity (Neal, Wood, & Quinn, 2006). In the psychological literature, habits are “automated response dispositions that are cued by aspects of the performance context” (Neal et al., 2006, p. 198) and in terms of value may be good, bad, or indifferent. Habits can be simple aspects of our daily routine (e.g. how we squeeze the toothpaste tube) or they can be relatively complex parts of an expert routine (e.g. an engineer checking for safety in the interactions of components). But to count as habitual, they must operate primarily automatically and be controlled by cues in the individual’s context. They are learned by repetition in a similar context so that procedural memory – that aspect of memory that stores and controls action sequences – is “cognitively tuned” to both the context and the response. This suggests their relationship to expertise: those parts of expertise that can be described as “automated response dispositions” can be thought of as habits. But as we will see, expertise is more than a collection of habits. Taking Moral Action Still, even habits are not simple chains of stimulus–response links without representations of the environment or goals. There are roles for consciousness, goals, and motivational states in habits (Neal et al., 2006). At the simple habit level, Rothman, Sheeran, and Wood (2009) propose a model of habit change that includes both automatic and controlled processes that regulate eating behavior at different times in the behavior change process. Some habits are controlled almost entirely by performance context cues. Others are not always performed in a particular context but their performance can be triggered, without conscious intervention, by particular goals in the appropriate context. The more a habit is under the control of environmental cues, and the more highly practiced it is, the more difficult it is to intentionally alter (Neal, Wood, Labrecque, & Lally, 2012).33 When a particular action only occurs rarely, or is performed in complex interaction with goals and contexts, it may require a great deal of practice to become s habitual (Neal et al., 2012). This helps to make sense of the long practice times required to cultivate expertise, which will consist of a multitude of habits that are of integrated with both goals and contexts. One advantage of the mostly automatic nature of habits is that they do not require much in the way of cognitive resources (Neal et al., 2006). In complex or stressful contexts, this leaves the actor with the cognitive resources to concentrate on other ro aspects of performance. Of course, if the habit is not appropriately sensitive to context changes, it may be performed at inappropriate times. Expertise may consist in part of tuning habits so that they are expressed only in the appropriate contexts. The lack of such tuning is called “cognitive entrenchment” in the organizational literature lP (Dane, 2010).34 6.4.1 How Are Habits Regulated? na The appropriate integration of habits into expertise requires that they be sensitive to goals and contexts, even if they are so well learned that they are automatic in activation and execution. Neal, Wood, and Quin (2006, p. 200) call this process of integration Fi 33 In the habit literature, habits that are always performed in a particular context are termed “strong” habits while those that are deployed depending on the goal and the context are called “moderate strength” habits. This language is one of the last vestiges of the behaviorist interest in habits, and it can be misleading. It considers habits as isolated units that are stronger or weaker, rather than as possibly integrated units in a larger expertise in a domain. One might easily call habits that are activated only in the appropriate context “flexible habits,” or even “strong habits,” because they are tightly integrated into expertise. 34 This detachment of habits from context has the ironic effect of making habits feel unconnected to the sense of self. Thus, people think their non-­habitual actions are more informative about who they are (Neal et al., 2006, p. 201). This is perhaps because the self is autobiographical and more dependent on declarative, narrative memory. This disconnection of habit from the self could be one reason for the “humility” shown in exemplars. It might also help us understand why we think our judgment in difficult (non-­automatic) situations is the marker of our moral character rather than the developed automatized skills of moral expertise. Skills and Knowledge 165 self-­regulation,35 and note that it consists of “monitoring and adjusting responses in the service of the self.” But if habits are automatic, how can this kind of self-­regulation interact with them? One suggestion is that the perception of some metacognitive difficulty or disfluency in the process is a cue for conscious intervention (Alter et al., 2007; Moulton et al., 2007; Neal et al., 2006). For instance, when an individual has multiple goals, these can conflict with each other and activate competing responses. When complex contexts activate competing habits, this too may cause disfluency. Or when a goal is blocked (perhaps by some conflict with the context, such as a pattern of data that does not fit with a medical diagnosis) disfluency may be experienced. Thus, experts need to use markers of disfluency (Moulton et al., 2007) to break out of automatic routines and respond consciously to these difficulties. Moulton et al. (2007) have a model of “slowing down when you should” and their model of s expertise showcases the ability to switch back and forth from automatic to controlled processes. Their work is based in research on medical expertise, and they draw from of a model of expertise by Schön (1984) taken from engineering, architecture, management, psychotherapy, and town planning. In contrast to the Dreyfus and Dreyfus (2004) model mentioned earlier of “doing what normally works,” they ask how expertise copes in extraordinary circumstances. They mark the ability to switch back ro and forth from automatic to controlled process as the critical skill needed for expertise in extraordinary circumstances. This ability to self-­ regulate is facilitated by awareness of the situation that allows detection of disfluency, the connection of that disfluency to situational parameters, and the initiation of appropriate corrective lP action (Alter et al., 2007). The expert then has a well-­practiced controlled process to search for alternative solutions to the issue, both naming the difficulty and framing it, placing it in the larger picture of the situation and goals (Schön, 1984).36 Some of the psychological processes underlying this flexibility of automatic action have been described by De Neys (2012, 2021), though again there is disagreement over how na the processes play out (Kruglanski & Szumowska, 2020; Mamede et al., 2010; Wood et al., 2021). Another sort of disfluency can come from recognition that one’s performance in different domains is differentially successful. One barrier to the sort of integrity that is achieved from cross-­domain consistency is competition between domains. Fi Competition can arise from simple conflicts for limited resources (e.g. time) or from more complex conflicts when the goals associated with different cultural or personal domains are in conflict (Schwartz, 2010). When we speak of moral integrity (Mumford et al., 2001; Paine, 1994; Pritchard, 2006), we often refer to consistency in value commitments or consistency of behavior with a particular value commitment (see Chapter 5). But if we think of moral action in the context of domain dependent expertise, it becomes clear that one might have commitment to a domain but not the requisite level of expertise in it. And one can thus speak of 35 Note that this is a different use of the term than what we have used in Section 6.1.2. It is not unusual for such terms to be treated slight differently by different authors (see, e.g. the table of definitions for moral psychology in the Introduction). 36 This process is reminiscent of the hermeneutic framework that Gadamer (1996) provides in his work on medical practice. Taking Moral Action lack of skill as a threat to integrity. Integrity can be threatened by the inevitable competition for limited resources, or from a lack of ethical commitment to domains other than the chosen one, or from a lack of some skill in a less well-­practiced domain. Restoring integrity, then, involves the skill of recognizing the disfluency and moving to address it. The expert has the cognitive capacity to be aware of disfluency and situational context in part because the automatized habits require little capacity to run. Habits are thus a two edged sword: they can both free the expert to respond flexibly to the extraordinary (Moulton et al., 2007) and trap the expert into routines that are not appropriate to the context (Dane, 2010). s 6.5 Skills Go Awry of Finally, we must make a comment about the moral in the phrase moral skill. What is peculiarly moral about these skills? Psychopaths can exhibit significant self-­ regulation skills in the service of their goals, but still show “feckless disregard” and meanness toward others (Skeem et al., 2011, p. 107). This seems to be based ro in the facet of psychopathy associated with sensitivity to norms (Luke, Neumann, & Gawronski, 2021). The classic work on German police participation in the final solution describes at least one subset of the most efficient “Jew-­ hunters” as having particular emotional regulation skills that allowed them to dislP tance themselves from their work (Browning, 1992, p. 127) and thus to participate willingly in mass murder. Thus, the relationship between morality and the skills and expertise we outline here is at the very least complex, if not contradictory and dialectical.37 Skills and knowledge can be separated from morality and can indeed serve immoral ends. As we have na seen in the various models of moral exemplars (e.g. Colby & Damon, 1992; Walker & Hennig, 2004), moral action and its influences are characterized by equifinality – the same moral action can come about in many different ways. And any particular influence (e.g. a skill, a personality characteristic, etc.) is multi-­final – it can support or contribute to a range of both moral and immoral action. But in most instances, Fi absent moral luck (Nagel, 1979; Williams, 1981), moral actors must have some skills to successfully obtain their goals. Thus, if we want to understand, and ultimately to help develop, successful moral action, we will want to understand the role that skill plays in it. A final thing to note regarding the moral reach of skills is their seeming domain specificity. Even more general skills, such as emotion regulation, can manifest differently in different life domains (Harley et al., 2019). And one can easily imagine that things like moral attentiveness, the ability to recognize moral issues, would depend on knowledge and skill in the particular domain in question (e.g. Nathaniel Borenstein’s recognition of the dangers of particular military software). 37 See the discussion on this in Chapter 9. Skills and Knowledge 167 6.6 Discussion When we include taking action in the domain of morality, expertise based in knowledge, skill, and habit becomes immediately relevant. This approach is both a description of how one operates in a domain and a description of an ideal state toward which one constantly strives. How might this change our picture of moral action? 6.6.1 Conclusion 1. Principled decision making is likely not the primary path to taking moral action. Moral judgment and moral decision-­making may be important skills when operating in difficult situations, but much skilled moral action is not consciously guided. s From the perspective of skill, expertise, and habit, conscious moral judgment and decision-­making of the sort that is measured in moral reasoning tests is likely an exceptional occurrence. Moral acting in everyday life may more often consist of of automatically or habitually pursuing a moral goal rather than constantly deliberating about moral dilemmas. Principled decision-­making may not be primary in terms of being learned first, or in ro terms of being foundational. It is probably one necessary but not sufficient ingredient in the ongoing behavior stream of expertise. It may be most likely to be called upon when some disfluency occurs in action that needs resolution, but even then it may involve intermediate level knowledge in a domain rather than any return to foundational ethical principles. The only way you can claim that principled decision-­making is lP the primary path to moral action is to define moral action as action that occurs based on principled decision-­making. And to do this leaves out a great deal of moral action. 2. Many of the skills and habits that support moral action are domain limited. Expertise is always expertise in some domain. To discover this, one needs only to venture outside that domain (e.g. attempt casual conversation or humanitarian na assistance in another culture). Noticing and responding to a moral issue in one’s family requires different skills and knowledge than doing so at work. Moral exemplars in social service often find themselves regretting the ways they have treated their families. There are more general level skills, such as emotion regulation, that underlie moral action across domains, but even these are likely to have domain Fi limitations. It may well be that this domain specificity of skills contributes to the problem of behavioral integrity that we review in Chapter 5. 3. By designing kind environments, we can leverage the learning of moral expertise in a domain. If we treat moral action as a design problem (see Chapter 3), we can better support the acquisition of moral expertise in new domains. We can identify and teach skills that are automatized in moral action and problem-­solving skills that operate consciously when disfluency in automatic action requires it. Concentrating exclusively on moral judgment will not be enough to support expertise in moral action. When possible, we can provide unambiguous, rapid feedback that supports the development of internally consistent and externally valid mental models and intuition that can underlie automated moral action. Some domains will be more conducive to this approach than others. Value conflicts in some domains will make it harder, and some disfluency in moral action may be due to these conflicts (rather than character). Taking Moral Action 6.6.2 Application On Saturday April 30, 1977, fourteen women gathered for the first demonstration of the Mothers of the Plaza de Mayo. They ignored the warnings of danger from their families and gathered at the center of political power in Argentina to give witness to the disappearances and demand answers. Some of them were themselves later disappeared. These women, and the thousands who joined them, are not famous for their good will. They are famous for their fierce determination, their dogged resistance, their courage, and their skill in resistance and public protest. They are in short famous for courageous skilled moral action. The original members met each other while visiting the same bureaucratic offices in search of their children. They banded together to protest, then organized to march, and then initiated an international information campaign to counter government s propaganda. They knew how to do some of these things, they also knew how to find people with additional skills and how to convince them to take the risk of joining the of movement. Many are still marching today and running websites and international campaigns to keep up the search for those still lost and to prevent the current government from reducing penalties on those convicted of crimes. ro 6."
6,6.3,"Expert Performance We can think of excellence in moral acting as the achievement of expertise in a domain (Dreyfus & Dreyfus, 2004; Narvaez, 2005, 2010). The model of moral action as expertise conforms well to the recently resurgent idea of moral action consisting of the exercising of the virtues (Annas, 2006; Anscombe, 1958; MacIntyre, 1981). Like virtue, expertise is a characteristic of the individual and can be held at various levels of excellence. Like virtue, expertise consists of habitual and even automatic ways of performing certain tasks, and these ways can be acquired through practice. It is likely that descriptions of an individual as “having” a virtue (e.g. honesty) are actually descriptions of a characteristic way of acting well (acting in an expert manner in regard to being honest), rather than descriptions of a characteristic the individual “has” that s causes virtuous action.25 The expertise model of morality thus sees consistent moral action as the use of skills to strive for excellence with regard to particular (moral) goals in a particular of domain. The caveat regarding the nature of goals is important here. It has been shown, for instance, that mentoring in service of exclusively success-­oriented goals can lead young scientists to actually care less about moral issues, and be less moral ro in their practice of science (Anderson et al., 2007). As discussed in Chapter 5, one can have many other goals than moral ones, including enjoyment, sociality, and achievement (McGregor & Little, 1998). All people, even psychopaths (Skeem et al., 2011), have some of the skills associated with achieving moral goals, and lP need them in order to navigate our shared social life. But moral exemplars, individuals recognized for excellence in striving after moral goals, have achieved high levels of expertise in these skills. Narvaez (2010) makes the analogy with music. Everyone appreciates and participates in music to some extent, but few of us have extensively practiced both the appreciation and performance of music: these are experts. The literature on expertise na presents some consensus on the differences between novices and experts who: 1. Have more and better organized domain knowledge (declarative, procedural and conditional). 2. Perceive and react to the world differently, noticing detail, risk, and opportunity. Fi 3. Act in the domain in an automatic and effortless way, when things are normal. Common to all the models is the idea that expertise can be learned over time, with practice and appropriate feedback (Dane, 2010). This learning arc was noticed long ago by Zeami (Motokio, 1400/1984) who cataloged the developmental progression of expertise in his medieval treatises on Japanese Noh theater. According to Zeami, 25 Hulsey and Hampson (2014) have proposed a model of virtue as composed of habits and expert skills. They combine these under the idea of Habitus, borrowing from both Thomas Aquinas and the early emotion researcher Magda Arnold (Arnold, 1960) who based much of her theorizing on Aquinas’ Habitus. Their model is consistent with much of what is presented in this text. Taking Moral Action the rules that the beginner obeys (Shu) are “beautiful fictions,” and with practice the novice can advance to the stage where the practitioner can detach (Ha) from the rules and break them intentionally in the right circumstances. True experts transcend (Ri) the rules, and even though they may seem to violate them, their action can propose the modification of the rules (Murata, 2010). This Shu–Ha–Ri progression has been taken up in the martial arts and in computer science (Boehm & Turner, 2003) to describe levels of mastery. But can we really speak of expertise in the moral domain? Narvaez (1998) compared moral experts and non-­experts and showed the experts behaved like experts in other well-­studied domains (e.g. chess). Given complex moral narratives to read, they gave more explanation and total expressions, showed deeper understanding and engagement in texts, disagreed with the narrative of text more often, and had more and better organized logic. Following the chronicity metaphor of expertise, Narvaez s et al. (2006) showed that moral “chronics” respond faster and make more dispositional inferences when making judgments about morally relevant stories.26 Similarly, people of with higher moral reasoning scores showed a better recall of moral arguments in texts, and particularly better recall of more complex moral arguments (Narvaez & Gleason, 1995). This research program makes the case that at least some aspects of moral skill and knowledge follow the patterns one would expect from the expertise ro literature. And the use of expertise models in applied domains with clear moral relevance (Dane, 2010; Moulton et al., 2007) shows that others find the model a useful way to think about morally relevant action. Box 6.1 shows the model of “mature moral functioning” Narvaez (2010) has lP developed from her research program. The complete model of moral expertise depicts moral experts as different in perception, cognition, action, metacognition, and meta-­ action. This kind of comprehensive expertise is based in extensive practice within a domain of morality (e.g. within a profession or calling). This facilitates the expert’s ability to be a more sensitive perceiver of ethically relevant occurrences, a more creana tive proposer of action plans, a better implementer of those plans, and a more thoughtful planner and networker in shaping the moral ecology. This expansive, and even ideal, model of moral expertise is still limited by the recognition that moral expertise is typically developed within a domain. Even these highly skilled moral experts are limited in their expertise to those aspects of their Fi world to which they have dedicated themselves. The work on moral exemplars seems to support this segmentation of moral expertise. People recognized for high moral achievement in social service or in a profession are often not such high achievers in other domains of their lives (e.g. their families are regularly negatively affected). It is unclear whether this neglect comes from inevitable competition for limited resources, lack of ethical commitment to domains other than the chosen one, or lack of some skill in the less well-­practiced domain (Lapsley & Narvaez, 2006, p. 253). One difficulty of the model of expertise provided here is that at times it seems to locate the action of expertise almost entirely in automatized responses to the 26 The term “chronics” is taken from the social cognition literature to refer to individuals whose mental models for a particular domain are most complex, detailed, and chronically accessible (Higgins et al., 1982). Skills and Knowledge 159 Box 6.1 According to Narvaez (2010, p. 172), mature moral ­functioning involves: • Basic socialization generally expected of adults (e.g. emotion regulation) • Basic habits and disposition conducive to self-­development • Moral imagination • Ethical expertise in a particular domain (e.g. a profession, or community service). Including • greater skills in ethical sensitivity • ethical judgment • ethical focus s • flexible adaptation within networks of relationships • individual capacities for: of ◦◦ habituated empathic concern (targeted feelings of compassion combined with a sense of responsibility and propensity to act) ◦◦ moral metacognition (manage and complete tasks, monitor progress, adapt plans and strategy), including moral locus of control, moral self-­ ro monitoring, and moral self-­reflection • collective capacities for: ◦◦ moral dialogue, commitment to and skill at initiating and supporting community dialogue about moral action lP ◦◦ moral institutions, the construction, maintenance and reform of social institutions This expertise looks different in every individual, and any particular moral expert cannot serve as the model for how all should operate. Note also that Narvaez (2010) conceives of moral expertise as occurring within domains, na rather than being a more general, cross-­domain expertise. ­environment.27 This may be because the model is based on the work on expertise by Dreyfus & Dreyfus (2004). Their model sees expertise as consisting primarily of highly Fi practiced perception–judgment–action routines that develop over time. In the Drefus & Dreyfus (2004) model, these routines are seen as flexible and working under most circumstances. But what happens when they do not work?28 We will look in detail at this issue in Section 6.4. For now we should note that the ability to be aware of the situation and to recognize when ordinary, practiced, expert routines are not working is itself a part of expertise, as is the ability to be reflective about the breakdown and to do appropriate puzzle-­solving when normal solutions do not work (Moulton et al., 2007). 27 Though Narvaez (2010) is very explicit about the roles for thoughtful, conscious guidance of action. 28 Dreyfus and Dreyfus (2004, p. 256) do note that “in familiar but problematic situations, the expert deliberates about the appropriateness of his or her intuitions.” They do not give much explanation about how this deliberation works but they admit that “expert deliberation is not inferior to intuition” (p. 255). Still, to say that it is “not inferior” is small praise. Taking Moral Action 6.3.1 The Development of Expertise Dreyfus and Dreyfus (2004) propose a five-­stage model of skill acquisition. They begin their analysis with two morally neutral skills, driving and chess, and go on to consider the pattern of acquisition in the domain of morality.29 The five steps along the continuum of expertise they describe are: 1. Novice: action is guided by context-­free situational features and rules for determining actions based on those features of the situation. This simplistic approach fails in complex contexts. 2. Advanced beginner: guidance for action begins to be based in recognition of aspects of the context. At this level, maxims (e.g. make things as simple as possible) replace context-­free rules. s 3. Competence: the multiplicity of features and aspects that one must consider, even given maxims to help sort them, begins to overwhelm judgment because of comof binatorial explosion. Hierarchical structures based on an individual’s goals for that situation are imposed to limit the complexity. Goal choice is emotionally fraught because there is a lack of clear rules at this meta level. 4. Proficiency: action is guided by the adoption of a perspective that guides choices ro among higher-­level goals. Flow in the task become continuous but is still punctuated by conscious planning and effort. 5. Expertise: “Normally an expert does not deliberate. He or she neither reasons nor acts deliberately. He or she simply spontaneously does what has normally worked lP and … it normally works” (Dreyfus & Dreyfus, 2004, p. 253, ellipsis in original). The stages are not discontinuous, and in appropriate environments, this development of expertise proceeds in tandem with appropriate practice. One can, for instance, see advances in expertise in the processing of moral discourse develop across c­ hildhood na (Eisenberg, 2005; Narvaez & Gleason, 1995). Kind environments (Hogarth, 2001) provide support for the development of such expertise. Weather forecasting and sports are such environments, providing unambiguous, rapid feedback of success or error, and giving rise to internally consistent and externally valid mental models and intuition. When coupled with coaching in both practice and theory, these environFi ments can support rapid expertise development. Wicked environments, on the other hand, do not provide the feedback needed because, for instance, definitions of success are malleable and feedback is ambiguous, difficult to recognize, or easy to reinterpret.30 This makes it difficult to get (and easy to avoid) the feedback that can inform expert performance. Given a kind environment, deliberate practice is necessary but not sufficient to achieve expert level performance. Campitelli and Gobet (2011) suggest it requires approximately 3,000 hours of deliberate practice, but this number varies tremendously (e.g. from hundreds to more than 20,000 hours to achieve master levels in 29 But virtue ethics suggests that even these skills in a domain of practice are not morally neutral. 30 This leads to the interesting and ironic hypothesis that the domain of morality may be wicked in this technical sense. Skills and Knowledge 161 chess). This wide variability may be explained by individual differences in ability, sensitive periods for development (Campitelli & Gobet, 2011), and coaching ­ (Hogarth, 2001). These numbers are likely to also vary widely by domain, and expertise may well not be a linear function of hours of deliberate practice (Campitelli & Gobet, 2011). One skill might be easy to learn at rudimentary levels (e.g. English) but difficult to excel at, while another may pose difficulties from the very beginning (e.g. Chinese). Where does morality stand in this? We do not know. The idea of morality as an expertise is still too young for these questions to have been investigated. 6.3.2 Automaticity in Expertise There appears to be an odd irony in the Dreyfus and Dreyfus (2004) presentation of s this progression in expertise. At the highest levels, automaticity rules performance, and the expert seems to do best when thinking least. This is a provocative idea, but of there is some evidence to support it. Hassin and Bargh (2009) provide evidence that automatic processes do not need to be rigid and inflexible. Automatic-­level goals can facilitate flexible action to achieve them, and automatic-­level routines can even help resolve self-­regulation dilemmas. One advantage of the automatic level of processing ro and action guidance is that it uses less energy, and thus frees the actor to concentrate on other things (Schmeichel, Vohs, & Baumeister, 2003). There is still controversy on the ways that goals and automated skills interact (Kruglanski & Szumowska, 2020; Mamede et al., 2010; Wood, Mazar, & Neal, 2021) but it lies with an agreement that lP a goal-­flexible, adaptive automaticity could underlie expert negotiation of difficult tasks (and thus difficult moral tasks). In Section 6.4 we will look at another model of expertise that makes knowing when to drop out of automatic processing into deliberative processing a central aspect of expertise. na 6.3.3 What Knowledge and Skill? What kinds of skills and knowledge does one learn as one becomes more morally expert? The traditional Piagetian approach (Hatano & Inagaki, 2000; Narvaez, 2005) saw advancement driven by cognitive capability in foundational logical-­mathematical Fi operations. Advance in these operations supposedly produced advances across all domains of thought and action. This hierarchical structure is no longer viewed as valid in most circles (Hatano & Inagaki, 2000; Lapsley & Narvaez, 2006).31 Most work on conceptual development now sees it as similar to expertise in a domain, within the multiple domains of knowledge and action in our lives.32 So, the first broad answer to the question is that it will be knowledge and skill relevant to the domain of morality, and perhaps with regard to morality within a specific domain of action, such as a profession or one’s family of origin. This does not seem like a remarkable statement unless one reflects on the short history of developmental theory outlined here. 31 This change is one reason behind the move to the “neo-­Kohlberg” theory that depends on concepts like schemas and expertise (Narvaez, 2005). 32 We should note that there is some dispute among philosophers about whether knowledge is a necessary component of a virtue (Winter, 2011). Taking Moral Action Beyond this quite vague description, can we specify what kind of knowledge is involved in expertise? Narvaez (2005) uses schema theory taken from Marshall (1995) to construct a model of moral skills and knowledge for the purpose of teaching them. She lists four types of knowledge: 1. Identification: knowledge of essential elements of the domain so that one can identify them. 2. Elaboration: knowledge that enables creation of a situational mental model. 3. Planning: knowledge of how to combine what is known to form expectations and make plans. 4. Execution: knowledge to guide the execution of plans and their revision when things go wrong. s Can one obtain reasonably valid descriptions of the relevant skills and knowledge in a domain? Much research in organizational psychology shows we can get reasonaof bly valid descriptions of the skills involved in particular jobs (Fleishman & Mumford, 1991; Fleishman et al., 1991). In the domain of morality, attempts have been made to catalog and validate skills involved in moral judgment (Wainryb & Brehl, 2006) and moral behavior among school children (Narvaez, 2006). Lists of ro moral skills and knowledge have been developed for various professions, including computing professionals (Huff & Martin, 1995), dentistry (Bebeau, 1994), and medicine (Pinijphon, 2009). How do these skills and knowledge differ between novices and experts? Keefer and lP Ashley (2001) asked experts in engineering ethics and undergraduate students in engineering to write responses to complex cases in engineering ethics. They found that expert ethical thinkers in this domain were more likely to: • appeal to middle-­level principles that identify role-­specific obligations (e.g. due na diligence in safety inspections) • make greater use of professional knowledge in order to recognize moral issues and relevant facts (e.g. knowledge about interactions among safety aspects of particular systems) • employ more contextually sensitive reasoning strategies when crafting resolutions Fi including: ◦◦ identifying alternative moral issues ◦◦ assessing the moral implications of actions ◦◦ providing “alternative practical resolutions” One surprising aspect of the findings is that novices in the domain tended to use the more abstract, “philosophical” reasoning strategies, while domain experts (many of whom were philosophers) used middle-­level concepts and role-­specific obligation to identify problems and think about the cases. The discussion so far makes it seem as though the skills and knowledge outlined here are entirely the work of the isolated individual. But at least some of the skill one has in identifying moral issues comes from knowing how to interact with others to investigate and understand their perspectives. Similar social skills can be found in each of the categories listed earlier. Chapter 3 makes this point in detail. Skills and Knowledge 163 6.3.4 Domain Specificity We have already noted that expertise is domain specific. This is in part what one means when one speaks of expertise – expertise is always expertise-­in-­something. The virtues that moral exemplars in engineering listed for other engineers include more general items such as integrity and courage, but also domain-­specific items like “habit of documenting work” and “competence” (Pritchard, 1998, 2001). One of the computing moral exemplars that one author (CH) interviewed commented that technical and creative incompetence can produce additional ethical temptation to cut corners and to do sub-­par, unethical work (Huff & Barnard, 2009). Others have noted that moral exemplars in social service often find themselves regretting the ways they have treated their families. Colby and Damon (1992) speculate that this is not a simple case of not having concern for their families, but more s likely a result of conflict among moral goals given limited resources. They base this hypothesis on the ways their exemplars spoke about valuing their families’ welfare, of feeling compelled to spend time on their other moral commitments, and feeling guilt and distress over the neglect this produced. Given the inevitable limited resources individuals have, it seems reasonable there might actually be competition among domains (Lapsley & Narvaez, 2006). So, at least in this case, it may not be a lack of ro skill in the domain of the family that produces the neglect. But if resource limitations lead to less practice in one domain (e.g. family) it may lead to less knowledge about that domain and less skill in practicing in that domain. Thus, those led to neglect a domain may find themselves less able to practice in it when they do finally find the lP time; and they may find their well-­honed skills in other domains less successful than they might hope. 6.4 Habits na When one speaks of habits, the term is often modified by an implied “bad.” But in his Nichomachean Ethics, Aristotle suggests that the virtuous person was prepared (or “cultivated”) for virtue by learning good habits (Aristotle, 340 BCE/1941, NE 10.9 1179b4-­31). The importance of habits for moral behavior can be seen from how Fi much of our overall behavior they control. In experience sampling studies, habitual actions comprise 45% of everyday activity (Neal, Wood, & Quinn, 2006). In the psychological literature, habits are “automated response dispositions that are cued by aspects of the performance context” (Neal et al., 2006, p. 198) and in terms of value may be good, bad, or indifferent. Habits can be simple aspects of our daily routine (e.g. how we squeeze the toothpaste tube) or they can be relatively complex parts of an expert routine (e.g. an engineer checking for safety in the interactions of components). But to count as habitual, they must operate primarily automatically and be controlled by cues in the individual’s context. They are learned by repetition in a similar context so that procedural memory – that aspect of memory that stores and controls action sequences – is “cognitively tuned” to both the context and the response. This suggests their relationship to expertise: those parts of expertise that can be described as “automated response dispositions” can be thought of as habits. But as we will see, expertise is more than a collection of habits. Taking Moral Action Still, even habits are not simple chains of stimulus–response links without representations of the environment or goals. There are roles for consciousness, goals, and motivational states in habits (Neal et al., 2006). At the simple habit level, Rothman, Sheeran, and Wood (2009) propose a model of habit change that includes both automatic and controlled processes that regulate eating behavior at different times in the behavior change process. Some habits are controlled almost entirely by performance context cues. Others are not always performed in a particular context but their performance can be triggered, without conscious intervention, by particular goals in the appropriate context. The more a habit is under the control of environmental cues, and the more highly practiced it is, the more difficult it is to intentionally alter (Neal, Wood, Labrecque, & Lally, 2012).33 When a particular action only occurs rarely, or is performed in complex interaction with goals and contexts, it may require a great deal of practice to become s habitual (Neal et al., 2012). This helps to make sense of the long practice times required to cultivate expertise, which will consist of a multitude of habits that are of integrated with both goals and contexts. One advantage of the mostly automatic nature of habits is that they do not require much in the way of cognitive resources (Neal et al., 2006). In complex or stressful contexts, this leaves the actor with the cognitive resources to concentrate on other ro aspects of performance. Of course, if the habit is not appropriately sensitive to context changes, it may be performed at inappropriate times. Expertise may consist in part of tuning habits so that they are expressed only in the appropriate contexts. The lack of such tuning is called “cognitive entrenchment” in the organizational literature lP (Dane, 2010).34 6.4.1 How Are Habits Regulated? na The appropriate integration of habits into expertise requires that they be sensitive to goals and contexts, even if they are so well learned that they are automatic in activation and execution. Neal, Wood, and Quin (2006, p. 200) call this process of integration Fi 33 In the habit literature, habits that are always performed in a particular context are termed “strong” habits while those that are deployed depending on the goal and the context are called “moderate strength” habits. This language is one of the last vestiges of the behaviorist interest in habits, and it can be misleading. It considers habits as isolated units that are stronger or weaker, rather than as possibly integrated units in a larger expertise in a domain. One might easily call habits that are activated only in the appropriate context “flexible habits,” or even “strong habits,” because they are tightly integrated into expertise. 34 This detachment of habits from context has the ironic effect of making habits feel unconnected to the sense of self. Thus, people think their non-­habitual actions are more informative about who they are (Neal et al., 2006, p. 201). This is perhaps because the self is autobiographical and more dependent on declarative, narrative memory. This disconnection of habit from the self could be one reason for the “humility” shown in exemplars. It might also help us understand why we think our judgment in difficult (non-­automatic) situations is the marker of our moral character rather than the developed automatized skills of moral expertise. Skills and Knowledge 165 self-­regulation,35 and note that it consists of “monitoring and adjusting responses in the service of the self.” But if habits are automatic, how can this kind of self-­regulation interact with them? One suggestion is that the perception of some metacognitive difficulty or disfluency in the process is a cue for conscious intervention (Alter et al., 2007; Moulton et al., 2007; Neal et al., 2006). For instance, when an individual has multiple goals, these can conflict with each other and activate competing responses. When complex contexts activate competing habits, this too may cause disfluency. Or when a goal is blocked (perhaps by some conflict with the context, such as a pattern of data that does not fit with a medical diagnosis) disfluency may be experienced. Thus, experts need to use markers of disfluency (Moulton et al., 2007) to break out of automatic routines and respond consciously to these difficulties. Moulton et al. (2007) have a model of “slowing down when you should” and their model of s expertise showcases the ability to switch back and forth from automatic to controlled processes. Their work is based in research on medical expertise, and they draw from of a model of expertise by Schön (1984) taken from engineering, architecture, management, psychotherapy, and town planning. In contrast to the Dreyfus and Dreyfus (2004) model mentioned earlier of “doing what normally works,” they ask how expertise copes in extraordinary circumstances. They mark the ability to switch back ro and forth from automatic to controlled process as the critical skill needed for expertise in extraordinary circumstances. This ability to self-­ regulate is facilitated by awareness of the situation that allows detection of disfluency, the connection of that disfluency to situational parameters, and the initiation of appropriate corrective lP action (Alter et al., 2007). The expert then has a well-­practiced controlled process to search for alternative solutions to the issue, both naming the difficulty and framing it, placing it in the larger picture of the situation and goals (Schön, 1984).36 Some of the psychological processes underlying this flexibility of automatic action have been described by De Neys (2012, 2021), though again there is disagreement over how na the processes play out (Kruglanski & Szumowska, 2020; Mamede et al., 2010; Wood et al., 2021). Another sort of disfluency can come from recognition that one’s performance in different domains is differentially successful. One barrier to the sort of integrity that is achieved from cross-­domain consistency is competition between domains. Fi Competition can arise from simple conflicts for limited resources (e.g. time) or from more complex conflicts when the goals associated with different cultural or personal domains are in conflict (Schwartz, 2010). When we speak of moral integrity (Mumford et al., 2001; Paine, 1994; Pritchard, 2006), we often refer to consistency in value commitments or consistency of behavior with a particular value commitment (see Chapter 5). But if we think of moral action in the context of domain dependent expertise, it becomes clear that one might have commitment to a domain but not the requisite level of expertise in it. And one can thus speak of 35 Note that this is a different use of the term than what we have used in Section 6.1.2. It is not unusual for such terms to be treated slight differently by different authors (see, e.g. the table of definitions for moral psychology in the Introduction). 36 This process is reminiscent of the hermeneutic framework that Gadamer (1996) provides in his work on medical practice. Taking Moral Action lack of skill as a threat to integrity. Integrity can be threatened by the inevitable competition for limited resources, or from a lack of ethical commitment to domains other than the chosen one, or from a lack of some skill in a less well-­practiced domain. Restoring integrity, then, involves the skill of recognizing the disfluency and moving to address it. The expert has the cognitive capacity to be aware of disfluency and situational context in part because the automatized habits require little capacity to run. Habits are thus a two edged sword: they can both free the expert to respond flexibly to the extraordinary (Moulton et al., 2007) and trap the expert into routines that are not appropriate to the context (Dane, 2010). s 6.5 Skills Go Awry of Finally, we must make a comment about the moral in the phrase moral skill. What is peculiarly moral about these skills? Psychopaths can exhibit significant self-­ regulation skills in the service of their goals, but still show “feckless disregard” and meanness toward others (Skeem et al., 2011, p. 107). This seems to be based ro in the facet of psychopathy associated with sensitivity to norms (Luke, Neumann, & Gawronski, 2021). The classic work on German police participation in the final solution describes at least one subset of the most efficient “Jew-­ hunters” as having particular emotional regulation skills that allowed them to dislP tance themselves from their work (Browning, 1992, p. 127) and thus to participate willingly in mass murder. Thus, the relationship between morality and the skills and expertise we outline here is at the very least complex, if not contradictory and dialectical.37 Skills and knowledge can be separated from morality and can indeed serve immoral ends. As we have na seen in the various models of moral exemplars (e.g. Colby & Damon, 1992; Walker & Hennig, 2004), moral action and its influences are characterized by equifinality – the same moral action can come about in many different ways. And any particular influence (e.g. a skill, a personality characteristic, etc.) is multi-­final – it can support or contribute to a range of both moral and immoral action. But in most instances, Fi absent moral luck (Nagel, 1979; Williams, 1981), moral actors must have some skills to successfully obtain their goals. Thus, if we want to understand, and ultimately to help develop, successful moral action, we will want to understand the role that skill plays in it. A final thing to note regarding the moral reach of skills is their seeming domain specificity. Even more general skills, such as emotion regulation, can manifest differently in different life domains (Harley et al., 2019). And one can easily imagine that things like moral attentiveness, the ability to recognize moral issues, would depend on knowledge and skill in the particular domain in question (e.g. Nathaniel Borenstein’s recognition of the dangers of particular military software). 37 See the discussion on this in Chapter 9. Skills and Knowledge 167 6.6 Discussion When we include taking action in the domain of morality, expertise based in knowledge, skill, and habit becomes immediately relevant. This approach is both a description of how one operates in a domain and a description of an ideal state toward which one constantly strives. How might this change our picture of moral action? 6.6.1 Conclusion 1. Principled decision making is likely not the primary path to taking moral action. Moral judgment and moral decision-­making may be important skills when operating in difficult situations, but much skilled moral action is not consciously guided. s From the perspective of skill, expertise, and habit, conscious moral judgment and decision-­making of the sort that is measured in moral reasoning tests is likely an exceptional occurrence. Moral acting in everyday life may more often consist of of automatically or habitually pursuing a moral goal rather than constantly deliberating about moral dilemmas. Principled decision-­making may not be primary in terms of being learned first, or in ro terms of being foundational. It is probably one necessary but not sufficient ingredient in the ongoing behavior stream of expertise. It may be most likely to be called upon when some disfluency occurs in action that needs resolution, but even then it may involve intermediate level knowledge in a domain rather than any return to foundational ethical principles. The only way you can claim that principled decision-­making is lP the primary path to moral action is to define moral action as action that occurs based on principled decision-­making. And to do this leaves out a great deal of moral action. 2. Many of the skills and habits that support moral action are domain limited. Expertise is always expertise in some domain. To discover this, one needs only to venture outside that domain (e.g. attempt casual conversation or humanitarian na assistance in another culture). Noticing and responding to a moral issue in one’s family requires different skills and knowledge than doing so at work. Moral exemplars in social service often find themselves regretting the ways they have treated their families. There are more general level skills, such as emotion regulation, that underlie moral action across domains, but even these are likely to have domain Fi limitations. It may well be that this domain specificity of skills contributes to the problem of behavioral integrity that we review in Chapter 5. 3. By designing kind environments, we can leverage the learning of moral expertise in a domain. If we treat moral action as a design problem (see Chapter 3), we can better support the acquisition of moral expertise in new domains. We can identify and teach skills that are automatized in moral action and problem-­solving skills that operate consciously when disfluency in automatic action requires it. Concentrating exclusively on moral judgment will not be enough to support expertise in moral action. When possible, we can provide unambiguous, rapid feedback that supports the development of internally consistent and externally valid mental models and intuition that can underlie automated moral action. Some domains will be more conducive to this approach than others. Value conflicts in some domains will make it harder, and some disfluency in moral action may be due to these conflicts (rather than character). Taking Moral Action 6.6.2 Application On Saturday April 30, 1977, fourteen women gathered for the first demonstration of the Mothers of the Plaza de Mayo. They ignored the warnings of danger from their families and gathered at the center of political power in Argentina to give witness to the disappearances and demand answers. Some of them were themselves later disappeared. These women, and the thousands who joined them, are not famous for their good will. They are famous for their fierce determination, their dogged resistance, their courage, and their skill in resistance and public protest. They are in short famous for courageous skilled moral action. The original members met each other while visiting the same bureaucratic offices in search of their children. They banded together to protest, then organized to march, and then initiated an international information campaign to counter government s propaganda. They knew how to do some of these things, they also knew how to find people with additional skills and how to convince them to take the risk of joining the of movement. Many are still marching today and running websites and international campaigns to keep up the search for those still lost and to prevent the current government from reducing penalties on those convicted of crimes. ro 6.6.3 Open Questions The idea of moral skill has been embedded in virtue models of moral action since before Aristotle and Confucius. But there has been remarkably little empirical work lP on the skilled action aspects of moral action. We are still in the beginning stages: 1. What skills are involved in what cultures and domains of moral action? There are numerous applied attempts to catalog the skills involved in moral action, but these all suffer from the same “laundry list” complaints made about virtue na approaches (see Chapter 4). Different lists often have little overlap, and the inclusion or exclusion of particular skills seems arbitrary and unrelated to systematic theory. Given the domain-­based nature of expertise, one should not expect a complete skill set that is applicable across all domains. Instead, one might expect some core skills and a large proliferation of domain-­specific skills in the various cultures, Fi professions, vocations, and contexts in which one can take moral action. In parallel with the literature on leadership, these contexts may interact in complex ways with characteristics of the actor and moral ecology. For this reason, work in this area might best start with careful empirical attention to domain and cultural differences and then search for shared or overlapping items. One can then ask which skills might be transferrable across which domain boundaries. 2. How do actors negotiate the interplay between controlled and automatic moral action? Increases in expertise move moral action from the controlled to the automatic. High levels of expertise require subtle shifts between automatic and controlled processing and action. We are only beginning to understand the integration of automatic and controlled action, much less moral action. What controls the interplay between these two ways of taking moral action? What environmental and personal characteristics make cognitive entrenchment more or less likely? What Skills and Knowledge 169 skills are required to recognize disfluency and take controlled action based on it? Are there different kinds of disfluency and do they interact with different characteristics of the environment (e.g. kind/wicked)? 3. How do people understand and learn from moral failure? The point of the discussion in this chapter about disfluency is that one can (but often does not have to) recognize when one’s skilled performance is failing. What are the characteristics of the actor and the situation that allow this recognition to occur and that facilitate effective reparative action? The list of skills associated with moral action present multiple points of failure in this process, including ones that may differ from one domain to another. Self-­regulation involves the organization of attentional, motivational, emotional, and other internal resources in the service of goals. There are multiple points of failure associated with each of these. One can fail in deciding which of many alternate goals to pursue, in planning how best to s attain a valued end, in protecting goals from competing concerns, in recovery when initial efforts fail, and in deciding whether to continue or abandon goals after of failure. The resilience of each of these failure points may also differ depending on the surrounding moral ecology. 4. How does the expertise model help us understand cultural disagreement about moral action? ro One way that cultural disagreements can be viewed is as differences in expertise in different domains or moral ecologies. The knowledge and skill needed for expert-­ level moral acting in an individualistic culture may be quite different from that needed for a collectivist culture (not to mention more specific aspects of a culture, lP e.g. particular religious commitments). There is no requirement that experts always agree (otherwise it would be a simple rule-­oriented domain and require no expertise). If we think about cultural disagreement as disagreement among experts with different kinds of expertise, we may find some guidance regarding the nature, structure, and extent of the moral disagreements one can find between cultures. na 6.7 Further Readings These suggested readings are designed to lead the reader further into the literature Fi that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. • Benita (2020) “Freedom to feel: A self-­determination theory account of emotion regulation.” A recent review of emotion regulation literature that focuses on the autonomy of the individual. • Dreyfus and Dreyfus (2004) “The ethical implications of the five-­ stage skill-­ acquisition model.” Experts in expertise apply their model to moral action. • Koole (2009). “The psychology of emotion regulation: An integrative review.” A model of emotional regulation that analyses it as the intersection of its functions (goal, need, and person) and the involved systems (attention, knowledge, and body). • Kuhl et al. (2021). “The functional architecture of human motivation.” The most recent summary of personality systems interactions theory that attempts to locate many personality skills in interdependent systems. Taking Moral Action • Narvaez (2005). “The neo-­Kohlbergian tradition and beyond: Schemas, expertise, and character.” An early paper proposing skills and expertise that support moral action. • Narvaez (2010) “Moral complexity: The fatal attraction of truthiness and the importance of mature moral functioning.” A model of mature moral functioning looked at through the lens of expertise across a variety of systems (e.g. cognition, emotion, etc.). • Wood et al. (2021) “Habits and goals in human behavior: Separate but interacting systems.” A review of work on habits that concludes that habits can be activated independent of goals but they can also be integrated into goal pursuit. s"
6,6.4,"Habits na When one speaks of habits, the term is often modified by an implied “bad.” But in his Nichomachean Ethics, Aristotle suggests that the virtuous person was prepared (or “cultivated”) for virtue by learning good habits (Aristotle, 340 BCE/1941, NE 10.9 1179b4-­31). The importance of habits for moral behavior can be seen from how Fi much of our overall behavior they control. In experience sampling studies, habitual actions comprise 45% of everyday activity (Neal, Wood, & Quinn, 2006). In the psychological literature, habits are “automated response dispositions that are cued by aspects of the performance context” (Neal et al., 2006, p. 198) and in terms of value may be good, bad, or indifferent. Habits can be simple aspects of our daily routine (e.g. how we squeeze the toothpaste tube) or they can be relatively complex parts of an expert routine (e.g. an engineer checking for safety in the interactions of components). But to count as habitual, they must operate primarily automatically and be controlled by cues in the individual’s context. They are learned by repetition in a similar context so that procedural memory – that aspect of memory that stores and controls action sequences – is “cognitively tuned” to both the context and the response. This suggests their relationship to expertise: those parts of expertise that can be described as “automated response dispositions” can be thought of as habits. But as we will see, expertise is more than a collection of habits. Taking Moral Action Still, even habits are not simple chains of stimulus–response links without representations of the environment or goals. There are roles for consciousness, goals, and motivational states in habits (Neal et al., 2006). At the simple habit level, Rothman, Sheeran, and Wood (2009) propose a model of habit change that includes both automatic and controlled processes that regulate eating behavior at different times in the behavior change process. Some habits are controlled almost entirely by performance context cues. Others are not always performed in a particular context but their performance can be triggered, without conscious intervention, by particular goals in the appropriate context. The more a habit is under the control of environmental cues, and the more highly practiced it is, the more difficult it is to intentionally alter (Neal, Wood, Labrecque, & Lally, 2012).33 When a particular action only occurs rarely, or is performed in complex interaction with goals and contexts, it may require a great deal of practice to become s habitual (Neal et al., 2012). This helps to make sense of the long practice times required to cultivate expertise, which will consist of a multitude of habits that are of integrated with both goals and contexts. One advantage of the mostly automatic nature of habits is that they do not require much in the way of cognitive resources (Neal et al., 2006). In complex or stressful contexts, this leaves the actor with the cognitive resources to concentrate on other ro aspects of performance. Of course, if the habit is not appropriately sensitive to context changes, it may be performed at inappropriate times. Expertise may consist in part of tuning habits so that they are expressed only in the appropriate contexts. The lack of such tuning is called “cognitive entrenchment” in the organizational literature lP (Dane, 2010).34 6.4.1 How Are Habits Regulated? na The appropriate integration of habits into expertise requires that they be sensitive to goals and contexts, even if they are so well learned that they are automatic in activation and execution. Neal, Wood, and Quin (2006, p. 200) call this process of integration Fi 33 In the habit literature, habits that are always performed in a particular context are termed “strong” habits while those that are deployed depending on the goal and the context are called “moderate strength” habits. This language is one of the last vestiges of the behaviorist interest in habits, and it can be misleading. It considers habits as isolated units that are stronger or weaker, rather than as possibly integrated units in a larger expertise in a domain. One might easily call habits that are activated only in the appropriate context “flexible habits,” or even “strong habits,” because they are tightly integrated into expertise. 34 This detachment of habits from context has the ironic effect of making habits feel unconnected to the sense of self. Thus, people think their non-­habitual actions are more informative about who they are (Neal et al., 2006, p. 201). This is perhaps because the self is autobiographical and more dependent on declarative, narrative memory. This disconnection of habit from the self could be one reason for the “humility” shown in exemplars. It might also help us understand why we think our judgment in difficult (non-­automatic) situations is the marker of our moral character rather than the developed automatized skills of moral expertise. Skills and Knowledge 165 self-­regulation,35 and note that it consists of “monitoring and adjusting responses in the service of the self.” But if habits are automatic, how can this kind of self-­regulation interact with them? One suggestion is that the perception of some metacognitive difficulty or disfluency in the process is a cue for conscious intervention (Alter et al., 2007; Moulton et al., 2007; Neal et al., 2006). For instance, when an individual has multiple goals, these can conflict with each other and activate competing responses. When complex contexts activate competing habits, this too may cause disfluency. Or when a goal is blocked (perhaps by some conflict with the context, such as a pattern of data that does not fit with a medical diagnosis) disfluency may be experienced. Thus, experts need to use markers of disfluency (Moulton et al., 2007) to break out of automatic routines and respond consciously to these difficulties. Moulton et al. (2007) have a model of “slowing down when you should” and their model of s expertise showcases the ability to switch back and forth from automatic to controlled processes. Their work is based in research on medical expertise, and they draw from of a model of expertise by Schön (1984) taken from engineering, architecture, management, psychotherapy, and town planning. In contrast to the Dreyfus and Dreyfus (2004) model mentioned earlier of “doing what normally works,” they ask how expertise copes in extraordinary circumstances. They mark the ability to switch back ro and forth from automatic to controlled process as the critical skill needed for expertise in extraordinary circumstances. This ability to self-­ regulate is facilitated by awareness of the situation that allows detection of disfluency, the connection of that disfluency to situational parameters, and the initiation of appropriate corrective lP action (Alter et al., 2007). The expert then has a well-­practiced controlled process to search for alternative solutions to the issue, both naming the difficulty and framing it, placing it in the larger picture of the situation and goals (Schön, 1984).36 Some of the psychological processes underlying this flexibility of automatic action have been described by De Neys (2012, 2021), though again there is disagreement over how na the processes play out (Kruglanski & Szumowska, 2020; Mamede et al., 2010; Wood et al., 2021). Another sort of disfluency can come from recognition that one’s performance in different domains is differentially successful. One barrier to the sort of integrity that is achieved from cross-­domain consistency is competition between domains. Fi Competition can arise from simple conflicts for limited resources (e.g. time) or from more complex conflicts when the goals associated with different cultural or personal domains are in conflict (Schwartz, 2010). When we speak of moral integrity (Mumford et al., 2001; Paine, 1994; Pritchard, 2006), we often refer to consistency in value commitments or consistency of behavior with a particular value commitment (see Chapter 5). But if we think of moral action in the context of domain dependent expertise, it becomes clear that one might have commitment to a domain but not the requisite level of expertise in it. And one can thus speak of 35 Note that this is a different use of the term than what we have used in Section 6.1.2. It is not unusual for such terms to be treated slight differently by different authors (see, e.g. the table of definitions for moral psychology in the Introduction). 36 This process is reminiscent of the hermeneutic framework that Gadamer (1996) provides in his work on medical practice. Taking Moral Action lack of skill as a threat to integrity. Integrity can be threatened by the inevitable competition for limited resources, or from a lack of ethical commitment to domains other than the chosen one, or from a lack of some skill in a less well-­practiced domain. Restoring integrity, then, involves the skill of recognizing the disfluency and moving to address it. The expert has the cognitive capacity to be aware of disfluency and situational context in part because the automatized habits require little capacity to run. Habits are thus a two edged sword: they can both free the expert to respond flexibly to the extraordinary (Moulton et al., 2007) and trap the expert into routines that are not appropriate to the context (Dane, 2010). s"
6,6.5,"Skills Go Awry of Finally, we must make a comment about the moral in the phrase moral skill. What is peculiarly moral about these skills? Psychopaths can exhibit significant self-­ regulation skills in the service of their goals, but still show “feckless disregard” and meanness toward others (Skeem et al., 2011, p. 107). This seems to be based ro in the facet of psychopathy associated with sensitivity to norms (Luke, Neumann, & Gawronski, 2021). The classic work on German police participation in the final solution describes at least one subset of the most efficient “Jew-­ hunters” as having particular emotional regulation skills that allowed them to dislP tance themselves from their work (Browning, 1992, p. 127) and thus to participate willingly in mass murder. Thus, the relationship between morality and the skills and expertise we outline here is at the very least complex, if not contradictory and dialectical.37 Skills and knowledge can be separated from morality and can indeed serve immoral ends. As we have na seen in the various models of moral exemplars (e.g. Colby & Damon, 1992; Walker & Hennig, 2004), moral action and its influences are characterized by equifinality – the same moral action can come about in many different ways. And any particular influence (e.g. a skill, a personality characteristic, etc.) is multi-­final – it can support or contribute to a range of both moral and immoral action. But in most instances, Fi absent moral luck (Nagel, 1979; Williams, 1981), moral actors must have some skills to successfully obtain their goals. Thus, if we want to understand, and ultimately to help develop, successful moral action, we will want to understand the role that skill plays in it. A final thing to note regarding the moral reach of skills is their seeming domain specificity. Even more general skills, such as emotion regulation, can manifest differently in different life domains (Harley et al., 2019). And one can easily imagine that things like moral attentiveness, the ability to recognize moral issues, would depend on knowledge and skill in the particular domain in question (e.g. Nathaniel Borenstein’s recognition of the dangers of particular military software). 37 See the discussion on this in Chapter 9. Skills and Knowledge 167 6.6 Discussion When we include taking action in the domain of morality, expertise based in knowledge, skill, and habit becomes immediately relevant. This approach is both a description of how one operates in a domain and a description of an ideal state toward which one constantly strives. How might this change our picture of moral action? 6.6.1 Conclusion 1. Principled decision making is likely not the primary path to taking moral action. Moral judgment and moral decision-­making may be important skills when operating in difficult situations, but much skilled moral action is not consciously guided. s From the perspective of skill, expertise, and habit, conscious moral judgment and decision-­making of the sort that is measured in moral reasoning tests is likely an exceptional occurrence. Moral acting in everyday life may more often consist of of automatically or habitually pursuing a moral goal rather than constantly deliberating about moral dilemmas. Principled decision-­making may not be primary in terms of being learned first, or in ro terms of being foundational. It is probably one necessary but not sufficient ingredient in the ongoing behavior stream of expertise. It may be most likely to be called upon when some disfluency occurs in action that needs resolution, but even then it may involve intermediate level knowledge in a domain rather than any return to foundational ethical principles. The only way you can claim that principled decision-­making is lP the primary path to moral action is to define moral action as action that occurs based on principled decision-­making. And to do this leaves out a great deal of moral action. 2. Many of the skills and habits that support moral action are domain limited. Expertise is always expertise in some domain. To discover this, one needs only to venture outside that domain (e.g. attempt casual conversation or humanitarian na assistance in another culture). Noticing and responding to a moral issue in one’s family requires different skills and knowledge than doing so at work. Moral exemplars in social service often find themselves regretting the ways they have treated their families. There are more general level skills, such as emotion regulation, that underlie moral action across domains, but even these are likely to have domain Fi limitations. It may well be that this domain specificity of skills contributes to the problem of behavioral integrity that we review in Chapter 5. 3. By designing kind environments, we can leverage the learning of moral expertise in a domain. If we treat moral action as a design problem (see Chapter 3), we can better support the acquisition of moral expertise in new domains. We can identify and teach skills that are automatized in moral action and problem-­solving skills that operate consciously when disfluency in automatic action requires it. Concentrating exclusively on moral judgment will not be enough to support expertise in moral action. When possible, we can provide unambiguous, rapid feedback that supports the development of internally consistent and externally valid mental models and intuition that can underlie automated moral action. Some domains will be more conducive to this approach than others. Value conflicts in some domains will make it harder, and some disfluency in moral action may be due to these conflicts (rather than character). Taking Moral Action 6.6.2 Application On Saturday April 30, 1977, fourteen women gathered for the first demonstration of the Mothers of the Plaza de Mayo. They ignored the warnings of danger from their families and gathered at the center of political power in Argentina to give witness to the disappearances and demand answers. Some of them were themselves later disappeared. These women, and the thousands who joined them, are not famous for their good will. They are famous for their fierce determination, their dogged resistance, their courage, and their skill in resistance and public protest. They are in short famous for courageous skilled moral action. The original members met each other while visiting the same bureaucratic offices in search of their children. They banded together to protest, then organized to march, and then initiated an international information campaign to counter government s propaganda. They knew how to do some of these things, they also knew how to find people with additional skills and how to convince them to take the risk of joining the of movement. Many are still marching today and running websites and international campaigns to keep up the search for those still lost and to prevent the current government from reducing penalties on those convicted of crimes. ro"
6,6.6,"Discussion When we include taking action in the domain of morality, expertise based in knowledge, skill, and habit becomes immediately relevant. This approach is both a description of how one operates in a domain and a description of an ideal state toward which one constantly strives. How might this change our picture of moral action? 6.6.1 Conclusion 1. Principled decision making is likely not the primary path to taking moral action. Moral judgment and moral decision-­making may be important skills when operating in difficult situations, but much skilled moral action is not consciously guided. s From the perspective of skill, expertise, and habit, conscious moral judgment and decision-­making of the sort that is measured in moral reasoning tests is likely an exceptional occurrence. Moral acting in everyday life may more often consist of of automatically or habitually pursuing a moral goal rather than constantly deliberating about moral dilemmas. Principled decision-­making may not be primary in terms of being learned first, or in ro terms of being foundational. It is probably one necessary but not sufficient ingredient in the ongoing behavior stream of expertise. It may be most likely to be called upon when some disfluency occurs in action that needs resolution, but even then it may involve intermediate level knowledge in a domain rather than any return to foundational ethical principles. The only way you can claim that principled decision-­making is lP the primary path to moral action is to define moral action as action that occurs based on principled decision-­making. And to do this leaves out a great deal of moral action. 2. Many of the skills and habits that support moral action are domain limited. Expertise is always expertise in some domain. To discover this, one needs only to venture outside that domain (e.g. attempt casual conversation or humanitarian na assistance in another culture). Noticing and responding to a moral issue in one’s family requires different skills and knowledge than doing so at work. Moral exemplars in social service often find themselves regretting the ways they have treated their families. There are more general level skills, such as emotion regulation, that underlie moral action across domains, but even these are likely to have domain Fi limitations. It may well be that this domain specificity of skills contributes to the problem of behavioral integrity that we review in Chapter 5. 3. By designing kind environments, we can leverage the learning of moral expertise in a domain. If we treat moral action as a design problem (see Chapter 3), we can better support the acquisition of moral expertise in new domains. We can identify and teach skills that are automatized in moral action and problem-­solving skills that operate consciously when disfluency in automatic action requires it. Concentrating exclusively on moral judgment will not be enough to support expertise in moral action. When possible, we can provide unambiguous, rapid feedback that supports the development of internally consistent and externally valid mental models and intuition that can underlie automated moral action. Some domains will be more conducive to this approach than others. Value conflicts in some domains will make it harder, and some disfluency in moral action may be due to these conflicts (rather than character). Taking Moral Action 6.6.2 Application On Saturday April 30, 1977, fourteen women gathered for the first demonstration of the Mothers of the Plaza de Mayo. They ignored the warnings of danger from their families and gathered at the center of political power in Argentina to give witness to the disappearances and demand answers. Some of them were themselves later disappeared. These women, and the thousands who joined them, are not famous for their good will. They are famous for their fierce determination, their dogged resistance, their courage, and their skill in resistance and public protest. They are in short famous for courageous skilled moral action. The original members met each other while visiting the same bureaucratic offices in search of their children. They banded together to protest, then organized to march, and then initiated an international information campaign to counter government s propaganda. They knew how to do some of these things, they also knew how to find people with additional skills and how to convince them to take the risk of joining the of movement. Many are still marching today and running websites and international campaigns to keep up the search for those still lost and to prevent the current government from reducing penalties on those convicted of crimes. ro 6.6.3 Open Questions The idea of moral skill has been embedded in virtue models of moral action since before Aristotle and Confucius. But there has been remarkably little empirical work lP on the skilled action aspects of moral action. We are still in the beginning stages: 1. What skills are involved in what cultures and domains of moral action? There are numerous applied attempts to catalog the skills involved in moral action, but these all suffer from the same “laundry list” complaints made about virtue na approaches (see Chapter 4). Different lists often have little overlap, and the inclusion or exclusion of particular skills seems arbitrary and unrelated to systematic theory. Given the domain-­based nature of expertise, one should not expect a complete skill set that is applicable across all domains. Instead, one might expect some core skills and a large proliferation of domain-­specific skills in the various cultures, Fi professions, vocations, and contexts in which one can take moral action. In parallel with the literature on leadership, these contexts may interact in complex ways with characteristics of the actor and moral ecology. For this reason, work in this area might best start with careful empirical attention to domain and cultural differences and then search for shared or overlapping items. One can then ask which skills might be transferrable across which domain boundaries. 2. How do actors negotiate the interplay between controlled and automatic moral action? Increases in expertise move moral action from the controlled to the automatic. High levels of expertise require subtle shifts between automatic and controlled processing and action. We are only beginning to understand the integration of automatic and controlled action, much less moral action. What controls the interplay between these two ways of taking moral action? What environmental and personal characteristics make cognitive entrenchment more or less likely? What Skills and Knowledge 169 skills are required to recognize disfluency and take controlled action based on it? Are there different kinds of disfluency and do they interact with different characteristics of the environment (e.g. kind/wicked)? 3. How do people understand and learn from moral failure? The point of the discussion in this chapter about disfluency is that one can (but often does not have to) recognize when one’s skilled performance is failing. What are the characteristics of the actor and the situation that allow this recognition to occur and that facilitate effective reparative action? The list of skills associated with moral action present multiple points of failure in this process, including ones that may differ from one domain to another. Self-­regulation involves the organization of attentional, motivational, emotional, and other internal resources in the service of goals. There are multiple points of failure associated with each of these. One can fail in deciding which of many alternate goals to pursue, in planning how best to s attain a valued end, in protecting goals from competing concerns, in recovery when initial efforts fail, and in deciding whether to continue or abandon goals after of failure. The resilience of each of these failure points may also differ depending on the surrounding moral ecology. 4. How does the expertise model help us understand cultural disagreement about moral action? ro One way that cultural disagreements can be viewed is as differences in expertise in different domains or moral ecologies. The knowledge and skill needed for expert-­ level moral acting in an individualistic culture may be quite different from that needed for a collectivist culture (not to mention more specific aspects of a culture, lP e.g. particular religious commitments). There is no requirement that experts always agree (otherwise it would be a simple rule-­oriented domain and require no expertise). If we think about cultural disagreement as disagreement among experts with different kinds of expertise, we may find some guidance regarding the nature, structure, and extent of the moral disagreements one can find between cultures. na"
6,6.7,"Further Readings These suggested readings are designed to lead the reader further into the literature Fi that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. • Benita (2020) “Freedom to feel: A self-­determination theory account of emotion regulation.” A recent review of emotion regulation literature that focuses on the autonomy of the individual. • Dreyfus and Dreyfus (2004) “The ethical implications of the five-­ stage skill-­ acquisition model.” Experts in expertise apply their model to moral action. • Koole (2009). “The psychology of emotion regulation: An integrative review.” A model of emotional regulation that analyses it as the intersection of its functions (goal, need, and person) and the involved systems (attention, knowledge, and body). • Kuhl et al. (2021). “The functional architecture of human motivation.” The most recent summary of personality systems interactions theory that attempts to locate many personality skills in interdependent systems. Taking Moral Action • Narvaez (2005). “The neo-­Kohlbergian tradition and beyond: Schemas, expertise, and character.” An early paper proposing skills and expertise that support moral action. • Narvaez (2010) “Moral complexity: The fatal attraction of truthiness and the importance of mature moral functioning.” A model of mature moral functioning looked at through the lens of expertise across a variety of systems (e.g. cognition, emotion, etc.). • Wood et al. (2021) “Habits and goals in human behavior: Separate but interacting systems.” A review of work on habits that concludes that habits can be activated independent of goals but they can also be integrated into goal pursuit. s"
7,7.1,"What Kind of Reason? What is the role of reason in moral action? This relatively straightforward question has s become more contentious in psychology in the last decades. Kohlberg’s developmental models of morality (Kohlberg, 1964, 1983) have presumed a basis in formal logic of and the ability to generalize it across situations and people (Gibbs, 1977; Gibbs et al., 2007). But other models of rationality parse the world slightly differently. Formal decision theory models of rationality look to maximize our “goal satisfaction” measured by some subjective utility (usefulness) that we perceive in possible outro comes (Payne & Bettman, 2004). We are then rational to the extent that we choose the outcomes that maximize the utility associated with the goal – see Fischhoff and Downs (1997) for an example of this approach and Weber and Johnson (2009) for a critique. As a third option, expertise models of rationality match performance against lP that of selected experts in the area (Dreyfus & Dreyfus, 2004; Schön, 1984). In their respective research literature, each of these three approaches usually proceeds without reference to the other approaches, and limits its investigations to those phenomena most congenial to its particular understanding of reason (Evans & Elqayam, 2011). Kohlbergian approaches focus on logical operations in the applicana tion of principles (Rest et al., 1999). Decision theory approaches concentrate on problems amenable to probabilistic forecasting (Aktipis & Kurzban, 2004; Sunstein, 2005; Yamagishi et al., 2014) Expertise models focus on skilled performance (Huff, 2014; Narvaez & Bock, 2014; Narvaez & Lapsley, 2005). In the realm of moral psychology this means theorists using one of these approaches limit their Fi understanding of morality to only rational deliberation about morality instead of other possible influences, such as personality or emotion. They then further limit their understanding of morality to rationality considered as either logical operations, utility, or expertise and the particular kinds of moral problem most congenial to that approach. One tension all the models share is that between prescribing the correct beliefs and prescribing correct actions. Theoretical reasoning is correct when it leads to correct beliefs (x is good, better, best), while practical reasoning is correct when it leads to action that helps to achieve our (im)moral goals (Over, 2004). Most work in judgment and decision-­ making presupposes practical reason, or “instrumentalist” reason (Over, 2004). Thus: “Reason is wholly instrumental. It cannot tell us where to go; at best it can tell us how to get there. It is a gun for hire that can be employed in the service of any goals we have, good or bad” Simon (1983, pp. 7–8). This “gun for hire” problem will become crucial later as we look at how reason supports immorality. Moral Reason 181 The instrumental nature of rationality does, however, also allow us to open up the field to see more parts of an action as rational. The cognitive psychologist Over (2004) uses the analogy of passing a car to explain this. When overtaking and passing a car, one could narrate all the preconscious and conscious rational judgments one makes in order to do so successfully. These processes are what are called preconscious; we often do not pay attention to them, but we can monitor them. One also does many other things entirely nonconsciously, such as judging the distance between two cars. It is important to get this judgment “good enough” to support the successful achievement of the goal, but it is usually done below the level of consciousness. One does it with “dedicated cognitive processes” (Over, 2004). The same can be said for an action in the moral realm: being a good partner involves much conscious but also much preconscious and nonconscious rational judgment.2 Thus, thinking of reason as instrumentally connected to action makes a much broader variety of rationality, judgment, and skill immediately relevant to moral s psychology. Conscious moral deliberation becomes just the tip of the iceberg. Another tension shared by models of rationality is that between normative prescripof tion of correct reasoning and simple description of how people reason. Many models of reason – and most published research on reason (see Elqayam & Evans, 2011) – p ­ resume a correct way to reason and this benchmark allows researchers to document ways people depart from the model, thus also achieving the goal of description. But this approach ro also implicitly restricts its reach to those places where the “correct” answer can be calculated, and thus ignores many domains of life in which people do important reasoning (Evans & Elqayam, 2011). In response, many researchers are now adopting purely descriptive approaches to rationality (for recent attempts in moral psychology, see Killen lP & Dahl, 2021; Malle, 2021). One lesson for moral psychology is that a turn toward the descriptive may help us get a better grasp of the variety of ways people are moral and the broad range of things that influence moral action.3 But before we move on to these approaches, we will first look at the most widely recognized normative model of moral cognition, one based in conscious logical reasoning about moral principle. Understanding na the complexities of Lawrence Kohlberg’s moral psychology and its eventual fragmentation will be crucial to understanding the current state of the field. 7.2 Kohlberg, Relativism, and Moral Reason Fi If we were required to select the single researcher who had most influenced the development of moral psychology in the last seventy years, the selection would be easy: it is still Lawrence Kohlberg. From his dissertation work in 1958 on moral stages in children, through his long career, and up to his untimely demise in 1987 (Walsh, 2001) Kohlberg founded moral psychology as a sub-­field of developmental psychology and guided its research paradigm for three decades. Now, more than three decades after his death, the field is still influenced by his conceptualizations, accumulated research output, and idealistic commitment to moral education (Frimer & Walker, 2008; 2 One may consciously plan how to support the other’s plans (conscious) and be listening in conversation for those plans (preconscious), while taking turns in sharing the floor of the conversation (nonconscious). All are relevant to the goal of supporting the other. 3 See our argument for this turn in the Introduction. Taking Moral Action Thoma, 2014). The cottage industry of research that has flowered in his wake has made significant revisions, and some outright refutations, to his claims. And it has expanded its scope of inquiry far beyond the relatively narrow category of “moral judgment” that his approach prescribed. But even when he was wrong, Kohlberg was usually wrong in interesting ways. Most presentations of Kohlberg’s system present it as a static six-­stage conceptualization (see Box 7.1). On the contrary, it changed constantly in response to Kohlberg’s own data and to challenges from others. For instance, in later longitudinal studies of his original dissertation participants, some of the people regressed in his stage model, moving from stages 5 and 6 in high school (the highest) to stages 3 and 4 in college. Kohlberg and Kramer (1969, p. 109) called this “sophomore retrogression.” If one believes stages should not include regression, then this was a fault of the instrument, and the scoring system was revised to reinstate invariant forward progression (Gibbs et al., 2007). This s led to a further difficulty, in that the modified scoring system then produced extreme scarcity in attainment of higher stages in the model. Stage 6 ended up being omitted of from the final version of the scoring manual (Colby et al., 1983; Gibbs et al., 2007).4 Thus, the system was constantly evolving over the years Kohlberg was alive. This short review of the most well-­known version of cognition-­based moral judgment will focus on five aspects of Kohlberg’s approach: (1) its challenge to moral relaro tivism; (2) its requirement of explicit judgment; (3) its grounding in cognitive developmental stages; (4) the use of responses to dilemmas as a primary assessment method; and (5) its claims to cultural universality. Each of these still resonate in the field today. We will go on to look at modifications and critiques of the Kohlberg syslP tem of moral development. 7.2.1 Kohlberg’s System for Challenging Moral Relativism This chapter began with the famous comment from the philosopher David Hume na that one cannot bridge the gap from descriptive, empirical “is” statements and prescriptive, normative “ought” statements. In an article titled “From is to Ought” Kohlberg (1971) explains his focus on the implications that empirical moral psychology has for philosophy. He claims he wants to go from is to ought and back again in his research primarily because he is worried about how psychological moral relativism Fi might produce manipulative moral education (Kohlberg, 1971, p. 225). In the first pages of his dissertation, he signals his intent to challenge the reigning psychological approaches to moral development (Kohlberg, 1958, pp. 1–3). He views them as relativistic, reducing moral judgment to simple cultural socialization. And this socialization approach does not, in his eyes, recognize the special claim that judgments in the moral realm have – that they are about what is good and right, and that one can transcend and rationally critique a culture’s judgments about the good. 7.2.1.1 Against Moral Relativism One central concern that Kohlberg had with the cultural relativist position was that it gave license to the moral educator to simply manipulate students into accepting the dominant culture’s morality – to socialize them 4 The collapse of evidence for stage 6 left stranded the even more speculative possibility of a stage 7 in which moral principles were grounded in meta-­ethical or religious commitments (Kohlberg & Power, 1981; Walker & Frimer, 2008). Moral Reason 183 Box 7.1 Kohlberg’s Stages This presentation of the stages is taken from Colby et al. (1983, pp. 3–4). The three major divisions are influenced by Dewey and Tufts and other theorists (Kohlberg, 1971, p. 183). Preconventional level Stage 1: Heteronomous morality: Right is judged in concrete, physical terms. Motivation is avoiding punishment. Social perspective is Normative: Higher Levels of Adequacy in Justice Reasoning egocentric. Empirical: Measured Transformations of Justice Reasoning Stage 2: Individualism: Right is judged as acting in one’s own interest s and being fair. Motivation is serving own interests and recognizing other’s interests. Social perspective is concrete and individualistic. of Conventional level Stage 3: Conformity in mutual relationships: Right is conformity to role expectations and proper motives. Motivation is being a good ro person in your own and other’s eyes and maintaining rules. Social perspective is individual responsibility in mutual relationships. Stage 4: Accepted duties, societal contribution: Right is conformity to duty constructed within a moral system. Motivation is lP conscience-­based obligation and maintaining the moral system. Social perspective is aware of societal and system level in addition to relationships. Postconventional level na Stage 5: Postconventional/principled: Right is based on nonrelative values such as life and liberty; these trump rules in social systems. Motivation is obligation to social and interpersonal contract. Social perspective is aware of values that are prior to contracts. Stage 6: Universal ethical principles: Right is based on universal principles Fi of justice; laws and contracts are right when they rest on these principles. Motivation is personally appropriated universal principles. Social perspective is the foundation of social interaction in moral principle. The two arrows represent the parallelism of the empirically measured developmental pattern (right) with the philosophically normative adequacy (left) of that reasoning (Levine, Kohlberg, & Hewer, 1985, p. 95). without regard to facilitating critical thinking skills that might generate a critique of the society (Kohlberg, 1971, p. 225). He attempts to ground his response to the cultural relativism dominant in psychology by constructing his system on two kinds of explicitly normative approaches: a rational normative approach and a morally normative one. It is rationally normative in the sense he borrows from the philosopher John Dewey Taking Moral Action (Dewey & Tufts, 1908): action should be based on conscious weighing of reasons based in rationality. Thus, Kohlberg was trying to construct a “theory of rational moral judgment like that now present in economics” (Kohlberg, 1971, p. 225).5 It is morally normative in that as one progresses in the stages of moral development one incorporates more of this kind of independent, rational, moral reasoning. This progression itself is borrowed from Dewey’s systematization of societal ethical progression, which runs from early group life, to group morality, to personal, principled morality (Dewey & Tufts, 1908, p. 17). They present this in the anthropological categories current at the time as a cultural progression, developing toward a more rational basis for moral judgment in a culture.6 But in what way does Kohlberg actually go from “is to ought?” His claim of doing so is not based on a logical derivation. This would be the naturalistic fallacy.7 It is instead based on what he described as a “parallelism” between empirical s ­psychology and normative philosophy: that the normative and the empirical will be shown to have similar structure. He claims, for instance, that the empirical of developmental sequence he outlines will also roughly correspond to judgments of the ethical adequacy of the reasons given in those stages. In short, the claim is that the higher descriptive stages of the model are philosophically more adequate. ro Kohlberg’s project is an attempt to find an empirical argument against relativism in order to limit coercion in moral education. If increasing sequences of human development correspond to increases in moral/ethical judgment, and if this sequence is found cross-­culturally, then the philosophical adequacy of moral judgment can itself lP be said to be both rational and cross-­culturally invariant. This parallelism will make cultural relativism difficult to defend. In turn, this will make the idea that morality is simply socialization seem inadequate, thereby putting limits on arbitrary attempts at moral socialization. One can stand up to powerful socializers in the name of moral principle (Killen & Dahl, 2021). na 7.2.1.2 Explicit Judgment In his attempt to move away from the socialization of morality approach that was broadly accepted in his day, Kohlberg turned away from concepts like conformity and guilt and instead focused on explicit moral judgment, putting the weight of judgment back on the individual: “An action … is neither good Fi nor bad unless it has been preceded by a judgment of right or wrong” (Kohlberg, 1958, p. 5). In later work (Kohlberg et al., 1983) he would call this the assumption of phenomenalism. Any actions that are not consciously chosen for moral reasons are not in the domain of study. This assumption has until recently been widely shared in moral psychology (Narvaez, 2010). This approach treats nonconscious influence, personality, emotion, and even skilled automatized action as at best irrelevant and at worst a biasing influence (Walker & Hennig, 2004). The current blooming of research 5 See also p. 52 in his 1958 dissertation. 6 These cultural assumptions have been strongly critiqued in the current anthropological literature (Keane, 2015; Shweder, Mahapatra, & Miller, 1987). 7 See n. 1. Moral Reason 185 in moral psychology has come about in part because it has freed itself from this narrow definition. But the narrow focus on conscious reason was central to Kohlberg’s project of overcoming the relativism inherent in the pure socialization approaches of behaviorist and psychodynamic approaches. This suggests that rejecting Kohlberg’s conscious phenomenalism may come with a cost: opening up descriptive psychological approaches to a naïve cultural relativism. For instance, the recent work in moral foundations theory is quite explicit in its interest in cultural differences in morality and embrace of relativism (Graham et al., 2011). Other theorists are skeptical of this turn (Killen & Dahl, 2021; Narvaez, 2010). 7.2.1.3 Cognitive Developmental Stages In constructing his developmental stage system, Kohlberg put two keys from Piaget to good use. First was his construction of stages that were cumulative, invariant, and dependent on the logic of the domain for s their sequence. The second followed from this, and was Piaget’s identification of social interaction as a primary developmental influence in moral development (Gibbs of et al., 2007). Thus, the stages identified in Box 7.1 do not, in Kohlberg’s system, depend on any specially dedicated evolutionary modules (Cosmides & Tooby, 2008) or on anything more than biological development and accumulated experience that support the abilro ity to make the relevant distinctions. Once one has the cognitive capacity to recognize others’ perspectives, and enough practice doing so, one can move from pre-­ conventional to conventional moral reasoning. Thus, one can expect that advancement in moral reasoning stages will co-­occur with advancement in abstract reasoning, lP but also with more extensive experience of peer interaction that requires and provides practice for social perspective taking. Moral judgment and its development are patterned by the kind of cognitive and social creatures we are. One outcome of this emphasis is that, at least at the lower levels, one can expect the stages and their progression to be cross-­culturally similar. But to the extent that cultures restrict opporna tunities for social perspective taking (by, e.g. restricting social interaction), one might see less movement to higher stages – specifically because it is in part this social interaction that drives development. This commitment to stage progression based on logical properties of the domain allowed Kohlberg to challenge relativism by showing that, across cultures, more philFi osophically adequate moral reasoning was achieved by a naturally occurring developmental sequence. But its cognitive foundations also required the model to assume that advances in the logical progression could not be retreated from. Once one acquires the capacity and learns the logical transformation of perspective taking, regression away from this ability makes little sense,unless it is cognitive capacity that is being lost.8 8 At least, it makes little sense in a logical system, and threatens to undermine the anti-­ relativist goal of the system. It might well make sense in a human system. But to recognize this would lose the parallelism that is central to the project. Taking Moral Action 7.2.1.4 Dilemma-­based Assessment Kohlberg’s assessment model was, as fits his system, based in the conscious giving of reasons in a conversation. But it was a particular kind of conversation he had most in mind. As he initially said in his dissertation: it is clear that our conception of morality implies or refers to rather complex thoughts and feelings about action in genuine conflict or crisis situations. Accordingly, we decided to use extensively probed open-­ended individual interviews about hypothetical conflict situations which posed genuine dilemmas to educated adults (Kohlberg, 1958, pp. 75–76) Thus, instead of using Piaget’s method of asking for comment on pairs of stories that are modified in particular ways (e.g. a child broke fifteen cups vs. just one cup), Kohlberg selected stories where values were conflicted and one had to choose a course of action. Which action was chosen was not central to the coding. Kohlberg rather concentrated s on the reasons one gave for the choice and how one reasoned. This assessment method was cumbersome, time-­consuming, and required highly trained interviewers and codof ers. Others have adapted the dilemma technique to questionnaire forms that are machine-­scored (Rest et al., 1999), and this achievement is in part responsible for the widespread use of Kohlberg’s approach as a method in ethics assessment. There is another legacy to Kohlberg’s measurement approach: the giving of ro rational explanations in the context of value conflicts and choice dilemmas. This looks most like what philosophers do in constructing cases to make their arguments in ethics and meta-­ethics. But because it always places the thinker in a difficult moral choice, it narrows the domain of ethics and morality to what Pincoffs lP (1971, p. 571) has called “quandary ethics,” and it results in “an indefensibly narrow conception of the subject of ethics.” This leaves us with an even narrower focus in morality: not only conscious reasoning about morality but also conscious reasoning about a particular aspect of morality – those situations where values are in conflict and the only possible options play those values off against each other. na This approach ignores moral action that is done without conscious intent, but it excludes even the moral cognition and action of exemplars who spend most of their conscious (and perhaps unconscious) energy pursuing a moral goal to which they long ago dedicated themselves. 7.2.1.5 Universality Claims Kohlberg’s system is founded in the development of Fi basic human reasoning capacity in the context of social perspective taking and reason giving. Because it has this structure, it makes a controversial claim for the cultural universality of the stages of moral reasoning. All people in all cultures should move from one stage to the next as they develop in moral reasoning. And this development in moral reasoning should be tied to practice in social perspective taking. This leads to two empirical predictions: (1) that, at least in early stages there should be parallel development across cultures; and (2) that this development, particularly for higher stages, should depend on social experience that requires perspective taking and reasoning about it. An implication of this approach is that: moral judgment maturity should correlate with age, education, higher socioeconomic status, urban (versus rural) settings, and community participation, insofar as these variables index the affordance and accumulation of diverse social experiences and perspective-­taking opportunities through social participation (Gibbs et al., 2007, p. 446) Moral Reason 187 The short answer to this question is that, at least for the progression in stages 1–3, one does find the correlations one would expect across a wide variety of cultures: two large reviews of the evidence in studies across forty-­two countries come to this conclusion (Gibbs et al., 2007). Progression from stages 1 to 2 occurred in most cultures by late childhood, with the exceptions having to do with experiential variables (e.g. education, rural setting) that would reduce exposure to social perspective taking. By late adolescence, stage 3 becomes the predominant reasoning level across cultures, and stage 4 begins to predominate among adults across cultures, with the exception of rural and less well-­educated samples. But at the higher levels, particularly the transition to post-­conventional thinking, the stage progression begins to fall apart. It seems most descriptive of the development of individuals, across cultures, with education at the university level, perhaps because this facilitates social perspective taking (Gibbs et al., 2007). Does s this mean that individuals in rural cultures are necessarily less morally developed in their reasoning? Or that the theory is necessarily biased against those without acaof demic training? Some theorists have suggested that the emphasis on justice reasoning in Kohlberg’s post-­conventional stages misses the diversity of ways one might become post-­ conventional in morality. One can critique and transcend conventional moral standro ards, for instance, by existential reflection (Gibbs, 1977), or by using the resources already available in the culture to propose alternative ways of thinking (Gibbs et al., 2007). Asking “Why do bad things happen to good people?” or “Why be moral?” can be the beginning of stepping outside of conventional morality and facing lP moral questions from an independent (and thus post-­conventional), existential perspective. But one can also use religious principle to critique conventional morality. One of the central characteristics of religion is its critique of conventional morality (Bellah, 2011). Gregg (2005, chapter 3) reviews how the values of Islam help to counter and limit the honor/shame system in Middle Eastern countries, and even na help to “set the developmental task of identity formation … to integrate pursuits of honor and piety into a whole, or at least a balanced life” (Gregg, 2005, p. 167).9 7.2.2 Critiques of Kohlberg’s System Fi In part because of his controversial claims, and in part because the system was for many years the reigning paradigm for thinking about morality, Kohlberg’s system has collected many detractors, critiques, and attempts at modification. We have already seen evidence of two, the limitations of conscious rationality and the complexity of cross-­ cultural application. Here we will review a few others that have received attention. 7.2.2.1 Gender and the Concept of Care One of the most widely known controversies in moral psychology of the previous century was that initiated by Carol Gilligan in her 9 Kohlberg would score basic religious commitments as a part of conventional morality (Richards & Davison, 1992) but might score more sophisticated religious reflection as post-­conventional (Gibbs, 1977). Taking Moral Action (1977) book In a Different Voice. Its strength for moral psychology was to point out an alternative developmental path for moral judgment and action that focused on human relations and an ethic of care. Gilligan claimed that women were more guided by care in networks of relationship while men were guided by abstract concerns of justice and thus that Kohlberg’s system underestimates the moral development of women. These claims did not hold up under further investigation (Gibbs et al., 2007; Walker, 1984). If anything, there is a slight developmental advantage for women, and both men and women use care reasoning about equally. 7.2.2.2 Pre-­Conventional Morality and Complexity The early stages of Kohlberg’s system have also suffered from fragmentation. Young children are often genuinely other-­oriented, though they have trouble connecting this with reasoning about others’ experience and their own motivations (Malti & Ongley, 2014). Even toddlers s (Tomasello & Vaish, 2013) and infants (Van de Vondervoort & Hamlin, 2018; Wynn & Bloom, 2014) understand something about helping, cooperation, other’s feelings, of etc. Much of the development is tracked by development of “theory of mind,” that is, the child’s understanding of the relations between mental states, emotions, and behavior in both the self and other (Lagattuta & Weller, 2014; Malti & Ongley, 2014; Wellman, 2018). ro 7.2.2.3 Post-­Conventional Morality and Cultural Pluralism The anthropologists Shweder and Menon (2014) agree with Kohlberg that a simplistic cultural relativism poses significant problems for a good description of the special status of morality across lP cultures but critique Kohlberg’s approach to moral objectivism. Their moral objectivism is instead a descriptive moral universal: all cultures seem to assume an “objective moral charter.” Across all cultures, moral judgments are seen as making claims about an objective moral reality that other reasonable minds must agree with. The relativist ideal means in the end that “there is no meaningful distinction to be drawn between morality na and power” whether that power is exercised by individuals, governments, or cultures (Shweder & Menon, 2014, pp. 14–15). Thus, they argue for a pluralist vision, one that holds in tension cultural diversity of moral judgment, respect for the moral judgment of others, and a commitment to understanding the “objective moral charter.” Of course power is involved in social change attempts, but it is often not Fi simply about power but about a vision of the good (Killen & Dahl, 2021)."
7,7.2,"Kohlberg, Relativism, and Moral Reason Fi If we were required to select the single researcher who had most influenced the development of moral psychology in the last seventy years, the selection would be easy: it is still Lawrence Kohlberg. From his dissertation work in 1958 on moral stages in children, through his long career, and up to his untimely demise in 1987 (Walsh, 2001) Kohlberg founded moral psychology as a sub-­field of developmental psychology and guided its research paradigm for three decades. Now, more than three decades after his death, the field is still influenced by his conceptualizations, accumulated research output, and idealistic commitment to moral education (Frimer & Walker, 2008; 2 One may consciously plan how to support the other’s plans (conscious) and be listening in conversation for those plans (preconscious), while taking turns in sharing the floor of the conversation (nonconscious). All are relevant to the goal of supporting the other. 3 See our argument for this turn in the Introduction. Taking Moral Action Thoma, 2014). The cottage industry of research that has flowered in his wake has made significant revisions, and some outright refutations, to his claims. And it has expanded its scope of inquiry far beyond the relatively narrow category of “moral judgment” that his approach prescribed. But even when he was wrong, Kohlberg was usually wrong in interesting ways. Most presentations of Kohlberg’s system present it as a static six-­stage conceptualization (see Box 7.1). On the contrary, it changed constantly in response to Kohlberg’s own data and to challenges from others. For instance, in later longitudinal studies of his original dissertation participants, some of the people regressed in his stage model, moving from stages 5 and 6 in high school (the highest) to stages 3 and 4 in college. Kohlberg and Kramer (1969, p. 109) called this “sophomore retrogression.” If one believes stages should not include regression, then this was a fault of the instrument, and the scoring system was revised to reinstate invariant forward progression (Gibbs et al., 2007). This s led to a further difficulty, in that the modified scoring system then produced extreme scarcity in attainment of higher stages in the model. Stage 6 ended up being omitted of from the final version of the scoring manual (Colby et al., 1983; Gibbs et al., 2007).4 Thus, the system was constantly evolving over the years Kohlberg was alive. This short review of the most well-­known version of cognition-­based moral judgment will focus on five aspects of Kohlberg’s approach: (1) its challenge to moral relaro tivism; (2) its requirement of explicit judgment; (3) its grounding in cognitive developmental stages; (4) the use of responses to dilemmas as a primary assessment method; and (5) its claims to cultural universality. Each of these still resonate in the field today. We will go on to look at modifications and critiques of the Kohlberg syslP tem of moral development. 7.2.1 Kohlberg’s System for Challenging Moral Relativism This chapter began with the famous comment from the philosopher David Hume na that one cannot bridge the gap from descriptive, empirical “is” statements and prescriptive, normative “ought” statements. In an article titled “From is to Ought” Kohlberg (1971) explains his focus on the implications that empirical moral psychology has for philosophy. He claims he wants to go from is to ought and back again in his research primarily because he is worried about how psychological moral relativism Fi might produce manipulative moral education (Kohlberg, 1971, p. 225). In the first pages of his dissertation, he signals his intent to challenge the reigning psychological approaches to moral development (Kohlberg, 1958, pp. 1–3). He views them as relativistic, reducing moral judgment to simple cultural socialization. And this socialization approach does not, in his eyes, recognize the special claim that judgments in the moral realm have – that they are about what is good and right, and that one can transcend and rationally critique a culture’s judgments about the good. 7.2.1.1 Against Moral Relativism One central concern that Kohlberg had with the cultural relativist position was that it gave license to the moral educator to simply manipulate students into accepting the dominant culture’s morality – to socialize them 4 The collapse of evidence for stage 6 left stranded the even more speculative possibility of a stage 7 in which moral principles were grounded in meta-­ethical or religious commitments (Kohlberg & Power, 1981; Walker & Frimer, 2008). Moral Reason 183 Box 7.1 Kohlberg’s Stages This presentation of the stages is taken from Colby et al. (1983, pp. 3–4). The three major divisions are influenced by Dewey and Tufts and other theorists (Kohlberg, 1971, p. 183). Preconventional level Stage 1: Heteronomous morality: Right is judged in concrete, physical terms. Motivation is avoiding punishment. Social perspective is Normative: Higher Levels of Adequacy in Justice Reasoning egocentric. Empirical: Measured Transformations of Justice Reasoning Stage 2: Individualism: Right is judged as acting in one’s own interest s and being fair. Motivation is serving own interests and recognizing other’s interests. Social perspective is concrete and individualistic. of Conventional level Stage 3: Conformity in mutual relationships: Right is conformity to role expectations and proper motives. Motivation is being a good ro person in your own and other’s eyes and maintaining rules. Social perspective is individual responsibility in mutual relationships. Stage 4: Accepted duties, societal contribution: Right is conformity to duty constructed within a moral system. Motivation is lP conscience-­based obligation and maintaining the moral system. Social perspective is aware of societal and system level in addition to relationships. Postconventional level na Stage 5: Postconventional/principled: Right is based on nonrelative values such as life and liberty; these trump rules in social systems. Motivation is obligation to social and interpersonal contract. Social perspective is aware of values that are prior to contracts. Stage 6: Universal ethical principles: Right is based on universal principles Fi of justice; laws and contracts are right when they rest on these principles. Motivation is personally appropriated universal principles. Social perspective is the foundation of social interaction in moral principle. The two arrows represent the parallelism of the empirically measured developmental pattern (right) with the philosophically normative adequacy (left) of that reasoning (Levine, Kohlberg, & Hewer, 1985, p. 95). without regard to facilitating critical thinking skills that might generate a critique of the society (Kohlberg, 1971, p. 225). He attempts to ground his response to the cultural relativism dominant in psychology by constructing his system on two kinds of explicitly normative approaches: a rational normative approach and a morally normative one. It is rationally normative in the sense he borrows from the philosopher John Dewey Taking Moral Action (Dewey & Tufts, 1908): action should be based on conscious weighing of reasons based in rationality. Thus, Kohlberg was trying to construct a “theory of rational moral judgment like that now present in economics” (Kohlberg, 1971, p. 225).5 It is morally normative in that as one progresses in the stages of moral development one incorporates more of this kind of independent, rational, moral reasoning. This progression itself is borrowed from Dewey’s systematization of societal ethical progression, which runs from early group life, to group morality, to personal, principled morality (Dewey & Tufts, 1908, p. 17). They present this in the anthropological categories current at the time as a cultural progression, developing toward a more rational basis for moral judgment in a culture.6 But in what way does Kohlberg actually go from “is to ought?” His claim of doing so is not based on a logical derivation. This would be the naturalistic fallacy.7 It is instead based on what he described as a “parallelism” between empirical s ­psychology and normative philosophy: that the normative and the empirical will be shown to have similar structure. He claims, for instance, that the empirical of developmental sequence he outlines will also roughly correspond to judgments of the ethical adequacy of the reasons given in those stages. In short, the claim is that the higher descriptive stages of the model are philosophically more adequate. ro Kohlberg’s project is an attempt to find an empirical argument against relativism in order to limit coercion in moral education. If increasing sequences of human development correspond to increases in moral/ethical judgment, and if this sequence is found cross-­culturally, then the philosophical adequacy of moral judgment can itself lP be said to be both rational and cross-­culturally invariant. This parallelism will make cultural relativism difficult to defend. In turn, this will make the idea that morality is simply socialization seem inadequate, thereby putting limits on arbitrary attempts at moral socialization. One can stand up to powerful socializers in the name of moral principle (Killen & Dahl, 2021). na 7.2.1.2 Explicit Judgment In his attempt to move away from the socialization of morality approach that was broadly accepted in his day, Kohlberg turned away from concepts like conformity and guilt and instead focused on explicit moral judgment, putting the weight of judgment back on the individual: “An action … is neither good Fi nor bad unless it has been preceded by a judgment of right or wrong” (Kohlberg, 1958, p. 5). In later work (Kohlberg et al., 1983) he would call this the assumption of phenomenalism. Any actions that are not consciously chosen for moral reasons are not in the domain of study. This assumption has until recently been widely shared in moral psychology (Narvaez, 2010). This approach treats nonconscious influence, personality, emotion, and even skilled automatized action as at best irrelevant and at worst a biasing influence (Walker & Hennig, 2004). The current blooming of research 5 See also p. 52 in his 1958 dissertation. 6 These cultural assumptions have been strongly critiqued in the current anthropological literature (Keane, 2015; Shweder, Mahapatra, & Miller, 1987). 7 See n. 1. Moral Reason 185 in moral psychology has come about in part because it has freed itself from this narrow definition. But the narrow focus on conscious reason was central to Kohlberg’s project of overcoming the relativism inherent in the pure socialization approaches of behaviorist and psychodynamic approaches. This suggests that rejecting Kohlberg’s conscious phenomenalism may come with a cost: opening up descriptive psychological approaches to a naïve cultural relativism. For instance, the recent work in moral foundations theory is quite explicit in its interest in cultural differences in morality and embrace of relativism (Graham et al., 2011). Other theorists are skeptical of this turn (Killen & Dahl, 2021; Narvaez, 2010). 7.2.1.3 Cognitive Developmental Stages In constructing his developmental stage system, Kohlberg put two keys from Piaget to good use. First was his construction of stages that were cumulative, invariant, and dependent on the logic of the domain for s their sequence. The second followed from this, and was Piaget’s identification of social interaction as a primary developmental influence in moral development (Gibbs of et al., 2007). Thus, the stages identified in Box 7.1 do not, in Kohlberg’s system, depend on any specially dedicated evolutionary modules (Cosmides & Tooby, 2008) or on anything more than biological development and accumulated experience that support the abilro ity to make the relevant distinctions. Once one has the cognitive capacity to recognize others’ perspectives, and enough practice doing so, one can move from pre-­ conventional to conventional moral reasoning. Thus, one can expect that advancement in moral reasoning stages will co-­occur with advancement in abstract reasoning, lP but also with more extensive experience of peer interaction that requires and provides practice for social perspective taking. Moral judgment and its development are patterned by the kind of cognitive and social creatures we are. One outcome of this emphasis is that, at least at the lower levels, one can expect the stages and their progression to be cross-­culturally similar. But to the extent that cultures restrict opporna tunities for social perspective taking (by, e.g. restricting social interaction), one might see less movement to higher stages – specifically because it is in part this social interaction that drives development. This commitment to stage progression based on logical properties of the domain allowed Kohlberg to challenge relativism by showing that, across cultures, more philFi osophically adequate moral reasoning was achieved by a naturally occurring developmental sequence. But its cognitive foundations also required the model to assume that advances in the logical progression could not be retreated from. Once one acquires the capacity and learns the logical transformation of perspective taking, regression away from this ability makes little sense,unless it is cognitive capacity that is being lost.8 8 At least, it makes little sense in a logical system, and threatens to undermine the anti-­ relativist goal of the system. It might well make sense in a human system. But to recognize this would lose the parallelism that is central to the project. Taking Moral Action 7.2.1.4 Dilemma-­based Assessment Kohlberg’s assessment model was, as fits his system, based in the conscious giving of reasons in a conversation. But it was a particular kind of conversation he had most in mind. As he initially said in his dissertation: it is clear that our conception of morality implies or refers to rather complex thoughts and feelings about action in genuine conflict or crisis situations. Accordingly, we decided to use extensively probed open-­ended individual interviews about hypothetical conflict situations which posed genuine dilemmas to educated adults (Kohlberg, 1958, pp. 75–76) Thus, instead of using Piaget’s method of asking for comment on pairs of stories that are modified in particular ways (e.g. a child broke fifteen cups vs. just one cup), Kohlberg selected stories where values were conflicted and one had to choose a course of action. Which action was chosen was not central to the coding. Kohlberg rather concentrated s on the reasons one gave for the choice and how one reasoned. This assessment method was cumbersome, time-­consuming, and required highly trained interviewers and codof ers. Others have adapted the dilemma technique to questionnaire forms that are machine-­scored (Rest et al., 1999), and this achievement is in part responsible for the widespread use of Kohlberg’s approach as a method in ethics assessment. There is another legacy to Kohlberg’s measurement approach: the giving of ro rational explanations in the context of value conflicts and choice dilemmas. This looks most like what philosophers do in constructing cases to make their arguments in ethics and meta-­ethics. But because it always places the thinker in a difficult moral choice, it narrows the domain of ethics and morality to what Pincoffs lP (1971, p. 571) has called “quandary ethics,” and it results in “an indefensibly narrow conception of the subject of ethics.” This leaves us with an even narrower focus in morality: not only conscious reasoning about morality but also conscious reasoning about a particular aspect of morality – those situations where values are in conflict and the only possible options play those values off against each other. na This approach ignores moral action that is done without conscious intent, but it excludes even the moral cognition and action of exemplars who spend most of their conscious (and perhaps unconscious) energy pursuing a moral goal to which they long ago dedicated themselves. 7.2.1.5 Universality Claims Kohlberg’s system is founded in the development of Fi basic human reasoning capacity in the context of social perspective taking and reason giving. Because it has this structure, it makes a controversial claim for the cultural universality of the stages of moral reasoning. All people in all cultures should move from one stage to the next as they develop in moral reasoning. And this development in moral reasoning should be tied to practice in social perspective taking. This leads to two empirical predictions: (1) that, at least in early stages there should be parallel development across cultures; and (2) that this development, particularly for higher stages, should depend on social experience that requires perspective taking and reasoning about it. An implication of this approach is that: moral judgment maturity should correlate with age, education, higher socioeconomic status, urban (versus rural) settings, and community participation, insofar as these variables index the affordance and accumulation of diverse social experiences and perspective-­taking opportunities through social participation (Gibbs et al., 2007, p. 446) Moral Reason 187 The short answer to this question is that, at least for the progression in stages 1–3, one does find the correlations one would expect across a wide variety of cultures: two large reviews of the evidence in studies across forty-­two countries come to this conclusion (Gibbs et al., 2007). Progression from stages 1 to 2 occurred in most cultures by late childhood, with the exceptions having to do with experiential variables (e.g. education, rural setting) that would reduce exposure to social perspective taking. By late adolescence, stage 3 becomes the predominant reasoning level across cultures, and stage 4 begins to predominate among adults across cultures, with the exception of rural and less well-­educated samples. But at the higher levels, particularly the transition to post-­conventional thinking, the stage progression begins to fall apart. It seems most descriptive of the development of individuals, across cultures, with education at the university level, perhaps because this facilitates social perspective taking (Gibbs et al., 2007). Does s this mean that individuals in rural cultures are necessarily less morally developed in their reasoning? Or that the theory is necessarily biased against those without acaof demic training? Some theorists have suggested that the emphasis on justice reasoning in Kohlberg’s post-­conventional stages misses the diversity of ways one might become post-­ conventional in morality. One can critique and transcend conventional moral standro ards, for instance, by existential reflection (Gibbs, 1977), or by using the resources already available in the culture to propose alternative ways of thinking (Gibbs et al., 2007). Asking “Why do bad things happen to good people?” or “Why be moral?” can be the beginning of stepping outside of conventional morality and facing lP moral questions from an independent (and thus post-­conventional), existential perspective. But one can also use religious principle to critique conventional morality. One of the central characteristics of religion is its critique of conventional morality (Bellah, 2011). Gregg (2005, chapter 3) reviews how the values of Islam help to counter and limit the honor/shame system in Middle Eastern countries, and even na help to “set the developmental task of identity formation … to integrate pursuits of honor and piety into a whole, or at least a balanced life” (Gregg, 2005, p. 167).9 7.2.2 Critiques of Kohlberg’s System Fi In part because of his controversial claims, and in part because the system was for many years the reigning paradigm for thinking about morality, Kohlberg’s system has collected many detractors, critiques, and attempts at modification. We have already seen evidence of two, the limitations of conscious rationality and the complexity of cross-­ cultural application. Here we will review a few others that have received attention. 7.2.2.1 Gender and the Concept of Care One of the most widely known controversies in moral psychology of the previous century was that initiated by Carol Gilligan in her 9 Kohlberg would score basic religious commitments as a part of conventional morality (Richards & Davison, 1992) but might score more sophisticated religious reflection as post-­conventional (Gibbs, 1977). Taking Moral Action (1977) book In a Different Voice. Its strength for moral psychology was to point out an alternative developmental path for moral judgment and action that focused on human relations and an ethic of care. Gilligan claimed that women were more guided by care in networks of relationship while men were guided by abstract concerns of justice and thus that Kohlberg’s system underestimates the moral development of women. These claims did not hold up under further investigation (Gibbs et al., 2007; Walker, 1984). If anything, there is a slight developmental advantage for women, and both men and women use care reasoning about equally. 7.2.2.2 Pre-­Conventional Morality and Complexity The early stages of Kohlberg’s system have also suffered from fragmentation. Young children are often genuinely other-­oriented, though they have trouble connecting this with reasoning about others’ experience and their own motivations (Malti & Ongley, 2014). Even toddlers s (Tomasello & Vaish, 2013) and infants (Van de Vondervoort & Hamlin, 2018; Wynn & Bloom, 2014) understand something about helping, cooperation, other’s feelings, of etc. Much of the development is tracked by development of “theory of mind,” that is, the child’s understanding of the relations between mental states, emotions, and behavior in both the self and other (Lagattuta & Weller, 2014; Malti & Ongley, 2014; Wellman, 2018). ro 7.2.2.3 Post-­Conventional Morality and Cultural Pluralism The anthropologists Shweder and Menon (2014) agree with Kohlberg that a simplistic cultural relativism poses significant problems for a good description of the special status of morality across lP cultures but critique Kohlberg’s approach to moral objectivism. Their moral objectivism is instead a descriptive moral universal: all cultures seem to assume an “objective moral charter.” Across all cultures, moral judgments are seen as making claims about an objective moral reality that other reasonable minds must agree with. The relativist ideal means in the end that “there is no meaningful distinction to be drawn between morality na and power” whether that power is exercised by individuals, governments, or cultures (Shweder & Menon, 2014, pp. 14–15). Thus, they argue for a pluralist vision, one that holds in tension cultural diversity of moral judgment, respect for the moral judgment of others, and a commitment to understanding the “objective moral charter.” Of course power is involved in social change attempts, but it is often not Fi simply about power but about a vision of the good (Killen & Dahl, 2021). 7.2.3 What Remains of Kohlberg A systematic response to these difficulties in the Kohlberg project has been mounted by James Rest, Darcia Narvaez, Muriel Bebeau, and Steven Thoma in what they call a “neo-­Kohlbergian” model of morality (Rest et al., 1999). Their approach is consciously eclectic, borrowing from multiple research traditions within psychology (Narvaez, 2005, 2010; Narvaez & Bock, 2002, 2014; Thoma, Derryberry, & Crowson, 2013) to construct a recognizably Kohlbergian approach that is much more flexible and congenial to the current burgeoning of research in moral reasoning presented in the rest of this chapter. One thing not modified in the neo-­Kohlbergians’ various accounts is the commitment to a Kohlberg-­style moral objectivism rooted in a developmental worldview: it Moral Reason 189 is difficult to talk about moral development if one thinks any moral approach is as adequate as the next. Development beyond childhood requires a conventional recognition of mutual dependence and social rules that limit or modify one’s desires. Further development beyond this conventional stage requires the ability to construct a representation of that system and to critique it. This cultural critique is made possible by natural variations in value systems in the moral ecology that can provide cognitive and emotional resources for both critique of conventional morality and moral persuasion to influence the conventional moral ecology. This critique and persuasion can use such cultural resources as religion, social influence from groups, shared cultural commitments (e.g. agreed upon rights), and attractive practices from other cultures (e.g. recognition of various rights) to critique the culture itself and to work for social change. At the individual level, it may also be these resources that make possible a switch to a post-­conventional moral commitment. There is still much s work to be done to document how this occurs (Keane, 2015) and whether this ­critique depends psychologically on an objectivist conception of moral judgment of (Killen & Dahl, 2021). Without this ability to engage in cultural critique “there might still be an Atlantic slave trade” (Narvaez, 2010, p. 168). Narvaez and colleagues see this sort of moral advance as the result of “more agile perspective taking, an ability to appeal to ideals ro that are shareable and not exclusive” (Narvaez, 2010, p. 167). The context of this quote suggests that this “post-­conventional thinking” should be shareable across cultures and thus provide a limited and negotiable kind of cultural universal in the domain of morality. The neo-­Kohlbergian approaches see cognitive, schematic prolP cessing as an important influence in moral judgment and action. However, they also see intuitive, implicit processing and emotion as equally important partners. It is to these intuitive aspects of cognition that we now turn. na 7.3 Implicit Cognition and Two-­Process Models That we are often “of two minds” about things has been recognized by both ancient and modern authors. Augustine of Hippo’s Confessions (Augustine, 397/2007, Book 8, chapter 9) offered an early exploration of multiple wills. The Scottish empiriFi cist Adam Smith (1759/2009) proposed that it was the interaction of our passions and an imagined “impartial spectator” that together shaped our choices. Schelling (1800/1993) revived the concept of the unconscious as a central part of knowing and acting (McGrath, 2012). Kierkegaard explored the dynamics of multiple aspects of the self (Kierkegaard, 1849/2004). And, of course, Freud systematized the unconscious (Breuer & Freud, 1895/2000) as a dynamic, emotionally rich driver of thought and action. All these theorists were pointing to various aspects of unconscious processing and its relation to conscious, controlled processing. More recently, the unconscious has been resurrected by cognitive psychologists as nonconscious processing, at least initially stripped of its association with creative impulses and emotional content. Fodor (1983) introduced one of the first such ­systems, though the term “dual process” had been used earlier in reference to a contrast between conscious and nonconscious influences on behavior (Wason & Evans, 1975). Since these early beginnings, work on dual process theories of cognition Taking Moral Action could fill volumes (e.g. Kahneman, 2011; Nisbett & Ross, 1980). Dual process ­theories are widely divergent in their assumptions (see Evans & Stanovich, 2013 for a review) and have some detractors (Kruglanski & Thompson, 1999; Osman, 2004). But they have proven quite influential in moral psychology. After looking for some structure in what we might mean by dual processes, we will review four significant theoretical approaches in moral psychology that have been influenced by dual process theories but give different answers to what the content of those processes might be. 7.3.1 What Are Two-­Process Models? It is important to begin this section with the plural. There is not one agreed upon two-­process approach to understanding cognition. Theorists disagree on a range of issues, including whether there are two or even more systems, whether the difference s is one of type (with a clear distinction) or of mode (with a range of intermediate positions), the extent to which they can be consciously controlled, and a host of other of disagreements (Evans & Stanovich, 2013). Any generalization at this early stage of theorizing should be done with caution. Nevertheless, if we assume for the moment that there are only two types of processing, and that they are distinct, what is the distinction? It is that some of the cognitive ro processing we do requires cognitive effort – it takes concentration and working memory. But at other times, and for other kinds of stimuli, processing is relatively effortless and requires little in the way of working memory. This latter kind of process has been called “system 1” processing, in partial reference to the thought that it evolved lP earlier than the more effortful, working-­memory-­intensive processing, which is called “system 2.” Table 7.1 presents a schematic of the two systems of processing. The items listed under defining features are, according to Evans and Stanovich (2013), the characteristics of the two types that are central and always present, while the typical correlates section lists characteristics that are often associated with the type, but for na which there are exceptions.10 The bottom section of the table lists characteristics of the two processes that are often cited when the processes are proposed as different systems that evolved somewhat separately. Like Kohlberg (1958), when we think of cognition we normally think of conscious, deliberate, guided processing, or type 2 processing. We usually have conscious Fi access to both the processes and their outcomes. That is, we are aware of and deliberatively guide our selection of the things we consider, how and how long we consider them, and the conclusions we reach. This deliberation takes effort, can be abstract and hypothetical (e.g. What if it were not my country’s flag?) and is associated with intelligence. Type 1 processes are rapid, more hidden from our awareness, usually proceed without our conscious guidance, and we only have access to their seemingly self-­evident conclusions. For this reason, type 1 processes are often called “intuitive.” 10 This slipperiness of the definitions of the two systems is not new. As early as 1989, Bargh argued that awareness, attention, intention, and control are a loosely tethered set of attributes of automatic processes. Thus, the idea that type 1 processes occur in great variety has at least a moderately long history. Moral Reason 191 Table 7.1 Characteristic properties of dual-­process cognition. Type 1 process (intuitive) Type 2 process (reflective) Defining features: Does not require working memory Requires working memory Autonomous Cognitive decoupling;mental simulation Typical (but not necessary) correlates: Fast Slow High capacity Capacity limited Parallel Serial Nonconscious Conscious Biased responses Normative responses s Contextualized Abstract Automatic Controlled Associative Rule-­based of Experience-­based decision-­making Consequentialdecision-­making Independent of cognitive ability Correlated with cognitive ability When considered as evolved systems: Evolved early ro Evolved late Shared with other animals Distinctively human Implicit knowledge Explicit knowledge Basic emotions Complex emotions lP Source: Adapted from Evans and Stanovich (2013) and De Neys (2021). A good example of how the two processes interact in the moral domain is moral dumbfounding (Haidt, Björklund, & Murphy, 2000; Haidt, Koller, & Dias, 1993). na This occurs when we have an immediate, obvious, moral reaction to some occurrence (e.g. someone in private cleaning the toilet with the flag of their country).11 In this reaction, one can see the two processes take somewhat separate paths. The immediacy of the initial moral reaction is a clue that we are dealing with a type 1 process. But when asked to give reasons for the reaction, people often spin their mental wheels, Fi unable to overcome the parts of the scenario that suggest it should not be condemned (e.g. it is a private act, based in practical frugality, no one knows of it, it hurts no one). To answer “it’s just dishonorable” feels to many people like it is not a real, logic-­based reason.12 Thus, those considering this scenario are often left dumbfounded; they have a clear, compelling moral reaction (type 1) but cannot generate a (type 2) reason for it. The two processes come apart and it appears that the type 2 11 It should be noted that Western, liberal college students are the least likely to have moral objections to the flag scenario (Haidt et al., 1993). But for many, in many cultures, it produces an immediate negative, condemning reaction. 12 Note that this is a descriptive account of the experience of subjects who have participated in these experiments (and of our students’ self-­report in classes). Under many philosophical accounts and in many cultures, honor can indeed be a moral reason on its own (e.g. Bok, 2014). Taking Moral Action conscious reason system is left in the dishonorable position of futilely trying to give reasons for a moral judgment that has already been made. 7.3.2 Complexities of Two-­Process Approaches Now that we have the basic outline, we can begin to explore some of the complexities. Most of those complexities have to do with type 1 processing and the interactions between the two types of processes. Some theorists suggest that in the moral domain, type 2 reasoning is not the “real” cause of our moral judgments but only a servant of the intuitive, more emotional type 1 processes. As Hume put it in the eighteenth century, “Reason is, and ought only to be, the slave of the passions” (Haidt, 2001; Hume, 1739/1985, ­section 2.3.3). Unfortunately, much of the debate about whether type 1 or 2 reasons ing is the primary source for moral judgment is misplaced because it misses the profound interaction between the two processes. In Chapter 6 we can see how pracof tice can transform a conscious process of judgment into an automatic one, and how cognitive disfluency can recall an expert from automatic into controlled conscious processing of a difficult problem. In both childhood and adulthood we can train and influence type 1 processing, partly based in our type 2 decision-­making and planro ning.13 Thus, the intuitions of type 1 processing provide grist for the mill of type 2 processing, and the planning and decision-­making of type 2 processes help to construct experiences that train and influence type 1 processes. In such an interdependent system, attempting to privilege one system over the other as the source of moral lP cognition for all or most instances is futile. However, people may well have individual differences in the extent to which they use and develop one system or the other (Evans & Stanovich, 2013). For instance, the work of Tversky and Kahneman (1974) has been a long campaign of showing bias in people’s thinking in a wide variety of cognitive tasks where there is a known (but na nonintuitive) right answer. This was some of the original work that motivated theorists to develop two-­process theories of cognition. But there is a group of people who consistently do better at these tasks: those who are appropriately motivated and people higher in intelligence. Still, even those high in intelligence use the “biased,” intuitive, system 1 approaches when they provide the correct answer. Thus, some people Fi do privilege one system over the other, at least some of the time. But we cannot easily maintain that one system is more basic or more biased than the other. They interact, are both subject to bias, and can be thought of as balancing each other.14 7.3.3 Contents of Type 1 Processes So far, we have only talked about characteristics of type 1 processes (e.g. automatic, fast, nonconscious). But this leaves unanswered the question of what the actual contents of these processes are. What are people (not) thinking about when engaging in type 1 and type 2 processes in the moral domain? 13 We cover the processes underlying this training in Chapters 6 and 9. 14 See Section 7.5.3. Moral Reason 193 We review here four somewhat independent answers to this question.15 The first makes the claim that strongly content specific modules have evolved that, in effect, do our moral reasoning for us in particular domains. The remaining three approaches sometime use this module language but mean something less stringent by it. All the approaches assume that there is some set of principles, values, or schemas that structure both type 1 and 2 ways of thinking about morality. They are organized in advance of experience but not necessarily tightly organized and automatic. 7.3.3.1 Moral Modules as Content Many studies show a regularity in the way people ignore logical structure and reason within specific moral content areas (e.g. cheating, incest; these are called “content effects”). Some theorists claim that content effects show the primacy of strong evolutionary modules for content-­specific reasoning (Cosmides & Tooby, 2008; Cushman, Young, & Hauser, 2006). s For instance, Cosmides and Tooby (2008, p. 65) approach the contents of moral reasoning from what they call an “ecological rationality” standpoint, consisting of the of broad claim that there is a limited set of “functionally isolated” modules for moral rationality. Each has evolved separately, is associated with a particular domain (cheating, dominance, hazard detection), and operates independently of oversight by conscious type 2 reasoning (Beller, 2010). Each module independently evolved because ro that set of reasoning procedures was an “evolutionarily stable strategy” that consistently gave survival advantage to the species (Cosmides & Tooby, 2008, p. 70). Evidence for these structures is provided by the established effect that people are very good at detecting and reasoning about cheating (John was obligated to share, he lP did not). In logical form, this is a violation of an if–then, or conditional, rule. But while they are particularly good at detecting cheating, people are not good at detecting all violations of if–then rules. This at least establishes that cheating is part of a special domain where people perform if–then violation detection very well, setting it apart from general reasoning ability. na This strong claim that there are independent modules of particular types of moral reasoning has been disputed by both philosophers (Prinz, 2008) and psychologists (Chater & Oaksford, 1996; Pietraszewski & Wertz, 2022). The most cited claim is how difficult it is to establish the evolutionary argument (see Chapter 1). The strong claim for independent, evolutionary modules of moral reasoning remains controverFi sial. But there are more flexible kinds of evolutionary modules that require a less stringent evidence base. We turn now to these. 7.3.3.2 Moral Foundations as Content In a program of research originally focused on moral emotion and culture (Haidt et al., 1993; Rozin et al., 1999), Jonathon Haidt and colleagues have done much to establish intuitive type 1 reasoning as a foundational feature of human moral cognition. The intertwining of emotion and reasoning in this approach is so crucial that we will cover the theory in both this chapter and Chapter 8. 15 There are, of course, more approaches than four. For example, Schein and Gray (2015) insist there is only one dimension, harm, and Janoff-­Bulman and colleagues include a dimension to explain why we might have different morals regarding in-­vs. out-­ groups ­(Janoff-­Bulman & Carnes, 2013; Janoff-­Bulman & Carnes, 2018; Janoff-­Bulman, Sheikh, & Baldacci, 2008; Janoff-­Bulman, Sheikh, & Hepp, 2009). Taking Moral Action A deep connection of emotion and cognition can be found in moral foundations theory, an approach that is an explicit rejection of the rationally based approach found in Kohlberg. This suggests the distance psychological moral theory has recently traveled.16 For now, we will concentrate on those aspects of the theory that are typically type 1 rationality. Haidt and colleagues claim that moral reasoning does not typically consist of conscious, guided, logical reasoning based in principles (Haidt, 2007). It is instead based in nonconscious processes. These processes are structured by our evolutionary history, and they produce an emotion-­based conscious awareness that something is wrong or right, but without any access to the processes that produced reaction. Thus, moral judgment is typically and foundationally an intuitive type 1 process. This much seems to be shared with the strong moral module approaches covered earlier. But the moral foundations here are not strictly limited to specific domains like incest or cheats ing (though they might be best triggered by stimuli from particular domains). They are more general ways of responding to the environment. From a cognitive standof point, moral foundations can be seen as moderately flexible schemas that might be activated in a range of situations and then produce different moral reactions depending on which foundation is activated. In the evolution of this approach, one can find four (Haidt & Joseph, 2004), five ro (Haidt, 2007), or six (Iyer et al., 2012) separate foundations. The most often-­cited formulation includes five foundations, each labeled with two words to indicate the range of meaning: lP 1. Harm/care: A concern for the well-­being of individuals and whether they are harmed or helped. 2. Fairness/reciprocity: A concern for the equal or equitable treatment of people, including issues of rights, distribution of resources and privileges, and liberty. 3. In-­group/loyalty: A concern for loyalty to and maintenance of a group, including na family, organizations, friendships, teams, ethnicities, and countries. 4. Authority/respect: A concern for respect and deference to authority or privilege as an obligation in social relations. 5. Purity/sanctity: A concern for the sacred, the pure, or the divine that may be as variously expressed as cleanliness or obedience to divine command. Fi Foundations 1, 2, 4, and 5 were the early list proposed, and a sixth foundation of liberty/oppression has been recently proposed. Haidt and colleagues see this fluctuation as part of an empirical attempt to find a set of schemas that are foundational in that they have an evolutionary heritage and structure moral reactions in a distinct way (Graham et al., 2011). Their pragmatic approach is based on seeing the structure of morality as an empirical question. Though they usually list five foundations, they are open to additional ones as well as to evidence that suggests that two or more of them are in fact one unit. Much of the research to support these foundational schemas as 16 If one looks further back than Kohlberg, one can find that the new two-­ process approaches share much with learning and psychodynamic approaches, though couched in very different language. Moral Reason 195 indeed foundational comes from large-­scale internet surveys and self-­report measures, though some have looked at existing texts of conservative and liberal sermons for patterns of their use (Graham, Haidt, & Nosek, 2009) and investigated the relationship between the intuitions that proceed from the foundations and conscious awareness of their use (Haidt, 2001; Haidt et al., 1993). The causal status of the foundations is somewhat ambiguous, since much of the research involves direct self-­report of reasoning associated with each foundation – though there is evidence that they operate at a nonconscious level (Helzer & Pizarro, 2011; Wheatley & Haidt, 2005). The foundations are, then, associated with both type 1 and 2 cognition and it is unclear which aspect is more important. Nor is it clear that the foundations Haidt and colleagues list as typically liberal (1 and 2) and conservative (3 to 5) are necessarily at odds. Frimer, Tell, and Haidt (2015), for instance, find evidence that for certain issues (e.g. the environment) sacredness is s shared among conservatives and liberals. Though there is still much work to do in determining how system 1 and 2 processes interact with schema processing, the moral of foundations approach has become a central research program in moral psychology. 7.3.3.3 Human Values as Content Any theory of moral reasoning depends on a theory of value that will identify the moral good (Schroeder, 2021). Thus, another ro approach to the contents of moral reasoning is the rigorously inductive, cross-­cultural mapping of values by Schwartz and colleagues (Bardi & Schwartz, 2003; Roccas et al., 2002; Schwartz, 2006, 2010).17 They have shown a two-­ dimensional organization that defines the value dimensions within which individuals from differing lP cultures operate.18 Work in over seventy countries using a variety of instruments converges on this solution that represents the similarities in the way values relate to each other across cultures. Figure 7.1 shows the standard circular arrangement of the 10-­value solution, with the two dimensions labeled self-­ enhancement – self-­ transcendence and conservation – openness to change. At both individual and at na cultural levels, support of any one value on the circle tends to correlate with support for adjacent ones, and less support for those on the opposite pole. As with other attempts to map the structure of moral concerns, the world of morality does not always fall into easily discerned categories. Depending upon the instrument, populations, and criteria, Schwartz and colleagues have suggested seven (Schwartz & Fi Bilsky, 1987), ten (Schwartz, 1992), and nineteen (Schwartz et al., 2012) values. There is extensive overlap between the foundations approach of Haidt and colleagues and the value approach of Schwartz and colleagues (Graham et al., 2011; Zapko-­ Willmes, Schwartz, Richter, & Kandler, 2021), but some domains, such as sacredness, seem unique to the foundations approach while others (e.g. hedonism and more recently, concern for nature) are uniquely represented in the values approach. The relation of these values at cultural and individual levels is still an active area of inquiry (Borg, Bardi, & Schwartz, 2015; Schwartz, 2016). One anthropological approach is to speak of more or less local morality systems that are particular We also cover this approach in the chapter on Moral Ecology. 17 Work by Geert Hofstede (2001) and by Ronald Inglehart and Christian Welzel (2005) 18 makes similar points about variation in values among cultures. Taking Moral Action SelfTranscendence UniversSelfalism Direction Openness to Benevolence Change Stimulation Conformity Tradition Hedonism s Security Conservation of Achievement Power SelfEnhancement ro Figure 7.1 Schwartz circle of value regions. Source: Adapted from Borg, Bardi, and Schwartz (2015). lP ­configurations of the values, with their complex embodiment in the artifacts, ceremonies, documents etc. of a culture, and with the individual negotiating among the multiple morality systems that they encounter (Keane, 2015). na 7.3.3.4 Relational Models as Content A final approach to the contents of moral reasoning draws its methods and criteria from anthropology. Fiske and colleagues (A. P. Fiske, 2002; A. P. Fiske & Haslam, 2005; Rai & Fiske, 2011) base their approach in the judgments that are appropriate to certain kinds of social relations. The advantage of this approach is that it makes clear its particular theoretical stance: Fi that moral judgment is rooted in regulating obligations and privileges in social relations, and that different kinds of relations have different roles, obligations, and privileges. The approach is thus rigorously descriptive rather than normative. It describes the roles and the judgments that fit with them. What are the dimensions on which people agree and disagree in particular kinds of relationships? How are the dimensions used? How do the judgments structure social relations (and vice versa)? The approach thus avoids talk of “bias” in moral reasoning. Here, the task is simply to describe how the judgments cluster based on the social relations they support and how they function. The four basic relations emerge from extensive evidence and theory in cross-­cultural work in anthropology and consist of: • Unity – basic relation: in-­group Motive: care for and support the integrity of in-­groups by eliminating contamination threats and providing aid based in compassion. Moral Reason 197 • Hierarchy – basic relation: hierarchy Motive: respect rank in social groups. Superiors are entitled to deference but have obligations to the group. • Equality – basic relation: equal footing Motive: balanced, in-­kind reciprocity, equal treatment, input, and opportunity. • Proportionality – basic relation: proportional or economic exchange Motive: rewards and punishments should be proportionate to merit, benefits to contributions. These roles can often be mixed in particular relationships. Two friends might communally share some items, trade others, and let one take the lead in an area of expertise. s In addition to describing the social relations underlying morality and the motivating power of morality, Fiske claims to provide a universal structure for the agreements and disagreements among individuals within a culture and between cultures. Cultural of disagreement is ubiquitous but has a structure. Any act, from cutting one’s hair to genocide, might be justified or condemned in moral terms within a culture at a particular time by being placed in relation to one of these motives. Thus, Fiske makes the ro claim (also suggested by others, e.g. Graham & Haidt, 2012; Skitka, Hanson, & Wisneski, 2016; Skitka & Morgan, 2014; Skitka & Mullen, 2002) that even what some call evil acts can be seen by their perpetrators as moral obligations, or at least as morally permissible options. The claim is that cross-­cultural understanding and influence is made possible by lP understanding the moral basis of the claims that individuals in each culture have. Fiske labels his approach a pluralist one, meaning it recognizes more than one value by which one measures moral goodness. But the approach does not seem to have any commitments within it that would keep one from a thorough relativist conclusion – that all morality is reduced to power struggles based on these dimensions. An alternana tive, though still descriptive, anthropological approach is offered by Shweder (Shweder & Menon, 2014; Shweder et al., 1997), which recognizes and attempts to grapple with an “objective moral charter” that sees moral judgments as different from simple influence attempts based in power. Fi"
7,7.3,"Implicit Cognition and Two-­Process Models That we are often “of two minds” about things has been recognized by both ancient and modern authors. Augustine of Hippo’s Confessions (Augustine, 397/2007, Book 8, chapter 9) offered an early exploration of multiple wills. The Scottish empiriFi cist Adam Smith (1759/2009) proposed that it was the interaction of our passions and an imagined “impartial spectator” that together shaped our choices. Schelling (1800/1993) revived the concept of the unconscious as a central part of knowing and acting (McGrath, 2012). Kierkegaard explored the dynamics of multiple aspects of the self (Kierkegaard, 1849/2004). And, of course, Freud systematized the unconscious (Breuer & Freud, 1895/2000) as a dynamic, emotionally rich driver of thought and action. All these theorists were pointing to various aspects of unconscious processing and its relation to conscious, controlled processing. More recently, the unconscious has been resurrected by cognitive psychologists as nonconscious processing, at least initially stripped of its association with creative impulses and emotional content. Fodor (1983) introduced one of the first such ­systems, though the term “dual process” had been used earlier in reference to a contrast between conscious and nonconscious influences on behavior (Wason & Evans, 1975). Since these early beginnings, work on dual process theories of cognition Taking Moral Action could fill volumes (e.g. Kahneman, 2011; Nisbett & Ross, 1980). Dual process ­theories are widely divergent in their assumptions (see Evans & Stanovich, 2013 for a review) and have some detractors (Kruglanski & Thompson, 1999; Osman, 2004). But they have proven quite influential in moral psychology. After looking for some structure in what we might mean by dual processes, we will review four significant theoretical approaches in moral psychology that have been influenced by dual process theories but give different answers to what the content of those processes might be. 7.3.1 What Are Two-­Process Models? It is important to begin this section with the plural. There is not one agreed upon two-­process approach to understanding cognition. Theorists disagree on a range of issues, including whether there are two or even more systems, whether the difference s is one of type (with a clear distinction) or of mode (with a range of intermediate positions), the extent to which they can be consciously controlled, and a host of other of disagreements (Evans & Stanovich, 2013). Any generalization at this early stage of theorizing should be done with caution. Nevertheless, if we assume for the moment that there are only two types of processing, and that they are distinct, what is the distinction? It is that some of the cognitive ro processing we do requires cognitive effort – it takes concentration and working memory. But at other times, and for other kinds of stimuli, processing is relatively effortless and requires little in the way of working memory. This latter kind of process has been called “system 1” processing, in partial reference to the thought that it evolved lP earlier than the more effortful, working-­memory-­intensive processing, which is called “system 2.” Table 7.1 presents a schematic of the two systems of processing. The items listed under defining features are, according to Evans and Stanovich (2013), the characteristics of the two types that are central and always present, while the typical correlates section lists characteristics that are often associated with the type, but for na which there are exceptions.10 The bottom section of the table lists characteristics of the two processes that are often cited when the processes are proposed as different systems that evolved somewhat separately. Like Kohlberg (1958), when we think of cognition we normally think of conscious, deliberate, guided processing, or type 2 processing. We usually have conscious Fi access to both the processes and their outcomes. That is, we are aware of and deliberatively guide our selection of the things we consider, how and how long we consider them, and the conclusions we reach. This deliberation takes effort, can be abstract and hypothetical (e.g. What if it were not my country’s flag?) and is associated with intelligence. Type 1 processes are rapid, more hidden from our awareness, usually proceed without our conscious guidance, and we only have access to their seemingly self-­evident conclusions. For this reason, type 1 processes are often called “intuitive.” 10 This slipperiness of the definitions of the two systems is not new. As early as 1989, Bargh argued that awareness, attention, intention, and control are a loosely tethered set of attributes of automatic processes. Thus, the idea that type 1 processes occur in great variety has at least a moderately long history. Moral Reason 191 Table 7.1 Characteristic properties of dual-­process cognition. Type 1 process (intuitive) Type 2 process (reflective) Defining features: Does not require working memory Requires working memory Autonomous Cognitive decoupling;mental simulation Typical (but not necessary) correlates: Fast Slow High capacity Capacity limited Parallel Serial Nonconscious Conscious Biased responses Normative responses s Contextualized Abstract Automatic Controlled Associative Rule-­based of Experience-­based decision-­making Consequentialdecision-­making Independent of cognitive ability Correlated with cognitive ability When considered as evolved systems: Evolved early ro Evolved late Shared with other animals Distinctively human Implicit knowledge Explicit knowledge Basic emotions Complex emotions lP Source: Adapted from Evans and Stanovich (2013) and De Neys (2021). A good example of how the two processes interact in the moral domain is moral dumbfounding (Haidt, Björklund, & Murphy, 2000; Haidt, Koller, & Dias, 1993). na This occurs when we have an immediate, obvious, moral reaction to some occurrence (e.g. someone in private cleaning the toilet with the flag of their country).11 In this reaction, one can see the two processes take somewhat separate paths. The immediacy of the initial moral reaction is a clue that we are dealing with a type 1 process. But when asked to give reasons for the reaction, people often spin their mental wheels, Fi unable to overcome the parts of the scenario that suggest it should not be condemned (e.g. it is a private act, based in practical frugality, no one knows of it, it hurts no one). To answer “it’s just dishonorable” feels to many people like it is not a real, logic-­based reason.12 Thus, those considering this scenario are often left dumbfounded; they have a clear, compelling moral reaction (type 1) but cannot generate a (type 2) reason for it. The two processes come apart and it appears that the type 2 11 It should be noted that Western, liberal college students are the least likely to have moral objections to the flag scenario (Haidt et al., 1993). But for many, in many cultures, it produces an immediate negative, condemning reaction. 12 Note that this is a descriptive account of the experience of subjects who have participated in these experiments (and of our students’ self-­report in classes). Under many philosophical accounts and in many cultures, honor can indeed be a moral reason on its own (e.g. Bok, 2014). Taking Moral Action conscious reason system is left in the dishonorable position of futilely trying to give reasons for a moral judgment that has already been made. 7.3.2 Complexities of Two-­Process Approaches Now that we have the basic outline, we can begin to explore some of the complexities. Most of those complexities have to do with type 1 processing and the interactions between the two types of processes. Some theorists suggest that in the moral domain, type 2 reasoning is not the “real” cause of our moral judgments but only a servant of the intuitive, more emotional type 1 processes. As Hume put it in the eighteenth century, “Reason is, and ought only to be, the slave of the passions” (Haidt, 2001; Hume, 1739/1985, ­section 2.3.3). Unfortunately, much of the debate about whether type 1 or 2 reasons ing is the primary source for moral judgment is misplaced because it misses the profound interaction between the two processes. In Chapter 6 we can see how pracof tice can transform a conscious process of judgment into an automatic one, and how cognitive disfluency can recall an expert from automatic into controlled conscious processing of a difficult problem. In both childhood and adulthood we can train and influence type 1 processing, partly based in our type 2 decision-­making and planro ning.13 Thus, the intuitions of type 1 processing provide grist for the mill of type 2 processing, and the planning and decision-­making of type 2 processes help to construct experiences that train and influence type 1 processes. In such an interdependent system, attempting to privilege one system over the other as the source of moral lP cognition for all or most instances is futile. However, people may well have individual differences in the extent to which they use and develop one system or the other (Evans & Stanovich, 2013). For instance, the work of Tversky and Kahneman (1974) has been a long campaign of showing bias in people’s thinking in a wide variety of cognitive tasks where there is a known (but na nonintuitive) right answer. This was some of the original work that motivated theorists to develop two-­process theories of cognition. But there is a group of people who consistently do better at these tasks: those who are appropriately motivated and people higher in intelligence. Still, even those high in intelligence use the “biased,” intuitive, system 1 approaches when they provide the correct answer. Thus, some people Fi do privilege one system over the other, at least some of the time. But we cannot easily maintain that one system is more basic or more biased than the other. They interact, are both subject to bias, and can be thought of as balancing each other.14 7.3.3 Contents of Type 1 Processes So far, we have only talked about characteristics of type 1 processes (e.g. automatic, fast, nonconscious). But this leaves unanswered the question of what the actual contents of these processes are. What are people (not) thinking about when engaging in type 1 and type 2 processes in the moral domain? 13 We cover the processes underlying this training in Chapters 6 and 9. 14 See Section 7.5.3. Moral Reason 193 We review here four somewhat independent answers to this question.15 The first makes the claim that strongly content specific modules have evolved that, in effect, do our moral reasoning for us in particular domains. The remaining three approaches sometime use this module language but mean something less stringent by it. All the approaches assume that there is some set of principles, values, or schemas that structure both type 1 and 2 ways of thinking about morality. They are organized in advance of experience but not necessarily tightly organized and automatic. 7.3.3.1 Moral Modules as Content Many studies show a regularity in the way people ignore logical structure and reason within specific moral content areas (e.g. cheating, incest; these are called “content effects”). Some theorists claim that content effects show the primacy of strong evolutionary modules for content-­specific reasoning (Cosmides & Tooby, 2008; Cushman, Young, & Hauser, 2006). s For instance, Cosmides and Tooby (2008, p. 65) approach the contents of moral reasoning from what they call an “ecological rationality” standpoint, consisting of the of broad claim that there is a limited set of “functionally isolated” modules for moral rationality. Each has evolved separately, is associated with a particular domain (cheating, dominance, hazard detection), and operates independently of oversight by conscious type 2 reasoning (Beller, 2010). Each module independently evolved because ro that set of reasoning procedures was an “evolutionarily stable strategy” that consistently gave survival advantage to the species (Cosmides & Tooby, 2008, p. 70). Evidence for these structures is provided by the established effect that people are very good at detecting and reasoning about cheating (John was obligated to share, he lP did not). In logical form, this is a violation of an if–then, or conditional, rule. But while they are particularly good at detecting cheating, people are not good at detecting all violations of if–then rules. This at least establishes that cheating is part of a special domain where people perform if–then violation detection very well, setting it apart from general reasoning ability. na This strong claim that there are independent modules of particular types of moral reasoning has been disputed by both philosophers (Prinz, 2008) and psychologists (Chater & Oaksford, 1996; Pietraszewski & Wertz, 2022). The most cited claim is how difficult it is to establish the evolutionary argument (see Chapter 1). The strong claim for independent, evolutionary modules of moral reasoning remains controverFi sial. But there are more flexible kinds of evolutionary modules that require a less stringent evidence base. We turn now to these. 7.3.3.2 Moral Foundations as Content In a program of research originally focused on moral emotion and culture (Haidt et al., 1993; Rozin et al., 1999), Jonathon Haidt and colleagues have done much to establish intuitive type 1 reasoning as a foundational feature of human moral cognition. The intertwining of emotion and reasoning in this approach is so crucial that we will cover the theory in both this chapter and Chapter 8. 15 There are, of course, more approaches than four. For example, Schein and Gray (2015) insist there is only one dimension, harm, and Janoff-­Bulman and colleagues include a dimension to explain why we might have different morals regarding in-­vs. out-­ groups ­(Janoff-­Bulman & Carnes, 2013; Janoff-­Bulman & Carnes, 2018; Janoff-­Bulman, Sheikh, & Baldacci, 2008; Janoff-­Bulman, Sheikh, & Hepp, 2009). Taking Moral Action A deep connection of emotion and cognition can be found in moral foundations theory, an approach that is an explicit rejection of the rationally based approach found in Kohlberg. This suggests the distance psychological moral theory has recently traveled.16 For now, we will concentrate on those aspects of the theory that are typically type 1 rationality. Haidt and colleagues claim that moral reasoning does not typically consist of conscious, guided, logical reasoning based in principles (Haidt, 2007). It is instead based in nonconscious processes. These processes are structured by our evolutionary history, and they produce an emotion-­based conscious awareness that something is wrong or right, but without any access to the processes that produced reaction. Thus, moral judgment is typically and foundationally an intuitive type 1 process. This much seems to be shared with the strong moral module approaches covered earlier. But the moral foundations here are not strictly limited to specific domains like incest or cheats ing (though they might be best triggered by stimuli from particular domains). They are more general ways of responding to the environment. From a cognitive standof point, moral foundations can be seen as moderately flexible schemas that might be activated in a range of situations and then produce different moral reactions depending on which foundation is activated. In the evolution of this approach, one can find four (Haidt & Joseph, 2004), five ro (Haidt, 2007), or six (Iyer et al., 2012) separate foundations. The most often-­cited formulation includes five foundations, each labeled with two words to indicate the range of meaning: lP 1. Harm/care: A concern for the well-­being of individuals and whether they are harmed or helped. 2. Fairness/reciprocity: A concern for the equal or equitable treatment of people, including issues of rights, distribution of resources and privileges, and liberty. 3. In-­group/loyalty: A concern for loyalty to and maintenance of a group, including na family, organizations, friendships, teams, ethnicities, and countries. 4. Authority/respect: A concern for respect and deference to authority or privilege as an obligation in social relations. 5. Purity/sanctity: A concern for the sacred, the pure, or the divine that may be as variously expressed as cleanliness or obedience to divine command. Fi Foundations 1, 2, 4, and 5 were the early list proposed, and a sixth foundation of liberty/oppression has been recently proposed. Haidt and colleagues see this fluctuation as part of an empirical attempt to find a set of schemas that are foundational in that they have an evolutionary heritage and structure moral reactions in a distinct way (Graham et al., 2011). Their pragmatic approach is based on seeing the structure of morality as an empirical question. Though they usually list five foundations, they are open to additional ones as well as to evidence that suggests that two or more of them are in fact one unit. Much of the research to support these foundational schemas as 16 If one looks further back than Kohlberg, one can find that the new two-­ process approaches share much with learning and psychodynamic approaches, though couched in very different language. Moral Reason 195 indeed foundational comes from large-­scale internet surveys and self-­report measures, though some have looked at existing texts of conservative and liberal sermons for patterns of their use (Graham, Haidt, & Nosek, 2009) and investigated the relationship between the intuitions that proceed from the foundations and conscious awareness of their use (Haidt, 2001; Haidt et al., 1993). The causal status of the foundations is somewhat ambiguous, since much of the research involves direct self-­report of reasoning associated with each foundation – though there is evidence that they operate at a nonconscious level (Helzer & Pizarro, 2011; Wheatley & Haidt, 2005). The foundations are, then, associated with both type 1 and 2 cognition and it is unclear which aspect is more important. Nor is it clear that the foundations Haidt and colleagues list as typically liberal (1 and 2) and conservative (3 to 5) are necessarily at odds. Frimer, Tell, and Haidt (2015), for instance, find evidence that for certain issues (e.g. the environment) sacredness is s shared among conservatives and liberals. Though there is still much work to do in determining how system 1 and 2 processes interact with schema processing, the moral of foundations approach has become a central research program in moral psychology. 7.3.3.3 Human Values as Content Any theory of moral reasoning depends on a theory of value that will identify the moral good (Schroeder, 2021). Thus, another ro approach to the contents of moral reasoning is the rigorously inductive, cross-­cultural mapping of values by Schwartz and colleagues (Bardi & Schwartz, 2003; Roccas et al., 2002; Schwartz, 2006, 2010).17 They have shown a two-­ dimensional organization that defines the value dimensions within which individuals from differing lP cultures operate.18 Work in over seventy countries using a variety of instruments converges on this solution that represents the similarities in the way values relate to each other across cultures. Figure 7.1 shows the standard circular arrangement of the 10-­value solution, with the two dimensions labeled self-­ enhancement – self-­ transcendence and conservation – openness to change. At both individual and at na cultural levels, support of any one value on the circle tends to correlate with support for adjacent ones, and less support for those on the opposite pole. As with other attempts to map the structure of moral concerns, the world of morality does not always fall into easily discerned categories. Depending upon the instrument, populations, and criteria, Schwartz and colleagues have suggested seven (Schwartz & Fi Bilsky, 1987), ten (Schwartz, 1992), and nineteen (Schwartz et al., 2012) values. There is extensive overlap between the foundations approach of Haidt and colleagues and the value approach of Schwartz and colleagues (Graham et al., 2011; Zapko-­ Willmes, Schwartz, Richter, & Kandler, 2021), but some domains, such as sacredness, seem unique to the foundations approach while others (e.g. hedonism and more recently, concern for nature) are uniquely represented in the values approach. The relation of these values at cultural and individual levels is still an active area of inquiry (Borg, Bardi, & Schwartz, 2015; Schwartz, 2016). One anthropological approach is to speak of more or less local morality systems that are particular We also cover this approach in the chapter on Moral Ecology. 17 Work by Geert Hofstede (2001) and by Ronald Inglehart and Christian Welzel (2005) 18 makes similar points about variation in values among cultures. Taking Moral Action SelfTranscendence UniversSelfalism Direction Openness to Benevolence Change Stimulation Conformity Tradition Hedonism s Security Conservation of Achievement Power SelfEnhancement ro Figure 7.1 Schwartz circle of value regions. Source: Adapted from Borg, Bardi, and Schwartz (2015). lP ­configurations of the values, with their complex embodiment in the artifacts, ceremonies, documents etc. of a culture, and with the individual negotiating among the multiple morality systems that they encounter (Keane, 2015). na 7.3.3.4 Relational Models as Content A final approach to the contents of moral reasoning draws its methods and criteria from anthropology. Fiske and colleagues (A. P. Fiske, 2002; A. P. Fiske & Haslam, 2005; Rai & Fiske, 2011) base their approach in the judgments that are appropriate to certain kinds of social relations. The advantage of this approach is that it makes clear its particular theoretical stance: Fi that moral judgment is rooted in regulating obligations and privileges in social relations, and that different kinds of relations have different roles, obligations, and privileges. The approach is thus rigorously descriptive rather than normative. It describes the roles and the judgments that fit with them. What are the dimensions on which people agree and disagree in particular kinds of relationships? How are the dimensions used? How do the judgments structure social relations (and vice versa)? The approach thus avoids talk of “bias” in moral reasoning. Here, the task is simply to describe how the judgments cluster based on the social relations they support and how they function. The four basic relations emerge from extensive evidence and theory in cross-­cultural work in anthropology and consist of: • Unity – basic relation: in-­group Motive: care for and support the integrity of in-­groups by eliminating contamination threats and providing aid based in compassion. Moral Reason 197 • Hierarchy – basic relation: hierarchy Motive: respect rank in social groups. Superiors are entitled to deference but have obligations to the group. • Equality – basic relation: equal footing Motive: balanced, in-­kind reciprocity, equal treatment, input, and opportunity. • Proportionality – basic relation: proportional or economic exchange Motive: rewards and punishments should be proportionate to merit, benefits to contributions. These roles can often be mixed in particular relationships. Two friends might communally share some items, trade others, and let one take the lead in an area of expertise. s In addition to describing the social relations underlying morality and the motivating power of morality, Fiske claims to provide a universal structure for the agreements and disagreements among individuals within a culture and between cultures. Cultural of disagreement is ubiquitous but has a structure. Any act, from cutting one’s hair to genocide, might be justified or condemned in moral terms within a culture at a particular time by being placed in relation to one of these motives. Thus, Fiske makes the ro claim (also suggested by others, e.g. Graham & Haidt, 2012; Skitka, Hanson, & Wisneski, 2016; Skitka & Morgan, 2014; Skitka & Mullen, 2002) that even what some call evil acts can be seen by their perpetrators as moral obligations, or at least as morally permissible options. The claim is that cross-­cultural understanding and influence is made possible by lP understanding the moral basis of the claims that individuals in each culture have. Fiske labels his approach a pluralist one, meaning it recognizes more than one value by which one measures moral goodness. But the approach does not seem to have any commitments within it that would keep one from a thorough relativist conclusion – that all morality is reduced to power struggles based on these dimensions. An alternana tive, though still descriptive, anthropological approach is offered by Shweder (Shweder & Menon, 2014; Shweder et al., 1997), which recognizes and attempts to grapple with an “objective moral charter” that sees moral judgments as different from simple influence attempts based in power. Fi 7.3.4 Critiques of Two-­Process Models We should not end this section without noting that despite their clear success in ­capturing the market of research in moral cognition, two-­process models have also drawn some criticism, much of it trying to maintain a single system (Hassin, 2013; Hassin, Bargh, & Zimmerman, 2009; Kruglanski & Thompson, 1999; Osman, 2004). Evans and Stanovich (2013) provide convincing replies to critiques of two-­process models of cognition. One outcome of their defense of multiple processes is that there may indeed be more than two types of processing (taking us back to the evolutionary modules with which we began this section). Malle (2021) has reshuffled the types of moral judgments to suggest a different path forward. If, as it seems, there are at least four types of moral judgments (evaluations, norm judgments, wrongness judgments, and blame judgments), each with ­different objects, information, speed, and social function, one might take the characteristics of Taking Moral Action each of the two processes (speed, access, automaticity, control, etc.) and do the empirical work to ask which characteristics are associated with which types of moral judgments (Malle, 2021, p. 310). This sidesteps the entire two-­process approach and at the same time offers an empirical test of it. This approach might find evidence for more than two processes, with different relations to different types of moral judgment and interactions among them. De Neys and colleagues (Bago & De Neys, 2019; De Neys, 2012, 2021) offer another approach to fragmenting the two processes. They provides convincing ­evidence that system 1, the supposedly nonlogical intuitive system does indeed provide (1) intuition based on logical inference and (2) an intuition of potential conflict between that inference and any associative intuition (see also Hassin, 2013; Hassin et al., 2009). This intuition of conflict relates interestingly to the work covered in Chapter 6 on the metacognitive disfluency experts use to signal the need to drop out s of automatic skilled behavior and begin problem-­solving. System 1 (or whatever name one now gives it) might be providing this essential disfluency intuition in of expertise. From an applied social change perspective, Killen and Dahl (2021) complain that two-­process approaches in practice restrict the emotional aspect of intuition to negative affect, not considering compassion, a motivation that is clearly in eviro dence in many social change movements (and not likely generated by system 2). In addition, the relatively narrow focus on the truth value of the “outcome” of the processes fails to account for the urgency and deep commitment that must go along with any judgment that is to result in a prolonged and committed attempt lP to produce societal change (Killen & Dahl, 2021, p. 1216). Section 7.4 is relevant to this critique. Finally, Cesario, Johnson, and Eisthen (2020) suggest that most presentations of two-­process systems ignore the consensus in the neuroscience community that there are no simple divisions into automatic and online systems and that characna terization of system 1 as an “early evolutionary” system ignores significant continuity among species and unnecessarily separates many different cooperative systems. Because of this tremendous flux in data and theory, the reader would be ill-­advised to conclude that there are only two cognitive processes and that those are mostly difFi ferentiated on whether they are open to consciousness or not. More than likely, there are multiple processes that share similarities and differences that influence a variety of types of moral cognition. And one probably find things influencing moral cognition in almost all of them (Dinh & Lord, 2013)."
7,7.4,"Naturalistic Moral Cognition Another promising approach to moral cognition shares at least one assumption with two-­process approaches: that rather than depending on a general moral logic, domain-­ specific cognition matters. These approaches have variously been called naturalistic decision-­making (Lipschitz et al., 2001), real-­life decision structuring (Galotti, 2007), grounded cognition (Barsolou et al., 2003), and autobiographical reasoning (De Silveira & Habermas, 2011). Here, we refer to them all as naturalistic decision-­making Moral Reason 199 (Zsambok & Klein, 2014). Research in these overlapping areas shares several features (Evans & Elqayam, 2011): • It is focused on capabilities that people possess rather than a model of how one ought to think (see Section 7.1). • It attempts to be descriptive of the actual processes based on those abilities. • It is not usually done in labs, or with naïve subjects. • The situations of interest often involve severe time pressure (e.g. military decisions), ill-­defined goals (e.g. college selection), and high personal stakes (e.g. firefighting). • It is shaped by the structure of the environment as much as the abilities of the actor. s • It often involves studying people with some degree of expertise. Research like this finds that perceiving situations and matching roles or solutions is of more important than calculating outcomes or courses of action. For instance, chess experts match possible solutions to situations (Newell & Simon, 1972), and managers match situations to roles in a “logic of obligation” (March, 1982). It also finds ro that this sort of naturalistic decision-­making is best modeled within domains, based on the kinds of decisions made in those domains (Barrett & Kurzban, 2006) rather than in generic, one-­size-­fits-­all reasoning models. The logic and function of autobiographical narrative is, for instance, much more complicated than that of simple hislP torical truth-­discovery (Adler et al., 2017; Rasmussen & Habermas, 2011). Autobiographical reasoning has a directive function that involves understanding the past and predicting the future, but it also has important functions in self-­definition and social engagement and functioning (Bluck et al., 2005). Work in all these domains is shot through with moral perception, evaluation, planning, and action. But this work has rarely been seen as work in moral psychology. na 7.5 Reasoning Goes Awry: Two Paths to Moral Failure One final thing needs to be said about moral reasoning: reason is often employed Fi in the service of immoral and even evil goals. We mentioned this issue in Section 7.1, but here we catalog some of the ways that reasoning goes awry. This judgment that reasoning has gone bad is not based on rules of logic or other “normative” cognitive models. One can in fact closely follow rules of inference, deduction, and induction while planning genocide. Reason does not protect us from immorality. We investigate here some circumstances in which reason either transforms our perception of an evil goal into an acceptable or obligatory one or distances us from guilt. Hart and colleagues (Hart, 2005b; Hart & Carlo, 2005) have used the term moral collapse to refer to moral failures like genocide. These instances are surely one end of a continuum of moral failure whose other end might begin with good deeds left undone. We will use the term moral failure here as a term of convenience to describe those instances ranging from participation in genocide to the omission of possible good. This allows us to look at the cognitive reasoning that contributes to these sorts of moral Taking Moral Action ­failure. We will concentrate here on two paths that might lead one to bring the “hired gun” of reason into the service of moral failure: moral identity and empathy avoidance. 7.5.1 Moral Identity and Moral Failure A variety of researchers have pointed to the centrality of moral identity in circumscribing the circle of moral concern (Aquino et al., 2006; Clayton & Opotow, 2003; Fowler, Law, & Gaesser, 2021; Hart, 2005a; Opotow, 2001, 2005, 2010; Skitka, 2010; Skitka et al., 2016; Skitka & Mullen, 2002). See Chapter 9, Section 9.3.1.3 for more detail on this. Once a group is excluded from moral concern, it becomes a legitimate, and possibly even obligatory, target for aggression. If the in-­group is constituted in explicit rejection of an out-­group that is perceived to be threatening (e.g. as in the case of war) then it may be morally obligatory to directly aggress against the out-­ s group, to support in-­group members who aggress, and to punish in-­group members who do not. Moral identity need not be the source of such extreme behavior; one of may simply ignore the needs of those outside the circle. This approach is a more profoundly social idea of moral identity than is often found in the literature.19 The point here is that once moral identity defines others as outside, then one can bring motivated reasoning (Epley & Gilovich, 2016; Klein & Epley, 2017) to bear to legitimize neglect or aggression. ro 7.5.2 Moral Distancing and Moral Failure lP Another path that recruits cognitive strategies in service of moral failure is the avoidance of the aversive emotion that is aroused by watching others suffer. This suffering may not be directly or indirectly caused by the person watching. But the person watching may have a variety of reasons to avoid the aversive emotion: inability to escape the scene, a preference to pursue goals other than relieving the suffering, etc. na In this case, cognitive distancing strategies can be called into service to reduce the aversive emotion. Bandura (1999, 2002) provides a list of strategies that serve to produce psychological distance from the (in)action itself, the effects of the (in)action, from those harmed by action or inaction, or by reconstruing the nature of responsibility. The list Fi attempts to be comprehensive but there is no theoretical reason to suppose it is completely exhaustive.20 Some items from the list follow. 7.5.2.1 Modifying the Descriptions of the Action • Moral justification: immoral conduct is made acceptable by portraying it as in ­service of a morally worthy goal. • Advantageous comparison: comparing the current actions either to those they are reacting to (since Microsoft has done X, we can do Y) or to more severe possibilities (I know the data is insecure, but at least we are not selling it). 19 Chapters 3, 5, and 9 explore this socially grounded moral identity in detail. 20 Our list includes most of the items listed by Bandura (1999, 2002) and several items from other authors where they seemed relevant. Moral Reason 201 • Euphemistic labeling: sanitizing (collateral damage of bombing), use of the passive (the workers became redundant), or use of specialized jargon (adverse consequences for medical accidents) to reduce awareness of the actual circumstances of the action. 7.5.2.2 Modifying the Attitude Toward Consequences • Minimizing: altering the description of the consequences to make them seem less bad (e.g. undercounting casualties). • Ignoring: various strategies will allow one to ignore consequences including physical distance (design of software is usually done at a distance) and redirection of attention (paying attention to other aspects of the situation). Those living near Auschwitz never thought to ask about the smoke, or if they did, they preferred not to know. s • Misconstruing: thinking that the outcome is different than it was. Often done by rapists but also by others (e.g. gassing as humane extermination). of • Seeing injustice in nonmoral terms: we can avoid seeing social injustice by seeing market forces or other “nonmoral” causes behind them. For instance, seeing job loss as simply a part of creative destruction in the economy rather than as a social problem that requires justice (Opotow, 2010). ro • Seeing injustice as misfortune: seeing injustice as unfortunate luck or circumstances rather than as systematic societal arrangement of risk shunted onto certain categories of people. For instance displacement of poor neighborhoods for highways or crowding in inadequate housing (Opotow, 2010). lP 7.5.2.3 Modifying Attitudes Toward the Victim • Dehumanization: making the victims of the action out to be less than human, and thus less deserving of moral consideration. Often done as a part of war. But also done in labels given computer users (e.g. lusers at MIT) and clients. na • Blaming the victim: claiming that the fate of the victim is in part caused by the victim’s own actions or characteristics (“If he weren’t so stupid I wouldn’t have to shock him” – from one of the participants in the Milgram obedience studies). 7.5.2.4 Modifying Attitudes Toward Responsibility Fi • Displacement of responsibility: claiming that someone or some circumstance other than the self is ultimately responsible. This is often done in hierarchy but also by consultants (one purpose of consulting is to acquire a detached party on whom the bad news can be blamed). In fact, almost anyone can find a way to blame either other people or circumstances that require them to act in morally reprehensible ways. • Diffusion of responsibility: in most endeavors more than one person is required. When one acts as part of a group, the psychological burden of responsibility is lessened. When the group is responsible for a product, it is usually the case that individual members feel responsible only for those parts that directly concern them, and then only in relation to their role in the group (rather than their relation to the client/user). • Moral decoupling: judging others’ or one’s own actions independently of their moral worth, e.g. praising a politician or sports star for skill while ignoring other moral failures (Bhattacharjee, Berman, & Reed, 2013). Taking Moral Action • Selective use of moral principles: different moral principles (e.g. harm, justice, sacredness, etc.) can result in different evaluations of an action. Instead of a comprehensive analysis of moral principles, or even of those deemed most relevant, one can selectively choose those that support a desired evaluation. For instance, Uhlmann et al. (2009) found that Americans judging the killing of Iraqis by American forces were more likely to use reasoning that allowed for trading off costs and benefits than were those judging the killing of Americans by Iraqis. This is an imposing list of the ways cognitive resources can be recruited in the service of moral failure. Of course, the list can be used for a positive purpose: to ask oneself or others if they are using these strategies without justification. The positive use of these strategies to check oneself or one’s society is a crucial aspect of holding s ourselves and others morally responsible, and of maintaining a cultural critique that influences how we think of our actions. So, a recognition of the tools that allow for bias based in cognitive reasoning can support moral critique. of"
7,7.5,"Reasoning Goes Awry: Two Paths to Moral Failure One final thing needs to be said about moral reasoning: reason is often employed Fi in the service of immoral and even evil goals. We mentioned this issue in Section 7.1, but here we catalog some of the ways that reasoning goes awry. This judgment that reasoning has gone bad is not based on rules of logic or other “normative” cognitive models. One can in fact closely follow rules of inference, deduction, and induction while planning genocide. Reason does not protect us from immorality. We investigate here some circumstances in which reason either transforms our perception of an evil goal into an acceptable or obligatory one or distances us from guilt. Hart and colleagues (Hart, 2005b; Hart & Carlo, 2005) have used the term moral collapse to refer to moral failures like genocide. These instances are surely one end of a continuum of moral failure whose other end might begin with good deeds left undone. We will use the term moral failure here as a term of convenience to describe those instances ranging from participation in genocide to the omission of possible good. This allows us to look at the cognitive reasoning that contributes to these sorts of moral Taking Moral Action ­failure. We will concentrate here on two paths that might lead one to bring the “hired gun” of reason into the service of moral failure: moral identity and empathy avoidance. 7.5.1 Moral Identity and Moral Failure A variety of researchers have pointed to the centrality of moral identity in circumscribing the circle of moral concern (Aquino et al., 2006; Clayton & Opotow, 2003; Fowler, Law, & Gaesser, 2021; Hart, 2005a; Opotow, 2001, 2005, 2010; Skitka, 2010; Skitka et al., 2016; Skitka & Mullen, 2002). See Chapter 9, Section 9.3.1.3 for more detail on this. Once a group is excluded from moral concern, it becomes a legitimate, and possibly even obligatory, target for aggression. If the in-­group is constituted in explicit rejection of an out-­group that is perceived to be threatening (e.g. as in the case of war) then it may be morally obligatory to directly aggress against the out-­ s group, to support in-­group members who aggress, and to punish in-­group members who do not. Moral identity need not be the source of such extreme behavior; one of may simply ignore the needs of those outside the circle. This approach is a more profoundly social idea of moral identity than is often found in the literature.19 The point here is that once moral identity defines others as outside, then one can bring motivated reasoning (Epley & Gilovich, 2016; Klein & Epley, 2017) to bear to legitimize neglect or aggression. ro 7.5.2 Moral Distancing and Moral Failure lP Another path that recruits cognitive strategies in service of moral failure is the avoidance of the aversive emotion that is aroused by watching others suffer. This suffering may not be directly or indirectly caused by the person watching. But the person watching may have a variety of reasons to avoid the aversive emotion: inability to escape the scene, a preference to pursue goals other than relieving the suffering, etc. na In this case, cognitive distancing strategies can be called into service to reduce the aversive emotion. Bandura (1999, 2002) provides a list of strategies that serve to produce psychological distance from the (in)action itself, the effects of the (in)action, from those harmed by action or inaction, or by reconstruing the nature of responsibility. The list Fi attempts to be comprehensive but there is no theoretical reason to suppose it is completely exhaustive.20 Some items from the list follow. 7.5.2.1 Modifying the Descriptions of the Action • Moral justification: immoral conduct is made acceptable by portraying it as in ­service of a morally worthy goal. • Advantageous comparison: comparing the current actions either to those they are reacting to (since Microsoft has done X, we can do Y) or to more severe possibilities (I know the data is insecure, but at least we are not selling it). 19 Chapters 3, 5, and 9 explore this socially grounded moral identity in detail. 20 Our list includes most of the items listed by Bandura (1999, 2002) and several items from other authors where they seemed relevant. Moral Reason 201 • Euphemistic labeling: sanitizing (collateral damage of bombing), use of the passive (the workers became redundant), or use of specialized jargon (adverse consequences for medical accidents) to reduce awareness of the actual circumstances of the action. 7.5.2.2 Modifying the Attitude Toward Consequences • Minimizing: altering the description of the consequences to make them seem less bad (e.g. undercounting casualties). • Ignoring: various strategies will allow one to ignore consequences including physical distance (design of software is usually done at a distance) and redirection of attention (paying attention to other aspects of the situation). Those living near Auschwitz never thought to ask about the smoke, or if they did, they preferred not to know. s • Misconstruing: thinking that the outcome is different than it was. Often done by rapists but also by others (e.g. gassing as humane extermination). of • Seeing injustice in nonmoral terms: we can avoid seeing social injustice by seeing market forces or other “nonmoral” causes behind them. For instance, seeing job loss as simply a part of creative destruction in the economy rather than as a social problem that requires justice (Opotow, 2010). ro • Seeing injustice as misfortune: seeing injustice as unfortunate luck or circumstances rather than as systematic societal arrangement of risk shunted onto certain categories of people. For instance displacement of poor neighborhoods for highways or crowding in inadequate housing (Opotow, 2010). lP 7.5.2.3 Modifying Attitudes Toward the Victim • Dehumanization: making the victims of the action out to be less than human, and thus less deserving of moral consideration. Often done as a part of war. But also done in labels given computer users (e.g. lusers at MIT) and clients. na • Blaming the victim: claiming that the fate of the victim is in part caused by the victim’s own actions or characteristics (“If he weren’t so stupid I wouldn’t have to shock him” – from one of the participants in the Milgram obedience studies). 7.5.2.4 Modifying Attitudes Toward Responsibility Fi • Displacement of responsibility: claiming that someone or some circumstance other than the self is ultimately responsible. This is often done in hierarchy but also by consultants (one purpose of consulting is to acquire a detached party on whom the bad news can be blamed). In fact, almost anyone can find a way to blame either other people or circumstances that require them to act in morally reprehensible ways. • Diffusion of responsibility: in most endeavors more than one person is required. When one acts as part of a group, the psychological burden of responsibility is lessened. When the group is responsible for a product, it is usually the case that individual members feel responsible only for those parts that directly concern them, and then only in relation to their role in the group (rather than their relation to the client/user). • Moral decoupling: judging others’ or one’s own actions independently of their moral worth, e.g. praising a politician or sports star for skill while ignoring other moral failures (Bhattacharjee, Berman, & Reed, 2013). Taking Moral Action • Selective use of moral principles: different moral principles (e.g. harm, justice, sacredness, etc.) can result in different evaluations of an action. Instead of a comprehensive analysis of moral principles, or even of those deemed most relevant, one can selectively choose those that support a desired evaluation. For instance, Uhlmann et al. (2009) found that Americans judging the killing of Iraqis by American forces were more likely to use reasoning that allowed for trading off costs and benefits than were those judging the killing of Americans by Iraqis. This is an imposing list of the ways cognitive resources can be recruited in the service of moral failure. Of course, the list can be used for a positive purpose: to ask oneself or others if they are using these strategies without justification. The positive use of these strategies to check oneself or one’s society is a crucial aspect of holding s ourselves and others morally responsible, and of maintaining a cultural critique that influences how we think of our actions. So, a recognition of the tools that allow for bias based in cognitive reasoning can support moral critique. of 7.5.3 Reflective Equilibrium and Moral Failure This balancing of various considered moral judgments against each other was given a ro name by the philosopher Rawls (1971/1999): reflective equilibrium.21 We are using this method in our suggestion that recognizing the strategies of moral distancing and the limitations of moral identity can lead us to recognize and avoid moral failure. This equilibrium involves consulting those with expertise in an area, and also our intuitions lP (Daniels, 2018). In both this chapter and Chapter 9, we argue for the close integration of moral emotion in our moral intuition. And in Chapter 3 we document how closely linked rationality is to the specific moral ecologies in which it occurs. For this reason, we prefer explicitly to add social and emotional reflection to the idea of reflective equilibrium: social–emotional reflective equilibrium (Huff & Furchert, 2016). na A considered balance of respected social influences, careful emotional responses, and conscious reflection can at least guard against moral failure, and is entirely in the spirit of the original proposal of reflective equilibrium. It is simply more explicit about what should be included in the equilibrium. Fi 7.6 Discussion 7.6.1 Conclusion We began this chapter with a reconsideration of the dominant paradigm in moral psychology for three decades, the cognitive developmental research program of Kohlberg. After reviewing the legacy of that program, we soon found ourselves in a web of different research programs that took us far from Kohlberg’s commitment to consciously controlled pure reasoning processes and their relation to philosophical 21 See Daniels (2018) for a history of the concept and its reception and critique and Narvaez (2010) for an integration of a similar concept into a psychological theory of moral expertise. Moral Reason 203 moral reasoning. This movement is reflected in the understandings we summarize here, and the questions that remain: 1. We should be clearer what we mean when speaking of moral reason. The research conversation on cognition is changing in ways that depart dramatically from the old school of consciously controlled executive function. The move in cognitive psychology toward implicit cognition, two-­(or more) process models of cognition, the incorporation of emotion, and naturalistic cognition should lead us away from a normative commitment to conscious rational processing and toward a descriptive understanding of the ways that different kinds of processes we call reasoning are involved in moral action. When speaking of reason and moral action, we will need to be more specific about what type of reason, what capabilities that type has, the biases associated with it, and how it interacts with other s systems. 2. There is a great deal of moral cognition that is not conscious. of The Kohlberg research tradition in moral psychology championed an emphasis on conscious logical thinking as the foundational aspect of morality. But as cognitive psychology itself has opened its doors to the varieties of cognition in human living, moral psychology is also beginning to open its doors and recognize the many ways ro cognitive processing interacts with moral life. Many cognitive processes are ­automatic – either in origin (e.g. perceptual judgment) or because they are so well practiced, they require little working memory (e.g. expertise-­based judgment). Moral exemplars, people who excel at particular kinds of moral action, report lP expending little of their energy on deciding what is right or wrong and the most energy on planning and implementing their goal-­directed activity. So, even in this chapter on cognitive processes – or perhaps especially in this chapter on cognitive processes – we find a shift away from the role of conscious deliberation and toward the multiplicity of ways that cognition is “the servant of ” and even the “hired gun na for” (im)moral action. 3. Moral cognition is for moral acting. This is an application of Fiske’s (1992) admonition that “thinking is for doing.”22 It recognizes that much moral action is based in instrumental reasoning of how to achieve moral goals that have already been adopted. And that the skills of moral Fi perception, moral reflection, self-­regulation etc. that are called upon in moral action (see Chapter 6) have a rationality to them that may be implicit and domain specific. This gives reason a greater role than the biased motivated reasoning in the “lawyer” metaphor in the new synthesis proposal (Haidt, 2007). Surely, we use motivated reasoning to simply buttress our own positions or defend our prejudices. But when people do search for the right thing to do, they often use cognitive processes (in interaction with emotion and social identity) to critique their own culture and plan action to change it (Killen & Dahl, 2021). Thus, when considered as an analysis of cultural critique, much of the original work in the Kohlberg tradition still stands and can provide important structure to further investigation. But much more work remains to be done in how these conscious 22 Which she takes from William James (1890/1950, p. 959) Principles of Psychology. Taking Moral Action processes interact with automatic processes and other influences to structure and guide moral action. We find people constantly choosing their way among the multiple influences on their (im)moral goals and plans of action. The change in focus, then, is from isolated conscious moral problem-­solving of self-­contained moral puzzles and toward goal-­directed action and all the cognitive processes that support the goals and the action. 4. Moral reason can be both a useful guide and a source of bias. One of the central motivators of the insistence on conscious moral cognition as the “real” moral cognition (whether in Kohlberg or in two-­process models) is the idea that only principled reasoning can save us from personal bias and relativism. There are several difficulties with this line of approach to moral cognition. First, the role of reason is already morally ambiguous. Clearly, reason has a strong role to play in justifying or protecting moral failure through a variety of s moral distancing mechanisms. Second, the reduction of morality to a simple power struggle is not the only possible option after one opens the door to other of influences on moral cognition. Many theorists allow that a critique of moral culture can be more than a simple power struggle. It can include appeals to intuition, to an objective moral charter, to shared humanity, to religion, or to any of multiple values that can balance each other in the moral ecology of a ro culture. Of course, this balance is often lost, resulting in moral collapse. One of the themes of Chapter 3 is the search for how a moral ecology might maintain an appropriate social–emotional reflective equilibrium. The final problem in viewing reason as the bulwark against relativism and moral collapse is that moral lP collapse most often happens because of an imbalance in the moral ecology, when, for example, moral identity is too closely tied to the interests of an in-­ group. Rationality does not guard against such dangers, instead it can become the “hired gun” that serves the imbalance. na 7.6.2 Application At the end of Chapter 3, you can read about the shifting moral ecologies associated with Nathaniel Borenstein’s decision to become a NATO consultant. Because of his expertise in online learning systems, and despite his history as a peace activist, he had Fi been recruited by NATO to help them design a training system for tactical nuclear missile launchers. While doing so, he found commercial firms making evidence-­based arguments that including modern training software and help systems on missile launchers was the best way to upgrade the skills of military personnel who operated the launchers. These arguments were rational, plausible, and based in psychological evidence. But due to his experience developing software for real systems, Borenstein was skeptical. Consider this quote from Borenstein (1989, 17): Solving one problem often creates a host of new ones. I devote my efforts rather narrow-­ mindedly to learning how to make computers easier for people to use. But more usable programs are not always better in every sense. Making a program seem simple to the user usually means making its internals far more complex, and this often makes it less reliable. This is not the kind of tradeoff one makes lightly when dealing with computers that control nuclear weapons. Moral Reason 205 This is ethical rationality based in expertise in a domain. The reasoning here is not high-­level ethical argument about the good. Borenstein already knows his moral commitments – he is an unalloyed pacifist. But as a software developer, he knows that all design choices involve value tradeoffs. And he has extensive experience with one particular one: trading off reliability for ease of use in the human interface. He recognizes the tradeoff and its dangers easily, almost automatically and without conscious search. He reports an emotional reaction (he is frightened by the tradeoff) based on his appraisal of the context (safety-­critical weapons systems). The emotion is part of what convinces him to agree to a consulting position. He was influenced by a phone call from “a pleasant-­sounding” lieutenant commander with a military moral ecology he perceived as being in opposition to his moral commitments (see Chapter 3). His participation in the panel resulted in a less dangerous outcome in software design and he reports “I was entirely unprepared to like the military men as much as I did. They s were smart, conscientious, and peaceable” (Borenstein 1989, 18). Borenstein’s turn in military consulting provides us with an example of the comof plexities of moral reason in real-­life situations. There is a great deal of cognitive processing, mixed with emotional responses and automatic, almost intuitive, reactions. There is very little abstract thinking about moral principles. The moral reasoning and moral action are deeply interwoven into expertise in a particular domain (software ro development) and embedded in multiple complex moral ecologies."
7,7.6,"Discussion 7.6.1 Conclusion We began this chapter with a reconsideration of the dominant paradigm in moral psychology for three decades, the cognitive developmental research program of Kohlberg. After reviewing the legacy of that program, we soon found ourselves in a web of different research programs that took us far from Kohlberg’s commitment to consciously controlled pure reasoning processes and their relation to philosophical 21 See Daniels (2018) for a history of the concept and its reception and critique and Narvaez (2010) for an integration of a similar concept into a psychological theory of moral expertise. Moral Reason 203 moral reasoning. This movement is reflected in the understandings we summarize here, and the questions that remain: 1. We should be clearer what we mean when speaking of moral reason. The research conversation on cognition is changing in ways that depart dramatically from the old school of consciously controlled executive function. The move in cognitive psychology toward implicit cognition, two-­(or more) process models of cognition, the incorporation of emotion, and naturalistic cognition should lead us away from a normative commitment to conscious rational processing and toward a descriptive understanding of the ways that different kinds of processes we call reasoning are involved in moral action. When speaking of reason and moral action, we will need to be more specific about what type of reason, what capabilities that type has, the biases associated with it, and how it interacts with other s systems. 2. There is a great deal of moral cognition that is not conscious. of The Kohlberg research tradition in moral psychology championed an emphasis on conscious logical thinking as the foundational aspect of morality. But as cognitive psychology itself has opened its doors to the varieties of cognition in human living, moral psychology is also beginning to open its doors and recognize the many ways ro cognitive processing interacts with moral life. Many cognitive processes are ­automatic – either in origin (e.g. perceptual judgment) or because they are so well practiced, they require little working memory (e.g. expertise-­based judgment). Moral exemplars, people who excel at particular kinds of moral action, report lP expending little of their energy on deciding what is right or wrong and the most energy on planning and implementing their goal-­directed activity. So, even in this chapter on cognitive processes – or perhaps especially in this chapter on cognitive processes – we find a shift away from the role of conscious deliberation and toward the multiplicity of ways that cognition is “the servant of ” and even the “hired gun na for” (im)moral action. 3. Moral cognition is for moral acting. This is an application of Fiske’s (1992) admonition that “thinking is for doing.”22 It recognizes that much moral action is based in instrumental reasoning of how to achieve moral goals that have already been adopted. And that the skills of moral Fi perception, moral reflection, self-­regulation etc. that are called upon in moral action (see Chapter 6) have a rationality to them that may be implicit and domain specific. This gives reason a greater role than the biased motivated reasoning in the “lawyer” metaphor in the new synthesis proposal (Haidt, 2007). Surely, we use motivated reasoning to simply buttress our own positions or defend our prejudices. But when people do search for the right thing to do, they often use cognitive processes (in interaction with emotion and social identity) to critique their own culture and plan action to change it (Killen & Dahl, 2021). Thus, when considered as an analysis of cultural critique, much of the original work in the Kohlberg tradition still stands and can provide important structure to further investigation. But much more work remains to be done in how these conscious 22 Which she takes from William James (1890/1950, p. 959) Principles of Psychology. Taking Moral Action processes interact with automatic processes and other influences to structure and guide moral action. We find people constantly choosing their way among the multiple influences on their (im)moral goals and plans of action. The change in focus, then, is from isolated conscious moral problem-­solving of self-­contained moral puzzles and toward goal-­directed action and all the cognitive processes that support the goals and the action. 4. Moral reason can be both a useful guide and a source of bias. One of the central motivators of the insistence on conscious moral cognition as the “real” moral cognition (whether in Kohlberg or in two-­process models) is the idea that only principled reasoning can save us from personal bias and relativism. There are several difficulties with this line of approach to moral cognition. First, the role of reason is already morally ambiguous. Clearly, reason has a strong role to play in justifying or protecting moral failure through a variety of s moral distancing mechanisms. Second, the reduction of morality to a simple power struggle is not the only possible option after one opens the door to other of influences on moral cognition. Many theorists allow that a critique of moral culture can be more than a simple power struggle. It can include appeals to intuition, to an objective moral charter, to shared humanity, to religion, or to any of multiple values that can balance each other in the moral ecology of a ro culture. Of course, this balance is often lost, resulting in moral collapse. One of the themes of Chapter 3 is the search for how a moral ecology might maintain an appropriate social–emotional reflective equilibrium. The final problem in viewing reason as the bulwark against relativism and moral collapse is that moral lP collapse most often happens because of an imbalance in the moral ecology, when, for example, moral identity is too closely tied to the interests of an in-­ group. Rationality does not guard against such dangers, instead it can become the “hired gun” that serves the imbalance. na 7.6.2 Application At the end of Chapter 3, you can read about the shifting moral ecologies associated with Nathaniel Borenstein’s decision to become a NATO consultant. Because of his expertise in online learning systems, and despite his history as a peace activist, he had Fi been recruited by NATO to help them design a training system for tactical nuclear missile launchers. While doing so, he found commercial firms making evidence-­based arguments that including modern training software and help systems on missile launchers was the best way to upgrade the skills of military personnel who operated the launchers. These arguments were rational, plausible, and based in psychological evidence. But due to his experience developing software for real systems, Borenstein was skeptical. Consider this quote from Borenstein (1989, 17): Solving one problem often creates a host of new ones. I devote my efforts rather narrow-­ mindedly to learning how to make computers easier for people to use. But more usable programs are not always better in every sense. Making a program seem simple to the user usually means making its internals far more complex, and this often makes it less reliable. This is not the kind of tradeoff one makes lightly when dealing with computers that control nuclear weapons. Moral Reason 205 This is ethical rationality based in expertise in a domain. The reasoning here is not high-­level ethical argument about the good. Borenstein already knows his moral commitments – he is an unalloyed pacifist. But as a software developer, he knows that all design choices involve value tradeoffs. And he has extensive experience with one particular one: trading off reliability for ease of use in the human interface. He recognizes the tradeoff and its dangers easily, almost automatically and without conscious search. He reports an emotional reaction (he is frightened by the tradeoff) based on his appraisal of the context (safety-­critical weapons systems). The emotion is part of what convinces him to agree to a consulting position. He was influenced by a phone call from “a pleasant-­sounding” lieutenant commander with a military moral ecology he perceived as being in opposition to his moral commitments (see Chapter 3). His participation in the panel resulted in a less dangerous outcome in software design and he reports “I was entirely unprepared to like the military men as much as I did. They s were smart, conscientious, and peaceable” (Borenstein 1989, 18). Borenstein’s turn in military consulting provides us with an example of the comof plexities of moral reason in real-­life situations. There is a great deal of cognitive processing, mixed with emotional responses and automatic, almost intuitive, reactions. There is very little abstract thinking about moral principles. The moral reasoning and moral action are deeply interwoven into expertise in a particular domain (software ro development) and embedded in multiple complex moral ecologies. 7.6.3 Open Questions lP 1. Where in human living does moral evaluation occur and what is it for? The move away from explicit cognition in moral psychology has occurred in parallel to a similar move in cognitive psychology. Moral psychologists have begun to adopt a multiplicity of descriptive and instrumentalist approaches, including evolutionary, two-­ process, expertise-­ based, and naturalistic moral judgment and na action models. These models have expanded our view of the role of reason in moral action in the same way that they have expanded our understanding of rationality in general. First, instead of focusing on isolated judgment, they are much more likely to focus on goal-­directed action and the role cognitive processing plays in it. This change in focus is a central aspect of this book: it argues for the study of Fi moral action and the influences and processes that support it. This is parallel to the instrumentalist approaches in human cognition. These approaches ask, “What is cognitive processing for?” The instrumentalist approach in moral psychology asks also, “How is cognitive processing involved in moral action?” Similarly, the descriptive approaches to cognition ask, “Where in human living is cognitive processing done?” Moral expertise approaches ask a similar question, as do anthropological models of moral cognition, as does the extensive literature on moral distancing. They thus expand our vision of where and when moral cognition operates, bringing into view a wider span of human action. The works of Malle (2021), Killen and Dahl (2021), and Epley and Tanenbaum (2017) are examples of promising steps in this direction. 2. Is it necessary to resolve the reason-­emotion tension in moral psychology? In short, no. The proponents on the two sides in the moral reason vs. emotion debate are in essential agreement that both matter. The exchanges frame the Taking Moral Action disagreement more as a differential weighting of reason vs. intuition/emotion. But this is too abstract. It might well be that reason plays a predominant role in some aspects of moral action (e.g. cultural critique, planning) and intuition/emotion plays a dominant role in others (e.g. compassion, commitment to social change), and that in most all moral action there is some level of balance. How these balances are achieved is the subject of the next question. 3. Might it be better to study moral evaluation rather moral reasoning? When an author wants to appeal to reason rather than bias, reason is often the preferred term (rather than cognitive processing). But even cognitive processing assumes that only cognition is what is under investigation. There is little neurological or psychological warrant for this assumption. We might better use moral evaluation to include a range of influences when cognitive, emotional, and social evaluation is occurring in the service of moral action. This avoids falling back on s the rationalist, foundationalist tropes of earlier approaches. And it allows for something like social–emotional reflective equilibrium as a process whose interacof tions, influences, processes, and limitations might be investigated."
7,7.7,Further Readings ro These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and lP recent work. Complete citations are provided in the references section. • Bandura (2002). “Selective moral disengagement in the exercise of moral agency.” A systematic review of the ways that motivated reasoning can distance us psychologically from the evil we do. na • Evans and Elqayam (2011). “Towards a descriptivist psychology of reasoning and decision making.” A useful overview of the question “what is reason?” in the cognitive psychology literature. • Gibbs et al. (2007). “Moral judgment development across cultures: Revisiting Kohlberg’s universality claims.” A relatively comprehensive review of the critiques Fi of the Kohlberg system and the empirical literature supporting those critiques. • Killen and Dahl (2021). “Moral reasoning enables developmental and social change.” A review of the parallels in moral reasoning that lead to individual development and to social change. Presents moral reasoning development in the light of lived experience. • Kohlberg (1971). “From is to ought: How to commit the naturalistic fallacy and get away with it in the study of moral development.” The classic statement of how the Kohlberg system moves back and forth from descriptive “is” statements and normative “ought” statements. • Malle (2021). “Moral Judgments.” A rearranging of the pieces in moral judgment that orients us more toward a descriptive psychology of types of moral judgment and their contexts. • Rest et al. (1999). “A Neo-­Kohlbergian approach: The DIT and schema theory.” The initial presentation of “neo” Kohlberg from the research group that designed and developed the most widely used test of Kolhbergian moral reasoning. Moral Reason 207
8,8.1,"An Overview of Theories of Emotion One might expect a chapter like this to offer a high-­level theory of the emotions. This cannot easily be done well. Some theorists have even suggested that a “general theory [of emotions] is neither necessary nor possible” (Nesse, 2014, p. 321). The Taking Moral Action, First Edition. Chuck Huff and Almut Furchert. © 2023 John Wiley & Sons Ltd. Published 2023 by John Wiley & Sons Ltd. Taking Moral Action deceptive single word emotion refers to an experience that varies dramatically in intensity, time course, physiological expression, action tendency, cognition, and of course, culture. Theories of emotion often succeed either by ruling out significant and interesting phenomena or by retreating to a low-­level reduction that loses touch with the actual experience and complexity of the phenomenon. Thankfully, there is at least some structure in the kinds of theoretical approaches. We present it here in terms of four different categories of theories – basic emotion theories, appraisal theories, cultural theories, and constructivist theories (Cameron, Lindquist, & Gray, 2015) – with each category allowing for somewhat greater complexity in description of the process and experience.1 Thus, as in many chapters in this book, we begin in principle without a definition, in order to expand our horizon and include potentially interesting phenomena. s 8.1.1 Basic Emotion Theories of Most introductory texts in psychology begin their section on emotion by talking about theories of “basic emotion.” This has the helpful pedagogical effect that it connects to the evolution and neuroscience chapters, and that it treats emotions as the separate things they often appear to be in language and in common sense. ro It also has distinct disadvantages: it treats emotions as wholly separate things, perpetuates the reason–emotion distinction, and only includes culture as an ­ afterthought. What the basic emotion theories share is (Cameron et al., 2015; Ekman, 1999; lP Ekman & Cordaro, 2011; Tracy & Randles, 2011): • a conception of “basic” as grounded in a specific physiological underpinning2 • a grounding in an evolutionary background, with the most basic emotions appearing in some form in other species na • the prediction of strong cross-­cultural similarities in elicitors, expression, and action motivation Fi 1 Note that there are even disagreements about the appropriate number of categories for the kinds of emotion theories. Ellsworth (2013) lists five categories: adaptive, basic emotions, dimensional, appraisal, and constructivist theories. Scherer and Peper (2001) list seven categories: adaptational models, dimensional models, motivational models, circuit and discrete emotion models, and meaning and construct models. Barrett et al. (2019) provide a two-­dimensional model of the conceptual space that emotion theories inhabit. The category system you choose depends on what differences and similarities you want to emphasize. 2 See Solomon (2002) for how this choice of the meaning of “basic” is already full of assumptions. One alternative for basic could be “basic in human experience,” such as anxiety for Kierkegaard (1849/2004) or compassion (sympathy) for Hume (1739/1985) or lust(desire) for Freud (1905/1962). Another alternative is “basic to human sociality,” such as anger for Aristotle (Sokolon, 2006). Ancient Hindu culture produced its own listing of basic emotions rooted in the role they play in poetry, drama, and moral life (Shweder et al., 2008). Moral Emotion 217 Most of the researchers in this tradition have been engaged in providing evidence of these characteristics for that subset of emotions that they list as basic.3 The huge complexity and variety of emotions is then produced by combining these elements or by rapid fluctuations between two or more of the basic emotions (Ekman & Cordaro, 2011; Ortony & Turner, 1990; Vaccaro, Kaplan, & Damasio, 2020). Basic emotions can also be modified by learning so that elicitors, expression, and action motivation are changed and shape the emotional process (see, e.g. work on display rules). If I am carrying a large grocery bag home, I might react with surprise if it splits open to spill my groceries on the sidewalk. This would elicit a characteristic body posture and facial expression, which might immediately be overridden by frantic attempts to rescue things, themselves overridden by attempts to display calm competence or humor. The mixed emotions I experience, and the manner in which I gather my groceries, would be shaped by which elicitors were present in that situation s (e.g. other people watching). Because these approaches ground emotion in evolutionarily shaped physiological of responses to the environment, basic emotion theories are also those that are most interested in establishing the causal chain of how “an emotion” proceeds.4 Thus, some versions see the physiological responses of an emotion as mostly automatic and prior to any thought, with thought chasing behind the already unfolding emotion ro and giving reasons for it. Simplistic versions of this end up justifying the emotion–­ reason dichotomy. More complex versions of basic emotion theories are the prototype for those approaches to moral emotions (Rozin et al., 1999) that see a limited number of basic moral emotions with identifiable elicitors (injustice), expressions lP (lowered eyebrow stare), and action motivations (assertion or aggression). 8.1.2 Appraisal Emotion Theories Appraisal theories see emotion experiences as structured appraisals of and motivana tions toward the world. Appraisal theories come in a variety of flavors, but they all share the mixing of cognition and emotion into the overall experience and shape of the ­emotion. The entire process is conceived as a dense weave of feedback loops among ­conscious and nonconscious cognition, physiology, subjective feel, action motivation, and action. Fi The central process, not surprisingly, is appraisal, and it comes in various forms. All appraisals are a form of judgment or evaluation about the world, and particularly about the implications of some particular state of the world (or of the self) for the self. When I walk down the street and the grocery bag that I am carrying splits open, spilling its contents onto the sidewalk, I very quickly experience feelings of shock, dismay, embarrassment, and perhaps anger. This complex cascade of emotion is interwoven 3 The number varies from three to ten, and researchers often add or subtract emotions from their own lists. See Solomon (2002, p. 123) for an argument that this variety in identifying a canonical number can be a sign of a healthy science and not a weakness. 4 In basic emotion theory work, one rarely sees an analysis of how a moderately complicated emotional experience like the one associated with lost groceries would proceed. Ellsworth (2013, p. 127) has shrewdly asked “Does Hamlet ever feel one of the six basic emotions?” Taking Moral Action and shaped by an equally complex set of appraisals, some very fast and automatic, others more controlled and reflective.5 In terms of the kinds of content these a­ ppraisals have, Ellsworth (2013, p. 125) lists “novelty, valence, certainty, goal conduciveness, agency, and control” as the dimensions most commonly proposed. Thus, upon my noticing the ripping of the grocery bag, the initial reflexive response might be one of novelty (it is not expected) quickly followed by valence (negative). These two responses combine to produce the reaction of shock listed earlier. The list of emotions following shock are shaped by a series of more complex appraisals involving how I view myself, how others view me, and a range of goals in addition to getting my groceries home (e.g. appearing competent). Thus, appraisal theories see emotional experience as being built up, or constructed, out of an often-­complex sequence of appraisal and emotional reaction to that appraisal, which includes subjective feeling, physiological processes, and motivations to action. For this reason, Ellsworth (2013) s prefers to avoid the word emotion and uses “emotional experiences” instead. The basic emotions, then, are not so basic (Ortony & Turner, 1990). Some of appraisal theorists see these emotional experiences as grouped into clear themes (Lazarus, 1991), while others see the variation as more open ended where appraisal structures can get us “to the right neighborhood, but not the street address” of the experience (Ellsworth, 2013). This understanding of emotion is compatible with ro the cottage industry of research on “moral emotions” (reviewed in Section 8.2) but does not make the assumptions about a limited set of basic emotions or universality. And it allows much more room for cognition and culture to play a central part in the emotional experience. lP 8.1.3 Cultural Emotion Theories It is just as certain that there are cultural differences in emotion as that there are cultural universals. For example, in one Buddhist village in Thailand, it is a moral failure na to show emotional involvement when something bad happens: it is better to tham jai, to practice a calm heart. But in a nearby Christian village, emotional involvement even to the point of anger is morally appropriate (Cassaniti, 2014). There are numerous examples of these sorts of differences both within national boundaries and across them (see Keltner, Oatley, & Jenkins, 2014, chapter 3; Shweder et al., 2008 for a Fi review). One can also look for variation across time. In Western cultures, religious conceptions made melancholy a preferred emotion in medieval times, while the reformation’s emphasis on a more merciful god had the effect of making smiling a more acceptable, and even pious, public face (Stearns, 2008). Corbin (1986) traces the change in the sense of disgust in France as it helped to establish a cultural divide between the washed and the unwashed. Thus, emotion is linked not only to culture but also to power. These cultural and historical differences can be quite complex and subtle (Matsumoto et al., 2008). The work on culture and emotion has mostly been interested in documenting these subtleties and in showing how they are related to 5 See Chapter 7 for a description of “two-­process models” that underlie these different kinds of cognitive appraisals. Moral Emotion 219 important themes such as power and morality (Shweder, 2012, 2014a, 2014b). The approach suggests there is likely an infinite number of emotional experiences that a culture or language can highlight and use – that they have structure and are related in thematic groups, although the same emotions do not always occur in the same group in every culture. Finally, the cultural approach encourages us to cast the widest net to understand the role of emotions in morality. It sees emotion as “the entire script” of the experience and its influences including the physiological state (chest pain, goose flesh), the affective experience (panic, emptiness), simple and complex perceptions of the event and the experience (death of a friend, oppression of a minority, victory in struggle), implications for the self (loss, success, empathy), associated social judgment (vice or virtue, sickness or health), and a plan or impetus toward action (withdraw, confess, revenge, comfort). The emotional experience is a continuous experience, of a unit, and though one can look at components,6 one cannot s adequately consider them in isolation. of 8.1.4 Constructionist Models of Emotion The most recent arrival on the scene of emotion theory are the constructivist approaches (Barrett, 2013; Clore & Ortony, 2013; Cunningham, Dunfield, & ro Stillman, 2013). These approaches combine elements of the three previous approaches and claim historical precedence to them via one of the founders of psychology, William James (Lindquist, 2013).7 They use physiological evidence generated by the basic emotion theories to claim that discrete emotion categories cannot consistently lP and specifically be localized to distinct brain regions (Lindquist et al., 2012). Their central claim is that we experience emotions as though they are basic but they are in fact constructed on the fly by conceptual acts that (1) match the situation with an appropriate, available emotion category and (2) initiate or enact “the embodied experience of the emotion” (Lebois et al., 2020). na Barrett (2013) recalls Darwin’s (1859) emphasis on variability as a central engine of evolution and begins the argument for constructivism by emphasizing the immense variation in appraisal, physiological signature, and expression with any category of emotion, using this variation as a central principle to deconstruct emotion as “not a thing but a category of instances” (Barrett, 2017, p. 16). This emphasis on categoriFi zation as the central engine in emotion production that directs bodily expression, situational meaning, action tendencies, etc. allows constructivism to embrace all the complexity of the cultural approaches. One primary distinguishing characteristic between appraisal and constructivist approaches is the amount of expected variation within any particular category, with constructivist approaches allowing for close to 6 Shweder et al. (2008, p. 415 ff) list eight components, and show their conceptual dependency with a long comparison of anger/lung lang in American and Tibetan respondents. The most important component in this instance is “normative social appraisals,” or ­morality. See Scherer and Peper (2001) for another attempt at a comprehensive listing of components and processes of emotional experience. 7 One can claim even further historical reach if one recognizes Magda Arnold’s (1960) arguably constructivist approach as grounded in Thomas Aquinas’s medieval scholastic understanding of habitus (Cornelius, 2006). Taking Moral Action infinite flexibility. Lebois et al. (2020) have demonstrated that people can learn very specifically situated emotions (in this case, fear of physical harm vs. social rejection and anger at physical harm vs. social rejection). Functional magnetic resonance imaging (fMRI) scans showed the neural activity of the two types of fear or the two types of anger overlapping as little as 11.5%. This kind of emotional learning can underlie tremendous flexibility in emotion while still connecting it to the neural substrate. And it suggests processes by which one might achieve very specific emotional expertise in a domain. 8.1.5 Preliminary Conclusions About Emotions and Morality Emotions are not simply “feelings” but are instead a complex of: (1) cognitive conceptualization (that arouses and shapes the emotion); (2) directed arousal (that provides s the “feel” of the emotion and signals its urgency); and (3) action tendency (that links action to the reaction of the emotion) (see Oatley, Keltner, & Jenkins, 2006 for an of overview). What does this picture of emotions tell us about the relations of moral emotion and reason to moral action? First, there are complex interrelationships between emotion and reason in moral action, rather than a simple opposition.8 The appraisal, cultural, and constructivist ro approaches all see emotion as in part constituted by reason. Moral emotions contain, and express the importance of, propositional knowledge. One is angry because an injustice, an important injustice, has occurred. When we learn the injustice was a mistake, or unintentional, our anger is modified. Given this intimate relationship lP between reason and emotion, there should be no surprise that moral reasoning can inform moral emotion and that moral emotion informs moral reasoning. Second, the function of emotion in moral action is to “prioritize thoughts, goals, and actions” (Keltner, Oatley et al., 2014, p. 237) in a world where there is rarely enough information to make a complete judgment based on reason or learning alone na (Oatley & Johnson-­Laird, 2011; Simon, 1967). Thus, rather than being a separate system that biases the primary functions of rational moral judgment, emotion is a basic part of our moral apparatus. It is not an interloper or an outside bias. If we were not emotional, we would not be able to be fully moral. Third, there is a great deal of complexity hidden in our emotional and moral lives Fi that is obscured by the simplistic opposition of reason and emotion. An emotional experience can vary over time and be transmuted, for instance, from envy to anger or sadness (R. Smith & Kim, 2007). Thus, there is likely no canonical list of discrete moral emotions, but rather a complex palette of emotional experience that varies over time and across cultures (Barrett, 2013; Ellsworth, 2013). It still might make sense to study “anger” as though it was a thing, but we should do so knowing how variable the experience is and how porous its boundaries are (if there are any boundaries). In addition to not being bounded in basic units, emotions are also not completely bounded within a person. Emotions are not merely personal, but are shared with 8 See Chapter 2 for the evidence for massive interconnectivity between emotion and cognition at the physiological level. See also Wong (2015) on the convergence between this conclusion of interconnectivity and the philosophical approaches of Mencius and Confucius. Moral Emotion 221 others and this sharing modifies how we and how those others feel (Goldenberg et al., 2015, 2020; E. R. Smith & Mackie, 2008; Wagner et al., 2015). Fourth and finally, emotions need not be the door to relativism. Since they contain propositional knowledge (appraisals) they can be subject to consistency criteria. Even the basic experience of an emotion can feel incorrect (Givon et al., 2022). Consistency criteria can have their effect through reappraisal during the process of the emotional experience (Did they really mean that?) or in the social sharing of emotion (Are you sure they meant that?).9 It involves asking the question: Given the relevant circumstances, what is the appropriate emotion? And thus, what appropriate judgment or action proceeds from that? Keane (2015, p. 194) provides rich examples of the social process of rational/emotional argument in several reform movements based on ­ethical commitments. For example, in the feminist consciousness-­raising movement, participants often discovered that, because of unacknowledged injustice, “they had s been ‘angry’ for years without realizing it.” Since they are shaped by appraisals, ­emotional experiences can hang together in predictable patterns that allow for perof sonal examination (Ellsworth, 2013) and philosophical and cultural critique (Gibbard, 2006). ro 8.2 The Moral Emotions Some emotions (e.g. anger, compassion) are more closely connected to issues of morality than are others (e.g. sadness, joy). In this section, we will review those emolP tions and look at how they are woven into our moral lives. First, however, a word must be said about how one identifies an emotion as belonging to the moral domain. Again, our approach is to be as inclusive as possible. And thus, almost every emotion, from angst to schadenfreude, might be found to have moral implications. But the list here is limited in part by the available research – na though the list is growing, only a good handful of emotions have enough work on them to merit inclusion for now. Haidt (2003b, p. 854), one of the pioneers in research on moral emotion, identifies the moral emotions as those meeting two criteria: an emotion is moral to the extent that (1) it is about others (is triggered by the actions or reactions of others, like righteous anger), and to the extent that (2) it proFi duces pro-­social motivations. Even here, though, things get difficult. (1) demarcates emotions as social. But there are, for instance, moral emotions such as gratitude or awe that lead to striving after religious goals (Emmons, 2005, 2008) or to self-­ transcendence (Koltko-­ Rivera, 2006) and that are thought of by many religious traditions as deeply moral but not prototypically social.10 Thus, the elicitors and motivations of a moral emotion may not always be social in nature. (2) marks moral emotions as providing motivation for pro-­ social behavior. This too is complicated, given that pro-­ social behavior 9 But see Chapter 5 for the many kinds of consistency criteria. 10 See Cuttick (1997) and Pratt (1928) for examples of this moral imperative in, respectively, Sufi and Buddhist approaches. Our thanks to David Wulff for providing these examples. Taking Moral Action can include altruistic punishment that involves harming others for the sake of ­reinforcing a moral value.11 Thus, disgust, anger, contempt, shame, pride, and a host of other moral emotions can lead to drastically immoral ends (aided and abetted by reason), resulting in moral collapse (Hart, 2005; Hart & Matsuba, 2007). So both criteria to demarcate moral emotions have difficulties. But they provide a place to begin; as long as we are aware of the limitations. To organize this review, we will use the divisions into four “emotion families,” suggested by Haidt (2003b): other-­condemning, other-­suffering, self-­conscious, and ­other-­praising.12 These families are more like overlapping sets, with some emotions falling equally into two families (e.g. for this reason we have moved guilt from Haidt’s self-­conscious family to the other-­suffering family – it has aspects of both). One can imagine more complicated moral emotions like envy (R. Smith & Kim, 2007) that could fall into three families (self-­conscious, other-­praising, and other-­condemning). Or s emotions such as the Thai emotion of tham jai, keeping a calm heart, that do not seem to fall easily into any family (Cassaniti, 2014). And one emotion can have difof ferent aspects depending on the context. Anger, for instance, plays a central role in close relationships, often contributing to relationship repair (Fitness, 2009, 2015) but shows a different face to threatening out-­groups (Fiske, 2015). The confusion that a close look at the families metaphor produces is a clue that we ro might not be looking at emotions correctly when we think they are primarily a reaction to one thing. They can be, and often are, a reaction to many things (see the grocery bag example in Section 8.1.1). But even deeper, they are less a reaction and more a relation to states of the world and to ourselves. So, anger is not a reaction to lP an injustice, it is about our relation to an injustice.13 The same with compassion, it is about our relation to a person. And as a relation, we have some freedom in shaping it. Even so the families have the advantage of suggesting similarities among groups of emotions, and of suggesting additional investigation when one finds complexities. In our review, we will follow two aspects of each moral emotion: the emotion as na information and as motivation. We know from appraisal research that appraisals are propositional in nature (Wu et al., 2021). For example, “that is unjust” can contain information about relevance based on my goals, intentionality of the actor, amount of harm, etc. Emotions also have a motivational component, or what some theorists have called an “action tendency” (Ellsworth, 2013). They both ready the body for a Fi particular kind of action and orient the individual toward that action. It is this interaction between information and motivation that makes moral emotion a central mover to moral action. Pay attention to this interaction as we review each moral emotion. 8.2.1 Other-­Condemning Moral Emotions These are emotions directed toward the condemnation or rejection of others. They share a focus on negative evaluations of the actions or character of others and an 11 See Chapter 1 for more on this concept. 12 Note that the titles of the categories already include information and motivation as aspects of the emotions. 13 See Chapter 5 for the variety of ways that this relation can be constituted. Moral Emotion 223 action tendency of rejection or aggression. They often also seem to combine with each other to produce hybrids like moral outrage (Salerno & Peter-­Hagene, 2013). 8.2.1.1 Disgust Disgust is an emotion associated with the rejection of unpleasant things. The human facial expression associated with core disgust is the same one displayed when tasting very bitter compounds (Herz, 2011). Even those blind from birth make the same expression of disgust as sighted people. There appear to be three “varieties” of disgust: (1) core disgust, related to contact with rotted food, disease, or open wounds; (2) sexual disgust, related to rejecting sexual acts; and (3) moral disgust, related to rejecting moral transgressions. These three types share some characteristics (e.g. aspects of facial expression) but differ in terms of what provokes them and in the shape of their motivation (Tybur, Lieberman, & Griskevicius, 2009). As with much work in moral emotions, these distinctions are under dispute, with some seeing moral s disgust as a mere metaphorical use and others claiming that the types are actually different emotions (see Cameron et al., 2015; Yoder, 2016 for a review). For our of purposes, it seems clear that there are at least “loose correspondences” (Cameron et al., 2015) in the form of moral rejection called moral disgust. It is a rejection that is more motivating and less malleable than simple avoidance based on prudence (e.g. disease is disgusting vs. it is prudent to avoid disease). Moral disgust has been ro shown to have the contamination pattern of core disgust (e.g. people will not want to wear the clothes worn by a murderer, even if they have been cleaned) (Rozin, Haidt, & McCauley, 2008). The evolutionary or cultural origins of these correspondences is, of course, under dispute. But as in many of the controversies in moral psychology, the lP answer likely lies in some combination of the two perspectives. We have already mentioned the difficulty of maintaining clear distinctions among emotions. In the moral domain, disgust often overlaps with anger in the rejection of moral harm. Salerno and Peter-­Hagene (2013) have documented how disgust and anger combine in moral outrage against particularly heinous offenses. Moral disgust na also has well-­documented overlap with other emotions, such as contempt (Cameron et al., 2015; Hutcherson & Gross, 2011). In summary, the information associated with the moral aspect of disgust is that the thing or person is not merely negative but is to be condemned and rejected because it violates, or is associated with the violation of, some moral value. The action tenFi dency is rejection and avoidance that is highly motivating and much less flexible than simple rejection based on prudence. The malleability of disgust, in particular its relation to other moral emotions, is an important open question. 8.2.1.2 Anger There is a voluminous literature on anger, what produces it, how it feels, how it affects the person, and what kind of behavior and goals it produces (Berkowitz & Harmon-­Jones, 2004). But the psychological focus on anger as a moral emotion is more recent.14 We mentioned earlier how it connects and blends with disgust, in its role of reacting to moral violation. Much older work on anger connects it with the appraisal of blocking a goal (Dollard et al., 1939). And this appraisal can 14 Aristotle, of course, saw anger as a moral, social, and indeed political emotion (Sokolon, 2006). Taking Moral Action blend into moral anger when we see intention, particularly unjustified intention. We can even find moral anger when we “see” intention in an inanimate object like a car that will not start (Waytz, Cacioppo, & Epley, 2010). So, the information or judgment about morality that moral anger encodes is about moral violation, but more specifically, unjustified moral violation. Scherer (1997) presents a large cross-­ cultural study in which reported episodes of anger were elicited primarily by appraisals of unfairness and immorality, and consistently more than mere goal frustration. The extent of the moral violation is also associated with the amount of anger and with the associated amount of preferred punishment for the offender (Carlsmith, Darley, & Robinson, 2002). Perpetrators and victims often disagree about the extent of a moral violation and thus about the appropriate response, and this disagreement can escalate into angry exchanges (Baumeister, Stillwell, & Wotman, 1990). One might think from the comments so far that the primary function of anger is to s motivate the victim to punish the offender as a means of self-­ defense (Darley, Carlsmith, & Robinson, 2000). And indeed, this is one of the motivations of moral of anger. But anger can also motivate altruistic punishment, defined as the punishment of a moral violator when you yourself are not the victim (Balliet & Van Lange, 2013; Boyd et al., 2003). Thus, one can be angry for another person and angry at the person who harmed them, with these processes being sometimes separable (Hechler & ro Kessler, 2018). Things get rapidly more complex when one considers anger in the context of close relationships, where anger and love coexist. In this context, one might say that the motivation is assertion of one’s interest even if one’s interest is the good of the other (Fitness, 2009, 2015). Its complexity is also apparent in long-­term social lP injustice, where despite progress much remains to be angry about (Lorde, 1981). Finally, anger is flexible in its motivational profile as one changes the frame in which the action is interpreted. In forgiveness, one reduces the motivation to punish the offender, but perhaps not one’s bad feelings toward them (Exline et al., 2003). Prayer for the offender can reduce anger, perhaps through cognitive reappraisal (Bremner, na Koole, & Bushman, 2011). Anger seems to be more flexible in responding to this kind of reappraisal than other moral emotions are, like disgust (Russell & ­Giner-­Sorolla, 2010), though it appears that disgust and anger can combine in moral outrage (Salerno & Peter-­Hagene, 2013). Fi 8.2.1.3 Contempt Like the moral aspects of anger and disgust, moral contempt is about moral rejection, but its scope and shape differ. Moral contempt is about morally loaded incompetence or unfitness. Contempt is a major driver in prejudice and stereotyping (Fiske, 2015) and is (with disgust) the primary emotion shown toward disliked groups perceived as lower in status or less competent. Perceptions of dominance or status are very strongly correlated with judgments of competence, across many cultures (Fiske, 2015), and contempt is the social emotion reserved for those who threaten status in this way. Others call this a community dimension and emphasize the perceived violation of community standards. This alternative dimension involves such things as failure in “duty, role-­obligation, respect for authority, loyalty, group honor, interdependence, and the preservation of the community” (Rozin et al., 1999). We do not know enough about contempt to be able to easily outline the appraisals that lead to it (Cameron et al., 2015). It seems likely that contempt is a complex Moral Emotion 225 emotion associated with perceiving the other as having bad or threatening intentions and being low in status or incompetent.15 This would include violators of duty to the group (e.g. traitors), or those who through willful incompetence within the group threaten it (bumblers), or with out-­group or outcast individuals who are viewed as both having bad intent and being less competent. This list allows one to see how contempt can easily be associated with anger for those who endanger us. The motivational aspect of contempt is similar to disgust: to “mark those who … represent a threat and avoid them” (Hutcherson & Gross, 2011, p. 720) perhaps by excluding or driving them away. It seems likely that the perception of a failure at intended action is required for the contempt to take on a moral tone (Hutcherson & Gross, 2011) and thus, unlike disgust, contempt seems to be a thoroughly social emotion. s 8.2.2 Other-­Suffering Moral Emotions of These moral emotions are focused on the suffering of others. But they both offer a stake for the self in the suffering of others, they connect the concerns of the self to the other. They are, then, more complicated than merely being outward focused, but they are focused on the other in a way that motivates the self to action to repair damage or to help or comfort the other. ro 8.2.2.1 Guilt We feel guilty when we perceive that we have committed a moral violation (Haidt, 2003b, p. 861). More specifically, a moral violation that harms lP someone else who is important to us (e.g. in a close relationship, group, or community). One often does not feel guilt when harming those who deserve it (see anger, contempt, and disgust, discussed earlier). Modern soldiers, for instance, are well trained in avoiding guilt for the harm they cause to the enemy – though the fog of war and the humanity of the enemy make this complicated (Grossman, 1996). na An important aspect of the appraisal that leads to a feeling of guilt (as opposed to shame) is that it focuses more on the act itself and its victim and less on the self who did the act.16 Its appraisal has an informational focus outward to the other. With this focus on the other who is harmed, guilt’s motivational influence leads to apology, to restoration of relationship, and to avoidance of future harm (Baumeister, Stillwell, & Fi Heatherton, 1994). Thus, guilt seems to be an emotion that draws people together after harm doing.17 An important complication in this story is that self-­report studies of guilt almost always turn up some instances of non-­social moral violations causing guilt. Haidt 15 See Fiske (2015) for a short review of these two dimensions, their implications in prejudice and stereotyping, and their associations with moral emotions. 16 Tangney et al. (2007, p. 358) discuss group-­based guilt. Because group-­based guilt is based in identity, this complicates things. There is also some evidence that the way one measures guilt can tap neurotic vs. pro-­social guilt (Tignor & Colvin, 2016). 17 There is evidence that in some shame-­based cultures, pure guilt is a rare and seldom discussed emotion. In these cultures, shame takes the role of reintegrating people into the group and encouraging them to address the harm they have done and reform their behavior (Boiger et al., 2013; Haidt, 2003b). Taking Moral Action (2003b, p. 861) speculates that this may be the simple mislabeling of shame as guilt, citing for instance of breaking one’s diet. Rather than treating this as a problem of measurement, it would be more productive to investigate the phenomenon itself. It seems possible that in cultures and sub-­cultures that value the ethical dimension of divinity or sacredness (Shweder et al., 2008), one can fail at a goal of maintaining purity and, concentrating on the act of failure, feel guilt and distance oneself from one’s action.18 Whether this requires a “person” to whom one reconciles is unclear. In this case, avoiding strict definitions of morality (e.g. as necessarily social) may help us discover important and complex aspects of moral functioning in some cultures. 8.2.2.2 Compassion In their textbook on the emotions, Keltner, Oatley et al. (2014, p. 219) call compassion the “master social emotion” that helps to “form stronger s social bonds of all kinds.” In this context, they cite the popular historian of religion Karen Armstrong (2006) and her claim that compassion is central to all the major of religious traditions. As with each emotion we review here, there is some controversy surrounding its form and centrality (Goetz, Keltner, & Simon-­Thomas, 2010).19 But there appears to be a growing consensus that compassion does indeed serve a central role in pro-­social emotions (Stellar et al., 2011). ro Compassion is the feeling of concern for another, accompanied by a desire to enhance that person’s welfare.20 But more specifically, it is the result of a cascade of appraisals about the eliciting situation (Goetz et al., 2010; Stellar et al., 2011).21 First, it focuses on the suffering of another person who is relevant to the self. This “relevant lP to the self” aspect is important to understand the unique motivating power of compassion. But it also helps to understand the wide variation in who is considered eligible for compassion. The Oliners (1988) have, for instance, documented how an extensive vision of who the in-­group is helped to shape the actions of rescuers in the na 18 Buber (1958) makes a distinction between guilt, a social moral emotion, and sin, an emotion associated with the self having violated the sacred. They can be conceptually distinguished, but can they be empirically distinguished? It might be useful to ask what Fi informational and motivational components are associated with sin. Is the emotional experience of sin more like guilt, leading the person to reparation, or more like shame, leading to negative self-­focus and withdrawal? Here is some fascinating territory for interaction between theology and psychology. 19 For example, see Chapter 1 for discussion on how a “selfish” evolutionary process might produce compassion as a central emotion in a social species. 20 Compassion need not always be directed outward. Neff (2003a, 2003b), drawing on Buddhist approaches, has defined self-­compassion as having three aspects: self-­kindness, a sense of common humanity, and mindfulness when evaluating the self and its weaknesses. Self-­compassion may be a better predictor of self-­worth and well-­being than self-­esteem scales (Barnard & Curry, 2011b; Neff & Vonk, 2009) and is associated with resilience in service workers, such as pastors (Barnard & Curry, 2011a). 21 Note that this series of appraisals are remarkably like those in the early models of helping (Latane & Darley, 1970). This similarity makes sense given that taking action to help is the primary motivational aspect of compassion. Moral Emotion 227 Holocaust.22 Second, there is an appraisal of deservingness of compassion. Compassion is often restricted when the person harmed has in some way contributed to or “deserved” that harm (Rudolph et al., 2004). Third, there is an appraisal of the ability one has to help. Because there is such a strong motivation to action in compassion, it is often reduced to the extent that one is helpless to intervene. This suppression of experiencing compassion when one cannot help puts stress on seeing oneself as a moral person (Cameron, Harris, & Payne, 2016; Cameron & Payne, 2012) and can be relieved only by some trade-­off of one’s moral commitments or one’s perception of the victim. Thus, even though (or perhaps because) compassion is the “master social emotion” it contains a complicated and contradictory set of appraisals and information about the world. Compassion “derives its strength from the emotional stake it offers the self in the other’s welfare” (Preston & de Waal, 2002, p. 279). The combination of appraisals in s compassion makes it uniquely motivating: that the person is indeed suffering, that they are deserving of compassion, and that one can help. These connect the self to the of other in a powerful way. The strength is mirrored in the physical expression characteristic of compassion, the head orientation toward the victim and a forward lean (Goetz et al., 2010). Compassion gives us an example of the complexity of the appraisal process and its ro effects on the shape and strength of a moral emotion. Researchers have documented similar complexity in the anger–disgust–contempt triad. It is a good sign that psychological research in moral emotions is now entering the domain of human complexity in relations. And as always, there is much more to be done. lP 8.2.3 Self-­Conscious Emotions This family of emotions has the self as the primary focus. In embarrassment, pride, and shame, one is aware of good or bad aspects of the self. All other moral emotions na (indeed, all emotions) implicate the self too, in that they mark how some state of the world is relevant for the self. But this family is also focused on the self in a self-­ reflexive fashion.23 One self-­consciously reflects on the self. Still, even these inward turned moral emotions are social: embarrassment requires a kind of “social exposure,” pride and shame can both be deeply implicated in social comparison. Fi 8.2.3.1 Embarrassment At first glance, embarrassment might not seem relevant to the moral domain, and some authors (Lewis, 2008) divide embarrassment into types, one of which is mere “social exposure” without any negative implications. But even mere social exposure can carry the threat of losing status in a group, being singled out for no good reason, or even being singled out with praise that one worries is more than one deserves (or will be tolerated). Thus, embarrassment is a self-­ focused emotion that is about one’s belongingness and obligations to the 22 See Chapters 4 and 5 for greater detail about how these individual differences in compassion play out in moral action. 23 It can easily become more complex. In subsequent rounds of appraisal, any other emotion can become caught in self-­reflection. Taking Moral Action group.24 It is ­pro-­social in that it motivates reintegration into the group.25 But even this motivation for reintegration is embedded in the self’s moral expectations about the self and its place in the social world. The information that embarrassment carries for the individual experiencing it is that there is a threat of loss of status in one’s group or society or of an uncomfortable status differential. For instance, in the classic Japanese novel Tale of Genji (Murasaki, [ca. 1000]) embarrassment is a central emotion that occurs sometimes because of improper behavior, but sometimes merely because one person is in the presence of a social superior (Keltner, Oatley et al., 2014, p. 78). Some theorists see these as two different forms of embarrassment with the improper behavior form appearing as a less intense version of shame (Lewis, 2008). Other authors point out the crucial cultural embeddedness of embarrassment and shame and suggest that, in cultures in which the self is deeply interdependent with others, shame and embars rassment “merge together into a single emotion of immense moral importance” (Haidt, 2003b, p. 859). of The primary moral motivation associated with embarrassment is to signal submission to others (Keltner & Buswell, 1997) or to be conciliatory and conforming (Tangney, Stuewig et al., 2007). It is like shame in that some of its facial expressions (e.g. averted eyes) express anxiety about evaluation, but it is differentiated from ro shame in that the desire to reintegrate with the group is stronger than the desire to hide (Keltner & Buswell, 1997). 8.2.3.2 Pride Pride generally comes from an appraisal that something good is lP associated with the self. It is a deeply self-­conscious emotion, and thus requires a sense of self. For this reason, even though it emerges in early childhood, it is only anchored in a detailed and inward sense of self in adolescence (Hart & Matsuba, 2007). It is often thought of as occurring in domains that are not necessarily moral, such as social recognition and occupational achievement. Here we will concentrate on pride na that is associated with moral being or doing. Moral pride is, then, the emotional reward when there is an achievement in the moral domain as suggested by Hart and Matsuba (2007). But there is more complexity here. Recent work distinguishes between two distinct types of pride, each of which can be about moral action: hubristic and authentic Fi (Dickens & Robins, 2022; Tracy & Robins, 2007). Hubristic moral pride is based in a judgment about the global self and its moral achievements, and it is often (but not necessarily) comparative. Authentic pride is occasioned by specific moral achievement and its connection to the self and its values (Hart & Matsuba, 2007).26 24 See Chapter 7 for moral foundations (Graham et al., 2011) that involve loyalty to the group. Embarrassment may be seen as a recognition of a threat to this value. 25 And it interestingly shares neural substrate with other pro-­social emotions such as compassion (Moll et al., 2007). 26 In a large cross-­sectional international sample (Orth, Robins, & Soto, 2010), authentic pride increases from adolescence into old age, while hubristic pride decreases from adolescence to adulthood, reaching a minimum around age sixty-­ five, and then begins to increase. This suggests a kind of moral maturation in this domain. Moral Emotion 229 The information in the emotion of pride differs depending upon the type. For hubristic pride, it is a sense of supremacy of the global self over others (Carver & Johnson, 2010; Tangney, Stuewig et al., 2007). It is usually comparative (Tangney, Stuewig et al., 2007) and related to social dominance (Carver & Johnson, 2010). Hubristic moral pride would come from thinking, for instance, that one (and perhaps one’s group) was more authentic, caring, and principled than others. It is about moral superiority that is explicitly comparative. It is a pride of “being” (Lewis, 2008). In contrast, authentic moral pride is a pride that stems from doing good. It results from the perception that one is responsible for a specific positive moral outcome, or has resisted a particular temptation, or acted in regard to particular obligations (Malti & Ongley, 2014). The motivational complex associated with hubristic pride is (not surprisingly) s ­negative and even anti-­social. Hubristic pride is associated with impulsivity, anger, aggression, seeking public recognition, narrow focus on financial success, and social of dominance (Carver & Johnson, 2010; Liu et al., 2016). In the business domain, it is associated with decisions to pursue unwise mergers and acquisitions that destroy value rather than create it (Bodolica & Spraggon, 2011). Because of the impulsivity and self-­centeredness, hubristic pride makes the maintenance of relationships (busiro ness or otherwise) difficult. It also serves a central emotional role in prejudice and intergroup bias (Fiske, 2015) and leads people to identify only with powerful others (Oveis, Horberg, & Keltner, 2010). Authentic moral pride is associated with self-­ control, adaptive achievement, and goal engagement (Carver & Johnson, 2010) and lP is a primary motive for “voluntary planned, sustained moral action” that reflects the self and its values (Hart & Matsuba, 2007, p. 117). If the distinctions among these types of pride seem too strongly drawn and simplistic, it is in part because they are: the literature is still young and developing. But there are interesting complexities. Bodolica (2011) recognizes, for instance, the dynamism na that hubristic pride can give an organizational leader, and Carver and Johnson (2010) list several aversive emotional experiences that tend not to correlate with either type of pride (e.g. anxiety/fear). There is also some suggestion that gratitude plays an essential role in how pride is expressed. Organizational leaders who experience pride in achievement tend to treat their employees well only if they feel grateful for employFi ees’ contributions to that success (Michie, 2009). Finally, we should note that, though hubristic pride is implicated in prejudice toward out-­groups (Fiske, 2015), there is very little published on hubristic moral pride, the pride that comes from thinking oneself morally superior. 8.2.3.3 Shame Shame is a moral emotion that is complicated by cross-­ cultural difference. In most Western cultures, shame comes from the appraisal that something is wrong or inadequate with the self. But in most non-­Western cultures, shame is part of a complex of embarrassment, shyness, modesty, and social fear, and is crucial to life embedded in social groups (Haidt, 2003b; Kitayama & Park, 2007). For instance, shame is a somewhat negative but culturally condoned emotion in Japan. Japanese schools have times set aside for hansei, to encourage children to take critical self-­ reflection in the service of self-­improvement (Boiger et al., 2013). Shame in the United States, however, is to be avoided because it threatens positive self-­regard Taking Moral Action (Haidt, 2003b). Thus, one can expect that the information embedded in shame and the motivational profile of shame will be quite different in Western vs. non-­Western cultures.27 In Western cultures, shame involves negative evaluation of the self, and often includes imagery of how one appears to others in this light (Tangney, Stuewig et al., 2007). It might be occasioned by something the person has done, but it can also be elicited by appearing inadequate, flawed, or defective (Haidt, 2003b). Thus, while shame is an inward-­focused moral emotion, it is in part about how this inward self appears to the outer social world. The inward focus is made clear by the motivations associated with shame: hiding, distress about the self, anger at others who make one look bad (Stuewig et al., 2010; Tangney, Stuewig et al., 2007). It is this withdrawing, defensively aggressive (to self and other) reaction that makes shame problematic in Western cultures. It leads one away from social engagement. Criminals who focus on s shame during their imprisonment are more likely to commit additional crimes and return to jail compared with those who focus on guilt (Tangney, Mashek, & of Stuewig, 2007).28 The withdrawal motivation associated with shame is part of what discourages victims of sex abuse from reporting incidences and the focus on negative self-­evaluation makes shame a central driver in depression long after sexual abuse has taken place (Lewis, 2008).29 ro In non-­Western cultures, shame is occasioned when one has violated social expectations (e.g. by asking for or needing help) or is in danger of violating social expectations (e.g. by simply being in the presence of someone higher ranking) (Boiger et al., 2013; Haidt, 2003b). In such cultures, there is no clear distinction between lP moral norms and social conventions (Shweder et al., 1997). Though still negative, the experience of shame in these cultures is less intense than in Western cultures (Boiger et al., 2013) and it serves as a motivation to reintegrate oneself into the group. It is pro-­social, less about the core self and more about behavior that can be remedied. We are just beginning to tease apart these complexities. na 27 The differences are not simply dichotomous. One can find them across time and within Fi shared cultures. For instance, as Western cultures have moved away from communal and toward individualist societies, they have also de-­emphasized shame. There are large differences within Japan in individualism (Kitayama et al., 2006), and one can place some cultures in the middle on the scale of independence–interdependence, thus implicating differences in the associated emotions – e.g. Kitayama et al. (2006) find that Britain and Germany occupy a space in between the United States and Japan on that scale. 28 The relationship of shame to criminal reform is still not well understood. The research program of Tangney and colleagues cited here suggests shame is problematic for reform. But a central theoretical perspective in restorative justice approaches is “reintegrative shaming” that focusses on making public disapproval of the crime explicit, with the goal of reintegrating the criminal (Harris, 2006). Perhaps the emphasis on “reintegrative” helps explain this disconnect in the literatures. 29 In the Western world, shaming might be understood as an act of moral violence, making a public show of focusing on the low worth of the shamed person. One can think of this as a punishment motive, using the emotion of shame to hurt the target and make the target of shaming feel bad. Moral Emotion 231 8.2.4 Other-­Praising Moral Emotions This emotion family recognizes positive characteristics in others, and responds with a range of reactions that strengthen relationships (Haidt, 2003a). Though they are outward focused, it is unclear whether the “other” need be human, or even personal. And they may also be as closely related to an inward-­focused relation to the self, as seen in the relationship between gratitude, awe, and humility (Kruse et al., 2014; Piff et al., 2015). 8.2.4.1 Elevation and Awe Elevation is the emotional response to witnessing acts of virtue or moral beauty (Algoe & Haidt, 2009). Its characteristic feeling is that of outward-­directed expansion, perhaps even uplifting and inspiring (Haidt, 2000). This description of the feeling suggests a motivational state, which is outward directed. s Those experiencing elevation often want to praise the other person, share news of the good deed, or even emulate it. Those experiencing elevation are motivated to become of like the other, at least in action.30 The subjective experience of elevation is different from simply feeling good or feeling happy, and evidence suggests that this difference leads to clear increases in pro-­ social activity on the part of those experiencing the emotion (Schnall, Roper, & ro Fessler, 2010). For example, in a study of Italian business leaders, it has been shown that leaders’ interpersonal fairness and self-­sacrifice leads to the emotion of elevation in employees, and that the experience of this emotion is a clear influence on employees’ organizational commitment and citizenship (Vianello, Galliani, & Haidt, 2010). lP It seems reasonable to expect such an emotional effect to be limited to the domain in which it occurs (e.g. the workplace), but there is no research that documents this. The experience of elevation, and its effects, is also influenced by one’s readiness to be open to it. People higher in moral identity, for instance, are more likely to experience elevation when they see morally praiseworthy action, and they are more likely to na emulate that action (Aquino, McFerran, & Laven, 2011).31 The link with moral identity and the subjective experience of elevation as a positive emotion together suggest that the motivation elevation produces is not one of overcoming some deficit or lack but instead one of approaching something desirable.32 However, it seems possible that the desirable here need not always be the moral. It may be that group socializaFi tion toward prejudice occurs in part because of a desire to emulate others (see Gatto & Dambrun, 2012 for an example involving police officers). We know very little about how flexible the experience of elevation is regarding its (im)moral goal. Finally, a note on the related emotion of awe, though it is not clear that this emotion fits the category of “other-­praising” (Shiota, Keltner, & Mossman, 2007). Awe stems from an appraisal of vastness that is not graspable, possibly accompanied by 30 The emotion that leads to the desire to emulate the other is treated by Zagzebski (2013, 2017) as a central component in a theory of virtue ethics. 31 This is again a place where the idea of a single focus of an emotion misleads us. It is more the relation of the self to the awe-­inspiring than simply the outward focus. One finds this theme in much religious poetry and writing (e.g. Rumi, Meister Eckhardt) and the relational aspect of awe is reflected in the current empirical work. 32 See Chapters 5 and 9 for the various ways one might be motivated to moral action. Taking Moral Action threat, exceptional beauty, virtue, and the supernatural (Keltner & Haidt, 2003). Because it is associated with a situation that “overwhelms current cognitive categories” awe has a complicated relationship with the information it provides. In some studies the experience of awe increases belief in supernatural agency, partly by ­motivating a desire for cognitive closure (Valdesolo & Graham, 2014). But in other studies it has been shown that those without a need for cognitive closure are more open to experiencing awe (Shiota et al., 2007). But there is agreement that, rather than being simply an enjoyable experience, awe increases pro-­social behavior, that is, it has an action tendency. How it does so is still unclear – perhaps by reframing one’s view of the self (Keltner, Kogan et al., 2014). And this reframing suggests again the dual nature of focus of these emotions: both other-­praising and inward focused. 8.2.4.2 Gratitude One may experience gratitude when one receives some benefit s from another, particularly if it is clear that the benefactor is acting out of a correct awareness of the needs of the recipient (Algoe & Haidt, 2009; Bono, Emmons, & of McCullough, 2012). Like elevation, gratitude’s elicitors and its effects are more specific than simple happiness (Kruse et al., 2014). Experiencing gratitude motivates one to want to return the favor, strengthen the relationship with the benefactor, or even to pass benefit on to others (Bono et al., 2012; Emmons & Kneezel, 2005; McCullough et al., 2001). ro One may experience gratitude, but there are a variety of influences that lead people away from this experience, even if they do receive benefits from others. These include perceptions of victimhood, envy or resentment, or an emphasis on materialistic values lP (see Bono et al., 2012 for a review). There is some evidence that insecure relationship attachment styles can lead to lower levels of gratitude (Dwiwardani et al., 2014). It makes sense that skepticism about relationships (being wary of or blaming others or being cynical about others’ motivations) should also reduce gratitude. Still, one should make the distinction between non-­gratitude and ingratitude. Non-­gratitude na may simply be the result of forgetting or paying attention to other things, but ingratitude has a more aggressive edge, and may even be motivated by a desire to punish or hurt the other (Emmons, 2007, p. 141). In addition to motivating people to draw closer to each other, gratitude can have other social effects. For instance, gratitude and humility are linked in a virtuous cycle Fi over time, in which one’s gratitude influences one’s view of the self as dependent on others (Kruse et al., 2014), but this cycle is likely to work only when one’s dependence is not seen as a burden (Bono et al., 2012).33 In Section"
8,8.2,"The Moral Emotions Some emotions (e.g. anger, compassion) are more closely connected to issues of morality than are others (e.g. sadness, joy). In this section, we will review those emolP tions and look at how they are woven into our moral lives. First, however, a word must be said about how one identifies an emotion as belonging to the moral domain. Again, our approach is to be as inclusive as possible. And thus, almost every emotion, from angst to schadenfreude, might be found to have moral implications. But the list here is limited in part by the available research – na though the list is growing, only a good handful of emotions have enough work on them to merit inclusion for now. Haidt (2003b, p. 854), one of the pioneers in research on moral emotion, identifies the moral emotions as those meeting two criteria: an emotion is moral to the extent that (1) it is about others (is triggered by the actions or reactions of others, like righteous anger), and to the extent that (2) it proFi duces pro-­social motivations. Even here, though, things get difficult. (1) demarcates emotions as social. But there are, for instance, moral emotions such as gratitude or awe that lead to striving after religious goals (Emmons, 2005, 2008) or to self-­ transcendence (Koltko-­ Rivera, 2006) and that are thought of by many religious traditions as deeply moral but not prototypically social.10 Thus, the elicitors and motivations of a moral emotion may not always be social in nature. (2) marks moral emotions as providing motivation for pro-­ social behavior. This too is complicated, given that pro-­ social behavior 9 But see Chapter 5 for the many kinds of consistency criteria. 10 See Cuttick (1997) and Pratt (1928) for examples of this moral imperative in, respectively, Sufi and Buddhist approaches. Our thanks to David Wulff for providing these examples. Taking Moral Action can include altruistic punishment that involves harming others for the sake of ­reinforcing a moral value.11 Thus, disgust, anger, contempt, shame, pride, and a host of other moral emotions can lead to drastically immoral ends (aided and abetted by reason), resulting in moral collapse (Hart, 2005; Hart & Matsuba, 2007). So both criteria to demarcate moral emotions have difficulties. But they provide a place to begin; as long as we are aware of the limitations. To organize this review, we will use the divisions into four “emotion families,” suggested by Haidt (2003b): other-­condemning, other-­suffering, self-­conscious, and ­other-­praising.12 These families are more like overlapping sets, with some emotions falling equally into two families (e.g. for this reason we have moved guilt from Haidt’s self-­conscious family to the other-­suffering family – it has aspects of both). One can imagine more complicated moral emotions like envy (R. Smith & Kim, 2007) that could fall into three families (self-­conscious, other-­praising, and other-­condemning). Or s emotions such as the Thai emotion of tham jai, keeping a calm heart, that do not seem to fall easily into any family (Cassaniti, 2014). And one emotion can have difof ferent aspects depending on the context. Anger, for instance, plays a central role in close relationships, often contributing to relationship repair (Fitness, 2009, 2015) but shows a different face to threatening out-­groups (Fiske, 2015). The confusion that a close look at the families metaphor produces is a clue that we ro might not be looking at emotions correctly when we think they are primarily a reaction to one thing. They can be, and often are, a reaction to many things (see the grocery bag example in Section 8.1.1). But even deeper, they are less a reaction and more a relation to states of the world and to ourselves. So, anger is not a reaction to lP an injustice, it is about our relation to an injustice.13 The same with compassion, it is about our relation to a person. And as a relation, we have some freedom in shaping it. Even so the families have the advantage of suggesting similarities among groups of emotions, and of suggesting additional investigation when one finds complexities. In our review, we will follow two aspects of each moral emotion: the emotion as na information and as motivation. We know from appraisal research that appraisals are propositional in nature (Wu et al., 2021). For example, “that is unjust” can contain information about relevance based on my goals, intentionality of the actor, amount of harm, etc. Emotions also have a motivational component, or what some theorists have called an “action tendency” (Ellsworth, 2013). They both ready the body for a Fi particular kind of action and orient the individual toward that action. It is this interaction between information and motivation that makes moral emotion a central mover to moral action. Pay attention to this interaction as we review each moral emotion. 8.2.1 Other-­Condemning Moral Emotions These are emotions directed toward the condemnation or rejection of others. They share a focus on negative evaluations of the actions or character of others and an 11 See Chapter 1 for more on this concept. 12 Note that the titles of the categories already include information and motivation as aspects of the emotions. 13 See Chapter 5 for the variety of ways that this relation can be constituted. Moral Emotion 223 action tendency of rejection or aggression. They often also seem to combine with each other to produce hybrids like moral outrage (Salerno & Peter-­Hagene, 2013). 8.2.1.1 Disgust Disgust is an emotion associated with the rejection of unpleasant things. The human facial expression associated with core disgust is the same one displayed when tasting very bitter compounds (Herz, 2011). Even those blind from birth make the same expression of disgust as sighted people. There appear to be three “varieties” of disgust: (1) core disgust, related to contact with rotted food, disease, or open wounds; (2) sexual disgust, related to rejecting sexual acts; and (3) moral disgust, related to rejecting moral transgressions. These three types share some characteristics (e.g. aspects of facial expression) but differ in terms of what provokes them and in the shape of their motivation (Tybur, Lieberman, & Griskevicius, 2009). As with much work in moral emotions, these distinctions are under dispute, with some seeing moral s disgust as a mere metaphorical use and others claiming that the types are actually different emotions (see Cameron et al., 2015; Yoder, 2016 for a review). For our of purposes, it seems clear that there are at least “loose correspondences” (Cameron et al., 2015) in the form of moral rejection called moral disgust. It is a rejection that is more motivating and less malleable than simple avoidance based on prudence (e.g. disease is disgusting vs. it is prudent to avoid disease). Moral disgust has been ro shown to have the contamination pattern of core disgust (e.g. people will not want to wear the clothes worn by a murderer, even if they have been cleaned) (Rozin, Haidt, & McCauley, 2008). The evolutionary or cultural origins of these correspondences is, of course, under dispute. But as in many of the controversies in moral psychology, the lP answer likely lies in some combination of the two perspectives. We have already mentioned the difficulty of maintaining clear distinctions among emotions. In the moral domain, disgust often overlaps with anger in the rejection of moral harm. Salerno and Peter-­Hagene (2013) have documented how disgust and anger combine in moral outrage against particularly heinous offenses. Moral disgust na also has well-­documented overlap with other emotions, such as contempt (Cameron et al., 2015; Hutcherson & Gross, 2011). In summary, the information associated with the moral aspect of disgust is that the thing or person is not merely negative but is to be condemned and rejected because it violates, or is associated with the violation of, some moral value. The action tenFi dency is rejection and avoidance that is highly motivating and much less flexible than simple rejection based on prudence. The malleability of disgust, in particular its relation to other moral emotions, is an important open question. 8.2.1.2 Anger There is a voluminous literature on anger, what produces it, how it feels, how it affects the person, and what kind of behavior and goals it produces (Berkowitz & Harmon-­Jones, 2004). But the psychological focus on anger as a moral emotion is more recent.14 We mentioned earlier how it connects and blends with disgust, in its role of reacting to moral violation. Much older work on anger connects it with the appraisal of blocking a goal (Dollard et al., 1939). And this appraisal can 14 Aristotle, of course, saw anger as a moral, social, and indeed political emotion (Sokolon, 2006). Taking Moral Action blend into moral anger when we see intention, particularly unjustified intention. We can even find moral anger when we “see” intention in an inanimate object like a car that will not start (Waytz, Cacioppo, & Epley, 2010). So, the information or judgment about morality that moral anger encodes is about moral violation, but more specifically, unjustified moral violation. Scherer (1997) presents a large cross-­ cultural study in which reported episodes of anger were elicited primarily by appraisals of unfairness and immorality, and consistently more than mere goal frustration. The extent of the moral violation is also associated with the amount of anger and with the associated amount of preferred punishment for the offender (Carlsmith, Darley, & Robinson, 2002). Perpetrators and victims often disagree about the extent of a moral violation and thus about the appropriate response, and this disagreement can escalate into angry exchanges (Baumeister, Stillwell, & Wotman, 1990). One might think from the comments so far that the primary function of anger is to s motivate the victim to punish the offender as a means of self-­ defense (Darley, Carlsmith, & Robinson, 2000). And indeed, this is one of the motivations of moral of anger. But anger can also motivate altruistic punishment, defined as the punishment of a moral violator when you yourself are not the victim (Balliet & Van Lange, 2013; Boyd et al., 2003). Thus, one can be angry for another person and angry at the person who harmed them, with these processes being sometimes separable (Hechler & ro Kessler, 2018). Things get rapidly more complex when one considers anger in the context of close relationships, where anger and love coexist. In this context, one might say that the motivation is assertion of one’s interest even if one’s interest is the good of the other (Fitness, 2009, 2015). Its complexity is also apparent in long-­term social lP injustice, where despite progress much remains to be angry about (Lorde, 1981). Finally, anger is flexible in its motivational profile as one changes the frame in which the action is interpreted. In forgiveness, one reduces the motivation to punish the offender, but perhaps not one’s bad feelings toward them (Exline et al., 2003). Prayer for the offender can reduce anger, perhaps through cognitive reappraisal (Bremner, na Koole, & Bushman, 2011). Anger seems to be more flexible in responding to this kind of reappraisal than other moral emotions are, like disgust (Russell & ­Giner-­Sorolla, 2010), though it appears that disgust and anger can combine in moral outrage (Salerno & Peter-­Hagene, 2013). Fi 8.2.1.3 Contempt Like the moral aspects of anger and disgust, moral contempt is about moral rejection, but its scope and shape differ. Moral contempt is about morally loaded incompetence or unfitness. Contempt is a major driver in prejudice and stereotyping (Fiske, 2015) and is (with disgust) the primary emotion shown toward disliked groups perceived as lower in status or less competent. Perceptions of dominance or status are very strongly correlated with judgments of competence, across many cultures (Fiske, 2015), and contempt is the social emotion reserved for those who threaten status in this way. Others call this a community dimension and emphasize the perceived violation of community standards. This alternative dimension involves such things as failure in “duty, role-­obligation, respect for authority, loyalty, group honor, interdependence, and the preservation of the community” (Rozin et al., 1999). We do not know enough about contempt to be able to easily outline the appraisals that lead to it (Cameron et al., 2015). It seems likely that contempt is a complex Moral Emotion 225 emotion associated with perceiving the other as having bad or threatening intentions and being low in status or incompetent.15 This would include violators of duty to the group (e.g. traitors), or those who through willful incompetence within the group threaten it (bumblers), or with out-­group or outcast individuals who are viewed as both having bad intent and being less competent. This list allows one to see how contempt can easily be associated with anger for those who endanger us. The motivational aspect of contempt is similar to disgust: to “mark those who … represent a threat and avoid them” (Hutcherson & Gross, 2011, p. 720) perhaps by excluding or driving them away. It seems likely that the perception of a failure at intended action is required for the contempt to take on a moral tone (Hutcherson & Gross, 2011) and thus, unlike disgust, contempt seems to be a thoroughly social emotion. s 8.2.2 Other-­Suffering Moral Emotions of These moral emotions are focused on the suffering of others. But they both offer a stake for the self in the suffering of others, they connect the concerns of the self to the other. They are, then, more complicated than merely being outward focused, but they are focused on the other in a way that motivates the self to action to repair damage or to help or comfort the other. ro 8.2.2.1 Guilt We feel guilty when we perceive that we have committed a moral violation (Haidt, 2003b, p. 861). More specifically, a moral violation that harms lP someone else who is important to us (e.g. in a close relationship, group, or community). One often does not feel guilt when harming those who deserve it (see anger, contempt, and disgust, discussed earlier). Modern soldiers, for instance, are well trained in avoiding guilt for the harm they cause to the enemy – though the fog of war and the humanity of the enemy make this complicated (Grossman, 1996). na An important aspect of the appraisal that leads to a feeling of guilt (as opposed to shame) is that it focuses more on the act itself and its victim and less on the self who did the act.16 Its appraisal has an informational focus outward to the other. With this focus on the other who is harmed, guilt’s motivational influence leads to apology, to restoration of relationship, and to avoidance of future harm (Baumeister, Stillwell, & Fi Heatherton, 1994). Thus, guilt seems to be an emotion that draws people together after harm doing.17 An important complication in this story is that self-­report studies of guilt almost always turn up some instances of non-­social moral violations causing guilt. Haidt 15 See Fiske (2015) for a short review of these two dimensions, their implications in prejudice and stereotyping, and their associations with moral emotions. 16 Tangney et al. (2007, p. 358) discuss group-­based guilt. Because group-­based guilt is based in identity, this complicates things. There is also some evidence that the way one measures guilt can tap neurotic vs. pro-­social guilt (Tignor & Colvin, 2016). 17 There is evidence that in some shame-­based cultures, pure guilt is a rare and seldom discussed emotion. In these cultures, shame takes the role of reintegrating people into the group and encouraging them to address the harm they have done and reform their behavior (Boiger et al., 2013; Haidt, 2003b). Taking Moral Action (2003b, p. 861) speculates that this may be the simple mislabeling of shame as guilt, citing for instance of breaking one’s diet. Rather than treating this as a problem of measurement, it would be more productive to investigate the phenomenon itself. It seems possible that in cultures and sub-­cultures that value the ethical dimension of divinity or sacredness (Shweder et al., 2008), one can fail at a goal of maintaining purity and, concentrating on the act of failure, feel guilt and distance oneself from one’s action.18 Whether this requires a “person” to whom one reconciles is unclear. In this case, avoiding strict definitions of morality (e.g. as necessarily social) may help us discover important and complex aspects of moral functioning in some cultures. 8.2.2.2 Compassion In their textbook on the emotions, Keltner, Oatley et al. (2014, p. 219) call compassion the “master social emotion” that helps to “form stronger s social bonds of all kinds.” In this context, they cite the popular historian of religion Karen Armstrong (2006) and her claim that compassion is central to all the major of religious traditions. As with each emotion we review here, there is some controversy surrounding its form and centrality (Goetz, Keltner, & Simon-­Thomas, 2010).19 But there appears to be a growing consensus that compassion does indeed serve a central role in pro-­social emotions (Stellar et al., 2011). ro Compassion is the feeling of concern for another, accompanied by a desire to enhance that person’s welfare.20 But more specifically, it is the result of a cascade of appraisals about the eliciting situation (Goetz et al., 2010; Stellar et al., 2011).21 First, it focuses on the suffering of another person who is relevant to the self. This “relevant lP to the self” aspect is important to understand the unique motivating power of compassion. But it also helps to understand the wide variation in who is considered eligible for compassion. The Oliners (1988) have, for instance, documented how an extensive vision of who the in-­group is helped to shape the actions of rescuers in the na 18 Buber (1958) makes a distinction between guilt, a social moral emotion, and sin, an emotion associated with the self having violated the sacred. They can be conceptually distinguished, but can they be empirically distinguished? It might be useful to ask what Fi informational and motivational components are associated with sin. Is the emotional experience of sin more like guilt, leading the person to reparation, or more like shame, leading to negative self-­focus and withdrawal? Here is some fascinating territory for interaction between theology and psychology. 19 For example, see Chapter 1 for discussion on how a “selfish” evolutionary process might produce compassion as a central emotion in a social species. 20 Compassion need not always be directed outward. Neff (2003a, 2003b), drawing on Buddhist approaches, has defined self-­compassion as having three aspects: self-­kindness, a sense of common humanity, and mindfulness when evaluating the self and its weaknesses. Self-­compassion may be a better predictor of self-­worth and well-­being than self-­esteem scales (Barnard & Curry, 2011b; Neff & Vonk, 2009) and is associated with resilience in service workers, such as pastors (Barnard & Curry, 2011a). 21 Note that this series of appraisals are remarkably like those in the early models of helping (Latane & Darley, 1970). This similarity makes sense given that taking action to help is the primary motivational aspect of compassion. Moral Emotion 227 Holocaust.22 Second, there is an appraisal of deservingness of compassion. Compassion is often restricted when the person harmed has in some way contributed to or “deserved” that harm (Rudolph et al., 2004). Third, there is an appraisal of the ability one has to help. Because there is such a strong motivation to action in compassion, it is often reduced to the extent that one is helpless to intervene. This suppression of experiencing compassion when one cannot help puts stress on seeing oneself as a moral person (Cameron, Harris, & Payne, 2016; Cameron & Payne, 2012) and can be relieved only by some trade-­off of one’s moral commitments or one’s perception of the victim. Thus, even though (or perhaps because) compassion is the “master social emotion” it contains a complicated and contradictory set of appraisals and information about the world. Compassion “derives its strength from the emotional stake it offers the self in the other’s welfare” (Preston & de Waal, 2002, p. 279). The combination of appraisals in s compassion makes it uniquely motivating: that the person is indeed suffering, that they are deserving of compassion, and that one can help. These connect the self to the of other in a powerful way. The strength is mirrored in the physical expression characteristic of compassion, the head orientation toward the victim and a forward lean (Goetz et al., 2010). Compassion gives us an example of the complexity of the appraisal process and its ro effects on the shape and strength of a moral emotion. Researchers have documented similar complexity in the anger–disgust–contempt triad. It is a good sign that psychological research in moral emotions is now entering the domain of human complexity in relations. And as always, there is much more to be done. lP 8.2.3 Self-­Conscious Emotions This family of emotions has the self as the primary focus. In embarrassment, pride, and shame, one is aware of good or bad aspects of the self. All other moral emotions na (indeed, all emotions) implicate the self too, in that they mark how some state of the world is relevant for the self. But this family is also focused on the self in a self-­ reflexive fashion.23 One self-­consciously reflects on the self. Still, even these inward turned moral emotions are social: embarrassment requires a kind of “social exposure,” pride and shame can both be deeply implicated in social comparison. Fi 8.2.3.1 Embarrassment At first glance, embarrassment might not seem relevant to the moral domain, and some authors (Lewis, 2008) divide embarrassment into types, one of which is mere “social exposure” without any negative implications. But even mere social exposure can carry the threat of losing status in a group, being singled out for no good reason, or even being singled out with praise that one worries is more than one deserves (or will be tolerated). Thus, embarrassment is a self-­ focused emotion that is about one’s belongingness and obligations to the 22 See Chapters 4 and 5 for greater detail about how these individual differences in compassion play out in moral action. 23 It can easily become more complex. In subsequent rounds of appraisal, any other emotion can become caught in self-­reflection. Taking Moral Action group.24 It is ­pro-­social in that it motivates reintegration into the group.25 But even this motivation for reintegration is embedded in the self’s moral expectations about the self and its place in the social world. The information that embarrassment carries for the individual experiencing it is that there is a threat of loss of status in one’s group or society or of an uncomfortable status differential. For instance, in the classic Japanese novel Tale of Genji (Murasaki, [ca. 1000]) embarrassment is a central emotion that occurs sometimes because of improper behavior, but sometimes merely because one person is in the presence of a social superior (Keltner, Oatley et al., 2014, p. 78). Some theorists see these as two different forms of embarrassment with the improper behavior form appearing as a less intense version of shame (Lewis, 2008). Other authors point out the crucial cultural embeddedness of embarrassment and shame and suggest that, in cultures in which the self is deeply interdependent with others, shame and embars rassment “merge together into a single emotion of immense moral importance” (Haidt, 2003b, p. 859). of The primary moral motivation associated with embarrassment is to signal submission to others (Keltner & Buswell, 1997) or to be conciliatory and conforming (Tangney, Stuewig et al., 2007). It is like shame in that some of its facial expressions (e.g. averted eyes) express anxiety about evaluation, but it is differentiated from ro shame in that the desire to reintegrate with the group is stronger than the desire to hide (Keltner & Buswell, 1997). 8.2.3.2 Pride Pride generally comes from an appraisal that something good is lP associated with the self. It is a deeply self-­conscious emotion, and thus requires a sense of self. For this reason, even though it emerges in early childhood, it is only anchored in a detailed and inward sense of self in adolescence (Hart & Matsuba, 2007). It is often thought of as occurring in domains that are not necessarily moral, such as social recognition and occupational achievement. Here we will concentrate on pride na that is associated with moral being or doing. Moral pride is, then, the emotional reward when there is an achievement in the moral domain as suggested by Hart and Matsuba (2007). But there is more complexity here. Recent work distinguishes between two distinct types of pride, each of which can be about moral action: hubristic and authentic Fi (Dickens & Robins, 2022; Tracy & Robins, 2007). Hubristic moral pride is based in a judgment about the global self and its moral achievements, and it is often (but not necessarily) comparative. Authentic pride is occasioned by specific moral achievement and its connection to the self and its values (Hart & Matsuba, 2007).26 24 See Chapter 7 for moral foundations (Graham et al., 2011) that involve loyalty to the group. Embarrassment may be seen as a recognition of a threat to this value. 25 And it interestingly shares neural substrate with other pro-­social emotions such as compassion (Moll et al., 2007). 26 In a large cross-­sectional international sample (Orth, Robins, & Soto, 2010), authentic pride increases from adolescence into old age, while hubristic pride decreases from adolescence to adulthood, reaching a minimum around age sixty-­ five, and then begins to increase. This suggests a kind of moral maturation in this domain. Moral Emotion 229 The information in the emotion of pride differs depending upon the type. For hubristic pride, it is a sense of supremacy of the global self over others (Carver & Johnson, 2010; Tangney, Stuewig et al., 2007). It is usually comparative (Tangney, Stuewig et al., 2007) and related to social dominance (Carver & Johnson, 2010). Hubristic moral pride would come from thinking, for instance, that one (and perhaps one’s group) was more authentic, caring, and principled than others. It is about moral superiority that is explicitly comparative. It is a pride of “being” (Lewis, 2008). In contrast, authentic moral pride is a pride that stems from doing good. It results from the perception that one is responsible for a specific positive moral outcome, or has resisted a particular temptation, or acted in regard to particular obligations (Malti & Ongley, 2014). The motivational complex associated with hubristic pride is (not surprisingly) s ­negative and even anti-­social. Hubristic pride is associated with impulsivity, anger, aggression, seeking public recognition, narrow focus on financial success, and social of dominance (Carver & Johnson, 2010; Liu et al., 2016). In the business domain, it is associated with decisions to pursue unwise mergers and acquisitions that destroy value rather than create it (Bodolica & Spraggon, 2011). Because of the impulsivity and self-­centeredness, hubristic pride makes the maintenance of relationships (busiro ness or otherwise) difficult. It also serves a central emotional role in prejudice and intergroup bias (Fiske, 2015) and leads people to identify only with powerful others (Oveis, Horberg, & Keltner, 2010). Authentic moral pride is associated with self-­ control, adaptive achievement, and goal engagement (Carver & Johnson, 2010) and lP is a primary motive for “voluntary planned, sustained moral action” that reflects the self and its values (Hart & Matsuba, 2007, p. 117). If the distinctions among these types of pride seem too strongly drawn and simplistic, it is in part because they are: the literature is still young and developing. But there are interesting complexities. Bodolica (2011) recognizes, for instance, the dynamism na that hubristic pride can give an organizational leader, and Carver and Johnson (2010) list several aversive emotional experiences that tend not to correlate with either type of pride (e.g. anxiety/fear). There is also some suggestion that gratitude plays an essential role in how pride is expressed. Organizational leaders who experience pride in achievement tend to treat their employees well only if they feel grateful for employFi ees’ contributions to that success (Michie, 2009). Finally, we should note that, though hubristic pride is implicated in prejudice toward out-­groups (Fiske, 2015), there is very little published on hubristic moral pride, the pride that comes from thinking oneself morally superior. 8.2.3.3 Shame Shame is a moral emotion that is complicated by cross-­ cultural difference. In most Western cultures, shame comes from the appraisal that something is wrong or inadequate with the self. But in most non-­Western cultures, shame is part of a complex of embarrassment, shyness, modesty, and social fear, and is crucial to life embedded in social groups (Haidt, 2003b; Kitayama & Park, 2007). For instance, shame is a somewhat negative but culturally condoned emotion in Japan. Japanese schools have times set aside for hansei, to encourage children to take critical self-­ reflection in the service of self-­improvement (Boiger et al., 2013). Shame in the United States, however, is to be avoided because it threatens positive self-­regard Taking Moral Action (Haidt, 2003b). Thus, one can expect that the information embedded in shame and the motivational profile of shame will be quite different in Western vs. non-­Western cultures.27 In Western cultures, shame involves negative evaluation of the self, and often includes imagery of how one appears to others in this light (Tangney, Stuewig et al., 2007). It might be occasioned by something the person has done, but it can also be elicited by appearing inadequate, flawed, or defective (Haidt, 2003b). Thus, while shame is an inward-­focused moral emotion, it is in part about how this inward self appears to the outer social world. The inward focus is made clear by the motivations associated with shame: hiding, distress about the self, anger at others who make one look bad (Stuewig et al., 2010; Tangney, Stuewig et al., 2007). It is this withdrawing, defensively aggressive (to self and other) reaction that makes shame problematic in Western cultures. It leads one away from social engagement. Criminals who focus on s shame during their imprisonment are more likely to commit additional crimes and return to jail compared with those who focus on guilt (Tangney, Mashek, & of Stuewig, 2007).28 The withdrawal motivation associated with shame is part of what discourages victims of sex abuse from reporting incidences and the focus on negative self-­evaluation makes shame a central driver in depression long after sexual abuse has taken place (Lewis, 2008).29 ro In non-­Western cultures, shame is occasioned when one has violated social expectations (e.g. by asking for or needing help) or is in danger of violating social expectations (e.g. by simply being in the presence of someone higher ranking) (Boiger et al., 2013; Haidt, 2003b). In such cultures, there is no clear distinction between lP moral norms and social conventions (Shweder et al., 1997). Though still negative, the experience of shame in these cultures is less intense than in Western cultures (Boiger et al., 2013) and it serves as a motivation to reintegrate oneself into the group. It is pro-­social, less about the core self and more about behavior that can be remedied. We are just beginning to tease apart these complexities. na 27 The differences are not simply dichotomous. One can find them across time and within Fi shared cultures. For instance, as Western cultures have moved away from communal and toward individualist societies, they have also de-­emphasized shame. There are large differences within Japan in individualism (Kitayama et al., 2006), and one can place some cultures in the middle on the scale of independence–interdependence, thus implicating differences in the associated emotions – e.g. Kitayama et al. (2006) find that Britain and Germany occupy a space in between the United States and Japan on that scale. 28 The relationship of shame to criminal reform is still not well understood. The research program of Tangney and colleagues cited here suggests shame is problematic for reform. But a central theoretical perspective in restorative justice approaches is “reintegrative shaming” that focusses on making public disapproval of the crime explicit, with the goal of reintegrating the criminal (Harris, 2006). Perhaps the emphasis on “reintegrative” helps explain this disconnect in the literatures. 29 In the Western world, shaming might be understood as an act of moral violence, making a public show of focusing on the low worth of the shamed person. One can think of this as a punishment motive, using the emotion of shame to hurt the target and make the target of shaming feel bad. Moral Emotion 231 8.2.4 Other-­Praising Moral Emotions This emotion family recognizes positive characteristics in others, and responds with a range of reactions that strengthen relationships (Haidt, 2003a). Though they are outward focused, it is unclear whether the “other” need be human, or even personal. And they may also be as closely related to an inward-­focused relation to the self, as seen in the relationship between gratitude, awe, and humility (Kruse et al., 2014; Piff et al., 2015). 8.2.4.1 Elevation and Awe Elevation is the emotional response to witnessing acts of virtue or moral beauty (Algoe & Haidt, 2009). Its characteristic feeling is that of outward-­directed expansion, perhaps even uplifting and inspiring (Haidt, 2000). This description of the feeling suggests a motivational state, which is outward directed. s Those experiencing elevation often want to praise the other person, share news of the good deed, or even emulate it. Those experiencing elevation are motivated to become of like the other, at least in action.30 The subjective experience of elevation is different from simply feeling good or feeling happy, and evidence suggests that this difference leads to clear increases in pro-­ social activity on the part of those experiencing the emotion (Schnall, Roper, & ro Fessler, 2010). For example, in a study of Italian business leaders, it has been shown that leaders’ interpersonal fairness and self-­sacrifice leads to the emotion of elevation in employees, and that the experience of this emotion is a clear influence on employees’ organizational commitment and citizenship (Vianello, Galliani, & Haidt, 2010). lP It seems reasonable to expect such an emotional effect to be limited to the domain in which it occurs (e.g. the workplace), but there is no research that documents this. The experience of elevation, and its effects, is also influenced by one’s readiness to be open to it. People higher in moral identity, for instance, are more likely to experience elevation when they see morally praiseworthy action, and they are more likely to na emulate that action (Aquino, McFerran, & Laven, 2011).31 The link with moral identity and the subjective experience of elevation as a positive emotion together suggest that the motivation elevation produces is not one of overcoming some deficit or lack but instead one of approaching something desirable.32 However, it seems possible that the desirable here need not always be the moral. It may be that group socializaFi tion toward prejudice occurs in part because of a desire to emulate others (see Gatto & Dambrun, 2012 for an example involving police officers). We know very little about how flexible the experience of elevation is regarding its (im)moral goal. Finally, a note on the related emotion of awe, though it is not clear that this emotion fits the category of “other-­praising” (Shiota, Keltner, & Mossman, 2007). Awe stems from an appraisal of vastness that is not graspable, possibly accompanied by 30 The emotion that leads to the desire to emulate the other is treated by Zagzebski (2013, 2017) as a central component in a theory of virtue ethics. 31 This is again a place where the idea of a single focus of an emotion misleads us. It is more the relation of the self to the awe-­inspiring than simply the outward focus. One finds this theme in much religious poetry and writing (e.g. Rumi, Meister Eckhardt) and the relational aspect of awe is reflected in the current empirical work. 32 See Chapters 5 and 9 for the various ways one might be motivated to moral action. Taking Moral Action threat, exceptional beauty, virtue, and the supernatural (Keltner & Haidt, 2003). Because it is associated with a situation that “overwhelms current cognitive categories” awe has a complicated relationship with the information it provides. In some studies the experience of awe increases belief in supernatural agency, partly by ­motivating a desire for cognitive closure (Valdesolo & Graham, 2014). But in other studies it has been shown that those without a need for cognitive closure are more open to experiencing awe (Shiota et al., 2007). But there is agreement that, rather than being simply an enjoyable experience, awe increases pro-­social behavior, that is, it has an action tendency. How it does so is still unclear – perhaps by reframing one’s view of the self (Keltner, Kogan et al., 2014). And this reframing suggests again the dual nature of focus of these emotions: both other-­praising and inward focused. 8.2.4.2 Gratitude One may experience gratitude when one receives some benefit s from another, particularly if it is clear that the benefactor is acting out of a correct awareness of the needs of the recipient (Algoe & Haidt, 2009; Bono, Emmons, & of McCullough, 2012). Like elevation, gratitude’s elicitors and its effects are more specific than simple happiness (Kruse et al., 2014). Experiencing gratitude motivates one to want to return the favor, strengthen the relationship with the benefactor, or even to pass benefit on to others (Bono et al., 2012; Emmons & Kneezel, 2005; McCullough et al., 2001). ro One may experience gratitude, but there are a variety of influences that lead people away from this experience, even if they do receive benefits from others. These include perceptions of victimhood, envy or resentment, or an emphasis on materialistic values lP (see Bono et al., 2012 for a review). There is some evidence that insecure relationship attachment styles can lead to lower levels of gratitude (Dwiwardani et al., 2014). It makes sense that skepticism about relationships (being wary of or blaming others or being cynical about others’ motivations) should also reduce gratitude. Still, one should make the distinction between non-­gratitude and ingratitude. Non-­gratitude na may simply be the result of forgetting or paying attention to other things, but ingratitude has a more aggressive edge, and may even be motivated by a desire to punish or hurt the other (Emmons, 2007, p. 141). In addition to motivating people to draw closer to each other, gratitude can have other social effects. For instance, gratitude and humility are linked in a virtuous cycle Fi over time, in which one’s gratitude influences one’s view of the self as dependent on others (Kruse et al., 2014), but this cycle is likely to work only when one’s dependence is not seen as a burden (Bono et al., 2012).33 In Section 8.2.4.1, we reviewed work that showed that leaders’ gratitude to their workers was an important influence in inspiring those workers to emulate their leaders (Vianello et al., 2010). Thus, gratitude calls forth elevation and emulation. 33 See Weidman, Cheng, and Tracy (2018) for an explanation of the type of humility that might best fit this virtuous cycle (appreciative vs. self-­abasing). One can also find this distinction in Thomas Merton’s (2009) commentary on the Rule of Benedict (Benedict of Nursia, 550/1980). Moral Emotion 233"
8,8.3,"Learning Moral Emotions From our review of moral emotions so far, one can see that having passions does not mean we are passive in our emotional experiences. We are constantly engaged in the appraisal that constructs them. As infants, we come with emotion built in, but much of the rest of life involves our grappling with our emotions, learning to guide, control, produce, and integrate them into our plans and actions. We do this because when our emotion regulation goes out of control, our emotion can indeed be overwhelming. But we also do so in part because when they are working well our emotions make our life rewarding. As we move from childhood to adolescence, we become aware of the complexities of relationships and situations, which results in increasingly complex moral emotions and cognition. We learn to recognize emotion in ourselves, to distins guish one emotion from another, to recognize mixed emotions, and to evaluate our emotions for appropriateness. There is, then, a developmental progression in the moral emotions.34 And there is an identifiable way to track emotional learning at the of neural level and to gauge its variability (Lebois et al., 2020). For example, consider the “Happy victimizer” phenomenon. As they develop and learn moral rules, children can say that some particular action (like stealing a toy) is ro bad. But early in this process they are also willing to say that a child who does the wrong action will feel happy, because the child gets his or her desire (the toy). It is only later, as they begin to come to terms with how emotions in others work, that they recognize that emotions can be linked both to getting what you want and to lP feeling bad if you break a rule. The extent to which one makes the connection between feeling bad and having done something wrong can predict delinquency in adolescence (Krettenauer, 2013). Children may not have developed the skills associated with theory of mind to anticipate other and self-­reactions to a transgression. But even adults may not see morality as centrally relevant to the self or as relevant to some particular situation (Malti & Ongley, 2014, p. 167). na Even in adulthood we can learn emotions. A meditation-­based compassion training program, in which one practices feeling compassion for a range of people, can increase altruistic action and change emotional experience (Weng et al., 2013). We can also learn to be more grateful (Bono et al., 2012). Consciousness-­raising groups (e.g. in the early feminist movement) achieve their purpose in part through training emoFi tional responses, such as learning when anger is appropriate (Keane, 2015). Even though there is clear evidence that our nonconscious intuition and emotion can drive moral judgment, specific attempts to reappraise our moral emotional responses can alter emotion and overturn these judgments (Feinberg et al., 2012). We can rethink (and refeel) our moral emotional reactions. Most forms of psychotherapy have at least some emotional component, and insight-­based therapies that concentrate on emotion recognition and reappraisal produce longer lasting effects in clients than more cognitive approaches (Keltner, Oatley et al., 2014, p. 373ff.). Rivers et al. (2013) have developed a successful training program in classrooms to help increase what they 34 See Keltner, Oatley et al. (2014, chapter 8) for a broad but concise review of the development of emotions. Taking Moral Action call “emotional intelligence” – the set of skills that allow pro-­social emotions to ­support good classroom environments. So, of course we can rethink our moral emotional reactions. We are not passive in the face of our passions. We should acknowledge, however, that we can rethink our emotions in order to be better killers in battle (Grossman, 1996) and to reduce our distress when we harm others (Bandura, 1999) as well as to be more compassionate. But given the right circumstances, we can learn, and unlearn, our moral emotions. This in turn means that we are not at the mercy of our emotions, not the passive victims of them, not always led astray by them. In fact, it means that one of the ways we are moral is by being emotional about those values to which we are passionately committed. s 8.4 Discussion of 8.4.1 Conclusion 1. Emotions are not simply biases, they are evaluations than can be appropriate or inappropriate. ro Are emotions always biasing to moral judgment and action? In short, no. Both emotion and reason can bias moral judgment, but it is not inevitable. In fact, the complex interactions among emotion and judgment are the reason we can be moral. Common to almost all definitions of emotion is the mixture of information lP and judgment, physiological reaction, subjective feel, and motivational profile.35 This complex interweaving of emotion and reflection, of appraisal, feeling, and action tendency, is what makes moral life work in the individual psyche, and in social interaction. We are moved to action by emotion, and our emotions are informed by judgment. This rapid switching among thoughts and feelings, interna rupting, conversing, and blending,36 gives us some idea of the constant interweaving of reason and emotion in our moral life. Rather than moral emotions biasing evaluations, moral emotions incorporate a significant aspect of evaluation, and are deeply entwined in moral judgment and action. Indeed, emotions can only be biasing because they contain cognition in the Fi form of information, judgment, and motivation. Nor is the strength of the 35 See Keltner, Oatley et al. (2014, p. 9) for at least nine different definitions of emotion. Definitions are less important than exploring the related processes within their contexts. It is more important to understand how any particular process works and the variations in how it works. So, in this chapter we have cast a wider net, loosened from definitional constraints, both in terms of emotion and the moral. 36 In Shakespeare’s Winter’s Tale, King Leontes narrates his thoughts and feelings as he comes to believe (falsely) that his wife has cheated on him: “Then’tis very credent, Thou may’st co-­join with something, and thou do’st, (And that beyond commission) and I find it, (And that to the infection of my brains, And hardening of my brows).” For those not facile with Shakespearian English, here is a transliteration showing the rapid switching among the thoughts: “It is then very believable, you may have co-­joined with something [King Polixenes], And you do! (and you do it outside my authority!) and I have found it!, and it causes me to be crazy, and to become angry.” Moral Emotion 235 emotion a good guide to whether it will bias moral evaluation. Even very strong emotional reactions (e.g. righteous anger, moved by compassion) can be morally beneficial. The gentler passions also can be biasing (e.g. the self-­pity that allows me to distance myself from those I harm). 2. We are not as passive in experiencing our moral emotions as we often believe. Emotions, and perhaps especially moral emotions, are not experiences we have, they are performances we do. Emotional responses can be learned and can be modified by reappraisal. Consciousness-­raising groups are settings where people learn what are considered appropriate moral emotional reactions. Compassion meditation has clear effects on shared emotion. Given a particular moral ecology and appropriate experience, perhaps we can become expert feelers. 3. We should include emotion in models of reflective equilibrium in moral evaluation. A reasonable goal here might be called reflective equilibrium among emotions and s rationality (Daniels, 2018; Narvaez, 2010; Rawls, 1971/1999). Since emotions can be tested for their appropriateness to a situation, and reasons and reasoning of can interact with this testing process, one can learn the skills of moral discernment by involving both emotion and reason. Emotion-­free rationality without a search for this equilibrium should be just as suspect as emotion-­laden judgment.37 But because emotions are social things, we need to add a social dimension to reflective ro equilibrium. One can see this in a little discussed aspect of Haidt’s (2001) model in which the moral emotions and reactions of one’s peers influence, often not consciously, one’s own moral emotions and reactions. The Japanese practice of using shame in hansei provides an opportunity for schoolchildren to learn appropriate lP moral emotions. Adding this social aspect suggests social–emotional reflective equilibrium as a process and goal for mature, or expert, moral action. 4. Moral emotion should be integrated into the teaching of ethics. Finally, since moral emotions are integral in moral action, what implication should this have for how we teach ethics? Perhaps we should reverse a long standing trend na in ethics education that presumes that solving ethical puzzles is the best training (Pincoffs, 1971) and begin to make ethics emotional again. To do so would involve (un)consciously training emotion – learning when to trust it, how to guide it, how to argue with (and for) it, and when and how to question it. Perhaps practicing appropriate emotional responses and their reappraisal through social–emotional Fi reflective equilibrium should be at the center of ethics training. Maybe it already is at the center of ethics training but unacknowledged and not well integrated. 8.4.2 Application The case of moral courage in the face of pressure to overturn the 2020 presidential election is replete with moral evaluation, where one finds both imbalance and attempts at balance in social–emotional reflective equilibrium. Donald Trump himself is a paradigmatic example of someone driven by emotion, intuition, and an often-­self-­serving 37 In Chapter 7, we look at how reason itself can go awry to bias moral judgment. In Chapter 9, we look at how one might cultivate this social–emotional reflective equilibrium. Taking Moral Action desire who uses reason only as the servant of his goals. Aaron Van Langevelde was in a role on the Michigan Board of State Canvassers that required him to give reasons for his actions, and so he is unlikely to offer emotional explanations. But if one looks closely at the reasons he gives, the urgency and difficulty of his position is easy to see. He voted to certify the election results in Michigan to avoid “constitutional chaos and the loss of our integrity” (all quotes are from his speech at Cardozo Law School in Boston where he received an award for professional courage, Bidgood, 2021). He explained that he was being asked by Trump and others to “disregard [his] oath of office,” “abandon [his] administrative role,” “ignore a clear legal duty,” and “take power [he] didn’t have.” Emotion-­loaded words like chaos, loss, disregard, abandon, and ignore all point to the emotional pull of his professional identity as a public servant but also as a lawyer for the Republican Party in Michigan. These words invoke emotions like fear, indignation, contempt, and scorn but also loyalty and devotion. s That the words he chooses are emotion-­laden is not a mistake or bias in his evaluation of the situation. In software design language, the emotions are not bugs but features. of They motivate him in the social–emotional reflective equilibrium to overcome the intense pressure he describes to be loyal to Trump. He mentions an outpouring of social pressure to vote no or to not attend the certification, even to the point that “my family and I were in danger.” But despite this pressure, he felt the “rule of law is a ro worthy cause.” This is an evaluation, driven by a balance of emotion and reason, socially validated by the award he received. He was surely not doing it to get the award (he was its first recipient); but the award was designed to offer public praise to shore up a shaking moral ecology. lP 8.4.3 Open Questions 1. How can we treat the wide confusion within and between emotion categories as an asset rather than a liability? na It seems sufficiently established that we will need to live with the wide plasticity within and between emotion categories like anger and awe. But how can we turn this into a theoretical asset rather than a confession of failure? We suggest it is by embracing the complexity of emotions from the neurological to the cultural level and finding solvable puzzles within this complexity. One way to do this is to study Fi the process of establishing social–emotional reflective equilibrium. Another is by following the developmental progression of emotional complexity over time within particular domains (e.g. How do doctors and therapists learn to properly emote in their fields?). Several other possibilities are listed for this in Section"
8,8.4,"Discussion of 8.4.1 Conclusion 1. Emotions are not simply biases, they are evaluations than can be appropriate or inappropriate. ro Are emotions always biasing to moral judgment and action? In short, no. Both emotion and reason can bias moral judgment, but it is not inevitable. In fact, the complex interactions among emotion and judgment are the reason we can be moral. Common to almost all definitions of emotion is the mixture of information lP and judgment, physiological reaction, subjective feel, and motivational profile.35 This complex interweaving of emotion and reflection, of appraisal, feeling, and action tendency, is what makes moral life work in the individual psyche, and in social interaction. We are moved to action by emotion, and our emotions are informed by judgment. This rapid switching among thoughts and feelings, interna rupting, conversing, and blending,36 gives us some idea of the constant interweaving of reason and emotion in our moral life. Rather than moral emotions biasing evaluations, moral emotions incorporate a significant aspect of evaluation, and are deeply entwined in moral judgment and action. Indeed, emotions can only be biasing because they contain cognition in the Fi form of information, judgment, and motivation. Nor is the strength of the 35 See Keltner, Oatley et al. (2014, p. 9) for at least nine different definitions of emotion. Definitions are less important than exploring the related processes within their contexts. It is more important to understand how any particular process works and the variations in how it works. So, in this chapter we have cast a wider net, loosened from definitional constraints, both in terms of emotion and the moral. 36 In Shakespeare’s Winter’s Tale, King Leontes narrates his thoughts and feelings as he comes to believe (falsely) that his wife has cheated on him: “Then’tis very credent, Thou may’st co-­join with something, and thou do’st, (And that beyond commission) and I find it, (And that to the infection of my brains, And hardening of my brows).” For those not facile with Shakespearian English, here is a transliteration showing the rapid switching among the thoughts: “It is then very believable, you may have co-­joined with something [King Polixenes], And you do! (and you do it outside my authority!) and I have found it!, and it causes me to be crazy, and to become angry.” Moral Emotion 235 emotion a good guide to whether it will bias moral evaluation. Even very strong emotional reactions (e.g. righteous anger, moved by compassion) can be morally beneficial. The gentler passions also can be biasing (e.g. the self-­pity that allows me to distance myself from those I harm). 2. We are not as passive in experiencing our moral emotions as we often believe. Emotions, and perhaps especially moral emotions, are not experiences we have, they are performances we do. Emotional responses can be learned and can be modified by reappraisal. Consciousness-­raising groups are settings where people learn what are considered appropriate moral emotional reactions. Compassion meditation has clear effects on shared emotion. Given a particular moral ecology and appropriate experience, perhaps we can become expert feelers. 3. We should include emotion in models of reflective equilibrium in moral evaluation. A reasonable goal here might be called reflective equilibrium among emotions and s rationality (Daniels, 2018; Narvaez, 2010; Rawls, 1971/1999). Since emotions can be tested for their appropriateness to a situation, and reasons and reasoning of can interact with this testing process, one can learn the skills of moral discernment by involving both emotion and reason. Emotion-­free rationality without a search for this equilibrium should be just as suspect as emotion-­laden judgment.37 But because emotions are social things, we need to add a social dimension to reflective ro equilibrium. One can see this in a little discussed aspect of Haidt’s (2001) model in which the moral emotions and reactions of one’s peers influence, often not consciously, one’s own moral emotions and reactions. The Japanese practice of using shame in hansei provides an opportunity for schoolchildren to learn appropriate lP moral emotions. Adding this social aspect suggests social–emotional reflective equilibrium as a process and goal for mature, or expert, moral action. 4. Moral emotion should be integrated into the teaching of ethics. Finally, since moral emotions are integral in moral action, what implication should this have for how we teach ethics? Perhaps we should reverse a long standing trend na in ethics education that presumes that solving ethical puzzles is the best training (Pincoffs, 1971) and begin to make ethics emotional again. To do so would involve (un)consciously training emotion – learning when to trust it, how to guide it, how to argue with (and for) it, and when and how to question it. Perhaps practicing appropriate emotional responses and their reappraisal through social–emotional Fi reflective equilibrium should be at the center of ethics training. Maybe it already is at the center of ethics training but unacknowledged and not well integrated. 8.4.2 Application The case of moral courage in the face of pressure to overturn the 2020 presidential election is replete with moral evaluation, where one finds both imbalance and attempts at balance in social–emotional reflective equilibrium. Donald Trump himself is a paradigmatic example of someone driven by emotion, intuition, and an often-­self-­serving 37 In Chapter 7, we look at how reason itself can go awry to bias moral judgment. In Chapter 9, we look at how one might cultivate this social–emotional reflective equilibrium. Taking Moral Action desire who uses reason only as the servant of his goals. Aaron Van Langevelde was in a role on the Michigan Board of State Canvassers that required him to give reasons for his actions, and so he is unlikely to offer emotional explanations. But if one looks closely at the reasons he gives, the urgency and difficulty of his position is easy to see. He voted to certify the election results in Michigan to avoid “constitutional chaos and the loss of our integrity” (all quotes are from his speech at Cardozo Law School in Boston where he received an award for professional courage, Bidgood, 2021). He explained that he was being asked by Trump and others to “disregard [his] oath of office,” “abandon [his] administrative role,” “ignore a clear legal duty,” and “take power [he] didn’t have.” Emotion-­loaded words like chaos, loss, disregard, abandon, and ignore all point to the emotional pull of his professional identity as a public servant but also as a lawyer for the Republican Party in Michigan. These words invoke emotions like fear, indignation, contempt, and scorn but also loyalty and devotion. s That the words he chooses are emotion-­laden is not a mistake or bias in his evaluation of the situation. In software design language, the emotions are not bugs but features. of They motivate him in the social–emotional reflective equilibrium to overcome the intense pressure he describes to be loyal to Trump. He mentions an outpouring of social pressure to vote no or to not attend the certification, even to the point that “my family and I were in danger.” But despite this pressure, he felt the “rule of law is a ro worthy cause.” This is an evaluation, driven by a balance of emotion and reason, socially validated by the award he received. He was surely not doing it to get the award (he was its first recipient); but the award was designed to offer public praise to shore up a shaking moral ecology. lP 8.4.3 Open Questions 1. How can we treat the wide confusion within and between emotion categories as an asset rather than a liability? na It seems sufficiently established that we will need to live with the wide plasticity within and between emotion categories like anger and awe. But how can we turn this into a theoretical asset rather than a confession of failure? We suggest it is by embracing the complexity of emotions from the neurological to the cultural level and finding solvable puzzles within this complexity. One way to do this is to study Fi the process of establishing social–emotional reflective equilibrium. Another is by following the developmental progression of emotional complexity over time within particular domains (e.g. How do doctors and therapists learn to properly emote in their fields?). Several other possibilities are listed for this in Section 8.4.3.2. 2. How do we establish social-­emotional reflective equilibrium? How might we do research on how and when people use a process like socio-­ emotional reflective equilibrium? Perhaps by looking at expert feelers. We might study those who are in jobs that require an integration of moral emotion and rationality in the service of getting things done. In short, by studying those who do emotional work (Grandey, 2000), work that involves the regulation of emotion as a part of the job. We can find them in war (Grossman, 1996), hospice nursing (Hill, 2005), counseling (Fowers, 2012; Fowers & Winakur, 2014), and even in food service (Grandey, 2000). Hill (2005), for instance, provides a moving example of the care taken by a team of nurses with a very difficult hospice patient. Much Moral Emotion 237 of their effort focused on maintaining compassion while making rational plans to deal with their own emotional reactions to constant provocation. They were regularly consulting both emotion and reason in the service of moral goals, compassionate care for the patient and concern for their own emotional welfare.38 Or perhaps we might look at morally exemplary actors, who have been studied in a wide range of professions and volunteer positions (Hart, Murzyn, & Archibald, 2013). A common finding among those who do work on moral exemplars is that these actors do not generally do lengthy rational deliberation in the course of their moral careers (Huff & Furchert, 2016). These, too, may be expert at the integration of reason and emotion in the service of moral goals. We might also look at training programs in monastic formation in Christian (Casey, 2005), Hindu (Rambachan, 2006), and other traditions with long experience in training for personal and spiritual growth. And we might look to clinical psychology for s systematic work and long experience in personal growth (Weinstein, Przybylski, & Ryan, 2013). Thus, there are places one can find relevant insight, but there is not of much work central to current moral psychology. 3. How do moral emotions play a role in prioritizing moral thoughts, goals and action? The complex world of moral action is one in which there is rarely enough information to make a complete judgment based on reason or learning alone. Emotions ro move us both to thought and to action. They do not belong to a separate system that only interferes with the primary functions of rational moral judgment. They are instead a basic part of our moral apparatus and functioning. They are a feature, not a bug. If we were not emotional, we would not be able to be fully moral. lP Much work in moral emotions has so far consisted in establishing the importance of moral emotion in moral thought and action. We need to begin analyzing the role they play as they interact with thoughts, goals, and actions, influencing them and being in turn influenced. How, for instance, do emotion and cognitive processing interact in consciousness-­raising groups, hansei, compassion meditana tion, intergroup conflict, and religious experience?"
8,8.5,"Further Readings Fi These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and recent work. Complete citations are provided in the references section. Please look to each section on a specific emotion for relevant references. • Scherer and Peper (2001). “Psychological theories of emotion and neurological research.” A neuroscience-­based review of emotions that provides one view of the aspects of an emotion. • Shweder et al. (2008). The cultural psychology of emotions: Ancient and renewed.” A review of cultural aspects of emotion that provides a comprehensive list of aspects of emotion. 38 Note that this team approach is social, emotional, and rational all at once, and it seeks to maintain a balance based upon a moral goal: compassionate professional care. Taking Moral Action • Keltner, Oatley et al. (2014). Understanding Emotions (3rd ed.). A textbook-­ length, comprehensive review of work on emotions. • Ellsworth (2013). “Appraisal theory: Old and new questions.” One of the primary appraisal theorists offers a critique and directions for work in the area. • Cameron et al. (2015). “A constructionist review of morality and emotions.” A review of emotion literature that finds no evidence for specific links between moral content (e.g. harm, purity) and discrete emotions (e.g. anger, disgust). • Barrett (2021). “This is how your brain makes your mind.” An approachable and clear overview of how emotions are constructed “on the fly.”"
9,9.1,"Traditional Accounts of Moral Formation Since humanity began telling stories, those stories have included themes of moral growth and degeneration.6 World and indigenous religions provide guidance for the formation of spiritual and moral identity or self (Narvaez et al., 2019). And, of course, philosophical systems East and West have concerned themselves with how one becomes, and accordingly does, good. In Sections 9.1.1–9.1.3, we present three traditions of moral formation in suggestive outline and urge the enterprising reader to look more carefully into each of them for clues and critiques of psychological research on moral formation. We hope these will serve as test cases of the intimacy and complexity of the processes and illustrate the need for integrative theory-­making in the field. s 9.1.1 Bildung of There is a German-­language narrative tradition of Bildung (education as personal formation) that has produced an entire genre of literary narrative, the Bildungsroman, the novel of personal formation (Golban, 2018), first clearly exemplified (and self-­ ro critiqued) by Goethe’s Wilhelm Meisters Lehrjahre (1795/2007). This genre is rooted in a long German tradition that refers to Bildung, a word for which “there is no economical translation” (Herdt, 2019, p. 6). According to the theological ethicist Jennifer Herdt, the Rhineland mystic Meister Eckhart, writing in the German vernacular, first used the German term Bild (picture or image) as a central concept in lP spiritual/moral formation. Influenced by a theological anthropology that views the person as an image of God, he claims the human task is one of reforming (überbilden) and informing (einbilden) one’s self toward the God-­image. The word Bildung holds both Bild as a noun and bilden as a verb, which literally means “the process of shaping” someone or something toward an image, or as the title of our chapter has it, na formation. It is a process of forming oneself, and allowing oneself to be formed, after an example (the Vorbild). It holds the religious resonances of the Judaic creation story (and Christian theological anthropology) in which humans are created (gebildet) in the image (Bild) of God. Bildung is often described as the educational process of encounter with the world that leads to the development of self, based on an image Fi of the ideal (Stojanov, 2012). But it is more complex than that and has a long history encompassing both variation and contradiction within it. It is, then, more profound than simple education. At least as articulated by Wilhelm von Humboldt (1792/1960) who transformed higher education in Germany, Bildung is the continual attempt of individuals, through experience or interaction with the world, to open up themselves to the world, to relate to that world, to be changed by it, and in particular to become open to the many different perspectives that others have on the world (Stojanov, 2012). This is a goal and vision of personal becoming that emphasizes human emotional and spiritual commitment in encounter with others. It shares things in common with Kohlberg’s insistence on wide 6 See our comment about the moral aspects of the 4,000-­year-­old Gilgamesh story in Chapter 3. Taking Moral Action ­encounter with the social world (see Chapter 7) but includes a much broader set of values, emotions, and skills within it, making change within the self – identity formation – a central aspect of the process. Finally, it opens the door to moral influence from reading and theater and from that part of our moral ecology that can engage the self from across the centuries of a tradition. This history is laid out in all its complexity by Herdt (2019). She traces the idea back to classical Greek paideia and Roman humanitas, an aristocratic project of educating the self for citizenship. Medieval theologians adapted this by appropriating the image of God as the goal for development, whence it passed into the German vernacular as various versions of bilden in Meister Eckhart’s writings. The tradition explodes in variation and creativity from there, with pietists (Arndt, Boehme), philosophers (Hegel, Herder), secular writers and humanists (Goethe, Schiller), and Pedagogues (Wilhelm von Humboldt) shaping and reshaping it in a dense weave of s influence and disagreement. Herdt (2019) detects a variety of themes of Bildung/formation for which we can of only give a quick list here: (1) Bildung as both gift and task, either religious as in coming from and returning to God, or secular as in emerging from the religion of art/ nature; (2) Bildung as radical, independent self-­construction; (3) Bildung as the effort of development into full humanity in loving association with others; (4) Bildung ro as an expansion of the self by encounter with the wide variety of human diversity, conditions, and opinions; (5) Bildung as a passive openness to being changed either by God or by the forces immanent in nature.7 The richness of the Bildung tradition is that it has been seen as a passive and an lP active process, a religious and a secular endeavor, an individualist and a communitarian education, and a mystical/emotional and an intellectual achievement. But all the variations share the idea of development into a full humanity by intentional encounter over time with something other than the self that produces a powerful transformation of the self.8 These variations are better seen as perspectives or tensions within the na tradition rather than contradictions. Thus, Bildung serves as a model for a moral psychology that itself incorporates tensions of individual autonomy vs. situational pressure, of emotion vs. reason, and of collectivist vs. individualistic culture; And also as a corrective for a moral psychology that has until now avoided grappling with issues of the ultimate. Fi Herdt also sees these themes re-­emerging in recent work by philosophers Martha Nussbaum and Anthony Appiah and their struggle to construct an ethics that recognizes humanity in all its diverse and brilliant vibrancy rather than the flat, colorless language of basic human rights (Appiah, 2001; Nussbaum, 1994). One can also see these themes and tensions in the American version of the liberal arts education and its emphasis on whole person learning, language learning, and study abroad (Hutchins, 1953). We turn now to a tradition that examines in detail the “powerful transformation of the self ” on which Bildung is based. 7 Most of these themes appear and are critiqued in Meister Wilhelm’s Lehrjahre (Goethe, 1795/2007), and this complexity is part of its status as a major work of art. 8 It must be said that this process is prone to failure, as seen in the incorporation of the German Bildung ideal into the National Socialist (Nazi) agenda. Moral Formation 251 9.1.2 Existential Appropriation Since ancient times there has been a tradition in philosophy emphasizing Socratic maieutic over the mere acquisition of knowledge and skill. This art of philosophical midwifery focuses on facilitating the birth of truth in the single individual. Such truth is different from objective knowledge or doctrine since it is mediated by an embodied process of existential appropriation,9 which refers to a range of internal processes like evaluating and re-­evaluating, choosing or struggling to choose, incorporating and embodying what “concerns us ultimately” (Tillich, 1952). The philosopher/­ theologian Søren Kierkegaard (1813–1855), often referred to as the Danish Socrates, places himself firmly in this maieutic tradition, and anchors this birthing of the moral self in a teleological context. Just as Socrates’s pedagogy of “paideia”10 challenged the status quo of ancient Athens, Kierkegaard’s revival of the maieutic practice aims to s offer an “existential corrective” to the idolization of objective knowledge (Furchert, 2005, 2022). At its center stands a complex psychological process of objecof tive and subjective reflection: the double movement of existential appropriation. The first part of this double reflection concerns our objective thinking about a particular truth, telos or value,11 or the factual “what” of its content; the second reflection concerns the subjective “how” of that very content or how one comes to relate to it ro (Furchert, 2022; Kierkegaard, 1846/1992). The concept of existential appropriation thus provides for a path from mere reflection about values to actually relating to it as a “truth for me,” by both adopting that truth or value and putting it into practice. We show in the Introduction (Section I.2) lP how Gadamer has described this application process as crucial for any context where professional (or ethical) knowledge needs to be applied to “the concrete case” (Gadamer, 1996). Bridging this gap between knowledge and application, what and how, is an act of constant evaluation, reasoning, and decision-­making, translating what we know into doing, and what we do back into knowing, always for a specific na and unique situational context (Gadamer, 1996; Huff & Furchert, 2023).12 Thus, the famous Kierkegaardian “leap” is not a leap “of faith” where one abandons reason but the leap with which the actor bridges the gap between knowing and Fi 9 Not to be confused with cultural appropriation, the superficial taking of ideas from a culture not one’s own. 10 While claiming to honor the goal of the Greek ideal of elite human development through cultural experience (paideia), Socrates’s approach to questioning knowledge and virtue also radically undermined its assumptions, focusing on the crucial role of choice in the individual (Herdt, 2019). 11 In our discussion, we will be using “truth,” “value,” and “telos” interchangeably. As will soon become apparent, moral truths, the sort of truths we are talking about, are ones that can be objectively studied but also involve a call to be adopted, taken seriously, considered with regard to what it means “for me.” This is often what is meant by a value – it contains a necessary, normative, element of the “should.” And it shares meaning with the ancient Greek use of “telos” as an end goal that gives meaning to and shapes the process. This admixture of normative and objective is actually a universal characteristic of the good across all societies (Shweder, 2012; Shweder & Menon, 2014; Shweder & Power, 2013). 12 The German philosopher and psychiatrist Karl Jaspers describes appropriation as the heart of what he calls Lebenspraxis, the existential practice of an examined life (Jaspers, 1938). Taking Moral Action acting, the very definition of reasonableness in practice: a continual movement from one domain (objective reasoning) to another (subjective engaging) which stands at the heart of moral appropriation, or of what it means to put a value into practice. Appropriation in the existential sense does not claim a single leap, but a constant bridging of the tension between objective and subjective reflection, theory and practice, knowing a value and engaging it. Existential value or goal appropriation is qualitatively different from knowing about the value, or from understanding that one’s culture “has” a particular value, or from borrowing someone else’s values, or even from studying a particular value and approving of it. Instead, it is a continuous existential act of being concerned for, focusing on, and being compelled by the greater good.13 And without this continuous commitment, there is no fuel to run the engine that might overcome the judgment–action gap we describe in Chapter 5. s The challenge here is to hold together both learning processes at the same time, the one that reflects on a truth or value per se and the one that reflects on the learner’s of relation to that truth. Both movements complement each other and make for what we call existential appropriation. Where there is no proper objective reflection, subjectivity becomes blind and easily captive to ideology or fecklessness. Where there is no proper subjective reflection, objectivity becomes lifeless and disconnected to daily ro living or dangerously biased in the conception of the good. The persistent hermeneutic cycle14 of objective and subjective reflection describes the tension the moral actor must hold together.15 It is how one moves from merely objective observation of ethical values to personal choice and commitment and thus to the place from which lP motivation to ethical action springs. But there are many values that we are balancing against each other at any time. How do we choose among the values we might apply in any situation? Existential appropriation highlights the teleological task at hand, namely choosing the kind of telos or higher good that guides our moral formation, by ultimately putting our long na list of relative values into place. Social science research on values has recognized this hierarchical nature of values (Cieciuch, Schwartz, & Davidov, 2015). The theologian Paul Tillich (1952), adopting Kierkegaard, speaks of “ultimate concern” to describe this central organizing commitment in one’s life toward “what concerns us ultimately.” Here the existential task goes beyond mere value accumulation by transFi forming or transcending our relative values for the sake of the ultimate, the “value of values.”16 Thus, existential appropriation is itself moral action: it requires interior 13 One can see here how Kierkegaard anticipated current psychological work on moral identity. 14 Kierkegaard’s description of this “double movement” is one progenitor of the hermeneutic philosophical approach (e.g. Gadamer’s hermeneutic circle), which, like Kierkegaard, also draws from the well of Socrates. 15 Kierkegaard’s terms for this are “contemporaneity” or “simultaneity.” 16 In the practical context of professional design work, JafariNaimi, Nathan, and Hargraves (2015) refer to this as the “value of values” that guides design and propose “service to the situations of human life and living” as the overarching goal for design. We have written on this in more detail in the context of value appropriation in software design (Huff & Furchert, 2014, 2023). Moral Formation 253 processes of choosing and prioritizing, of acquiring and giving up, of emotional and motivational change according to what concerns us ultimately, and thus the re-­sorting of all other values in relation to it. (See Chapter 5, Section 5.3.2 for a discussion about how complicated this sorting can be.) This re-­sorting requires evaluating my attachment to certain values and my need to detach from others. I might realize that I am ultimately attached to something that is not ultimate, or that my ethical commitments are rarely leading to engaging them when I feel I should. In the Introduction we present Elizabeth Cheney’s decision to serve on the Select Committee to investigate the attack on the US Capitol as an example of this re-­evaluation process. Thus, existential moral appropriation requires a constantly renewed change of heart. It recognizes the pull of the ultimate (or what one regards as ultimate), which cannot leave one unchanged. While a value merely informs but does not transform the individual, it does not leap into practice either. Hence, existential moral appros priation describes highly transformative interior actions: one strives toward the good (or evil) and at the same time is ultimately challenged and changed by its value.17 One of not only learns something by heart but also takes it to heart. Metaphorically speaking, moral formation requires the “education of the heart,” as Kierkegaard revived it for a postmodern audience, which can be understood as the intimate process of embodied learning that shapes our action in the world. ro 9.1.3 Monastic/Spiritual Formation The formation of the heart metaphorically understood as the moral and spiritual lP center of a person is also a crucial theme in monastic and spiritual formation across traditions. Most of the major religions have traditions of monastic practice in which individuals undergo rigorous training in search of spiritual formation as it is viewed within that religion.18 Self-­transformation is a central aspect of this formation, and moral formation is a foundational aspect of that. For example, Benedictine and Zen na Buddhist monks have exchanged extensive inter-­monastic visitations and they find striking parallels (and some interesting differences) between Benedictine spiritual practice and Zen Buddhist practice, particularly with regard to the lifelong formation of what the Benedictines call humility and the Buddhists call non-­ egocentricity (Augustine, 1986). Fi In these traditions, it is the setting aside of self-­serving commitments that helps to produce an unalloyed approach to loving both the self and others, often embedded in a complex virtue ethics.19 For instance, one can see the importance of humility, the “queen” of all virtues, in an early morality play by the Benedictine Abbess Hildegard 17 For Kierkegaard, thoughtful objective reflection and subjective appropriation (what he calls “double reflection”) should prevent inappropriate surrender to autocracy or ideology. Objective reflection necessarily involves stepping outside of motivated reasoning. The process is supposed to allow the reflector to distinguish relative values from ultimate ones. In practice, it likely involves some of the skills and attitudes we include under evaluative/ self-­transformative moral formation in Section 9.2. 18 Excluding Rabbinic Judaism, which views living in family and the world as itself holy. 19 We need to recognize that the word “self” is being used in multiple ways here, and that the various religious traditions themselves disagree on what might be meant by “the self.” Taking Moral Action of Bingen, Ordo Virtutum. Here, the virtues are personified as ideal archetypes or competencies toward which the self strives (von Bingen, 1141/1982, 1141/1990).20 Constant practice in humility is a central aspect of most Christian approaches to monastic formation, as is non-­egocentricity in Buddhism. The virtues a disciple in Advaita Vedanta Hinduism needs include non-­ attachment to the self and world (Rambachan, 2006); and it is only by achievement of this non-­attachment that one can truly see oneself and others and have compassion. In western Africa one of the most active communities of Muslim Sufism, the Divine Flood Sufism of Ibrahim Niasse, similarly emphasizes the renunciation of the old self (Z. V. Wright, 2015) in order to love others. All these approaches see the development of a non-­egocentric self as an ongoing requirement for the development of a broad set of virtues that themselves are seen as merely foundational for further spiritual progress. These parallels across major religions suggest that there is something in the monastic s journey that requires at least an instrumental goal of establishing a non-­egocentric self, a self that strives first toward a self-­transcendent goal, in order to achieve a healthy relaof tionship with the divine and the world. In all these monastic traditions, humility, or non-­ egocentricity, allows one to truly see/evaluate the self, and to truly have compassion for others. In most discussions of monasticism, these goals are explicitly moral in nature. One might think of humility as simply an emotion, as do Weidman, Cheng, and ro Tracy (2018) who use methods to map the structure of words associated with humility. Monastic traditions think of it more as a combination of skills one practices, attitudes toward the self and others, and appropriate self-­ transcendence. Weinstein, Przybylski, and Ryan (2013) propose three integrative characteristics of self-­regulation lP that sound suspiciously like the understanding of humility present in our traditional accounts: (1) conscious access to one’s emotions, motivations, and values; (2) taking responsibility for one’s emotions, decisions, and thoughts; and (3) non-­defensiveness in response to challenge. The deep monastic traditions across various major religions have also supported a na blossoming of spiritual formation and spiritual care approaches intended for those outside the monastic life. The voluminous writings of Thomas Merton (1948/1998, 1964, 1966, 1975, 2009) are an example of one attempt to make monastic approaches available more widely. The prolific work of the Buddhist monk Thích Nhât́ Hạnh has been widely adopted in the mindfulness movement in psychology (Shapiro & Fi Weisbaum, 2020). Spiritual formation/direction for laypeople in the United States and Europe has been predominantly Christian in its emphasis, and uses techniques and principles from Christian monasticism (e.g. the Jesuit Spiritual Exercises (Dyckman, Garvin, & Liebert, 2001; Houdek, 1996)). It has more recently adapted approaches from the psychological renaissance of mindfulness (Allen & Fry, 2022). And the approach is now being expanded to interreligious approaches seeking common ground across major religions and secular spirituality (Addison, 2000; Cline, 2018; Plante, 2021; Ruffing, 2002). 20 For an introduction to von Bingen’s philosophy, see Furchert (2019). See also Michael Casey’s (2005) An Unexciting Life for a review of the complexities of the several models of monastic formation. Humility plays a central role here, and in monastic formation in most religions. Moral Formation 255 Both monastic and spiritual formation traditions contain aspects of the previous two approaches: Bildung (Section 9.1.1) and existential appropriation (Section 9.1.2). Each emphasizes some form of humility or non-­egocentricity in concert with other values and virtues, and an ongoing process of inquiry and practice as central in the process of moral formation. 9.1.4 Themes and Questions from the Traditions In the following we extract three aspects or themes that all the traditional accounts seem to share, which in turn help us propose a framework for our further investigation of moral formation: 1. Constant evaluation and practice: All three traditions see self-­transformation as s more than change in a cognitive or emotional structure (though they all expect at least this). They also emphasize the requirement for continual practice, for action of that embodies the virtues or moral goals they seek. Bildung is an intentional, guided process of encounter, self-­ evaluation, and transformation. Existential appropriation is a continuous process of putting one’s ultimate commitment into both interior and exterior action. And the monastic tradition involves regular conro sultation with a teacher or elder in a constant practice of moral and spiritual virtues. All three traditions emphasize careful evaluation of the goals and actions and the role of openness to change based on evaluation of one’s practice. A corollary is that much like some models of expertise, though there may be some dramatic moment lP of turning, there is no single “leap” or conversion moment that produces the change, nor is there a final stage where one has arrived. Rather, one always continues in practice and development. 2. Transformation of heart/personality/moral identity in service of a self-­transcendent goal: All three traditions see the appropriation or adoption of some kind of self-­ na transcendent goal as central in the process. Bildung seeks transformation by encounter with the ideal in God, other people and cultures, the humanities, or art and nature. Existential appropriation grapples with the teleological task of choosing one’s ultimate concern and putting this into practice by transcending other, lesser values or projects. Monastic and spiritual formation across (and without) Fi religions requires transformation of the self in encounter with God or the spiritual. Non-­egocentricity plays a central role in this process because the process consists of turning away from a self-­serving goal and toward a self-­transcendent goal. All the traditions see this transformation as anchored both in action/practice and in change of heart, personality, or moral identity. 3. Schooling as an institutional or educative process that supports moral formation: All three traditions view moral formation as some kind of encounter with something outside the self that spurs, guides, and structures moral formation. One among the many forms of Bildung was an explicit renovation in higher education in Germany. Monasticism across all religions involves the construction of moral ecologies that support the study and practice of moral virtues. Existential appropriation sees the maieutic, midwifing pedagogy in personal education as a central support for the individual, though it is suspicious of institutions. Taking Moral Action We use these three themes to develop a framework for three aspects of moral formation: evaluative/self-­transformative (Section 9.2), normative/self-­transcending (Section 9.3), and facilitative/educative (Section 9.4). • The evaluative aspect focuses on intentional encounter, self-­transformative practice, and evaluation. We ask: How does the individual form and evaluate their ­progress (or failure) toward the moral goals and commitments they have set? • The normative aspect focuses on the moral goals/values themselves and on the complex processes of appropriating them, of incorporating them into the self, and thereby transcending the self. These are all processes that have often been overlooked in current research. We ask: Within what value space is moral formation occurring? And how does the individual actor change their relation to these values in s a way that might be called moral formation? • Finally, with facilitative/educative aspects of moral formation we return to moral ecology and ask: How can moral ecology support (or hinder) evaluative and normaof tive moral formation processes? Each aspect of moral formation has its own complexities, which interact with each other in many ways and with the surrounding moral ecology. Distinguishing between ro them allows us to inquire how the aspects overlap, and to integrate many seemingly unrelated literatures. The proposed themes will also help us integrate what has been shown in other chapters into a more focused picture. lP 9.2 Evaluative–Self-­Transformative Aspects of Moral Formation Evaluative moral formation marks those skilled processes by which we evaluate and na attempt to modify our moral actions in light of our moral goals or values. It thus involves recognizing relevant situations and internal states and processes, evaluating them, and making and implementing plans for change in a desired direction. We sketch here an overview of this aspect of moral formation as it has been covered in Chapters 4, 5, and 6. We then consider the narrative level of evaluation, which is not Fi well covered in those chapters. • In Chapter 4, we cover the recent turn toward idiographic models of personality that emphasize how the individual weaves their own path of moral consistency (Cervone, 2021; Mischel, 2004; Wrzus & Roberts, 2017). These models highlight the individual ways people adapt to their perceived environments and integrate a variety of influences in thought, feeling, and behavior, all in a way that allows for a pluralistic understanding of moral personality: that there is no singular moral personality (Wrzus & Roberts, 2017). • In Chapter 5, we suggest three integrative characteristics of self-­regulation that might support appropriate reflection on moral failure:21 (1) conscious awareness of 21 And that look suspiciously like the virtue of humility. See also Eskreis-­Winkler and Fishbach (2022) for a review of the emotional and cognitive barriers to learning from failure. Moral Formation 257 one’s emotions, motivations, and values; (2) taking responsibility for one’s emotions, decisions, and thoughts; and (3) non-­defensiveness in response to challenge (Weinstein et al., 2013). There, we also accumulate the evidence of the conceptual complexity and flexibility of self-­ evaluation that make awareness, responsibility, and non-­defensiveness important virtues in self-­reflection. • In Chapter 6, we review a useful model of personality change that is particularly relevant for evaluating moral formation (Wrzus & Roberts, 2017). The model concentrates on the awareness and evaluation of one’s reactions to a situation and using this evaluation to construct desired expectations for behavior in similar ­situations in the future. These desired expectations can be evaluated when those situations arise again. There we also cover other skills relevant to evaluative moral formation, like self-­regulation, moral attentiveness, and moral imagination. s 9.2.1 Telling Stories of But there is another level at which evaluative moral formation occurs: the narrative. These skills, processes, and influences just mentioned deal well with moral formation focused on high-­level traits (e.g. neuroticism) and mid-­level projects and personality difference (e.g. cynicism) (McAdams, 2013). They do not say much about how we ro tell stories to ourselves about ourselves and how those stories might influence evaluative moral formation. These stories are often designed to connect our past, present, and future in a coherent manner. Stories allow us to see meaning in our lives and guide our lives as we navigate into the future (Bluck et al., 2005; McAdams & lP Pals, 2006). This overarching narrative, woven from a sequence of stories, hopes, and regrets about the self, can be one of the formative influences in a reflective process that guides and monitors moral decisions and plans. Autobiographical memory, and the narratives we construct from it, have a significant directive function in our lives. These narratives help maintain personal identity na over time (exerting some consistency pressure) and guide the planning and nurturing of current and future social interactions (another kind of directive influence) (Bluck et al., 2005; Rasmussen & Habermas, 2011). Narratives have been shown, for example, to be central in constructing a sense of agency for those in psychotherapy, with the agency in turn becoming a leading indicator of therapeutic benefit (Adler, 2013; Fi Adler, Wagner, & McAdams, 2007). Thus, looking forward, we construct our agency in narrative and those narratives directly guide choice and planning (Bluck et al., 2005). Looking backward, we are especially motivated to make narrative sense out of negative occurrences and this reconstruction impacts our agency in helping others (McAdams et al., 2001). How can narrative play a role as an arbiter in evaluative moral reasoning? “Telling a story” can have evaluative force because it contains autobiographical reasoning, the set of interpretive actions used to make sense of who we are, where we have been and where we are going. Indicators of structural quality in a narrative (indicative of coherence) include believable causal chains, reactions, and descriptions, finding growth or regression over time, connecting episodes with clear beginnings and endings, ­foreshadowing, and retrospective review (Adler et al., 2015). Other narrative content that can bring evaluative force on behavior includes themes of motivation (agency, autonomy, generativity, intimacy, etc.), affect (positive or negative tone, redemption, Taking Moral Action contamination, anger, fear, etc.), and integrative meaning (change in moral identity, integration of contradictory themes) (Adler et al., 2015). The specific content of these themes in the narrative one constructs has implications for how the past and present are to be morally evaluated and how the future ought to be planned. Is there any evidence that narrative content has implications for evaluative moral formation? There is at least clear evidence that this narrative aspect helps to distinguish moral exemplars – individuals who are widely agreed to be admirable moral models – from those whose lives may be conventionally moral but are not centered on morality. And there is much work that suggests that narratives are central in guiding the moral formation process in moral exemplars. As part of an extensive research program that has compared moral exemplars to matched controls, Walker and Frimer (2015) did not find differences in personality traits or values, but did find differences at the narrative level. Moral exemplars’ stories s more often emphasized early secure attachment to parental figures, a lack of early enemies, and the presence of early support. In comparison to controls, their narratives of (but not trait scores) had more positive affective tone, were more likely to positively appraise interpersonal communication, and had language that tended to emphasize the needs of others. Finally, the stories exemplars told also tended to see good coming out of bad occurrences (a redemption theme, McAdams et al., 2001). These individual ro stories are woven together into a narrative of the self with implications for current and future moral action (Lapsley, 2016): actions such as nurturing current social relationships and guiding the development of future relationships (Bluck et al., 2005). Colby and Damon (1992) see this embedding of the moral exemplar in relationships that lP guide their careers as a central aspect of the development of moral exemplars. Still, there is very little work on the specific processes by which narratives guide evaluations of the self or constrain future moral action. The processes outlined by Wrzus and Roberts (2017) in Chapter 6 can surely be adapted to incorporate the ­ arrative level.22 One can imagine additional ways narrative might be recruited in n na moral formation (e.g. see Section 9.4.3). 9.2.2 Critique from the Three Traditions In sum, we have a vast and complex research literature, spread across several chapters Fi of this text, on how individuals might evaluate their performance in achieving their moral goals. Some attempts have been made to integrate and unify these ideas (e.g. Wrzus & Roberts, 2017). But even these integrations do not give us the practical programmatic approach to moral evaluation that some of the traditional accounts do. Monastic and spiritual formation traditions have detailed and rich approaches to self-­ examination (e.g. the dokusan interview in Zen Buddhism or Jesuit spiritual exercises in Christianity). Bildung has produced detailed narrative accounts of its individual practice and programmatic revisions to higher education in the service of its goal. Most psychological research in moral psychology has yet to be connected to such practical applications in any systematic way. 22 As can the processes found in the traditional accounts, and those in clinical psychology, religious conversion, and volunteerism. The traditional accounts seem to fit much better to this narrative aspect of evaluative moral formation. Moral Formation 259 In addition, one can see from the tradition of existential appropriation that the distinction between evaluative and normative is not as clear as our presentation would have it. In fact, the evaluative necessarily leads us to the normative. It cannot be disconnected. Only a robust set of defense mechanisms, rigidly deployed, can keep us from evaluating whether we are in fact caring about the right things. The “what” of our goals and the “how” of our relation to them need to be kept in constant tension. This is part of the dynamic that Colby and Damon (1992) explore that draws exemplars ever further into broader commitment as they evaluate their current commitments. Psychological research on evaluative moral formation could benefit in many ways from conversations with these traditions. 9.3 Normative/Self-­Transcending Aspects s of Moral Formation of Much of what we call the psychology of moral action consists of processes (e.g. self-­ regulation, etc.) that can be analyzed in a content-­free manner. That is, one can easily imagine a wide range of goals, values, or narratives that could drive these processes. For example, careful evaluative moral formation can serve a person’s goal of becoming more ro compassionate or ruthless in pursuit of a supreme value (Côté et al., 2011). Evaluative moral formation can be based on a narrative of good coming from the bad or a narrative of the constant, enervating resurgence of failure (McAdams et al., 2001). Moral attentiveness can be focused on threat from the outsider and compassion only for the lP insider (Hart, 2005b; Hart & Carlo, 2005). How can we find some structure in this confusing variation in values, ideals, goals, and projects that can direct both moral and immoral action? 9.3.1 Value Dimensions of Normative Formation na We have often mentioned pluralism in values in this book. What is the landscape of the variety of values from which people select some subset to guide their moral formation? If we want to become good, how do we determine what the good looks like? There are a wide array of works that identify dimensions of value in motivation content and little convergence among them.23 There is even disagreement about the Fi ultimate goal within and among the three humanistic traditions with which we began the chapter. Despite this disagreement and confusion, we will nevertheless attempt to systematize the variety of content and meaning that is relevant to moral becoming. It is easy to multiply examples of the different content and values that can drive moral formation. It is less easy to bring some structure to the diversity in a way that helps us understand it. In this section we will, in the Humboldtian spirit, be looking for the diversity and the structure in this wide variation. What are the various kinds of values, goals, projects, etc. that motivate moral action?24 Can we organize them in some way that allows us to understand their interrelationship? 23 This is in part because there are so many options and so little theoretical integration. See n. 5 for an incomplete listing of approaches and systems. 24 To see a more in-­depth discussion of values as self-­transcendent or ultimate, see the Introduction and Chapter 5. Taking Moral Action All developmental moral psychology presumes some movement in values (e.g. from self-­centeredness to the inclusion of others). It is implicit in the notion of development or formation that it is not mere change but movement toward some ideal or telos (Schachter & Ben Hur, 2019; Schnitker, King, & Houltberg, 2019). If we construct a space of values, goals, or projects relevant to moral action, how might the choosing individual move among them in commitment in a way that could be called formation? Thus, the questions we ask in this section are: Within what value space is moral formation occurring? And how does the individual actor attach or change their attachment to these values in a way that might be called moral formation?25 To engage these questions, we will look at five dimensions of the landscape of goals and values toward which one might orient moral formation, and from them construct a complex-­enough three-­dimensional space within which it would be productive to track moral formation and change. s 9.3.1.1 Self-­Transcendence In the Introduction, we proposed an existential turn (Section I.6.1) that reminds us of the need for self-­transcendence to move from of simply knowing that a value, ideal, or project has value to actually appropriating that value in one’s own life. It is how one moves from merely objective observation of ethical values to personal choice and commitment, and thus to the place from which motivation to moral action springs. We argued there that this turn opens up the self ro to transcendence to the variety of goals, values, or projects that might be treated as ultimate by the individual. This is a move away from attachment to self-­serving values to ultimate attachment to the greater good, or to ultimate values. lP SelfTranscendence UniversSelfalism Direction na Openness to Benevolence Change Stimulation Fi Conformity Tradition Hedonism Security Conservation Achievement Power SelfEnhancement Figure 9.1 Schwartz circle of value regions. Source: Adapted from Borg, Bardi, and Schwartz (2015). 25 These two questions mirror Kierkegaard’s distinction between the what and the how of existential appropriation. Moral Formation 261 In Chapter 3 (Figure 3.1) we introduced a cross-­culturally valid model of values that sees them as arranged around a circle in opposing pairs, with values near to each other on the circle being more compatible (reproduced here as Figure 9.1 for reader convenience). In it, one can see that self-­enhancement (lower left) is opposed, across the circle, to self-­transcendence (upper right). And at a near right angle to this is a dimension ranging from conservation (right) to openness to change (left). This is a second dimension in the value space that we will discuss in Section 9.3.1.2. The two dimensions form a circle with more specific values arranged around the circumference. The approach is based on the idea that cultures and individuals find themselves somewhere within the circle at a balance point between the various opposing values, endorsing all to some extent, but favoring some over others.26 The circle provides a structure for the characteristic ways that cultures and individuals balance these values (Borg, Bardi, & Schwartz, 2017). s In Section 9.3.3, we will review extensive work by Walker and Frimer suggesting that there is interesting individual development over the life span on the dimension of of self-­transcendence, e.g. not just a simple movement from one to the other but an integration of the two ends of the dimension, with self-­enhancement serving the goal of self-­transcendence (Walker & Frimer, 2015). This crucial developmental sequence makes it clear that self-­transcendence will be important to include in any model of ro moral formation. We cover this dimension in greater detail in that section. We label it as self-­transcendence in part to connect it to other literatures (Frankl, 1997; Koltko-­ Rivera, 2006; Maslow, 1969) and in part to allow Humboldtian space for the wide variety of values or projects for which people self-­transcend.27 lP The self-­transcendent end of this dimension needs to be considered at the idiographic level, because it is open with regards to the particular goal or telos of self-­ transcendence that each person might choose. See Section 9.6.1.5 on specific commitments and projects to get some idea of the diversity we are including here. Here, self-­transcendence is more the task or process required than the end goal itself, na which is complex and widely variable. Further, for each individual self-­transcendence may be more complicated than one goal. Here, the complexity of the self and its commitments that we outline in Chapter 5 becomes evident. One might have moderate Fi 26 This is a pictorial way of interpreting the rank ordering of the various values by ­different cultures (Schwartz, 2016; Schwartz et al., 2012). Empirical reality is a bit more complicated. Rank orderings in some cultures do not preserve the order of the circumplex (Schwartz, 2006), and thus the geometric balance point interpretation we offer here founders in these instances. The recruitment of one value in the service of another that we explain in Section 9.3.3 may help to understand some of these inversions. 27 Names of dimensions like these are always negotiable. Walker and Frimer (2015) replace “self-­enhancement” with “agency” and “self-­transcendence” with “communion” as their labels for the endpoints of this dimension, in part to connect it to other literatures. We prefer self-­transcendence in order to emphasize the multitude of non-­social goods to which one might be devoted (religion, art, environment, etc.). See the discussions in the Introduction and in Chapter 5. It is important to note that the label “self-­transcendence” here is not in itself a value, goal, or project. It is, rather, a stand in for the multitude of goods for which individuals might self-­transcend and that they might take as ultimate. This fundamentally alters the dimension by not anchoring this end in pro-­social values, while still allowing them among other ends. Taking Moral Action self-­transcendence toward the value of compassion (producing a general pro-­social attitude) and passionate, even ultimate, dedication to family or some other life project. These values might be integrated in some way (e.g. with compassion as the theme in a particular narrow project) or exist in tension across separate domains of the multidimensional self (e.g. work projects vs. family commitments). And to the extent that a particular value or goal is really considered to be ultimate, there should be tension to integrate it across the separate domains of the self. The point of ultimate value is that for some people, at least in some domains of their life, some value, telos, or life project is taken as the most important thing. And for some people, this extends over all domains in their life. We must include a caution here on recognizing the multiplicity of possible goals in self-­transcendence. Some goals for which people sacrifice themselves involve causing harm to others. Koltko-­Rivera (2006) grapples with this difficulty in his review of s Maslow’s understanding of self-­transcendence and admits that terrorism and other forms of evil can, at the idiographic level of personal commitments, look a great deal of like self-­transcendence. Thus, commitment to a self-­transcendent goal has a dark side (Hart & Carlo, 2005; Skitka, 2014; Skitka & Mullen, 2002; Washburn & Skitka, 2017). Scholars will need to do the work to distinguish between the goals. It may be that the psychological processes are very similar if not identical. Perhaps some ro of the other dimensions we list in Sections 9.3.1.2–9.3.1.5 will help us do so (e.g. inclusion). Opening up this dimension to this puzzle of identifying appropriate ultimate goals allows us to frame the problem of the crucial and unavoidable work of distinguishing what the good is and whether how we become good is the same prolP cess as how we become evil. This brings us back to the idiographic struggles of each individual as they engage in their teleological task of contemplating their ultimate concern (see Section 9.1.2). 9.3.1.2 Openness to Change The second dimension in the figure is openness vs. na conservation. This seems to be treated more as a personality characteristic that does not change much over time. Research seems to focus mostly on the ways this dimension tracks the (supposedly static) liberal – conservative continuum in the United States. But we might also find some interaction between trajectories in the two dimensions. Those with conservation commitments might show a different pattern of development Fi from self-­enhancement to self-­ transcendence than those with commitments to openness. This is speculation at this point, but one can imagine those who mature on the self-­ transcendence dimension in politically or institutionally or culturally conservative households might select very different kinds of life projects than those who might mature in households that value political, institutional, or cultural change. Seeing these two dimensions as forming a moral formation space allows us to ask these questions, and again to expand the space of what is moral and how people choose to be moral. 9.3.1.3 Inclusion/Exclusion This dimension is the extent to which we include others in our understanding of those deserving of moral consideration. The move from self-­ enhancement to self-­transcendence does not remove us from the messy difficulties of deciding for whom one should have compassion, or how others are included in one’s religious commitments, or for whom social justice is important. How wide should Moral Formation 263 one’s circle of concern be? We should note that the value circumplex model has “universalism” as one value at the self-­transcendence end of the dimension. And this suggests that the more one endorses or appropriates communion the wider one’s circle of concern should be. But the Schwartz (2016) model is based on averages across many people, and there may well be those for whom self-­transcendence does not entail opening wide the gates to all. For instance, we already know there are sub-­types of moral exemplars. The distinctiveness of two of the sub-­types (helper vs. reformer, see Chapter 3, Section 3.2.1.4) consists in part in for whom they are moral. Helpers care for certain individuals with needs, and do not much concentrate on societal change. Reformers want to change systems as an instrumental goal in service of producing justice or care for others.28 The latter may be more universalist in their embrace of others, while some helpers may be more restrictive in their compassion. The “deserving poor” is a standard trope s for those who want to limit social assistance. Still, even reformers limit their focus to particular social justice issues, and thus leave out those affected by the neglected of issues. A more theoretically targeted selection of moral exemplars might help us grasp some of the variation in ways that people do good and the extent of inclusion of others in that moral action. Susan Opotow explores this dynamic of with whom one values communion under ro the label moral inclusion/exclusion (Clayton & Opotow, 2003; Opotow, 2001, 2005) and we adopt this language for this dimension. She has reviewed how moral exclusion is constructed in a moral ecology (Opotow, 2001) and how programs stressing moral inclusion can help to reduce violence and injustice (Opotow, 2005). Others have lP begun to investigate what they call moral expansiveness, the inclusion of a wide range of others in their circle of concern. This work has shown expansiveness to uniquely predict willingness to prioritize humanitarian and environmental concern over personal and national interest (Crimston et al., 2016). Similarly, Graham et al. (2017) propose centrifugal and centripetal forces and frame them as separate and competing na pressures to form some balance along a continuum they call the moral circle. And, of course, work on altruism that used in-­depth interviews with those who helped Jews escape the Holocaust found a personality characteristic called extensivity (the extent to which one included others in the circle of moral concern) to best differentiate between those who helped and those who did not (Einolf, 2010; Oliner & Fi Oliner, 1988). These parallel theoretical accounts suggest there is likely another important dimension along which normative moral formation can take place. One might have great integrity about justice and care for those we include in the deserving community, while being callous and uncaring for those “other people.” We show a different moral face to those who are “them” than we do to those who are “us.” One can also limit one’s moral horizon without overt prejudice, by unexamined or intentional parochialism. Again, the Munsons (see the Introduction) serve as an example. At what point in their progression of commitment do they become exemplary? Even at the beginning, 28 One can, of course, do both or neither, as do some of the exemplars from Huff and Barnard (2009). Those doing neither were focused on more specific projects like mentoring (see Section 9.3.1.4 for what specific projects might look like). Taking Moral Action when caring only for their own foster children, they are self-­transcending, but their self-­transcendence is inclusive of only a small circle. We know a little about what might influence the inclusion dimension relevant to normative moral formation. It seems to be flexible depending on moral framing and domain but also reliably related to the development of moral identity.29 Its flexibility is influenced in part by empathy. In everyday life, we primarily experience empathy for close others rather than those at a distance (Depow, Frances, & Inzlicht, 2021). However, empathy is not inherently exclusive and one can frame judgments in a way that fosters egalitarian empathy (Fowler, Law, & Gaesser, 2021). One can likewise frame judgments in ways that encourage “virtuous violence” against the other (Cohen-­Chen, Pliskin, & Goldenberg, 2020; Fiske & Rai, 2014). Cultural preferences for tight framing of moral constraints and the moral circle can anchor inclusion but also change it as the culture reacts to external threats (Gelfand, 2012, 2021; s J. C. Wright, 2021). There is some evidence that higher levels of moral identity are associated with a of wider “circle of moral regard” (Aquino et al., 2006; Reed & Aquino, 2003). And even for those who value group loyalty, commitment to moral identity reduces the extent to which they are willing to endorse torture in its service (Smith et al., 2014). This at least allows us to say that even though conservative and liberal value commitro ments might look different, if they have integrated morality into their identity one can expect they will share some values (Frimer, Tell, & Haidt, 2015). So, we may need to differentiate between inclusion with regard to basic humanity (e.g. appropriate targets for compassion and human rights) and an inclusion that involves a more lP complete reception, incorporation of, and obligation to the other. Beyond simple viewing of others as part of “us,” participation within a community helps to construct our sense of self. Seeing one’s self as socially connected influences compassion and socially responsible behavior (Cojuharenco, Cornelissen, & Karelaia, 2016; Cross, Bacon, & Morris, 2000; Day & Impett, 2018; Vignoles, 2018). na In a longitudinal study of high-­school students, Pratt et al. (2003) found that self-­ ideal (measured by self-­report of traits one strives for, such as being a good citizen, fair, just, caring) predicted community involvement, but over time it was community involvement that led to increases of these self-­ideal traits. Thus, active participation in community can produce a virtuous cycle of self-­ascription of traits, followed by furFi ther community service. Hart (2005a, p. 260) argues that “If the notion of identity is to contribute to an understanding of moral functioning, then it must be a construct with deep roots in a social world.” As we consider incorporating inclusion/exclusion in our moral space, these roots will need to be both deep and specific to each individual and his or her personal history and moral ecology. Piliavin and colleagues (Grube & Piliavin, 2000; Piliavin & Callero, 1991) have shown the importance of “specific role identity” (as, e.g. a blood donor or a cancer society volunteer) in supporting volunteer activity. Rule and Bebeau (2005) and Huff and Barnard (2009) have also tracked the importance of specific 29 Graham et al. (2017) provide a short history of the use of this dimension and survey a host of factors that can influence one’s position on the dimension. Moral Formation 265 identity themes in professions. The extent to which these specific commitments limit or facilitate moral inclusion is as yet unexplored. 9.3.1.4 Rules vs. Goals We also need to consider the possibility that, for many people, or even for most people at one time or another, morality is not really about the pursuit of moral goals but instead the following of moral rules that serve as guardrails. Most professional codes of ethics include two types of items: things one ought not to do, and moral ideals one should approach (Harris, 2008). In Chapter 6, we explored Kuhl and Koole’s (2004) distinction between the self-­control system and the self-­maintenance system. This is roughly the distinction between those processes that help the person focus on the task at hand and avoid temptation and those processes that direct the person to take valued action. In the domain of engineering, the philosopher Charles Harris (2008) presents a s parallel distinction between preventive values and aspirational values. Preventive values are about “not violating moral rules.” These constitute about 80% of the text of the of National Society of Professional Engineers code of ethics and are essentially negative in form (e.g. not approving documents that do not conform to standards). Aspirational values are about approaching moral goals or values. Harris (2008) gives examples of designing safety into engineering systems that goes beyond codes and standards, eviro dencing a deep commitment to safe engineering, or to environmentally thoughtful engineering, or to engineering that takes its social embedding and impacts seriously. Similarly, Janoff-­Bulman and Carnes (2018) use the basic motivational processes of approach (prescriptive) and avoidance (proscriptive) to frame a model of moral lP motives that operates at three levels, the intrapersonal, the interpersonal, and the collective. This taxonomy provides useful insight, for instance, into the differences one finds at the collective level between conservatives, (who favor social order – an ­avoidance goal) and liberals (who favor social justice – an approach goal). Thus, the domain of moral rules and obligations (e.g. do not lie, cheat, plagiarize) na may well be associated with the self-­control system and have its own trajectory in moral formation. And the domain of aspirational goals (e.g. be a blood donor, care for the poor) may be associated with the self-­enhancement system, particularly when these moral goals are an important part of the self (Cervone & Tripathi, 2009).30 Additionally, each system may have its own distinctive pull on the moral action of Fi the individual. As Nucci (2004) notes, even if individuals do not have morality as a defining aspect of the self (and are thus not engaging the self-­enhancement system in the service of moral goals), there is still something about the moral domain that makes it difficult simply to ignore rules. “I’m not good at academics,” sounds qualitatively different (and much less dangerous) than “I’m not good at morality.” We expect the pull of rule-­based, inhibitory, preventative morality to be widely shared, even by those for whom moral goals are not central to the self.31 But there is very little work on how these two systems interact or how the two different kinds of moral motivations differ. See Chapter 6 for more on this distinction. 30 But we make exceptions for (and even inversions of) those rules when it comes to treating 31 outsiders and enemies (Cohen-­Chen et al., 2020; Fiske & Rai, 2014). Taking Moral Action 9.3.1.5 Specific Commitments and Projects So far, this discussion is operating at a highly abstract level of general themes in morality (self-­ enhancement and transcendence, moral identity, moral exclusion, rule following) rather than the concrete particulars of the specific causes to which people normally dedicate themselves.32 It seems likely, however, that the process is not one of becoming good at this abstract level, but more one of becoming good by being attached to a specific, concrete, personal moral goal (rather than an abstract value like communion, or even more vague, self-­ transcendence). Across all the research on exemplars, moral commitment appears to be particular. Despite Suzie Valadez speaking of God’s call to love all people, the people she serves are the poor “people of the dump” in Ciudad-­ Juarez, Mexico (Colby & Damon, 1992, chapter 3). Even though Stephen Engberg is committed to privacy rights and speaks at this abstract level, the particular privacy he cares about is in the design of business software in Denmark (Huff & Barnard, 2009). s Though Walker and Frimer (2007, p. 848) identified value dimensions behind particular concrete commitments, their exemplars were selected because they showed of concrete “extraordinary and long-­term commitment in providing care to individuals or groups, [or to] community service or humanitarian causes.” How do we get from smaller, concrete commitments to larger, more abstract ones? Colby and Damon (1992) propose a process that might lead from local, particular moral commitments ro to broader commitments and offer several examples of that process in their exemplars. They call these environmental personal growth affordances. But only a few of their exemplars show a clear pattern from specific to general.33 The more common development seems to be from lower to higher levels of commitment within a specific lP domain. In a similar vein, Koltko-­Rivera (2006, p. 302) explores Maslow’s concept of self-­ transcendence as “a motivational step beyond self-­actualization.” It is also clear here that the motivation is particular, as self-­transcendence may involve “service to others, devotion to an ideal (e.g., truth, art) or a cause (e.g., social justice, environmentalism, na the pursuit of science, a religious faith), and/or a desire to be united with what is perceived as transcendent or divine” (Koltko-­Rivera, 2006, p. 303). A similar pattern can be seen in research on how participation in volunteering or social activist work affects those who volunteer. A classic example is the study by McAdam (1989) on the effects of the 1964 Mississippi Freedom Summer project on Fi 212 participants in the project, as compared to 118 who signed up, were accepted, but did not go.34 Compared to the no-­shows, the participants were still deeply engaged in politics twenty years later, were more likely to be unmarried, have lower income, and to be concentrated in the helping professions (e.g. teaching). The study 32 Frimer et al.’s approach to categorizing agency and communion as terminal or instrumental involves either interviews in which people must identify values as terminal or an elaborate coding approach that finds the abstract themes in the text of the interview (Frimer et al., 2011). It is at this level of abstraction that they find patterns. In most of the interviews, their participants speak movingly about commitments to specific projects and actions. 33 We know of no other systematic data on this trajectory or its influences. 34 These were volunteers from all over the United States who came to Mississippi for a summer focused on civil-­rights organizing, non-­violent demonstration, and civil disobedience in support of civil rights for African Americans, particularly in the Jim Crow south. Moral Formation 267 is based on the completed applications of the two groups (obtained from archives) and a follow-­up survey sent to them in the late 1980s. The no-­shows “did not differ significantly from the participants in the values they brought to the project … [and] appear as essentially alike on a list of variables: race, social class, type of neighborhood, home region, type of school, and major in school” (McAdam, 1989, p. 749) But participation in the Freedom Summer likely affected their self-­concept and their later work (and even romantic partner) choices. The intertwining of personality, moral identity, skills and knowledge, and moral ecology are quite complicated here (see e.g. Bosi, 2016; Giugni, 2004; McAdam, 1989) but the effects of immersion in the complex moral ecology of civil resistance seem undeniable. By choosing to dedicate their summer to this project, the participants instigated a change in the national consciousness but also in their own. Abstract level commitments can also spawn particular concrete commitments. s Sophie Scholl was committed to the White Rose resistance movement because, in part, she was committed to exposing the injustice of the German regime in WWII of (see Introduction, Section I.3 and Coda). The more general commitment to support oppressed groups that one finds on the left in Western countries has been shown to be a source of extreme commitments to particular outgroups (e.g. Palestinians, Kurds) based on the perception of the group as unjustly oppressed. In some cases, ro identification with the oppressed out-­group (e.g. Kurds) is even stronger than identification with their own in-­group (e.g. Canadians), producing an interesting inversion of the inclusion dimension (Kunst et al., 2018). It seems likely, though, that most people with extraordinary levels of commitment lP to a particular cause did not decide to “become good” at a general level but instead had some initial attraction to a particular project (perhaps articulated as a more general ideal) and then became more committed. One may not plan to make high levels of commitment to a cause, but one could instead stumble upon or be drawn into it. This attraction itself might be based on previous value commitments that were free-­floating na and unattached to any specific cause. But there is very little research that would help us untangle the precedence of commitment to abstract values vs. specific causes. The philosopher Gadamer’s work on the problem of application (Gadamer, 1975, 1996) suggests that specific commitments in applied domains are unlikely to be the simple “application” of general commitments and principles to that domain. Moral Fi action at the level of commitment to these particular causes (Palestinians, Kurds, civil rights, etc.) or domains (e.g. engineering, medicine) is often thought of as simply applying knowledge (e.g. about rights) to specific cases (e.g. civil rights). But careful analysis of the problem of understanding in “application” suggests that there is knowledge and truth to be discovered in the process of application itself, knowledge that is unavailable from abstract knowledge of the domain. Knowing about privacy rights, for instance, is only a very small part of what one needs to “know” to be able to design software that protects privacy (Huff & Furchert, 2014). Movement back and forth from a specific application area to general principles seems more likely than top–down application. Goal-­directed moral formation does not have to be an entirely conscious process. Our goals can guide the focus of our attention, and this influence can happen outside of conscious awareness (Dijksterhuis & Aarts, 2010). This influence is particularly evident when those goals are ones that have been practiced to the point that pursuit of them has become habitual (Aarts & Dijksterhuis, 2000). Taking Moral Action As a part of the general pattern of development from agency to communion, there is clearly an increase in commitment to communion values from childhood through early adulthood. At this point, we know only that this trajectory has been documented. We have no evidence that it is the only trajectory that one would want to call moral formation, and some evidence that alternative paths exist. We know little about what individual differences or moral ecological influences there are on the trajectory. And, except among moral exemplars, we know little about the trajectory or its variation or influences among adults and older adults. 9.3.2 A Three-­Dimensional Moral Formation Space: Self-­Transcendence, Openness, and Inclusion We have just reviewed five dimensions (self-­transcendence, openness to change, inclusion, s rules, and specific projects) on which one might look for variation in values and commitments. One implication of this review is that there is a need for thoughtful integraof tion of the possible dimensions of the value landscape in moral action. With this tentative map of the landscape, we can document some movement within it that might count as normative moral formation – the choosing and appropriation of moral goals and the process of putting the normative into action. The appropriate criterion ro for success of any dimensional model is not whether the dimensions are “real” but whether they are helpful in discovering patterns and variation in moral formation and change. Our interest here is identifying a manageable subset that allows us to grasp the complexity of the differences in the good, or in moral commitments. lP We begin by leaving aside two possible candidates. The space of specific commitments and projects (Section 9.3.1.4) is simply too diverse to provide much explanatory power at the nomothetic level of averaged tendencies among many people.35 The rule–goal distinction (Section 9.3.1.4) is more of a dichotomy than a space within which formation might occur. And particular rules and goals are legion – see the lists na of rules and goals in any professional code of ethics. We are left with a three-­dimensional landscape that we will lightheartedly label TOI: self-­transcendence, openness, and inclusion.36 The dimension of transcendence is about what goal is chosen, while the other two are focused on how and for whom that goal is approached or implemented. One can imagine (and there appear to be Fi documented instances of) people moving along one dimension without much change on the other two.37 There is a significant research literature associated with the moral 35 One could reduce the complexity by forming types of projects (e.g. social justice, artistic, helping, etc.) in the same way one might think of types of goals for self-­transcendence. 36 Pronounced “toy.” 37 Movement within this space might also occur at several different levels of personality. McAdams (2013, p. 276) borrows language from William James (1892/1963) to ask the question: “What does the I see when it looks on the Me?” He proposes three ways or aspects of how this might happen, actor, agent, and author. In terms of moral formation process we might call these becoming good (actor), seeking particular goods (agent), and moral authorship (author). This additional layer of complexity in moral formation provides even more richness in how people shape their formation and gives the opportunity for further labyrinths of self-­deception or surprises of moral critique and insight. Moral Formation 269 aspects of each dimension. This alone argues that the dimensions in themselves are important for moral formation. And they do seem to be dimensional, allowing for various positions along a continuum (or perhaps multiple positions depending on the domain). Whether they are independent dimensions is a matter for empirical study, though work we reviewed in Sections 9.3.1.1–9.3.1.3 suggests patterns in which they may be somewhat correlated. The point of constructing a dimensional model like this is to open up exploration in the variety of ways people make moral commitments and take moral action. It helps to structure and identify the different ways people might self-­transcend. Those who transcend the self in service of a project might be committed (or resistant) to social change and shape their project or value commitments accordingly. Or they may be narrowly focused on helping a particular group, or motivated by the threat they perceive from another group. Exploring these variations in openness and inclusion will s expand our grasp of the many ways people embody moral action. of 9.3.3 Direction of Change in Moral Formation In addition to variation across individuals in value commitment, one can find variation across time in a person’s life. Schwartz (2006, Table 1) reports, for instance, that ro values of agentic self-­enhancement decrease over the life span in a variety of cultures, while communal self-­transcending values increase over the life span. Over time, how might we become more involved in pro-­social roles, or more committed to moral strivings and goals, or able to more thoroughly integrate themes of lP moral action into our life narratives? Can we even do so? Do most people’s values “improve with age … develop in the direction of greater tolerance, or wisdom or some other imagined enlightened state” (McAdams, 2015, p. 233)? There is surely a developmental progression in the moral domain from infancy to adolescence in terms of greater complexity and more pro-­social orientation. Kohlberg’s research program na in moral judgment documented this, as has much developmental research since then (see Gibbs et al., 2007; Lapsley, 2020; Lapsley & Hardy, 2017 for reviews). But is there “improvement with age” over time for adults? Schwartz’s (2006) cross cultural research program in values regularly shows increases in values of benevolence across the life span. However, beyond this documentation there is little systematic evidence. Fi McAdams (2015, p. 234) answers his question thus: “Scientific evidence for such a romantic view is sparse.” In fact, looking for simple value change over time may run into the same complexities that at one time led social and personality psychologists to conclude that there were no stable effects of personality on behavior (Mischel, 1968, 2004). Recall the fruitless search for consistency in “honest” behavior in children across situations by Hartshorne and May (1928). Only after decades of research did more sophisticated efforts find complex patterns of consistency that differed from one individual to the next (Cervone, 2004; Roberts & Wood, 2006; Shoda, LeeTiernan, & Mischel, 2002).38 A similar pattern may be emerging in normative moral formation. 38 See Chapter 4 for more on this. Taking Moral Action In a groundbreaking series of studies, the Canadian psychologists Walker, Frimer, and their colleagues (Frimer et al., 2011; Frimer et al., 2012; Walker & Frimer, 2015) have been identifying complex patterns of value change across the lifespan that they argue can clearly be labeled as moral development. They have documented changes in value themes in adolescents to adults and linked these changes to either actual moral behavior (as seen in moral exemplars) or to self-­reports of moral behavior. They are thus building a foundation for an argument about moral formation across the life span. They situate their research program within the value space provided by Schwartz’s value circumplex. Their central finding shows a move from characteristic adolescent endorsement of agentic values (e.g. personal achievement and competence values, on the lower left side of the Schwartz circle) to communal values in adulthood (e.g. benevolence and universal care values, on the upper right side of the circle).39 But this change is characterized by a certain complexity. The movement is not simply from s endorsement of one value to the other but also involves the way the value is endorsed. As adolescents and adults make this developmental transition they move from (1) seeof ing agency as more important than communion, to (2) seeing them as both valuable, and then (3) transforming their valuation of agency by seeing it as a means to ­achieving communion. Thus, agency is at first a terminal value, valued for its own sake, but later becomes at least in part an instrumental value, valued because it is instrumental in ro achieving communion. Their evidence for this transformation comes from a series of studies done with adolescents and adults using both qualitative and quantitative approaches (Dunlop, Walker, & Matsuba, 2013; Frimer, 2012; Frimer & Walker, 2009; Frimer et al., 2011; Frimer et al., 2012; Walker & Frimer, 2015). lP This research program suggests a developmental trajectory in the moral domain: that “displacing agency with communion as the terminal value should be a fundamental goal for moral development” (Walker & Frimer, 2015, p. 430). Note that with this claim, we have crossed the boundary from descriptive claims to normative claims: communion as the terminal value “should be a fundamental goal.” This move na from the empirical to the normative parallels Kohlberg’s earlier claim that he had found an empirical foundation for a normative ethic (Kohlberg, 1971). This approach is a slightly stronger claim than Kohlberg’s in that it is based in part on empirical observation of moral exemplars. This trajectory of displacing agency with communion may itself vary among individuals depending on what other value commitments Fi they have. For the sake of accuracy, we have presented the work of Walker and Frimer (2015) so far using the terms they prefer, agency and communion. But, given our Humboldtian approach, we have spent much of the book arguing that there are multiple goals, values, or projects one might call ultimate, and therefore anchor the moral realm for the individual who chooses that goal as ultimate. So, we have been using the terms self-­enhancing and self-­transcending to encompass all the possible values, goals, projects, etc. that people might take as ultimate concerns.40 39 As we discuss this research program, we will use the original dimension names (agency vs. communion) from Walker and Frimer (2015), rather than our preferred labels of self-­ enhancement to self-­transcendence. 40 In agreement with the dimensional terms originally used by Borg et al. (2015). Moral Formation 271 The heart of moral formation is this self-­ transcending value–goal–project ­appropriation process. It includes not just an internal reorganization of commitments but also skilled action, putting the self-­transcendent commitment into practice. The psychological question is: How do these processes of commitment and enacting work? One answer is to look to social–emotional–reflective equilibrium (SERE). One might think that this sort of embodied commitment to a self-­transcendent goal conflicts with the idea of equilibrium that we have identified in Chapters 7 and 8 (among others). Self-­transcendence, at least at its extremes, can produce extraordinary and life-­altering commitment for some moral exemplars. But the two concepts are really just different aspects of the same process. Equilibrium in SERE does not mean finding the easiest path but the most appropriate and practically viable answer to the question: What does a person like me do in a situation like this? When we commit to a self-­transcendent goal, we are still left with the everyday difficulties of imples menting our goals and intentions in the historical situations in which we find ourselves. It is in fact the continued practice of SERE within ongoing moral action (and the of continued practice of self-­transcendence within SERE) that makes self-­transcendent moral action possible. ro 9.3.4 Critique from the Three Traditions The issue of inclusion, for whom moral identity is relevant, is rarely addressed in the moral psychology literature. Both Bildung and monastic traditions make it central. Bildung is at its roots aristocratic, but it can provide a platform to embrace wide cullP tural diversity. Monastic and spiritual formation traditions across religions also view compassion for the other as central to development, though they emphasize care for those “in the community.” These traditions can help maintain the complexity of the “for whom” when we want both to avoid “ethnocentrism” and care for those to whom we have special obligations. na And centrally for this normative aspect of moral formation, the hierarchical and ultimate nature of value commitments needs to be better addressed. Kierkegaard and his secular adopters are clear about the decisive role of the ultimate telos (as was his Vorbild Socrates with his stressing of the “highest good”) in the rearranging of one’s entire life (and not just one’s “values”).41 True encounter with and appropriation of Fi the ultimate good is transformative to the individual. Surely not as a single experience but as an ongoing dialogue and reckoning as the phrase “ultimate concern” indicates. The Socratic method of midwifery is commonly thought of as based in leisurely Socratic discussion among aristocrats lying on couches, but the metaphors of giving birth and transformation of the heart make it clear that this is a much more extended process than an evening’s relaxed conversation, one that re-­sorts numerous life priorities and painfully touches many aspects of one’s life (as images of being pregnant, in labor, and giving birth suggest). One can see this re-­sorting and recognition of value happening in many of our historical cases. Elizabeth Cheney, for instance, spent most of her political career championing traditional conservative values. It was not until she was confronted with 41 See, for example, Gadamer (1975) on the revealing and concealing of truth in art. Taking Moral Action a transformed political landscape that she found she needed to insist on pre-­existing deeper commitments to, for instance, truth-­telling and the rule of law. This necessarily involved a painful reckoning with her previous commitments. She describes this ongoing adaptation based on ultimate commitments in an interview: “at each moment, … I knew that I had to do what was right. And I knew that the obligation of elected officials to abide by our oath, has to be more important than party, than partisanship, or than any political office” (Karl, 2022 August 21). The intimate psychological details of this elaborate dance of attachment and detachment of relative and ultimate ends (which necessarily includes self-­ transcendence) are yet to be explored by many who possess the tools to begin to grasp it. But it will have to involve a focus on how one values, relates, commits, and attaches to ultimate and relative ends and how this dance is done in changing life circumstances. s 9.4 Educative Aspects of Moral Formation of We have tried in various places to argue that the pull of the moral should is not always a social pull. It can sometimes be religious, or based in dedication to “truth, goodness, beauty, perfection, excellence, simplicity, elegance” (Maslow, 1969, p. 4). But ro all these shoulds, in order to be sustained, require a social matrix in which to thrive. All three of our formation traditions agree that there must, at the minimum, be something beyond the self that guides, encourages, and enables formation. Even the early Christian hermits living in the desert (the “desert elders”) required a social system to lP form their search for holiness (Stewart, 1991). We share our moral judgments with others and are influenced by the moral intuitions of others who are important to us. We look at moral exemplars, read books, attend religious services or theater, choose and gather friends, and go to schools to be inspired and to learn from them. These experiences can motivate us to change our intuitions, even without conscious reflecna tion, and produce a virtuous (or vicious) cycle of influence in which our narratives or goals guide and nurture our social surround: and the surround in turn influences us at both implicit and explicit levels (Wrzus & Roberts, 2017). 9.4.1 Moral Formation as Planned Moral Ecology Fi We noted that a central theme in all three traditions is schooling, with two of the traditions dedicated to founding institutions to support moral formation. Wilhelm Humboldt’s idea of Bildung (Humboldt, 1792/1960) was institutionalized first at the University of Berlin (later named Humboldt University) and dedicated as least as much to realizing the potential of the individual as it did to learning concepts, ideas, and traditions. For this reason, it incorporated research (in the humanities and sciences) so that the individual could take a critical stance to tradition, at least in terms of seeing it as incomplete and open to revision (Herdt, 2019). Monasticism across the religions is also an explicit attempt to create communities (even communities of hermits) to support moral and spiritual formation. The rules and structure of these communities vary, but they are all are justified by, and connected to, their role in helping the community and the individual in that community to concentrate on their moral and spiritual tasks. This has resulted in spectacular Moral Formation 273 architectural achievements (e.g. the Taung Kalat monastery in Burma) and ­millennia-­long continuous traditions of practice (e.g. those communities that follow the Rule of Benedict in Christianity), both in support of moral formation. Kohlberg’s educational program was headlined by the “Just Communities” approach, which also saw its role as creating communities where children, teachers, and administrators could learn to construct a more just and compassionate learning environment together, and thereby form themselves into more fair-­minded and caring persons. The ultimate (and unfulfilled) goal was that the schools and their graduates would become transformative in society (Higgins-­D’Alessandro, 2015). Kohlberg was clear that schools – all schools – teach a moral curriculum, whether it is hidden or intentional. His attempt was both to acknowledge this hidden curriculum and to be intentional about constructing it using what we know about moral formation. The term “hidden curriculum” was first coined by Philip Jackson (Jackson, 1968) s to describe those aspects of the curriculum that are implicit and at least in part unintentional in American K-­12 classrooms. A significant part of the hidden curriculum is of moral and focuses on what we should value and how one should act. It has become an accepted term of art in general education, as well as in medical education (Balboni et al., 2015; Lawrence et al., 2018). It does not take much imagination to extrapolate the hidden curriculum to the occurrence of socialization in organizations that makes ro corruption more (or less) likely. We discuss these processes in Chapter 3. Last, but not least, the tradition of Socratic paideia (Section 9.1.2) has been influential in both educational and therapeutic settings, emphasizing the maieutic aspect of moral and individual formation (philosophical midwifery). Much of the existential lP tradition understands schooling of the heart to be best practiced outside institutions, either in dialogue with a trusted teacher or Vorbild, or in dialogue with literature, art, and one’s own reflections. This process may be better represented in the p ­ sychological literature as social influence. na 9.4.2 Moral Formation as Social Influence Interaction with others who support or challenge our goals can shape both evaluative and normative aspects of moral formation. For instance, a central role of parents is to provide evaluation, support, and guidance to children in their development of moral Fi character (Lapsley, 2020). Close friends, mentors, and spouses can support or inhibit our attainment of valued goals, particularly when they encourage goals that are congruent with our own ideals for ourselves (Rusbult, Finkel, & Kumashiro, 2009). People who are very good in self-­regulation (e.g. in organizing themselves to achieve their goals) tend to shape their social surround to support their goal pursuits (Ent, Baumeister, & Tice, 2015). They prefer to spend time with, collaborate with, and be informed by others who are themselves good at goal pursuit or who are directly instrumental to their goals, choosing colleagues and mentors who support their goal pursuit (vanDellen et al., 2015). Though people with low self-­control tend to reap the most benefit from social support for their goals, they unfortunately are less likely to find themselves in situations where they receive it (Nielsen & Bauer, 2018). But beyond this, interaction can shape and change the moral goals we choose, the rules we emphasize, and the range of our moral concern. Colby and Damon (1992), in their classic study of moral exemplars, document how exemplars are open to, and Taking Moral Action even seek, influence from their social environment that widens their circle of concern. For example, because of her early interests in justice and fairness, Virginia Durr found herself interacting with a variety of social justice activists whose own commitments influenced her to make broader and deeper commitments to social justice (Colby & Damon, 1992, chapter 5). This influence was likely based in both explicit argument with others and implicit influence by others on the way she saw and responded to injustice. These served as catalysts for evaluative and normative moral formation and thus character and personality change. In addition to these interpersonal modes of influence on evaluative moral formation, the structure and social norms of the situations we inhabit can influence our personal development goals and plans. For instance, economies, architecture, and city planning all serve to distance many of us from the harm that meat-­eating causes to those animals we consume (Bastian & Loughnan, 2016). Prejudices and stereotypes, s but also architecture, serve to justify and maintain the existing social order, and vice versa (Jost & Banaji, 1994; Jost & Hunyady, 2005). Extensive work on the self in of cultural context shows that who we become, and who we want to become, is culturally shaped, even in terms of how we critique or struggle against the prevailing culture (Gibbs et al., 2007). ro 9.4.3 Moral Formation as Cultural Conservation and Critique Cultures vary systematically in terms of whether the relations between people are judged based upon independent experience and desire or interdependent social relalP tions.42 “The nail that sticks out is likely to be hammered down in Japan whereas the squeaky wheel attracts grease and attention in the United States” (Markus & Kitayama, 2010, p. 420). The goals, plans, hopes, and narratives of members of a culture are shaped by these ideals. Master narratives, those narratives that are supported by a culture, can shape the personal narrative that an individual adopts. But they can na also become the focus of conflict as people struggle to change or maintain those narratives. For instance, the heterosexual narrative of how family life develops has been challenged by the gay rights movement in the United States (Hammack, 2008), and the acceptable career narrative for women has changed in Western culture over the last decades (Keane, 2015). But in both of these instances, the narrative resources to criFi tique the prevailing culture arose from within that culture in terms of language about human rights – but also religion (Carter, 1993, pp. 39–40). Thus, narratives about moral ideals are influenced by disagreements within a culture and those disagreements often draw on resources from that culture. Across a range of cultures, those who are more politically liberal tend to emphasize justice and care goals, while those who are more politically conservative tend to emphasize loyalty, authority, and sanctity in their judgments and ideals (Graham, Haidt, & Nosek, 2009; Haidt & Joseph, 2004). The difficulty of this meta-­cultural disagreement in values lies in part with the inability of each side to articulate a narrative that appeals to the other side (Haidt, 2012). In these and many other ways, moral formation is socially and culturally embedded. 42 There is, of course, considerable variation within cultures in this dimension, and different aspects of a culture (e.g. legal vs. familial) may embed different assumptions about this. See Chapter 3 for more detail on these differences. Moral Formation 275 9.4.4 Moral Formation and Moral Luck The civil rights activist Virginia Durr did not pay attention to social injustice in her youth but, influenced over the years by her social network and her own commitments to justice and honor, she became exquisitely sensitive to recognizing injustice and working against it (Colby & Damon, 1992). To be sure, some of this was consciously guided, but other episodes seemed automatic and well-­practiced, such as her spontaneous reaction at a women’s church meeting in Alabama when a black participant was asked to leave during lunch since the venue did not allow integrated eating – she walked out with the woman and ate lunch outside (Colby & Damon, 1992, p. 114).43 Ms. Durr’s career in civil rights was also shaped by the accidents of her biography: attending a racially integrated liberal arts college, being introduced in Washington DC to significant figures in the civil rights movement, etc. So the moral luck that s accompanies us all can dramatically change our life stories in ways we do not anticipate.44 We might find that we are led toward some (im)moral goals as events overtake of us, or that our progress toward an (im)moral goal is restricted by events. Or one might not have any plans for becoming a particular kind of person, and instead simply find oneself drawn along a process. We have little systematic knowledge of the variety of paths in adulthood that lead one to moral action, or the role of intention in these ro paths. Or of the various ways that plans, goals, and narrative might reassert themselves in reaction to events. “We are never more (and sometimes much less) than the co-­authors of our own narratives. Only in fantasy do we live what story we please” (MacIntyre, 1981, p. 199).45 Moral formation is thus always multidimensional. It is lP sometimes more and sometimes less intentional, continuous, and controllable. 9.4.5 Critique from the Three Traditions Monasticism is precisely about constructing a moral ecology for moral and spiritual na development. The point of monastic community is to structure life and its influences in the service of the spiritual goal. In its long history, Christian monasticism has seen multiple waves of regression and reform (LeClercq, 1982) that might yield insight to the patterns that support institutions that are effective at moral formation and those that corrupt it. Bildung, in all its variations, is also about constructing an environment Fi conducive to moral growth. There are only hints of this dense interdependence of moral ecology and moral formation in the moral psychology literature. It is most explicit in the work of Nick Epley and colleagues on ethics as a design problem (Epley & Kumar, 2019; Epley & Tannenbaum, 2017).46 The complicated relationships between, for instance, organized religion, prejudice, and terrorism are well documented (see Paloutzian, 2017 for a review) but make no appearance in current 43 There is no evidence in the way she tells the story that her action was considered or weighed on its merits, she simply acted, “we had to go.” 44 See Williams (1981) for philosophical reflections on moral luck. 45 My thanks to Anthony Rudd for his reference to this poignant quote in his essay In Defense of Narrative (Rudd, 2007). 46 See also Killen and Dahl (2021), who make a strong case for social reform based in moral reasoning, though they acknowledge the social and emotional aspects of SERE. Taking Moral Action moral psychology. A fully developed moral psychology would see these issues as ­central. The complex histories of monasticism and Bildung and the existential revival of the Socratic maieutic could each provide fertile ground for theoretical efforts to develop this relationship. 9.5 Discussion All human lives show moral formation, but not all lives are centered on morality; perhaps not even all highly moral lives are centered on morality.47 But one can learn to be (more or less) moral, even in adulthood. This journey from self-­centeredness to socially necessary moral commitment and possibly to moral exemplarity occurs under s multiple constraints and influences and comes in many flavors. This text is in part a catalogue of these influences and processes, and of the myriad ways that personality, moral identity, skills and knowledge, and moral ecology interactively influence and of are influenced by the processes of emotion, reason, and moral formation. 9.5.1 Conclusion ro 1. We should replace a concern for foundationalist criteria and bias with a concern for the role of personal, interpersonal, and cultural critique. For moral formation, critique and struggle on the journey is a better metaphor lP than foundations for a building. The acceptance in moral psychology of what Walker (2004) calls formalist, or foundationalist, rational models (like those of Kohlberg etc.) has led to framing the issues of moral formation in terms of increasing commitment to a foundational criterion.48 This approach is taken in part to escape from a simple relativism that would make us prisoners of socialization or instinct. For example, in Kohlberg, knowledge of and concern for justice is both na the philosophical foundation and the developmental goal. Bias is then framed as coming from any source other than conscious reasoning about justice. Emotional, social, or cultural influence, religion, personality characteristics, etc. are all seen as bias (Walker, 2004). On the contrary, each of these can be a source of support for moral action, and reason can be a source of bias. In the vain pursuit of a foundaFi tionalist stance, we have cut ourselves off from the rich complexity of how and why we take moral action or progress in moral commitment. An alternative, descriptive, model will involve the recognition of the complex of supports and constraints on moral life, the role of an active agent in navigating them, and the process of self-­transcendence and adoption of moral goals. In every chapter in this text, we see the interweaving of these supports, constraints, and 47 One can imagine lives centered on spiritual or religious values that in the right circumstances result in extensive moral action, or lives devoted to ethical rule-­following (rather than to abstract values) that might have a moral profile distinctly different from other moral exemplars (e.g. the exemplary FBI agent). 48 See Lapsley and Hardy (2017) and Lapsley (2020) for a parallel critique of moral development research as isolated within the “cognitive developmental approach to socialization.” Moral Formation 277 navigation. Central processes in this interweaving are personal, interpersonal, and cultural critique. These processes of critique are usually supported by a range of resources: values, master narratives, social influence, emotion, moral ecological influence, etc. These critiques can drive moral formation and we need to better understand the patterns in how they unfold. And it is these processes that allow us to continually critique our personal and societal ultimate values. 2. We cannot avoid grappling with normative claims in studying moral formation. The research program of Frimer, Walker, and colleagues makes a compelling case that a central move in moral commitment is from agency alone to agency in the service of communion. Their empirical description of the movement leads them to say people should make this transition, and that this transition should be valued as morally good – clearly making a normative claim based on, or at least in tandem with, an empirical pattern.49 Further, they claim that an unavoidable task in moral s psychology will be grappling with how normative moral value is embedded in our empirical descriptions of moral development: of theories of moral personhood must endorse not only goals for how individuals should (deontologically) reason right from wrong but also what they should (teleologically) value as being good from bad. The new challenge becomes the highly controversial task of articuro lating and defending an account of which values are preferable in sufficiently broad terms to avoid ethnocentrism. To be clear, our point is that this task is categorically unavoidable for any theory of moral psychology … [W]hich non-­neutral conception of the good is most appropriate remains important conceptual work for the field. [emphasis in the original]50 lP (Frimer & Walker, 2008, pp. 337–338) We agree with the necessity of this task. It is, at the very least, the puzzle at the heart of the moral exemplar approach: studying exemplars necessarily assumes there is a way to describe excellence on a moral dimension and to identify exemplars on that dimension. The first dimension of the TOI model, self-­transcendence, na centers the problem of determining the highest good among the many values for which committed individuals might transcend the self. Adding the dimension of conservation-­openness helps further open up the space of ultimate values and moral exemplars who might serve them. It is clear that moral inclusion/exclusion is a crucial indicator of for whom the self-­ transcendent commitment applies. Fi Understanding self-­transcendence as a process of transcending one’s relative ends to serve a higher good will help to conceptualize the normative question as one of moral action, about how one brings the normative into action (see Section 9.5.1.4). Even rule-­based morality involves selection of which rules are appropriate in what circumstances. It is difficult to imagine any adequate description of moral formation that does not address the puzzles associated with these three dimensions. 49 This should can be read as an instrumental should, that human development in the usual way involves this transition. But it has a flavor of a moral should, of the infinite. Colby and Damon (2015) make a similar claim that the field must grapple with the normative. 50 Note that here the process of evaluation is still limited to reason, and that the criterion seems to be the limited goal of “avoiding ethnocentrism.” Taking Moral Action Choosing ways of evaluating these puzzles will be a central interdisciplinary task in moral psychology.51 3. Moral formation likely occurs across multiple domains and on multiple dimensions. A significant obstacle in research on moral formation has been the desire to identify and map moral formation based upon a single domain or dimension. The fault for this cannot entirely be placed on what Lapsley and Hardy (2017) call the “cognitive developmental approach to socialization.” One can find it in almost all research programs in the area, even those not descended from the Kohlberg project. But complexity is unavoidable. Moral formation occurs with specific, concrete, commitments to a cause and at the abstract value level; the processes operate at implicit and explicit levels; there are multiple dimensions on which one can measure moral change and multiple aspects or levels of personality that can drive moral commitment. We have selected three dimensions among these (TOI: self-­ s transcendence, openness, and inclusion) that we hope will provide the right level of abstraction and the necessary variation to stretch our understanding of moral of formation. 4. An adequate understanding of moral formation must include the dense weave of evaluative, normative, and educative aspects as they guide the processes of self-­Transcendence. ro Moral formation is guided by an ongoing process of commitment to values, goals, or projects, and by the relations among these commitments. It is shaped by individual processes of evaluation of how well we are upholding the values or achieving the goals, and whether those goals are appropriate or even of ultimate concern. It lP is also embedded in a social matrix that schools us in those commitments and evaluations. Moral formation encompasses personality, reason, emotion, skills, moral ecology, and moral identity. It is an internal action of commitment, but one calling for expression, practice, and evaluation in moral action within specific domains of life and social contexts. Recognizing which aspects of moral formation na are occurring at what times and how they interweave will be crucial to understanding individuals’ moral life trajectories as they navigate their lives. Understanding this complexity in moral formation will require interdisciplinary rigor in investigation, rather than simple hand waving. Our critiques of the processes at the end of each section suggest fertile ground for this interdisciplinary investigation. Fi 9.5.2 Application We met the Munson family in the Introduction and we return to them here. They were seemingly living the good life of the upper middle class when they decided to take in foster children. Their religious backgrounds suggest that communal value commitments played a part in this decision. But it may have been a more self-­centered desire for a family as fulfillment of a community role. It is also possible that their religious commitments were their first priority and that these in turn lead to ­commitment that 51 This task is the door to philosophy and theology. If the task of choosing “which values are preferable” is indeed unavoidable, then this door is also unavoidable. Theologians can do this without necessarily being sectarian, as exemplified by Herdt’s (2019) expansive conclusion to her book on Bildung. Moral Formation 279 a psychologist might describe as communal (though actually rooted in a religious value dimension). The monk Thomas Merton’s initial commitments seemed focused on personal religious need in a close-­knit monastic community, but the social upheaval of his time, and the religious narratives in which he was embedded, offered him an opportunity to channel this into a profound concern for the oppressed. Thus, his journey of moral formation, as well as the Munsons’, is shaped and supported by the variety of contexts, influences, and processes we outline in this book. The Munson narrative is one of a slow, stepwise increase in commitment. First, they committed to some particular children, then, faced with physically disabled children, they redoubled their commitment to the children but also extended it to other children like them who were having trouble finding services to help them. Their work in this area led to volunteering at schools, serving on boards, and eventually founding a charitable organization to provide the needed services to children in the area. s Surely the levels of commitment and the actual goal of their actions changed over time. But if we were to interview them, it seems unlikely they would describe the of process as one of continuous rational evaluation of their commitments and planned increases in action based on the outcome of those reflections. However, they might well agree with a narrative of a journey in which they were drawn to do more of the good than they had started out with. This deepening of what came to be an ultimate ro concern is part and parcel of moral formation approaches across contemplative and religious traditions, we can find it in concepts of existential appropriation as well as in the education of the heart. This deepening of what concerns us ultimately, the moral good we consider our highest, comes with the task of evaluating and re-­evaluating lP not only our normative value system, but also the nature of our attachments to each of them. It is as much shaped by the nature of our evaluations, choices, and commitments as it is by our situation and culture. At each turn in the journey, the Munsons might have decided they had done enough. Then they would not have been confronted with the next situation that also had its calls for commitment or rejection. na 9.5.3 Open Questions The central task and puzzle of this chapter is to assemble the various aspects of moral formation in a way that is faithful to the wide variety of (im)moral trajectories. Only Fi then can we begin carefully to think about how to empirically describe them and how to theoretically explain them. We suggest here some open questions that this attempt offers: 1. Are there common psychological aspects to the commitments to the many different types of self-­transcending values and ultimate concerns? We have noted that most moral exemplars do not start out with a conscious commitment to “being good” but begin instead with specific commitments as the Munsons or Thomas Merton do in our application case. At this more concrete level, there may be thousands of ways to get on the path to moral formation. In fact, an existential viewpoint would suggest that we are already and always on that path, whether we want it or not. Still, at some higher abstract level this multitude may fit the self-­enhancement to self-­transcendence description. We have regularly remarked that some things that are taken to be ultimate can lead to terrorism, Taking Moral Action genocide, and other evils. Are the processes of commitment, evaluation, and schooling the same in all cases, good and evil? Are there any of these processes that might help us in distinguishing good vs. evil vs. indifferent commitments? What aspects of these processes and commitments constitute what is commonly called virtue? How are they distinguished from vice? And what might we learn from studying the negative trajectory of someone’s moral formation? 2. What is the relation of skill development to taking moral action? The study by Frimer et al. (2012) provides us with a way to frame this question. In their study of exemplars taken from the front pages of Time Magazine, they identify “agentic” and communal exemplars. Agentic exemplars are known for taking effective action, but not really for taking effective moral action. Do these two groups share skill sets, or are there some skills that are more associated with taking effective moral action? What might these moral skills be? Does developing these s moral skills influence moral formation or are these two different tasks? The monastic tradition we covered early in the chapter highlights some form of humility as of crucial in moral formation. There are empirical literatures we review in this chapter that identify the skills associated with a robust humility. 3. How might the traditional accounts of moral formation help us understand and explain psychological processes of moral action? ro Most psychological analyses of moral formation tend to fragment the processes they study, and scientific psychology is often drawn to those aspects that are easiest to measure or seem most objective. They concentrate on cognition, or emotional regulation, and there is little within them that compels a theoretical change of lP perspective, broadening of focus, or deepening of understanding. Nor do they grapple with the existential depth of the struggle with the human condition and the infinite. This is how we end up with a pile of pearls and no string to bind them together. We have presented several more holistic approaches to moral formation that are non-­scientific but nevertheless deeply empirically oriented because they na are based in long traditions of observation and critique of human moral action. These traditions see moral formation as both the self’s careful navigation of the moral world and an intentional reflection on and deepening of our commitments; as a longing search for wholeness and a willingness to let oneself and one’s goals be challenged by the social and normative world one encounters. If they are compliFi cated and paradoxical, it is likely because the phenomenon they have been closely observing and trying to guide is itself complicated, paradoxical, and full of variation. We are not proposing these traditions as alternative psychological theories. Rather, each proposes its approach as a practical “school” for formation that suggests opportunities for psychological research. See our comments at the end of each section for specific critiques that draw from this well of practical, empirical experience. Rigorous interdisciplinary inquiry may help identify ways that existing theoretical and empirical approaches in psychology are overlooking or ignoring important aspects of the broader process of moral formation. 4. How does moral ecology interact with moral formation? A theme throughout this text has been the applied question of how we can construct moral ecologies that support moral action. We now have some language to phrase that question in a way that may advance the conversation: How can we Moral Formation 281 construct moral ecologies that support effective individual, social, and cultural c­ ritique in a way that helps achieve appropriate SERE in moral commitments and action? There are many questions remaining within each of the terms in that sentence. And modifiers like “appropriate” are invitations – perhaps even demands – for interdisciplinary collaboration. Nevertheless, we hope this phrasing of the question opens the doors to conversations in service of moral action. 5. How is a SERE achieved and maintained in the face of ultimate commitments? In several other chapters (e.g. Chapters 3, 7, and 8) we mention the processes of social and cultural critique. This chapter has primarily focused on processes of personal critique (as does Chapter 5). And we have argued often that seeking a SERE is a useful description for these processes. This balance occurs across multiple dimensions (social, emotional, cognitive). We do not propose a model for how this happens. We are simply specifying the things one must bring into equilibrium. The s phrase reflective equilibrium is taken from philosophy (Rawls, 1971/1999) and suggests a balance among considerations. But clearly, if one is considering ultimate of concerns, equally weighting all the concerns is out of the question. How does one find a weighted balance in the face of the ultimate? So, perhaps it is achieving the appropriate tension instead. Maintaining this tension among our values, goals, or projects might be what allows the process of recognizing disfluency (see Chapter 6) ro when the tension among our moral commitments becomes too great. This recognition of disfluency helps one to break out of automatic processes and begin conscious, controlled reflection on why things are not working. This reflection may mean re-­evaluating a host of things, including one’s ultimate commitment (see the lP Chapter 5 for the complexity involved here). Thus, reflective equilibrium might be better expressed as the feeling of peace or clarity one achieves after the weighing and recalibration process. na 9.6 Further Readings These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and Fi recent work. Complete citations are provided in the references section. • McAdams (2013). “The psychological self as actor, agent, and author.” An understanding of change in the self at three different levels. • Bluck et al. (2005). “A tale of three functions: The self-­reported uses of autobiographical memory.” An empirical study to explore the uses of autobiographical narrative in both change and maintenance of the self. • Colby and Damon (1992). Some Do Care: Contemporary Lives of Moral Commitment. A classic study of moral exemplars in social service in the United States that includes discussion of change in moral commitments over time. • Applebaum (2012). Iron Curtain: The Crushing of Eastern Europe 1944–1956. A study of Soviet repression in East Germany, Hungary, and Poland. It shows the complexities of changing moral ecologies and their influence on moral commitment and ultimate value. Taking Moral Action • Gelfand (2021). “Cultural evolutionary mismatches in response to collective threat.” An overview of the idea of cultural tightness: a concept containing both strictness of norm following and narrowness of in-­group. This varies across both cultures and over time. • Herdt (2019). Forming Humanity: Redeeming the German Bildung Tradition. A comprehensive, complex, and subtle overview of the Bildung tradition from its classical sources to its integration in current theological and philosophical thought. • Walker and Frimer (2015). “Developmental trajectories of agency and communion in moral motivation.” Theoretical review of their research program that documents change from agentic commitments to agency in service of communion in adolescents, young adults, and moral exemplars. • Wrzus and Roberts (2017). “Processes of personality development in adulthood: The TESSERA framework.” A complex model of personality change that incorpos rates both implicit and intentional change. of"
9,9.2,"Evaluative–Self-­Transformative Aspects of Moral Formation Evaluative moral formation marks those skilled processes by which we evaluate and na attempt to modify our moral actions in light of our moral goals or values. It thus involves recognizing relevant situations and internal states and processes, evaluating them, and making and implementing plans for change in a desired direction. We sketch here an overview of this aspect of moral formation as it has been covered in Chapters 4, 5, and 6. We then consider the narrative level of evaluation, which is not Fi well covered in those chapters. • In Chapter 4, we cover the recent turn toward idiographic models of personality that emphasize how the individual weaves their own path of moral consistency (Cervone, 2021; Mischel, 2004; Wrzus & Roberts, 2017). These models highlight the individual ways people adapt to their perceived environments and integrate a variety of influences in thought, feeling, and behavior, all in a way that allows for a pluralistic understanding of moral personality: that there is no singular moral personality (Wrzus & Roberts, 2017). • In Chapter 5, we suggest three integrative characteristics of self-­regulation that might support appropriate reflection on moral failure:21 (1) conscious awareness of 21 And that look suspiciously like the virtue of humility. See also Eskreis-­Winkler and Fishbach (2022) for a review of the emotional and cognitive barriers to learning from failure. Moral Formation 257 one’s emotions, motivations, and values; (2) taking responsibility for one’s emotions, decisions, and thoughts; and (3) non-­defensiveness in response to challenge (Weinstein et al., 2013). There, we also accumulate the evidence of the conceptual complexity and flexibility of self-­ evaluation that make awareness, responsibility, and non-­defensiveness important virtues in self-­reflection. • In Chapter 6, we review a useful model of personality change that is particularly relevant for evaluating moral formation (Wrzus & Roberts, 2017). The model concentrates on the awareness and evaluation of one’s reactions to a situation and using this evaluation to construct desired expectations for behavior in similar ­situations in the future. These desired expectations can be evaluated when those situations arise again. There we also cover other skills relevant to evaluative moral formation, like self-­regulation, moral attentiveness, and moral imagination. s 9.2.1 Telling Stories of But there is another level at which evaluative moral formation occurs: the narrative. These skills, processes, and influences just mentioned deal well with moral formation focused on high-­level traits (e.g. neuroticism) and mid-­level projects and personality difference (e.g. cynicism) (McAdams, 2013). They do not say much about how we ro tell stories to ourselves about ourselves and how those stories might influence evaluative moral formation. These stories are often designed to connect our past, present, and future in a coherent manner. Stories allow us to see meaning in our lives and guide our lives as we navigate into the future (Bluck et al., 2005; McAdams & lP Pals, 2006). This overarching narrative, woven from a sequence of stories, hopes, and regrets about the self, can be one of the formative influences in a reflective process that guides and monitors moral decisions and plans. Autobiographical memory, and the narratives we construct from it, have a significant directive function in our lives. These narratives help maintain personal identity na over time (exerting some consistency pressure) and guide the planning and nurturing of current and future social interactions (another kind of directive influence) (Bluck et al., 2005; Rasmussen & Habermas, 2011). Narratives have been shown, for example, to be central in constructing a sense of agency for those in psychotherapy, with the agency in turn becoming a leading indicator of therapeutic benefit (Adler, 2013; Fi Adler, Wagner, & McAdams, 2007). Thus, looking forward, we construct our agency in narrative and those narratives directly guide choice and planning (Bluck et al., 2005). Looking backward, we are especially motivated to make narrative sense out of negative occurrences and this reconstruction impacts our agency in helping others (McAdams et al., 2001). How can narrative play a role as an arbiter in evaluative moral reasoning? “Telling a story” can have evaluative force because it contains autobiographical reasoning, the set of interpretive actions used to make sense of who we are, where we have been and where we are going. Indicators of structural quality in a narrative (indicative of coherence) include believable causal chains, reactions, and descriptions, finding growth or regression over time, connecting episodes with clear beginnings and endings, ­foreshadowing, and retrospective review (Adler et al., 2015). Other narrative content that can bring evaluative force on behavior includes themes of motivation (agency, autonomy, generativity, intimacy, etc.), affect (positive or negative tone, redemption, Taking Moral Action contamination, anger, fear, etc.), and integrative meaning (change in moral identity, integration of contradictory themes) (Adler et al., 2015). The specific content of these themes in the narrative one constructs has implications for how the past and present are to be morally evaluated and how the future ought to be planned. Is there any evidence that narrative content has implications for evaluative moral formation? There is at least clear evidence that this narrative aspect helps to distinguish moral exemplars – individuals who are widely agreed to be admirable moral models – from those whose lives may be conventionally moral but are not centered on morality. And there is much work that suggests that narratives are central in guiding the moral formation process in moral exemplars. As part of an extensive research program that has compared moral exemplars to matched controls, Walker and Frimer (2015) did not find differences in personality traits or values, but did find differences at the narrative level. Moral exemplars’ stories s more often emphasized early secure attachment to parental figures, a lack of early enemies, and the presence of early support. In comparison to controls, their narratives of (but not trait scores) had more positive affective tone, were more likely to positively appraise interpersonal communication, and had language that tended to emphasize the needs of others. Finally, the stories exemplars told also tended to see good coming out of bad occurrences (a redemption theme, McAdams et al., 2001). These individual ro stories are woven together into a narrative of the self with implications for current and future moral action (Lapsley, 2016): actions such as nurturing current social relationships and guiding the development of future relationships (Bluck et al., 2005). Colby and Damon (1992) see this embedding of the moral exemplar in relationships that lP guide their careers as a central aspect of the development of moral exemplars. Still, there is very little work on the specific processes by which narratives guide evaluations of the self or constrain future moral action. The processes outlined by Wrzus and Roberts (2017) in Chapter 6 can surely be adapted to incorporate the ­ arrative level.22 One can imagine additional ways narrative might be recruited in n na moral formation (e.g. see Section 9.4.3). 9.2.2 Critique from the Three Traditions In sum, we have a vast and complex research literature, spread across several chapters Fi of this text, on how individuals might evaluate their performance in achieving their moral goals. Some attempts have been made to integrate and unify these ideas (e.g. Wrzus & Roberts, 2017). But even these integrations do not give us the practical programmatic approach to moral evaluation that some of the traditional accounts do. Monastic and spiritual formation traditions have detailed and rich approaches to self-­ examination (e.g. the dokusan interview in Zen Buddhism or Jesuit spiritual exercises in Christianity). Bildung has produced detailed narrative accounts of its individual practice and programmatic revisions to higher education in the service of its goal. Most psychological research in moral psychology has yet to be connected to such practical applications in any systematic way. 22 As can the processes found in the traditional accounts, and those in clinical psychology, religious conversion, and volunteerism. The traditional accounts seem to fit much better to this narrative aspect of evaluative moral formation. Moral Formation 259 In addition, one can see from the tradition of existential appropriation that the distinction between evaluative and normative is not as clear as our presentation would have it. In fact, the evaluative necessarily leads us to the normative. It cannot be disconnected. Only a robust set of defense mechanisms, rigidly deployed, can keep us from evaluating whether we are in fact caring about the right things. The “what” of our goals and the “how” of our relation to them need to be kept in constant tension. This is part of the dynamic that Colby and Damon (1992) explore that draws exemplars ever further into broader commitment as they evaluate their current commitments. Psychological research on evaluative moral formation could benefit in many ways from conversations with these traditions. 9.3 Normative/Self-­Transcending Aspects s of Moral Formation of Much of what we call the psychology of moral action consists of processes (e.g. self-­ regulation, etc.) that can be analyzed in a content-­free manner. That is, one can easily imagine a wide range of goals, values, or narratives that could drive these processes. For example, careful evaluative moral formation can serve a person’s goal of becoming more ro compassionate or ruthless in pursuit of a supreme value (Côté et al., 2011). Evaluative moral formation can be based on a narrative of good coming from the bad or a narrative of the constant, enervating resurgence of failure (McAdams et al., 2001). Moral attentiveness can be focused on threat from the outsider and compassion only for the lP insider (Hart, 2005b; Hart & Carlo, 2005). How can we find some structure in this confusing variation in values, ideals, goals, and projects that can direct both moral and immoral action? 9.3.1 Value Dimensions of Normative Formation na We have often mentioned pluralism in values in this book. What is the landscape of the variety of values from which people select some subset to guide their moral formation? If we want to become good, how do we determine what the good looks like? There are a wide array of works that identify dimensions of value in motivation content and little convergence among them.23 There is even disagreement about the Fi ultimate goal within and among the three humanistic traditions with which we began the chapter. Despite this disagreement and confusion, we will nevertheless attempt to systematize the variety of content and meaning that is relevant to moral becoming. It is easy to multiply examples of the different content and values that can drive moral formation. It is less easy to bring some structure to the diversity in a way that helps us understand it. In this section we will, in the Humboldtian spirit, be looking for the diversity and the structure in this wide variation. What are the various kinds of values, goals, projects, etc. that motivate moral action?24 Can we organize them in some way that allows us to understand their interrelationship? 23 This is in part because there are so many options and so little theoretical integration. See n. 5 for an incomplete listing of approaches and systems. 24 To see a more in-­depth discussion of values as self-­transcendent or ultimate, see the Introduction and Chapter 5. Taking Moral Action All developmental moral psychology presumes some movement in values (e.g. from self-­centeredness to the inclusion of others). It is implicit in the notion of development or formation that it is not mere change but movement toward some ideal or telos (Schachter & Ben Hur, 2019; Schnitker, King, & Houltberg, 2019). If we construct a space of values, goals, or projects relevant to moral action, how might the choosing individual move among them in commitment in a way that could be called formation? Thus, the questions we ask in this section are: Within what value space is moral formation occurring? And how does the individual actor attach or change their attachment to these values in a way that might be called moral formation?25 To engage these questions, we will look at five dimensions of the landscape of goals and values toward which one might orient moral formation, and from them construct a complex-­enough three-­dimensional space within which it would be productive to track moral formation and change. s 9.3.1.1 Self-­Transcendence In the Introduction, we proposed an existential turn (Section I.6.1) that reminds us of the need for self-­transcendence to move from of simply knowing that a value, ideal, or project has value to actually appropriating that value in one’s own life. It is how one moves from merely objective observation of ethical values to personal choice and commitment, and thus to the place from which motivation to moral action springs. We argued there that this turn opens up the self ro to transcendence to the variety of goals, values, or projects that might be treated as ultimate by the individual. This is a move away from attachment to self-­serving values to ultimate attachment to the greater good, or to ultimate values. lP SelfTranscendence UniversSelfalism Direction na Openness to Benevolence Change Stimulation Fi Conformity Tradition Hedonism Security Conservation Achievement Power SelfEnhancement Figure 9.1 Schwartz circle of value regions. Source: Adapted from Borg, Bardi, and Schwartz (2015). 25 These two questions mirror Kierkegaard’s distinction between the what and the how of existential appropriation. Moral Formation 261 In Chapter 3 (Figure 3.1) we introduced a cross-­culturally valid model of values that sees them as arranged around a circle in opposing pairs, with values near to each other on the circle being more compatible (reproduced here as Figure 9.1 for reader convenience). In it, one can see that self-­enhancement (lower left) is opposed, across the circle, to self-­transcendence (upper right). And at a near right angle to this is a dimension ranging from conservation (right) to openness to change (left). This is a second dimension in the value space that we will discuss in Section 9.3.1.2. The two dimensions form a circle with more specific values arranged around the circumference. The approach is based on the idea that cultures and individuals find themselves somewhere within the circle at a balance point between the various opposing values, endorsing all to some extent, but favoring some over others.26 The circle provides a structure for the characteristic ways that cultures and individuals balance these values (Borg, Bardi, & Schwartz, 2017). s In Section 9.3.3, we will review extensive work by Walker and Frimer suggesting that there is interesting individual development over the life span on the dimension of of self-­transcendence, e.g. not just a simple movement from one to the other but an integration of the two ends of the dimension, with self-­enhancement serving the goal of self-­transcendence (Walker & Frimer, 2015). This crucial developmental sequence makes it clear that self-­transcendence will be important to include in any model of ro moral formation. We cover this dimension in greater detail in that section. We label it as self-­transcendence in part to connect it to other literatures (Frankl, 1997; Koltko-­ Rivera, 2006; Maslow, 1969) and in part to allow Humboldtian space for the wide variety of values or projects for which people self-­transcend.27 lP The self-­transcendent end of this dimension needs to be considered at the idiographic level, because it is open with regards to the particular goal or telos of self-­ transcendence that each person might choose. See Section 9.6.1.5 on specific commitments and projects to get some idea of the diversity we are including here. Here, self-­transcendence is more the task or process required than the end goal itself, na which is complex and widely variable. Further, for each individual self-­transcendence may be more complicated than one goal. Here, the complexity of the self and its commitments that we outline in Chapter 5 becomes evident. One might have moderate Fi 26 This is a pictorial way of interpreting the rank ordering of the various values by ­different cultures (Schwartz, 2016; Schwartz et al., 2012). Empirical reality is a bit more complicated. Rank orderings in some cultures do not preserve the order of the circumplex (Schwartz, 2006), and thus the geometric balance point interpretation we offer here founders in these instances. The recruitment of one value in the service of another that we explain in Section 9.3.3 may help to understand some of these inversions. 27 Names of dimensions like these are always negotiable. Walker and Frimer (2015) replace “self-­enhancement” with “agency” and “self-­transcendence” with “communion” as their labels for the endpoints of this dimension, in part to connect it to other literatures. We prefer self-­transcendence in order to emphasize the multitude of non-­social goods to which one might be devoted (religion, art, environment, etc.). See the discussions in the Introduction and in Chapter 5. It is important to note that the label “self-­transcendence” here is not in itself a value, goal, or project. It is, rather, a stand in for the multitude of goods for which individuals might self-­transcend and that they might take as ultimate. This fundamentally alters the dimension by not anchoring this end in pro-­social values, while still allowing them among other ends. Taking Moral Action self-­transcendence toward the value of compassion (producing a general pro-­social attitude) and passionate, even ultimate, dedication to family or some other life project. These values might be integrated in some way (e.g. with compassion as the theme in a particular narrow project) or exist in tension across separate domains of the multidimensional self (e.g. work projects vs. family commitments). And to the extent that a particular value or goal is really considered to be ultimate, there should be tension to integrate it across the separate domains of the self. The point of ultimate value is that for some people, at least in some domains of their life, some value, telos, or life project is taken as the most important thing. And for some people, this extends over all domains in their life. We must include a caution here on recognizing the multiplicity of possible goals in self-­transcendence. Some goals for which people sacrifice themselves involve causing harm to others. Koltko-­Rivera (2006) grapples with this difficulty in his review of s Maslow’s understanding of self-­transcendence and admits that terrorism and other forms of evil can, at the idiographic level of personal commitments, look a great deal of like self-­transcendence. Thus, commitment to a self-­transcendent goal has a dark side (Hart & Carlo, 2005; Skitka, 2014; Skitka & Mullen, 2002; Washburn & Skitka, 2017). Scholars will need to do the work to distinguish between the goals. It may be that the psychological processes are very similar if not identical. Perhaps some ro of the other dimensions we list in Sections 9.3.1.2–9.3.1.5 will help us do so (e.g. inclusion). Opening up this dimension to this puzzle of identifying appropriate ultimate goals allows us to frame the problem of the crucial and unavoidable work of distinguishing what the good is and whether how we become good is the same prolP cess as how we become evil. This brings us back to the idiographic struggles of each individual as they engage in their teleological task of contemplating their ultimate concern (see Section 9.1.2). 9.3.1.2 Openness to Change The second dimension in the figure is openness vs. na conservation. This seems to be treated more as a personality characteristic that does not change much over time. Research seems to focus mostly on the ways this dimension tracks the (supposedly static) liberal – conservative continuum in the United States. But we might also find some interaction between trajectories in the two dimensions. Those with conservation commitments might show a different pattern of development Fi from self-­enhancement to self-­ transcendence than those with commitments to openness. This is speculation at this point, but one can imagine those who mature on the self-­ transcendence dimension in politically or institutionally or culturally conservative households might select very different kinds of life projects than those who might mature in households that value political, institutional, or cultural change. Seeing these two dimensions as forming a moral formation space allows us to ask these questions, and again to expand the space of what is moral and how people choose to be moral. 9.3.1.3 Inclusion/Exclusion This dimension is the extent to which we include others in our understanding of those deserving of moral consideration. The move from self-­ enhancement to self-­transcendence does not remove us from the messy difficulties of deciding for whom one should have compassion, or how others are included in one’s religious commitments, or for whom social justice is important. How wide should Moral Formation 263 one’s circle of concern be? We should note that the value circumplex model has “universalism” as one value at the self-­transcendence end of the dimension. And this suggests that the more one endorses or appropriates communion the wider one’s circle of concern should be. But the Schwartz (2016) model is based on averages across many people, and there may well be those for whom self-­transcendence does not entail opening wide the gates to all. For instance, we already know there are sub-­types of moral exemplars. The distinctiveness of two of the sub-­types (helper vs. reformer, see Chapter 3, Section 3.2.1.4) consists in part in for whom they are moral. Helpers care for certain individuals with needs, and do not much concentrate on societal change. Reformers want to change systems as an instrumental goal in service of producing justice or care for others.28 The latter may be more universalist in their embrace of others, while some helpers may be more restrictive in their compassion. The “deserving poor” is a standard trope s for those who want to limit social assistance. Still, even reformers limit their focus to particular social justice issues, and thus leave out those affected by the neglected of issues. A more theoretically targeted selection of moral exemplars might help us grasp some of the variation in ways that people do good and the extent of inclusion of others in that moral action. Susan Opotow explores this dynamic of with whom one values communion under ro the label moral inclusion/exclusion (Clayton & Opotow, 2003; Opotow, 2001, 2005) and we adopt this language for this dimension. She has reviewed how moral exclusion is constructed in a moral ecology (Opotow, 2001) and how programs stressing moral inclusion can help to reduce violence and injustice (Opotow, 2005). Others have lP begun to investigate what they call moral expansiveness, the inclusion of a wide range of others in their circle of concern. This work has shown expansiveness to uniquely predict willingness to prioritize humanitarian and environmental concern over personal and national interest (Crimston et al., 2016). Similarly, Graham et al. (2017) propose centrifugal and centripetal forces and frame them as separate and competing na pressures to form some balance along a continuum they call the moral circle. And, of course, work on altruism that used in-­depth interviews with those who helped Jews escape the Holocaust found a personality characteristic called extensivity (the extent to which one included others in the circle of moral concern) to best differentiate between those who helped and those who did not (Einolf, 2010; Oliner & Fi Oliner, 1988). These parallel theoretical accounts suggest there is likely another important dimension along which normative moral formation can take place. One might have great integrity about justice and care for those we include in the deserving community, while being callous and uncaring for those “other people.” We show a different moral face to those who are “them” than we do to those who are “us.” One can also limit one’s moral horizon without overt prejudice, by unexamined or intentional parochialism. Again, the Munsons (see the Introduction) serve as an example. At what point in their progression of commitment do they become exemplary? Even at the beginning, 28 One can, of course, do both or neither, as do some of the exemplars from Huff and Barnard (2009). Those doing neither were focused on more specific projects like mentoring (see Section 9.3.1.4 for what specific projects might look like). Taking Moral Action when caring only for their own foster children, they are self-­transcending, but their self-­transcendence is inclusive of only a small circle. We know a little about what might influence the inclusion dimension relevant to normative moral formation. It seems to be flexible depending on moral framing and domain but also reliably related to the development of moral identity.29 Its flexibility is influenced in part by empathy. In everyday life, we primarily experience empathy for close others rather than those at a distance (Depow, Frances, & Inzlicht, 2021). However, empathy is not inherently exclusive and one can frame judgments in a way that fosters egalitarian empathy (Fowler, Law, & Gaesser, 2021). One can likewise frame judgments in ways that encourage “virtuous violence” against the other (Cohen-­Chen, Pliskin, & Goldenberg, 2020; Fiske & Rai, 2014). Cultural preferences for tight framing of moral constraints and the moral circle can anchor inclusion but also change it as the culture reacts to external threats (Gelfand, 2012, 2021; s J. C. Wright, 2021). There is some evidence that higher levels of moral identity are associated with a of wider “circle of moral regard” (Aquino et al., 2006; Reed & Aquino, 2003). And even for those who value group loyalty, commitment to moral identity reduces the extent to which they are willing to endorse torture in its service (Smith et al., 2014). This at least allows us to say that even though conservative and liberal value commitro ments might look different, if they have integrated morality into their identity one can expect they will share some values (Frimer, Tell, & Haidt, 2015). So, we may need to differentiate between inclusion with regard to basic humanity (e.g. appropriate targets for compassion and human rights) and an inclusion that involves a more lP complete reception, incorporation of, and obligation to the other. Beyond simple viewing of others as part of “us,” participation within a community helps to construct our sense of self. Seeing one’s self as socially connected influences compassion and socially responsible behavior (Cojuharenco, Cornelissen, & Karelaia, 2016; Cross, Bacon, & Morris, 2000; Day & Impett, 2018; Vignoles, 2018). na In a longitudinal study of high-­school students, Pratt et al. (2003) found that self-­ ideal (measured by self-­report of traits one strives for, such as being a good citizen, fair, just, caring) predicted community involvement, but over time it was community involvement that led to increases of these self-­ideal traits. Thus, active participation in community can produce a virtuous cycle of self-­ascription of traits, followed by furFi ther community service. Hart (2005a, p. 260) argues that “If the notion of identity is to contribute to an understanding of moral functioning, then it must be a construct with deep roots in a social world.” As we consider incorporating inclusion/exclusion in our moral space, these roots will need to be both deep and specific to each individual and his or her personal history and moral ecology. Piliavin and colleagues (Grube & Piliavin, 2000; Piliavin & Callero, 1991) have shown the importance of “specific role identity” (as, e.g. a blood donor or a cancer society volunteer) in supporting volunteer activity. Rule and Bebeau (2005) and Huff and Barnard (2009) have also tracked the importance of specific 29 Graham et al. (2017) provide a short history of the use of this dimension and survey a host of factors that can influence one’s position on the dimension. Moral Formation 265 identity themes in professions. The extent to which these specific commitments limit or facilitate moral inclusion is as yet unexplored. 9.3.1.4 Rules vs. Goals We also need to consider the possibility that, for many people, or even for most people at one time or another, morality is not really about the pursuit of moral goals but instead the following of moral rules that serve as guardrails. Most professional codes of ethics include two types of items: things one ought not to do, and moral ideals one should approach (Harris, 2008). In Chapter 6, we explored Kuhl and Koole’s (2004) distinction between the self-­control system and the self-­maintenance system. This is roughly the distinction between those processes that help the person focus on the task at hand and avoid temptation and those processes that direct the person to take valued action. In the domain of engineering, the philosopher Charles Harris (2008) presents a s parallel distinction between preventive values and aspirational values. Preventive values are about “not violating moral rules.” These constitute about 80% of the text of the of National Society of Professional Engineers code of ethics and are essentially negative in form (e.g. not approving documents that do not conform to standards). Aspirational values are about approaching moral goals or values. Harris (2008) gives examples of designing safety into engineering systems that goes beyond codes and standards, eviro dencing a deep commitment to safe engineering, or to environmentally thoughtful engineering, or to engineering that takes its social embedding and impacts seriously. Similarly, Janoff-­Bulman and Carnes (2018) use the basic motivational processes of approach (prescriptive) and avoidance (proscriptive) to frame a model of moral lP motives that operates at three levels, the intrapersonal, the interpersonal, and the collective. This taxonomy provides useful insight, for instance, into the differences one finds at the collective level between conservatives, (who favor social order – an ­avoidance goal) and liberals (who favor social justice – an approach goal). Thus, the domain of moral rules and obligations (e.g. do not lie, cheat, plagiarize) na may well be associated with the self-­control system and have its own trajectory in moral formation. And the domain of aspirational goals (e.g. be a blood donor, care for the poor) may be associated with the self-­enhancement system, particularly when these moral goals are an important part of the self (Cervone & Tripathi, 2009).30 Additionally, each system may have its own distinctive pull on the moral action of Fi the individual. As Nucci (2004) notes, even if individuals do not have morality as a defining aspect of the self (and are thus not engaging the self-­enhancement system in the service of moral goals), there is still something about the moral domain that makes it difficult simply to ignore rules. “I’m not good at academics,” sounds qualitatively different (and much less dangerous) than “I’m not good at morality.” We expect the pull of rule-­based, inhibitory, preventative morality to be widely shared, even by those for whom moral goals are not central to the self.31 But there is very little work on how these two systems interact or how the two different kinds of moral motivations differ. See Chapter 6 for more on this distinction. 30 But we make exceptions for (and even inversions of) those rules when it comes to treating 31 outsiders and enemies (Cohen-­Chen et al., 2020; Fiske & Rai, 2014). Taking Moral Action 9.3.1.5 Specific Commitments and Projects So far, this discussion is operating at a highly abstract level of general themes in morality (self-­ enhancement and transcendence, moral identity, moral exclusion, rule following) rather than the concrete particulars of the specific causes to which people normally dedicate themselves.32 It seems likely, however, that the process is not one of becoming good at this abstract level, but more one of becoming good by being attached to a specific, concrete, personal moral goal (rather than an abstract value like communion, or even more vague, self-­ transcendence). Across all the research on exemplars, moral commitment appears to be particular. Despite Suzie Valadez speaking of God’s call to love all people, the people she serves are the poor “people of the dump” in Ciudad-­ Juarez, Mexico (Colby & Damon, 1992, chapter 3). Even though Stephen Engberg is committed to privacy rights and speaks at this abstract level, the particular privacy he cares about is in the design of business software in Denmark (Huff & Barnard, 2009). s Though Walker and Frimer (2007, p. 848) identified value dimensions behind particular concrete commitments, their exemplars were selected because they showed of concrete “extraordinary and long-­term commitment in providing care to individuals or groups, [or to] community service or humanitarian causes.” How do we get from smaller, concrete commitments to larger, more abstract ones? Colby and Damon (1992) propose a process that might lead from local, particular moral commitments ro to broader commitments and offer several examples of that process in their exemplars. They call these environmental personal growth affordances. But only a few of their exemplars show a clear pattern from specific to general.33 The more common development seems to be from lower to higher levels of commitment within a specific lP domain. In a similar vein, Koltko-­Rivera (2006, p. 302) explores Maslow’s concept of self-­ transcendence as “a motivational step beyond self-­actualization.” It is also clear here that the motivation is particular, as self-­transcendence may involve “service to others, devotion to an ideal (e.g., truth, art) or a cause (e.g., social justice, environmentalism, na the pursuit of science, a religious faith), and/or a desire to be united with what is perceived as transcendent or divine” (Koltko-­Rivera, 2006, p. 303). A similar pattern can be seen in research on how participation in volunteering or social activist work affects those who volunteer. A classic example is the study by McAdam (1989) on the effects of the 1964 Mississippi Freedom Summer project on Fi 212 participants in the project, as compared to 118 who signed up, were accepted, but did not go.34 Compared to the no-­shows, the participants were still deeply engaged in politics twenty years later, were more likely to be unmarried, have lower income, and to be concentrated in the helping professions (e.g. teaching). The study 32 Frimer et al.’s approach to categorizing agency and communion as terminal or instrumental involves either interviews in which people must identify values as terminal or an elaborate coding approach that finds the abstract themes in the text of the interview (Frimer et al., 2011). It is at this level of abstraction that they find patterns. In most of the interviews, their participants speak movingly about commitments to specific projects and actions. 33 We know of no other systematic data on this trajectory or its influences. 34 These were volunteers from all over the United States who came to Mississippi for a summer focused on civil-­rights organizing, non-­violent demonstration, and civil disobedience in support of civil rights for African Americans, particularly in the Jim Crow south. Moral Formation 267 is based on the completed applications of the two groups (obtained from archives) and a follow-­up survey sent to them in the late 1980s. The no-­shows “did not differ significantly from the participants in the values they brought to the project … [and] appear as essentially alike on a list of variables: race, social class, type of neighborhood, home region, type of school, and major in school” (McAdam, 1989, p. 749) But participation in the Freedom Summer likely affected their self-­concept and their later work (and even romantic partner) choices. The intertwining of personality, moral identity, skills and knowledge, and moral ecology are quite complicated here (see e.g. Bosi, 2016; Giugni, 2004; McAdam, 1989) but the effects of immersion in the complex moral ecology of civil resistance seem undeniable. By choosing to dedicate their summer to this project, the participants instigated a change in the national consciousness but also in their own. Abstract level commitments can also spawn particular concrete commitments. s Sophie Scholl was committed to the White Rose resistance movement because, in part, she was committed to exposing the injustice of the German regime in WWII of (see Introduction, Section I.3 and Coda). The more general commitment to support oppressed groups that one finds on the left in Western countries has been shown to be a source of extreme commitments to particular outgroups (e.g. Palestinians, Kurds) based on the perception of the group as unjustly oppressed. In some cases, ro identification with the oppressed out-­group (e.g. Kurds) is even stronger than identification with their own in-­group (e.g. Canadians), producing an interesting inversion of the inclusion dimension (Kunst et al., 2018). It seems likely, though, that most people with extraordinary levels of commitment lP to a particular cause did not decide to “become good” at a general level but instead had some initial attraction to a particular project (perhaps articulated as a more general ideal) and then became more committed. One may not plan to make high levels of commitment to a cause, but one could instead stumble upon or be drawn into it. This attraction itself might be based on previous value commitments that were free-­floating na and unattached to any specific cause. But there is very little research that would help us untangle the precedence of commitment to abstract values vs. specific causes. The philosopher Gadamer’s work on the problem of application (Gadamer, 1975, 1996) suggests that specific commitments in applied domains are unlikely to be the simple “application” of general commitments and principles to that domain. Moral Fi action at the level of commitment to these particular causes (Palestinians, Kurds, civil rights, etc.) or domains (e.g. engineering, medicine) is often thought of as simply applying knowledge (e.g. about rights) to specific cases (e.g. civil rights). But careful analysis of the problem of understanding in “application” suggests that there is knowledge and truth to be discovered in the process of application itself, knowledge that is unavailable from abstract knowledge of the domain. Knowing about privacy rights, for instance, is only a very small part of what one needs to “know” to be able to design software that protects privacy (Huff & Furchert, 2014). Movement back and forth from a specific application area to general principles seems more likely than top–down application. Goal-­directed moral formation does not have to be an entirely conscious process. Our goals can guide the focus of our attention, and this influence can happen outside of conscious awareness (Dijksterhuis & Aarts, 2010). This influence is particularly evident when those goals are ones that have been practiced to the point that pursuit of them has become habitual (Aarts & Dijksterhuis, 2000). Taking Moral Action As a part of the general pattern of development from agency to communion, there is clearly an increase in commitment to communion values from childhood through early adulthood. At this point, we know only that this trajectory has been documented. We have no evidence that it is the only trajectory that one would want to call moral formation, and some evidence that alternative paths exist. We know little about what individual differences or moral ecological influences there are on the trajectory. And, except among moral exemplars, we know little about the trajectory or its variation or influences among adults and older adults. 9.3.2 A Three-­Dimensional Moral Formation Space: Self-­Transcendence, Openness, and Inclusion We have just reviewed five dimensions (self-­transcendence, openness to change, inclusion, s rules, and specific projects) on which one might look for variation in values and commitments. One implication of this review is that there is a need for thoughtful integraof tion of the possible dimensions of the value landscape in moral action. With this tentative map of the landscape, we can document some movement within it that might count as normative moral formation – the choosing and appropriation of moral goals and the process of putting the normative into action. The appropriate criterion ro for success of any dimensional model is not whether the dimensions are “real” but whether they are helpful in discovering patterns and variation in moral formation and change. Our interest here is identifying a manageable subset that allows us to grasp the complexity of the differences in the good, or in moral commitments. lP We begin by leaving aside two possible candidates. The space of specific commitments and projects (Section 9.3.1.4) is simply too diverse to provide much explanatory power at the nomothetic level of averaged tendencies among many people.35 The rule–goal distinction (Section 9.3.1.4) is more of a dichotomy than a space within which formation might occur. And particular rules and goals are legion – see the lists na of rules and goals in any professional code of ethics. We are left with a three-­dimensional landscape that we will lightheartedly label TOI: self-­transcendence, openness, and inclusion.36 The dimension of transcendence is about what goal is chosen, while the other two are focused on how and for whom that goal is approached or implemented. One can imagine (and there appear to be Fi documented instances of) people moving along one dimension without much change on the other two.37 There is a significant research literature associated with the moral 35 One could reduce the complexity by forming types of projects (e.g. social justice, artistic, helping, etc.) in the same way one might think of types of goals for self-­transcendence. 36 Pronounced “toy.” 37 Movement within this space might also occur at several different levels of personality. McAdams (2013, p. 276) borrows language from William James (1892/1963) to ask the question: “What does the I see when it looks on the Me?” He proposes three ways or aspects of how this might happen, actor, agent, and author. In terms of moral formation process we might call these becoming good (actor), seeking particular goods (agent), and moral authorship (author). This additional layer of complexity in moral formation provides even more richness in how people shape their formation and gives the opportunity for further labyrinths of self-­deception or surprises of moral critique and insight. Moral Formation 269 aspects of each dimension. This alone argues that the dimensions in themselves are important for moral formation. And they do seem to be dimensional, allowing for various positions along a continuum (or perhaps multiple positions depending on the domain). Whether they are independent dimensions is a matter for empirical study, though work we reviewed in Sections 9.3.1.1–9.3.1.3 suggests patterns in which they may be somewhat correlated. The point of constructing a dimensional model like this is to open up exploration in the variety of ways people make moral commitments and take moral action. It helps to structure and identify the different ways people might self-­transcend. Those who transcend the self in service of a project might be committed (or resistant) to social change and shape their project or value commitments accordingly. Or they may be narrowly focused on helping a particular group, or motivated by the threat they perceive from another group. Exploring these variations in openness and inclusion will s expand our grasp of the many ways people embody moral action. of 9.3.3 Direction of Change in Moral Formation In addition to variation across individuals in value commitment, one can find variation across time in a person’s life. Schwartz (2006, Table 1) reports, for instance, that ro values of agentic self-­enhancement decrease over the life span in a variety of cultures, while communal self-­transcending values increase over the life span. Over time, how might we become more involved in pro-­social roles, or more committed to moral strivings and goals, or able to more thoroughly integrate themes of lP moral action into our life narratives? Can we even do so? Do most people’s values “improve with age … develop in the direction of greater tolerance, or wisdom or some other imagined enlightened state” (McAdams, 2015, p. 233)? There is surely a developmental progression in the moral domain from infancy to adolescence in terms of greater complexity and more pro-­social orientation. Kohlberg’s research program na in moral judgment documented this, as has much developmental research since then (see Gibbs et al., 2007; Lapsley, 2020; Lapsley & Hardy, 2017 for reviews). But is there “improvement with age” over time for adults? Schwartz’s (2006) cross cultural research program in values regularly shows increases in values of benevolence across the life span. However, beyond this documentation there is little systematic evidence. Fi McAdams (2015, p. 234) answers his question thus: “Scientific evidence for such a romantic view is sparse.” In fact, looking for simple value change over time may run into the same complexities that at one time led social and personality psychologists to conclude that there were no stable effects of personality on behavior (Mischel, 1968, 2004). Recall the fruitless search for consistency in “honest” behavior in children across situations by Hartshorne and May (1928). Only after decades of research did more sophisticated efforts find complex patterns of consistency that differed from one individual to the next (Cervone, 2004; Roberts & Wood, 2006; Shoda, LeeTiernan, & Mischel, 2002).38 A similar pattern may be emerging in normative moral formation. 38 See Chapter 4 for more on this. Taking Moral Action In a groundbreaking series of studies, the Canadian psychologists Walker, Frimer, and their colleagues (Frimer et al., 2011; Frimer et al., 2012; Walker & Frimer, 2015) have been identifying complex patterns of value change across the lifespan that they argue can clearly be labeled as moral development. They have documented changes in value themes in adolescents to adults and linked these changes to either actual moral behavior (as seen in moral exemplars) or to self-­reports of moral behavior. They are thus building a foundation for an argument about moral formation across the life span. They situate their research program within the value space provided by Schwartz’s value circumplex. Their central finding shows a move from characteristic adolescent endorsement of agentic values (e.g. personal achievement and competence values, on the lower left side of the Schwartz circle) to communal values in adulthood (e.g. benevolence and universal care values, on the upper right side of the circle).39 But this change is characterized by a certain complexity. The movement is not simply from s endorsement of one value to the other but also involves the way the value is endorsed. As adolescents and adults make this developmental transition they move from (1) seeof ing agency as more important than communion, to (2) seeing them as both valuable, and then (3) transforming their valuation of agency by seeing it as a means to ­achieving communion. Thus, agency is at first a terminal value, valued for its own sake, but later becomes at least in part an instrumental value, valued because it is instrumental in ro achieving communion. Their evidence for this transformation comes from a series of studies done with adolescents and adults using both qualitative and quantitative approaches (Dunlop, Walker, & Matsuba, 2013; Frimer, 2012; Frimer & Walker, 2009; Frimer et al., 2011; Frimer et al., 2012; Walker & Frimer, 2015). lP This research program suggests a developmental trajectory in the moral domain: that “displacing agency with communion as the terminal value should be a fundamental goal for moral development” (Walker & Frimer, 2015, p. 430). Note that with this claim, we have crossed the boundary from descriptive claims to normative claims: communion as the terminal value “should be a fundamental goal.” This move na from the empirical to the normative parallels Kohlberg’s earlier claim that he had found an empirical foundation for a normative ethic (Kohlberg, 1971). This approach is a slightly stronger claim than Kohlberg’s in that it is based in part on empirical observation of moral exemplars. This trajectory of displacing agency with communion may itself vary among individuals depending on what other value commitments Fi they have. For the sake of accuracy, we have presented the work of Walker and Frimer (2015) so far using the terms they prefer, agency and communion. But, given our Humboldtian approach, we have spent much of the book arguing that there are multiple goals, values, or projects one might call ultimate, and therefore anchor the moral realm for the individual who chooses that goal as ultimate. So, we have been using the terms self-­enhancing and self-­transcending to encompass all the possible values, goals, projects, etc. that people might take as ultimate concerns.40 39 As we discuss this research program, we will use the original dimension names (agency vs. communion) from Walker and Frimer (2015), rather than our preferred labels of self-­ enhancement to self-­transcendence. 40 In agreement with the dimensional terms originally used by Borg et al. (2015). Moral Formation 271 The heart of moral formation is this self-­ transcending value–goal–project ­appropriation process. It includes not just an internal reorganization of commitments but also skilled action, putting the self-­transcendent commitment into practice. The psychological question is: How do these processes of commitment and enacting work? One answer is to look to social–emotional–reflective equilibrium (SERE). One might think that this sort of embodied commitment to a self-­transcendent goal conflicts with the idea of equilibrium that we have identified in Chapters 7 and 8 (among others). Self-­transcendence, at least at its extremes, can produce extraordinary and life-­altering commitment for some moral exemplars. But the two concepts are really just different aspects of the same process. Equilibrium in SERE does not mean finding the easiest path but the most appropriate and practically viable answer to the question: What does a person like me do in a situation like this? When we commit to a self-­transcendent goal, we are still left with the everyday difficulties of imples menting our goals and intentions in the historical situations in which we find ourselves. It is in fact the continued practice of SERE within ongoing moral action (and the of continued practice of self-­transcendence within SERE) that makes self-­transcendent moral action possible. ro"
9,9.3,"Normative/Self-­Transcending Aspects s of Moral Formation of Much of what we call the psychology of moral action consists of processes (e.g. self-­ regulation, etc.) that can be analyzed in a content-­free manner. That is, one can easily imagine a wide range of goals, values, or narratives that could drive these processes. For example, careful evaluative moral formation can serve a person’s goal of becoming more ro compassionate or ruthless in pursuit of a supreme value (Côté et al., 2011). Evaluative moral formation can be based on a narrative of good coming from the bad or a narrative of the constant, enervating resurgence of failure (McAdams et al., 2001). Moral attentiveness can be focused on threat from the outsider and compassion only for the lP insider (Hart, 2005b; Hart & Carlo, 2005). How can we find some structure in this confusing variation in values, ideals, goals, and projects that can direct both moral and immoral action? 9.3.1 Value Dimensions of Normative Formation na We have often mentioned pluralism in values in this book. What is the landscape of the variety of values from which people select some subset to guide their moral formation? If we want to become good, how do we determine what the good looks like? There are a wide array of works that identify dimensions of value in motivation content and little convergence among them.23 There is even disagreement about the Fi ultimate goal within and among the three humanistic traditions with which we began the chapter. Despite this disagreement and confusion, we will nevertheless attempt to systematize the variety of content and meaning that is relevant to moral becoming. It is easy to multiply examples of the different content and values that can drive moral formation. It is less easy to bring some structure to the diversity in a way that helps us understand it. In this section we will, in the Humboldtian spirit, be looking for the diversity and the structure in this wide variation. What are the various kinds of values, goals, projects, etc. that motivate moral action?24 Can we organize them in some way that allows us to understand their interrelationship? 23 This is in part because there are so many options and so little theoretical integration. See n. 5 for an incomplete listing of approaches and systems. 24 To see a more in-­depth discussion of values as self-­transcendent or ultimate, see the Introduction and Chapter 5. Taking Moral Action All developmental moral psychology presumes some movement in values (e.g. from self-­centeredness to the inclusion of others). It is implicit in the notion of development or formation that it is not mere change but movement toward some ideal or telos (Schachter & Ben Hur, 2019; Schnitker, King, & Houltberg, 2019). If we construct a space of values, goals, or projects relevant to moral action, how might the choosing individual move among them in commitment in a way that could be called formation? Thus, the questions we ask in this section are: Within what value space is moral formation occurring? And how does the individual actor attach or change their attachment to these values in a way that might be called moral formation?25 To engage these questions, we will look at five dimensions of the landscape of goals and values toward which one might orient moral formation, and from them construct a complex-­enough three-­dimensional space within which it would be productive to track moral formation and change. s 9.3.1.1 Self-­Transcendence In the Introduction, we proposed an existential turn (Section I.6.1) that reminds us of the need for self-­transcendence to move from of simply knowing that a value, ideal, or project has value to actually appropriating that value in one’s own life. It is how one moves from merely objective observation of ethical values to personal choice and commitment, and thus to the place from which motivation to moral action springs. We argued there that this turn opens up the self ro to transcendence to the variety of goals, values, or projects that might be treated as ultimate by the individual. This is a move away from attachment to self-­serving values to ultimate attachment to the greater good, or to ultimate values. lP SelfTranscendence UniversSelfalism Direction na Openness to Benevolence Change Stimulation Fi Conformity Tradition Hedonism Security Conservation Achievement Power SelfEnhancement Figure 9.1 Schwartz circle of value regions. Source: Adapted from Borg, Bardi, and Schwartz (2015). 25 These two questions mirror Kierkegaard’s distinction between the what and the how of existential appropriation. Moral Formation 261 In Chapter 3 (Figure 3.1) we introduced a cross-­culturally valid model of values that sees them as arranged around a circle in opposing pairs, with values near to each other on the circle being more compatible (reproduced here as Figure 9.1 for reader convenience). In it, one can see that self-­enhancement (lower left) is opposed, across the circle, to self-­transcendence (upper right). And at a near right angle to this is a dimension ranging from conservation (right) to openness to change (left). This is a second dimension in the value space that we will discuss in Section 9.3.1.2. The two dimensions form a circle with more specific values arranged around the circumference. The approach is based on the idea that cultures and individuals find themselves somewhere within the circle at a balance point between the various opposing values, endorsing all to some extent, but favoring some over others.26 The circle provides a structure for the characteristic ways that cultures and individuals balance these values (Borg, Bardi, & Schwartz, 2017). s In Section 9.3.3, we will review extensive work by Walker and Frimer suggesting that there is interesting individual development over the life span on the dimension of of self-­transcendence, e.g. not just a simple movement from one to the other but an integration of the two ends of the dimension, with self-­enhancement serving the goal of self-­transcendence (Walker & Frimer, 2015). This crucial developmental sequence makes it clear that self-­transcendence will be important to include in any model of ro moral formation. We cover this dimension in greater detail in that section. We label it as self-­transcendence in part to connect it to other literatures (Frankl, 1997; Koltko-­ Rivera, 2006; Maslow, 1969) and in part to allow Humboldtian space for the wide variety of values or projects for which people self-­transcend.27 lP The self-­transcendent end of this dimension needs to be considered at the idiographic level, because it is open with regards to the particular goal or telos of self-­ transcendence that each person might choose. See Section 9.6.1.5 on specific commitments and projects to get some idea of the diversity we are including here. Here, self-­transcendence is more the task or process required than the end goal itself, na which is complex and widely variable. Further, for each individual self-­transcendence may be more complicated than one goal. Here, the complexity of the self and its commitments that we outline in Chapter 5 becomes evident. One might have moderate Fi 26 This is a pictorial way of interpreting the rank ordering of the various values by ­different cultures (Schwartz, 2016; Schwartz et al., 2012). Empirical reality is a bit more complicated. Rank orderings in some cultures do not preserve the order of the circumplex (Schwartz, 2006), and thus the geometric balance point interpretation we offer here founders in these instances. The recruitment of one value in the service of another that we explain in Section 9.3.3 may help to understand some of these inversions. 27 Names of dimensions like these are always negotiable. Walker and Frimer (2015) replace “self-­enhancement” with “agency” and “self-­transcendence” with “communion” as their labels for the endpoints of this dimension, in part to connect it to other literatures. We prefer self-­transcendence in order to emphasize the multitude of non-­social goods to which one might be devoted (religion, art, environment, etc.). See the discussions in the Introduction and in Chapter 5. It is important to note that the label “self-­transcendence” here is not in itself a value, goal, or project. It is, rather, a stand in for the multitude of goods for which individuals might self-­transcend and that they might take as ultimate. This fundamentally alters the dimension by not anchoring this end in pro-­social values, while still allowing them among other ends. Taking Moral Action self-­transcendence toward the value of compassion (producing a general pro-­social attitude) and passionate, even ultimate, dedication to family or some other life project. These values might be integrated in some way (e.g. with compassion as the theme in a particular narrow project) or exist in tension across separate domains of the multidimensional self (e.g. work projects vs. family commitments). And to the extent that a particular value or goal is really considered to be ultimate, there should be tension to integrate it across the separate domains of the self. The point of ultimate value is that for some people, at least in some domains of their life, some value, telos, or life project is taken as the most important thing. And for some people, this extends over all domains in their life. We must include a caution here on recognizing the multiplicity of possible goals in self-­transcendence. Some goals for which people sacrifice themselves involve causing harm to others. Koltko-­Rivera (2006) grapples with this difficulty in his review of s Maslow’s understanding of self-­transcendence and admits that terrorism and other forms of evil can, at the idiographic level of personal commitments, look a great deal of like self-­transcendence. Thus, commitment to a self-­transcendent goal has a dark side (Hart & Carlo, 2005; Skitka, 2014; Skitka & Mullen, 2002; Washburn & Skitka, 2017). Scholars will need to do the work to distinguish between the goals. It may be that the psychological processes are very similar if not identical. Perhaps some ro of the other dimensions we list in Sections 9.3.1.2–9.3.1.5 will help us do so (e.g. inclusion). Opening up this dimension to this puzzle of identifying appropriate ultimate goals allows us to frame the problem of the crucial and unavoidable work of distinguishing what the good is and whether how we become good is the same prolP cess as how we become evil. This brings us back to the idiographic struggles of each individual as they engage in their teleological task of contemplating their ultimate concern (see Section 9.1.2). 9.3.1.2 Openness to Change The second dimension in the figure is openness vs. na conservation. This seems to be treated more as a personality characteristic that does not change much over time. Research seems to focus mostly on the ways this dimension tracks the (supposedly static) liberal – conservative continuum in the United States. But we might also find some interaction between trajectories in the two dimensions. Those with conservation commitments might show a different pattern of development Fi from self-­enhancement to self-­ transcendence than those with commitments to openness. This is speculation at this point, but one can imagine those who mature on the self-­ transcendence dimension in politically or institutionally or culturally conservative households might select very different kinds of life projects than those who might mature in households that value political, institutional, or cultural change. Seeing these two dimensions as forming a moral formation space allows us to ask these questions, and again to expand the space of what is moral and how people choose to be moral. 9.3.1.3 Inclusion/Exclusion This dimension is the extent to which we include others in our understanding of those deserving of moral consideration. The move from self-­ enhancement to self-­transcendence does not remove us from the messy difficulties of deciding for whom one should have compassion, or how others are included in one’s religious commitments, or for whom social justice is important. How wide should Moral Formation 263 one’s circle of concern be? We should note that the value circumplex model has “universalism” as one value at the self-­transcendence end of the dimension. And this suggests that the more one endorses or appropriates communion the wider one’s circle of concern should be. But the Schwartz (2016) model is based on averages across many people, and there may well be those for whom self-­transcendence does not entail opening wide the gates to all. For instance, we already know there are sub-­types of moral exemplars. The distinctiveness of two of the sub-­types (helper vs. reformer, see Chapter 3, Section 3.2.1.4) consists in part in for whom they are moral. Helpers care for certain individuals with needs, and do not much concentrate on societal change. Reformers want to change systems as an instrumental goal in service of producing justice or care for others.28 The latter may be more universalist in their embrace of others, while some helpers may be more restrictive in their compassion. The “deserving poor” is a standard trope s for those who want to limit social assistance. Still, even reformers limit their focus to particular social justice issues, and thus leave out those affected by the neglected of issues. A more theoretically targeted selection of moral exemplars might help us grasp some of the variation in ways that people do good and the extent of inclusion of others in that moral action. Susan Opotow explores this dynamic of with whom one values communion under ro the label moral inclusion/exclusion (Clayton & Opotow, 2003; Opotow, 2001, 2005) and we adopt this language for this dimension. She has reviewed how moral exclusion is constructed in a moral ecology (Opotow, 2001) and how programs stressing moral inclusion can help to reduce violence and injustice (Opotow, 2005). Others have lP begun to investigate what they call moral expansiveness, the inclusion of a wide range of others in their circle of concern. This work has shown expansiveness to uniquely predict willingness to prioritize humanitarian and environmental concern over personal and national interest (Crimston et al., 2016). Similarly, Graham et al. (2017) propose centrifugal and centripetal forces and frame them as separate and competing na pressures to form some balance along a continuum they call the moral circle. And, of course, work on altruism that used in-­depth interviews with those who helped Jews escape the Holocaust found a personality characteristic called extensivity (the extent to which one included others in the circle of moral concern) to best differentiate between those who helped and those who did not (Einolf, 2010; Oliner & Fi Oliner, 1988). These parallel theoretical accounts suggest there is likely another important dimension along which normative moral formation can take place. One might have great integrity about justice and care for those we include in the deserving community, while being callous and uncaring for those “other people.” We show a different moral face to those who are “them” than we do to those who are “us.” One can also limit one’s moral horizon without overt prejudice, by unexamined or intentional parochialism. Again, the Munsons (see the Introduction) serve as an example. At what point in their progression of commitment do they become exemplary? Even at the beginning, 28 One can, of course, do both or neither, as do some of the exemplars from Huff and Barnard (2009). Those doing neither were focused on more specific projects like mentoring (see Section 9.3.1.4 for what specific projects might look like). Taking Moral Action when caring only for their own foster children, they are self-­transcending, but their self-­transcendence is inclusive of only a small circle. We know a little about what might influence the inclusion dimension relevant to normative moral formation. It seems to be flexible depending on moral framing and domain but also reliably related to the development of moral identity.29 Its flexibility is influenced in part by empathy. In everyday life, we primarily experience empathy for close others rather than those at a distance (Depow, Frances, & Inzlicht, 2021). However, empathy is not inherently exclusive and one can frame judgments in a way that fosters egalitarian empathy (Fowler, Law, & Gaesser, 2021). One can likewise frame judgments in ways that encourage “virtuous violence” against the other (Cohen-­Chen, Pliskin, & Goldenberg, 2020; Fiske & Rai, 2014). Cultural preferences for tight framing of moral constraints and the moral circle can anchor inclusion but also change it as the culture reacts to external threats (Gelfand, 2012, 2021; s J. C. Wright, 2021). There is some evidence that higher levels of moral identity are associated with a of wider “circle of moral regard” (Aquino et al., 2006; Reed & Aquino, 2003). And even for those who value group loyalty, commitment to moral identity reduces the extent to which they are willing to endorse torture in its service (Smith et al., 2014). This at least allows us to say that even though conservative and liberal value commitro ments might look different, if they have integrated morality into their identity one can expect they will share some values (Frimer, Tell, & Haidt, 2015). So, we may need to differentiate between inclusion with regard to basic humanity (e.g. appropriate targets for compassion and human rights) and an inclusion that involves a more lP complete reception, incorporation of, and obligation to the other. Beyond simple viewing of others as part of “us,” participation within a community helps to construct our sense of self. Seeing one’s self as socially connected influences compassion and socially responsible behavior (Cojuharenco, Cornelissen, & Karelaia, 2016; Cross, Bacon, & Morris, 2000; Day & Impett, 2018; Vignoles, 2018). na In a longitudinal study of high-­school students, Pratt et al. (2003) found that self-­ ideal (measured by self-­report of traits one strives for, such as being a good citizen, fair, just, caring) predicted community involvement, but over time it was community involvement that led to increases of these self-­ideal traits. Thus, active participation in community can produce a virtuous cycle of self-­ascription of traits, followed by furFi ther community service. Hart (2005a, p. 260) argues that “If the notion of identity is to contribute to an understanding of moral functioning, then it must be a construct with deep roots in a social world.” As we consider incorporating inclusion/exclusion in our moral space, these roots will need to be both deep and specific to each individual and his or her personal history and moral ecology. Piliavin and colleagues (Grube & Piliavin, 2000; Piliavin & Callero, 1991) have shown the importance of “specific role identity” (as, e.g. a blood donor or a cancer society volunteer) in supporting volunteer activity. Rule and Bebeau (2005) and Huff and Barnard (2009) have also tracked the importance of specific 29 Graham et al. (2017) provide a short history of the use of this dimension and survey a host of factors that can influence one’s position on the dimension. Moral Formation 265 identity themes in professions. The extent to which these specific commitments limit or facilitate moral inclusion is as yet unexplored. 9.3.1.4 Rules vs. Goals We also need to consider the possibility that, for many people, or even for most people at one time or another, morality is not really about the pursuit of moral goals but instead the following of moral rules that serve as guardrails. Most professional codes of ethics include two types of items: things one ought not to do, and moral ideals one should approach (Harris, 2008). In Chapter 6, we explored Kuhl and Koole’s (2004) distinction between the self-­control system and the self-­maintenance system. This is roughly the distinction between those processes that help the person focus on the task at hand and avoid temptation and those processes that direct the person to take valued action. In the domain of engineering, the philosopher Charles Harris (2008) presents a s parallel distinction between preventive values and aspirational values. Preventive values are about “not violating moral rules.” These constitute about 80% of the text of the of National Society of Professional Engineers code of ethics and are essentially negative in form (e.g. not approving documents that do not conform to standards). Aspirational values are about approaching moral goals or values. Harris (2008) gives examples of designing safety into engineering systems that goes beyond codes and standards, eviro dencing a deep commitment to safe engineering, or to environmentally thoughtful engineering, or to engineering that takes its social embedding and impacts seriously. Similarly, Janoff-­Bulman and Carnes (2018) use the basic motivational processes of approach (prescriptive) and avoidance (proscriptive) to frame a model of moral lP motives that operates at three levels, the intrapersonal, the interpersonal, and the collective. This taxonomy provides useful insight, for instance, into the differences one finds at the collective level between conservatives, (who favor social order – an ­avoidance goal) and liberals (who favor social justice – an approach goal). Thus, the domain of moral rules and obligations (e.g. do not lie, cheat, plagiarize) na may well be associated with the self-­control system and have its own trajectory in moral formation. And the domain of aspirational goals (e.g. be a blood donor, care for the poor) may be associated with the self-­enhancement system, particularly when these moral goals are an important part of the self (Cervone & Tripathi, 2009).30 Additionally, each system may have its own distinctive pull on the moral action of Fi the individual. As Nucci (2004) notes, even if individuals do not have morality as a defining aspect of the self (and are thus not engaging the self-­enhancement system in the service of moral goals), there is still something about the moral domain that makes it difficult simply to ignore rules. “I’m not good at academics,” sounds qualitatively different (and much less dangerous) than “I’m not good at morality.” We expect the pull of rule-­based, inhibitory, preventative morality to be widely shared, even by those for whom moral goals are not central to the self.31 But there is very little work on how these two systems interact or how the two different kinds of moral motivations differ. See Chapter 6 for more on this distinction. 30 But we make exceptions for (and even inversions of) those rules when it comes to treating 31 outsiders and enemies (Cohen-­Chen et al., 2020; Fiske & Rai, 2014). Taking Moral Action 9.3.1.5 Specific Commitments and Projects So far, this discussion is operating at a highly abstract level of general themes in morality (self-­ enhancement and transcendence, moral identity, moral exclusion, rule following) rather than the concrete particulars of the specific causes to which people normally dedicate themselves.32 It seems likely, however, that the process is not one of becoming good at this abstract level, but more one of becoming good by being attached to a specific, concrete, personal moral goal (rather than an abstract value like communion, or even more vague, self-­ transcendence). Across all the research on exemplars, moral commitment appears to be particular. Despite Suzie Valadez speaking of God’s call to love all people, the people she serves are the poor “people of the dump” in Ciudad-­ Juarez, Mexico (Colby & Damon, 1992, chapter 3). Even though Stephen Engberg is committed to privacy rights and speaks at this abstract level, the particular privacy he cares about is in the design of business software in Denmark (Huff & Barnard, 2009). s Though Walker and Frimer (2007, p. 848) identified value dimensions behind particular concrete commitments, their exemplars were selected because they showed of concrete “extraordinary and long-­term commitment in providing care to individuals or groups, [or to] community service or humanitarian causes.” How do we get from smaller, concrete commitments to larger, more abstract ones? Colby and Damon (1992) propose a process that might lead from local, particular moral commitments ro to broader commitments and offer several examples of that process in their exemplars. They call these environmental personal growth affordances. But only a few of their exemplars show a clear pattern from specific to general.33 The more common development seems to be from lower to higher levels of commitment within a specific lP domain. In a similar vein, Koltko-­Rivera (2006, p. 302) explores Maslow’s concept of self-­ transcendence as “a motivational step beyond self-­actualization.” It is also clear here that the motivation is particular, as self-­transcendence may involve “service to others, devotion to an ideal (e.g., truth, art) or a cause (e.g., social justice, environmentalism, na the pursuit of science, a religious faith), and/or a desire to be united with what is perceived as transcendent or divine” (Koltko-­Rivera, 2006, p. 303). A similar pattern can be seen in research on how participation in volunteering or social activist work affects those who volunteer. A classic example is the study by McAdam (1989) on the effects of the 1964 Mississippi Freedom Summer project on Fi 212 participants in the project, as compared to 118 who signed up, were accepted, but did not go.34 Compared to the no-­shows, the participants were still deeply engaged in politics twenty years later, were more likely to be unmarried, have lower income, and to be concentrated in the helping professions (e.g. teaching). The study 32 Frimer et al.’s approach to categorizing agency and communion as terminal or instrumental involves either interviews in which people must identify values as terminal or an elaborate coding approach that finds the abstract themes in the text of the interview (Frimer et al., 2011). It is at this level of abstraction that they find patterns. In most of the interviews, their participants speak movingly about commitments to specific projects and actions. 33 We know of no other systematic data on this trajectory or its influences. 34 These were volunteers from all over the United States who came to Mississippi for a summer focused on civil-­rights organizing, non-­violent demonstration, and civil disobedience in support of civil rights for African Americans, particularly in the Jim Crow south. Moral Formation 267 is based on the completed applications of the two groups (obtained from archives) and a follow-­up survey sent to them in the late 1980s. The no-­shows “did not differ significantly from the participants in the values they brought to the project … [and] appear as essentially alike on a list of variables: race, social class, type of neighborhood, home region, type of school, and major in school” (McAdam, 1989, p. 749) But participation in the Freedom Summer likely affected their self-­concept and their later work (and even romantic partner) choices. The intertwining of personality, moral identity, skills and knowledge, and moral ecology are quite complicated here (see e.g. Bosi, 2016; Giugni, 2004; McAdam, 1989) but the effects of immersion in the complex moral ecology of civil resistance seem undeniable. By choosing to dedicate their summer to this project, the participants instigated a change in the national consciousness but also in their own. Abstract level commitments can also spawn particular concrete commitments. s Sophie Scholl was committed to the White Rose resistance movement because, in part, she was committed to exposing the injustice of the German regime in WWII of (see Introduction, Section I.3 and Coda). The more general commitment to support oppressed groups that one finds on the left in Western countries has been shown to be a source of extreme commitments to particular outgroups (e.g. Palestinians, Kurds) based on the perception of the group as unjustly oppressed. In some cases, ro identification with the oppressed out-­group (e.g. Kurds) is even stronger than identification with their own in-­group (e.g. Canadians), producing an interesting inversion of the inclusion dimension (Kunst et al., 2018). It seems likely, though, that most people with extraordinary levels of commitment lP to a particular cause did not decide to “become good” at a general level but instead had some initial attraction to a particular project (perhaps articulated as a more general ideal) and then became more committed. One may not plan to make high levels of commitment to a cause, but one could instead stumble upon or be drawn into it. This attraction itself might be based on previous value commitments that were free-­floating na and unattached to any specific cause. But there is very little research that would help us untangle the precedence of commitment to abstract values vs. specific causes. The philosopher Gadamer’s work on the problem of application (Gadamer, 1975, 1996) suggests that specific commitments in applied domains are unlikely to be the simple “application” of general commitments and principles to that domain. Moral Fi action at the level of commitment to these particular causes (Palestinians, Kurds, civil rights, etc.) or domains (e.g. engineering, medicine) is often thought of as simply applying knowledge (e.g. about rights) to specific cases (e.g. civil rights). But careful analysis of the problem of understanding in “application” suggests that there is knowledge and truth to be discovered in the process of application itself, knowledge that is unavailable from abstract knowledge of the domain. Knowing about privacy rights, for instance, is only a very small part of what one needs to “know” to be able to design software that protects privacy (Huff & Furchert, 2014). Movement back and forth from a specific application area to general principles seems more likely than top–down application. Goal-­directed moral formation does not have to be an entirely conscious process. Our goals can guide the focus of our attention, and this influence can happen outside of conscious awareness (Dijksterhuis & Aarts, 2010). This influence is particularly evident when those goals are ones that have been practiced to the point that pursuit of them has become habitual (Aarts & Dijksterhuis, 2000). Taking Moral Action As a part of the general pattern of development from agency to communion, there is clearly an increase in commitment to communion values from childhood through early adulthood. At this point, we know only that this trajectory has been documented. We have no evidence that it is the only trajectory that one would want to call moral formation, and some evidence that alternative paths exist. We know little about what individual differences or moral ecological influences there are on the trajectory. And, except among moral exemplars, we know little about the trajectory or its variation or influences among adults and older adults. 9.3.2 A Three-­Dimensional Moral Formation Space: Self-­Transcendence, Openness, and Inclusion We have just reviewed five dimensions (self-­transcendence, openness to change, inclusion, s rules, and specific projects) on which one might look for variation in values and commitments. One implication of this review is that there is a need for thoughtful integraof tion of the possible dimensions of the value landscape in moral action. With this tentative map of the landscape, we can document some movement within it that might count as normative moral formation – the choosing and appropriation of moral goals and the process of putting the normative into action. The appropriate criterion ro for success of any dimensional model is not whether the dimensions are “real” but whether they are helpful in discovering patterns and variation in moral formation and change. Our interest here is identifying a manageable subset that allows us to grasp the complexity of the differences in the good, or in moral commitments. lP We begin by leaving aside two possible candidates. The space of specific commitments and projects (Section 9.3.1.4) is simply too diverse to provide much explanatory power at the nomothetic level of averaged tendencies among many people.35 The rule–goal distinction (Section 9.3.1.4) is more of a dichotomy than a space within which formation might occur. And particular rules and goals are legion – see the lists na of rules and goals in any professional code of ethics. We are left with a three-­dimensional landscape that we will lightheartedly label TOI: self-­transcendence, openness, and inclusion.36 The dimension of transcendence is about what goal is chosen, while the other two are focused on how and for whom that goal is approached or implemented. One can imagine (and there appear to be Fi documented instances of) people moving along one dimension without much change on the other two.37 There is a significant research literature associated with the moral 35 One could reduce the complexity by forming types of projects (e.g. social justice, artistic, helping, etc.) in the same way one might think of types of goals for self-­transcendence. 36 Pronounced “toy.” 37 Movement within this space might also occur at several different levels of personality. McAdams (2013, p. 276) borrows language from William James (1892/1963) to ask the question: “What does the I see when it looks on the Me?” He proposes three ways or aspects of how this might happen, actor, agent, and author. In terms of moral formation process we might call these becoming good (actor), seeking particular goods (agent), and moral authorship (author). This additional layer of complexity in moral formation provides even more richness in how people shape their formation and gives the opportunity for further labyrinths of self-­deception or surprises of moral critique and insight. Moral Formation 269 aspects of each dimension. This alone argues that the dimensions in themselves are important for moral formation. And they do seem to be dimensional, allowing for various positions along a continuum (or perhaps multiple positions depending on the domain). Whether they are independent dimensions is a matter for empirical study, though work we reviewed in Sections 9.3.1.1–9.3.1.3 suggests patterns in which they may be somewhat correlated. The point of constructing a dimensional model like this is to open up exploration in the variety of ways people make moral commitments and take moral action. It helps to structure and identify the different ways people might self-­transcend. Those who transcend the self in service of a project might be committed (or resistant) to social change and shape their project or value commitments accordingly. Or they may be narrowly focused on helping a particular group, or motivated by the threat they perceive from another group. Exploring these variations in openness and inclusion will s expand our grasp of the many ways people embody moral action. of 9.3.3 Direction of Change in Moral Formation In addition to variation across individuals in value commitment, one can find variation across time in a person’s life. Schwartz (2006, Table 1) reports, for instance, that ro values of agentic self-­enhancement decrease over the life span in a variety of cultures, while communal self-­transcending values increase over the life span. Over time, how might we become more involved in pro-­social roles, or more committed to moral strivings and goals, or able to more thoroughly integrate themes of lP moral action into our life narratives? Can we even do so? Do most people’s values “improve with age … develop in the direction of greater tolerance, or wisdom or some other imagined enlightened state” (McAdams, 2015, p. 233)? There is surely a developmental progression in the moral domain from infancy to adolescence in terms of greater complexity and more pro-­social orientation. Kohlberg’s research program na in moral judgment documented this, as has much developmental research since then (see Gibbs et al., 2007; Lapsley, 2020; Lapsley & Hardy, 2017 for reviews). But is there “improvement with age” over time for adults? Schwartz’s (2006) cross cultural research program in values regularly shows increases in values of benevolence across the life span. However, beyond this documentation there is little systematic evidence. Fi McAdams (2015, p. 234) answers his question thus: “Scientific evidence for such a romantic view is sparse.” In fact, looking for simple value change over time may run into the same complexities that at one time led social and personality psychologists to conclude that there were no stable effects of personality on behavior (Mischel, 1968, 2004). Recall the fruitless search for consistency in “honest” behavior in children across situations by Hartshorne and May (1928). Only after decades of research did more sophisticated efforts find complex patterns of consistency that differed from one individual to the next (Cervone, 2004; Roberts & Wood, 2006; Shoda, LeeTiernan, & Mischel, 2002).38 A similar pattern may be emerging in normative moral formation. 38 See Chapter 4 for more on this. Taking Moral Action In a groundbreaking series of studies, the Canadian psychologists Walker, Frimer, and their colleagues (Frimer et al., 2011; Frimer et al., 2012; Walker & Frimer, 2015) have been identifying complex patterns of value change across the lifespan that they argue can clearly be labeled as moral development. They have documented changes in value themes in adolescents to adults and linked these changes to either actual moral behavior (as seen in moral exemplars) or to self-­reports of moral behavior. They are thus building a foundation for an argument about moral formation across the life span. They situate their research program within the value space provided by Schwartz’s value circumplex. Their central finding shows a move from characteristic adolescent endorsement of agentic values (e.g. personal achievement and competence values, on the lower left side of the Schwartz circle) to communal values in adulthood (e.g. benevolence and universal care values, on the upper right side of the circle).39 But this change is characterized by a certain complexity. The movement is not simply from s endorsement of one value to the other but also involves the way the value is endorsed. As adolescents and adults make this developmental transition they move from (1) seeof ing agency as more important than communion, to (2) seeing them as both valuable, and then (3) transforming their valuation of agency by seeing it as a means to ­achieving communion. Thus, agency is at first a terminal value, valued for its own sake, but later becomes at least in part an instrumental value, valued because it is instrumental in ro achieving communion. Their evidence for this transformation comes from a series of studies done with adolescents and adults using both qualitative and quantitative approaches (Dunlop, Walker, & Matsuba, 2013; Frimer, 2012; Frimer & Walker, 2009; Frimer et al., 2011; Frimer et al., 2012; Walker & Frimer, 2015). lP This research program suggests a developmental trajectory in the moral domain: that “displacing agency with communion as the terminal value should be a fundamental goal for moral development” (Walker & Frimer, 2015, p. 430). Note that with this claim, we have crossed the boundary from descriptive claims to normative claims: communion as the terminal value “should be a fundamental goal.” This move na from the empirical to the normative parallels Kohlberg’s earlier claim that he had found an empirical foundation for a normative ethic (Kohlberg, 1971). This approach is a slightly stronger claim than Kohlberg’s in that it is based in part on empirical observation of moral exemplars. This trajectory of displacing agency with communion may itself vary among individuals depending on what other value commitments Fi they have. For the sake of accuracy, we have presented the work of Walker and Frimer (2015) so far using the terms they prefer, agency and communion. But, given our Humboldtian approach, we have spent much of the book arguing that there are multiple goals, values, or projects one might call ultimate, and therefore anchor the moral realm for the individual who chooses that goal as ultimate. So, we have been using the terms self-­enhancing and self-­transcending to encompass all the possible values, goals, projects, etc. that people might take as ultimate concerns.40 39 As we discuss this research program, we will use the original dimension names (agency vs. communion) from Walker and Frimer (2015), rather than our preferred labels of self-­ enhancement to self-­transcendence. 40 In agreement with the dimensional terms originally used by Borg et al. (2015). Moral Formation 271 The heart of moral formation is this self-­ transcending value–goal–project ­appropriation process. It includes not just an internal reorganization of commitments but also skilled action, putting the self-­transcendent commitment into practice. The psychological question is: How do these processes of commitment and enacting work? One answer is to look to social–emotional–reflective equilibrium (SERE). One might think that this sort of embodied commitment to a self-­transcendent goal conflicts with the idea of equilibrium that we have identified in Chapters 7 and 8 (among others). Self-­transcendence, at least at its extremes, can produce extraordinary and life-­altering commitment for some moral exemplars. But the two concepts are really just different aspects of the same process. Equilibrium in SERE does not mean finding the easiest path but the most appropriate and practically viable answer to the question: What does a person like me do in a situation like this? When we commit to a self-­transcendent goal, we are still left with the everyday difficulties of imples menting our goals and intentions in the historical situations in which we find ourselves. It is in fact the continued practice of SERE within ongoing moral action (and the of continued practice of self-­transcendence within SERE) that makes self-­transcendent moral action possible. ro 9.3.4 Critique from the Three Traditions The issue of inclusion, for whom moral identity is relevant, is rarely addressed in the moral psychology literature. Both Bildung and monastic traditions make it central. Bildung is at its roots aristocratic, but it can provide a platform to embrace wide cullP tural diversity. Monastic and spiritual formation traditions across religions also view compassion for the other as central to development, though they emphasize care for those “in the community.” These traditions can help maintain the complexity of the “for whom” when we want both to avoid “ethnocentrism” and care for those to whom we have special obligations. na And centrally for this normative aspect of moral formation, the hierarchical and ultimate nature of value commitments needs to be better addressed. Kierkegaard and his secular adopters are clear about the decisive role of the ultimate telos (as was his Vorbild Socrates with his stressing of the “highest good”) in the rearranging of one’s entire life (and not just one’s “values”).41 True encounter with and appropriation of Fi the ultimate good is transformative to the individual. Surely not as a single experience but as an ongoing dialogue and reckoning as the phrase “ultimate concern” indicates. The Socratic method of midwifery is commonly thought of as based in leisurely Socratic discussion among aristocrats lying on couches, but the metaphors of giving birth and transformation of the heart make it clear that this is a much more extended process than an evening’s relaxed conversation, one that re-­sorts numerous life priorities and painfully touches many aspects of one’s life (as images of being pregnant, in labor, and giving birth suggest). One can see this re-­sorting and recognition of value happening in many of our historical cases. Elizabeth Cheney, for instance, spent most of her political career championing traditional conservative values. It was not until she was confronted with 41 See, for example, Gadamer (1975) on the revealing and concealing of truth in art. Taking Moral Action a transformed political landscape that she found she needed to insist on pre-­existing deeper commitments to, for instance, truth-­telling and the rule of law. This necessarily involved a painful reckoning with her previous commitments. She describes this ongoing adaptation based on ultimate commitments in an interview: “at each moment, … I knew that I had to do what was right. And I knew that the obligation of elected officials to abide by our oath, has to be more important than party, than partisanship, or than any political office” (Karl, 2022 August 21). The intimate psychological details of this elaborate dance of attachment and detachment of relative and ultimate ends (which necessarily includes self-­ transcendence) are yet to be explored by many who possess the tools to begin to grasp it. But it will have to involve a focus on how one values, relates, commits, and attaches to ultimate and relative ends and how this dance is done in changing life circumstances. s 9.4 Educative Aspects of Moral Formation of We have tried in various places to argue that the pull of the moral should is not always a social pull. It can sometimes be religious, or based in dedication to “truth, goodness, beauty, perfection, excellence, simplicity, elegance” (Maslow, 1969, p. 4). But ro all these shoulds, in order to be sustained, require a social matrix in which to thrive. All three of our formation traditions agree that there must, at the minimum, be something beyond the self that guides, encourages, and enables formation. Even the early Christian hermits living in the desert (the “desert elders”) required a social system to lP form their search for holiness (Stewart, 1991). We share our moral judgments with others and are influenced by the moral intuitions of others who are important to us. We look at moral exemplars, read books, attend religious services or theater, choose and gather friends, and go to schools to be inspired and to learn from them. These experiences can motivate us to change our intuitions, even without conscious reflecna tion, and produce a virtuous (or vicious) cycle of influence in which our narratives or goals guide and nurture our social surround: and the surround in turn influences us at both implicit and explicit levels (Wrzus & Roberts, 2017). 9.4.1 Moral Formation as Planned Moral Ecology Fi We noted that a central theme in all three traditions is schooling, with two of the traditions dedicated to founding institutions to support moral formation. Wilhelm Humboldt’s idea of Bildung (Humboldt, 1792/1960) was institutionalized first at the University of Berlin (later named Humboldt University) and dedicated as least as much to realizing the potential of the individual as it did to learning concepts, ideas, and traditions. For this reason, it incorporated research (in the humanities and sciences) so that the individual could take a critical stance to tradition, at least in terms of seeing it as incomplete and open to revision (Herdt, 2019). Monasticism across the religions is also an explicit attempt to create communities (even communities of hermits) to support moral and spiritual formation. The rules and structure of these communities vary, but they are all are justified by, and connected to, their role in helping the community and the individual in that community to concentrate on their moral and spiritual tasks. This has resulted in spectacular Moral Formation 273 architectural achievements (e.g. the Taung Kalat monastery in Burma) and ­millennia-­long continuous traditions of practice (e.g. those communities that follow the Rule of Benedict in Christianity), both in support of moral formation. Kohlberg’s educational program was headlined by the “Just Communities” approach, which also saw its role as creating communities where children, teachers, and administrators could learn to construct a more just and compassionate learning environment together, and thereby form themselves into more fair-­minded and caring persons. The ultimate (and unfulfilled) goal was that the schools and their graduates would become transformative in society (Higgins-­D’Alessandro, 2015). Kohlberg was clear that schools – all schools – teach a moral curriculum, whether it is hidden or intentional. His attempt was both to acknowledge this hidden curriculum and to be intentional about constructing it using what we know about moral formation. The term “hidden curriculum” was first coined by Philip Jackson (Jackson, 1968) s to describe those aspects of the curriculum that are implicit and at least in part unintentional in American K-­12 classrooms. A significant part of the hidden curriculum is of moral and focuses on what we should value and how one should act. It has become an accepted term of art in general education, as well as in medical education (Balboni et al., 2015; Lawrence et al., 2018). It does not take much imagination to extrapolate the hidden curriculum to the occurrence of socialization in organizations that makes ro corruption more (or less) likely. We discuss these processes in Chapter 3. Last, but not least, the tradition of Socratic paideia (Section 9.1.2) has been influential in both educational and therapeutic settings, emphasizing the maieutic aspect of moral and individual formation (philosophical midwifery). Much of the existential lP tradition understands schooling of the heart to be best practiced outside institutions, either in dialogue with a trusted teacher or Vorbild, or in dialogue with literature, art, and one’s own reflections. This process may be better represented in the p ­ sychological literature as social influence. na 9.4.2 Moral Formation as Social Influence Interaction with others who support or challenge our goals can shape both evaluative and normative aspects of moral formation. For instance, a central role of parents is to provide evaluation, support, and guidance to children in their development of moral Fi character (Lapsley, 2020). Close friends, mentors, and spouses can support or inhibit our attainment of valued goals, particularly when they encourage goals that are congruent with our own ideals for ourselves (Rusbult, Finkel, & Kumashiro, 2009). People who are very good in self-­regulation (e.g. in organizing themselves to achieve their goals) tend to shape their social surround to support their goal pursuits (Ent, Baumeister, & Tice, 2015). They prefer to spend time with, collaborate with, and be informed by others who are themselves good at goal pursuit or who are directly instrumental to their goals, choosing colleagues and mentors who support their goal pursuit (vanDellen et al., 2015). Though people with low self-­control tend to reap the most benefit from social support for their goals, they unfortunately are less likely to find themselves in situations where they receive it (Nielsen & Bauer, 2018). But beyond this, interaction can shape and change the moral goals we choose, the rules we emphasize, and the range of our moral concern. Colby and Damon (1992), in their classic study of moral exemplars, document how exemplars are open to, and Taking Moral Action even seek, influence from their social environment that widens their circle of concern. For example, because of her early interests in justice and fairness, Virginia Durr found herself interacting with a variety of social justice activists whose own commitments influenced her to make broader and deeper commitments to social justice (Colby & Damon, 1992, chapter 5). This influence was likely based in both explicit argument with others and implicit influence by others on the way she saw and responded to injustice. These served as catalysts for evaluative and normative moral formation and thus character and personality change. In addition to these interpersonal modes of influence on evaluative moral formation, the structure and social norms of the situations we inhabit can influence our personal development goals and plans. For instance, economies, architecture, and city planning all serve to distance many of us from the harm that meat-­eating causes to those animals we consume (Bastian & Loughnan, 2016). Prejudices and stereotypes, s but also architecture, serve to justify and maintain the existing social order, and vice versa (Jost & Banaji, 1994; Jost & Hunyady, 2005). Extensive work on the self in of cultural context shows that who we become, and who we want to become, is culturally shaped, even in terms of how we critique or struggle against the prevailing culture (Gibbs et al., 2007). ro 9.4.3 Moral Formation as Cultural Conservation and Critique Cultures vary systematically in terms of whether the relations between people are judged based upon independent experience and desire or interdependent social relalP tions.42 “The nail that sticks out is likely to be hammered down in Japan whereas the squeaky wheel attracts grease and attention in the United States” (Markus & Kitayama, 2010, p. 420). The goals, plans, hopes, and narratives of members of a culture are shaped by these ideals. Master narratives, those narratives that are supported by a culture, can shape the personal narrative that an individual adopts. But they can na also become the focus of conflict as people struggle to change or maintain those narratives. For instance, the heterosexual narrative of how family life develops has been challenged by the gay rights movement in the United States (Hammack, 2008), and the acceptable career narrative for women has changed in Western culture over the last decades (Keane, 2015). But in both of these instances, the narrative resources to criFi tique the prevailing culture arose from within that culture in terms of language about human rights – but also religion (Carter, 1993, pp. 39–40). Thus, narratives about moral ideals are influenced by disagreements within a culture and those disagreements often draw on resources from that culture. Across a range of cultures, those who are more politically liberal tend to emphasize justice and care goals, while those who are more politically conservative tend to emphasize loyalty, authority, and sanctity in their judgments and ideals (Graham, Haidt, & Nosek, 2009; Haidt & Joseph, 2004). The difficulty of this meta-­cultural disagreement in values lies in part with the inability of each side to articulate a narrative that appeals to the other side (Haidt, 2012). In these and many other ways, moral formation is socially and culturally embedded. 42 There is, of course, considerable variation within cultures in this dimension, and different aspects of a culture (e.g. legal vs. familial) may embed different assumptions about this. See Chapter 3 for more detail on these differences. Moral Formation 275 9.4.4 Moral Formation and Moral Luck The civil rights activist Virginia Durr did not pay attention to social injustice in her youth but, influenced over the years by her social network and her own commitments to justice and honor, she became exquisitely sensitive to recognizing injustice and working against it (Colby & Damon, 1992). To be sure, some of this was consciously guided, but other episodes seemed automatic and well-­practiced, such as her spontaneous reaction at a women’s church meeting in Alabama when a black participant was asked to leave during lunch since the venue did not allow integrated eating – she walked out with the woman and ate lunch outside (Colby & Damon, 1992, p. 114).43 Ms. Durr’s career in civil rights was also shaped by the accidents of her biography: attending a racially integrated liberal arts college, being introduced in Washington DC to significant figures in the civil rights movement, etc. So the moral luck that s accompanies us all can dramatically change our life stories in ways we do not anticipate.44 We might find that we are led toward some (im)moral goals as events overtake of us, or that our progress toward an (im)moral goal is restricted by events. Or one might not have any plans for becoming a particular kind of person, and instead simply find oneself drawn along a process. We have little systematic knowledge of the variety of paths in adulthood that lead one to moral action, or the role of intention in these ro paths. Or of the various ways that plans, goals, and narrative might reassert themselves in reaction to events. “We are never more (and sometimes much less) than the co-­authors of our own narratives. Only in fantasy do we live what story we please” (MacIntyre, 1981, p. 199).45 Moral formation is thus always multidimensional. It is lP sometimes more and sometimes less intentional, continuous, and controllable."
9,9.4,"Educative Aspects of Moral Formation of We have tried in various places to argue that the pull of the moral should is not always a social pull. It can sometimes be religious, or based in dedication to “truth, goodness, beauty, perfection, excellence, simplicity, elegance” (Maslow, 1969, p. 4). But ro all these shoulds, in order to be sustained, require a social matrix in which to thrive. All three of our formation traditions agree that there must, at the minimum, be something beyond the self that guides, encourages, and enables formation. Even the early Christian hermits living in the desert (the “desert elders”) required a social system to lP form their search for holiness (Stewart, 1991). We share our moral judgments with others and are influenced by the moral intuitions of others who are important to us. We look at moral exemplars, read books, attend religious services or theater, choose and gather friends, and go to schools to be inspired and to learn from them. These experiences can motivate us to change our intuitions, even without conscious reflecna tion, and produce a virtuous (or vicious) cycle of influence in which our narratives or goals guide and nurture our social surround: and the surround in turn influences us at both implicit and explicit levels (Wrzus & Roberts, 2017). 9.4.1 Moral Formation as Planned Moral Ecology Fi We noted that a central theme in all three traditions is schooling, with two of the traditions dedicated to founding institutions to support moral formation. Wilhelm Humboldt’s idea of Bildung (Humboldt, 1792/1960) was institutionalized first at the University of Berlin (later named Humboldt University) and dedicated as least as much to realizing the potential of the individual as it did to learning concepts, ideas, and traditions. For this reason, it incorporated research (in the humanities and sciences) so that the individual could take a critical stance to tradition, at least in terms of seeing it as incomplete and open to revision (Herdt, 2019). Monasticism across the religions is also an explicit attempt to create communities (even communities of hermits) to support moral and spiritual formation. The rules and structure of these communities vary, but they are all are justified by, and connected to, their role in helping the community and the individual in that community to concentrate on their moral and spiritual tasks. This has resulted in spectacular Moral Formation 273 architectural achievements (e.g. the Taung Kalat monastery in Burma) and ­millennia-­long continuous traditions of practice (e.g. those communities that follow the Rule of Benedict in Christianity), both in support of moral formation. Kohlberg’s educational program was headlined by the “Just Communities” approach, which also saw its role as creating communities where children, teachers, and administrators could learn to construct a more just and compassionate learning environment together, and thereby form themselves into more fair-­minded and caring persons. The ultimate (and unfulfilled) goal was that the schools and their graduates would become transformative in society (Higgins-­D’Alessandro, 2015). Kohlberg was clear that schools – all schools – teach a moral curriculum, whether it is hidden or intentional. His attempt was both to acknowledge this hidden curriculum and to be intentional about constructing it using what we know about moral formation. The term “hidden curriculum” was first coined by Philip Jackson (Jackson, 1968) s to describe those aspects of the curriculum that are implicit and at least in part unintentional in American K-­12 classrooms. A significant part of the hidden curriculum is of moral and focuses on what we should value and how one should act. It has become an accepted term of art in general education, as well as in medical education (Balboni et al., 2015; Lawrence et al., 2018). It does not take much imagination to extrapolate the hidden curriculum to the occurrence of socialization in organizations that makes ro corruption more (or less) likely. We discuss these processes in Chapter 3. Last, but not least, the tradition of Socratic paideia (Section 9.1.2) has been influential in both educational and therapeutic settings, emphasizing the maieutic aspect of moral and individual formation (philosophical midwifery). Much of the existential lP tradition understands schooling of the heart to be best practiced outside institutions, either in dialogue with a trusted teacher or Vorbild, or in dialogue with literature, art, and one’s own reflections. This process may be better represented in the p ­ sychological literature as social influence. na 9.4.2 Moral Formation as Social Influence Interaction with others who support or challenge our goals can shape both evaluative and normative aspects of moral formation. For instance, a central role of parents is to provide evaluation, support, and guidance to children in their development of moral Fi character (Lapsley, 2020). Close friends, mentors, and spouses can support or inhibit our attainment of valued goals, particularly when they encourage goals that are congruent with our own ideals for ourselves (Rusbult, Finkel, & Kumashiro, 2009). People who are very good in self-­regulation (e.g. in organizing themselves to achieve their goals) tend to shape their social surround to support their goal pursuits (Ent, Baumeister, & Tice, 2015). They prefer to spend time with, collaborate with, and be informed by others who are themselves good at goal pursuit or who are directly instrumental to their goals, choosing colleagues and mentors who support their goal pursuit (vanDellen et al., 2015). Though people with low self-­control tend to reap the most benefit from social support for their goals, they unfortunately are less likely to find themselves in situations where they receive it (Nielsen & Bauer, 2018). But beyond this, interaction can shape and change the moral goals we choose, the rules we emphasize, and the range of our moral concern. Colby and Damon (1992), in their classic study of moral exemplars, document how exemplars are open to, and Taking Moral Action even seek, influence from their social environment that widens their circle of concern. For example, because of her early interests in justice and fairness, Virginia Durr found herself interacting with a variety of social justice activists whose own commitments influenced her to make broader and deeper commitments to social justice (Colby & Damon, 1992, chapter 5). This influence was likely based in both explicit argument with others and implicit influence by others on the way she saw and responded to injustice. These served as catalysts for evaluative and normative moral formation and thus character and personality change. In addition to these interpersonal modes of influence on evaluative moral formation, the structure and social norms of the situations we inhabit can influence our personal development goals and plans. For instance, economies, architecture, and city planning all serve to distance many of us from the harm that meat-­eating causes to those animals we consume (Bastian & Loughnan, 2016). Prejudices and stereotypes, s but also architecture, serve to justify and maintain the existing social order, and vice versa (Jost & Banaji, 1994; Jost & Hunyady, 2005). Extensive work on the self in of cultural context shows that who we become, and who we want to become, is culturally shaped, even in terms of how we critique or struggle against the prevailing culture (Gibbs et al., 2007). ro 9.4.3 Moral Formation as Cultural Conservation and Critique Cultures vary systematically in terms of whether the relations between people are judged based upon independent experience and desire or interdependent social relalP tions.42 “The nail that sticks out is likely to be hammered down in Japan whereas the squeaky wheel attracts grease and attention in the United States” (Markus & Kitayama, 2010, p. 420). The goals, plans, hopes, and narratives of members of a culture are shaped by these ideals. Master narratives, those narratives that are supported by a culture, can shape the personal narrative that an individual adopts. But they can na also become the focus of conflict as people struggle to change or maintain those narratives. For instance, the heterosexual narrative of how family life develops has been challenged by the gay rights movement in the United States (Hammack, 2008), and the acceptable career narrative for women has changed in Western culture over the last decades (Keane, 2015). But in both of these instances, the narrative resources to criFi tique the prevailing culture arose from within that culture in terms of language about human rights – but also religion (Carter, 1993, pp. 39–40). Thus, narratives about moral ideals are influenced by disagreements within a culture and those disagreements often draw on resources from that culture. Across a range of cultures, those who are more politically liberal tend to emphasize justice and care goals, while those who are more politically conservative tend to emphasize loyalty, authority, and sanctity in their judgments and ideals (Graham, Haidt, & Nosek, 2009; Haidt & Joseph, 2004). The difficulty of this meta-­cultural disagreement in values lies in part with the inability of each side to articulate a narrative that appeals to the other side (Haidt, 2012). In these and many other ways, moral formation is socially and culturally embedded. 42 There is, of course, considerable variation within cultures in this dimension, and different aspects of a culture (e.g. legal vs. familial) may embed different assumptions about this. See Chapter 3 for more detail on these differences. Moral Formation 275 9.4.4 Moral Formation and Moral Luck The civil rights activist Virginia Durr did not pay attention to social injustice in her youth but, influenced over the years by her social network and her own commitments to justice and honor, she became exquisitely sensitive to recognizing injustice and working against it (Colby & Damon, 1992). To be sure, some of this was consciously guided, but other episodes seemed automatic and well-­practiced, such as her spontaneous reaction at a women’s church meeting in Alabama when a black participant was asked to leave during lunch since the venue did not allow integrated eating – she walked out with the woman and ate lunch outside (Colby & Damon, 1992, p. 114).43 Ms. Durr’s career in civil rights was also shaped by the accidents of her biography: attending a racially integrated liberal arts college, being introduced in Washington DC to significant figures in the civil rights movement, etc. So the moral luck that s accompanies us all can dramatically change our life stories in ways we do not anticipate.44 We might find that we are led toward some (im)moral goals as events overtake of us, or that our progress toward an (im)moral goal is restricted by events. Or one might not have any plans for becoming a particular kind of person, and instead simply find oneself drawn along a process. We have little systematic knowledge of the variety of paths in adulthood that lead one to moral action, or the role of intention in these ro paths. Or of the various ways that plans, goals, and narrative might reassert themselves in reaction to events. “We are never more (and sometimes much less) than the co-­authors of our own narratives. Only in fantasy do we live what story we please” (MacIntyre, 1981, p. 199).45 Moral formation is thus always multidimensional. It is lP sometimes more and sometimes less intentional, continuous, and controllable. 9.4.5 Critique from the Three Traditions Monasticism is precisely about constructing a moral ecology for moral and spiritual na development. The point of monastic community is to structure life and its influences in the service of the spiritual goal. In its long history, Christian monasticism has seen multiple waves of regression and reform (LeClercq, 1982) that might yield insight to the patterns that support institutions that are effective at moral formation and those that corrupt it. Bildung, in all its variations, is also about constructing an environment Fi conducive to moral growth. There are only hints of this dense interdependence of moral ecology and moral formation in the moral psychology literature. It is most explicit in the work of Nick Epley and colleagues on ethics as a design problem (Epley & Kumar, 2019; Epley & Tannenbaum, 2017).46 The complicated relationships between, for instance, organized religion, prejudice, and terrorism are well documented (see Paloutzian, 2017 for a review) but make no appearance in current 43 There is no evidence in the way she tells the story that her action was considered or weighed on its merits, she simply acted, “we had to go.” 44 See Williams (1981) for philosophical reflections on moral luck. 45 My thanks to Anthony Rudd for his reference to this poignant quote in his essay In Defense of Narrative (Rudd, 2007). 46 See also Killen and Dahl (2021), who make a strong case for social reform based in moral reasoning, though they acknowledge the social and emotional aspects of SERE. Taking Moral Action moral psychology. A fully developed moral psychology would see these issues as ­central. The complex histories of monasticism and Bildung and the existential revival of the Socratic maieutic could each provide fertile ground for theoretical efforts to develop this relationship. 9.5 Discussion All human lives show moral formation, but not all lives are centered on morality; perhaps not even all highly moral lives are centered on morality.47 But one can learn to be (more or less) moral, even in adulthood. This journey from self-­centeredness to socially necessary moral commitment and possibly to moral exemplarity occurs under s multiple constraints and influences and comes in many flavors. This text is in part a catalogue of these influences and processes, and of the myriad ways that personality, moral identity, skills and knowledge, and moral ecology interactively influence and of are influenced by the processes of emotion, reason, and moral formation. 9.5.1 Conclusion ro 1. We should replace a concern for foundationalist criteria and bias with a concern for the role of personal, interpersonal, and cultural critique. For moral formation, critique and struggle on the journey is a better metaphor lP than foundations for a building. The acceptance in moral psychology of what Walker (2004) calls formalist, or foundationalist, rational models (like those of Kohlberg etc.) has led to framing the issues of moral formation in terms of increasing commitment to a foundational criterion.48 This approach is taken in part to escape from a simple relativism that would make us prisoners of socialization or instinct. For example, in Kohlberg, knowledge of and concern for justice is both na the philosophical foundation and the developmental goal. Bias is then framed as coming from any source other than conscious reasoning about justice. Emotional, social, or cultural influence, religion, personality characteristics, etc. are all seen as bias (Walker, 2004). On the contrary, each of these can be a source of support for moral action, and reason can be a source of bias. In the vain pursuit of a foundaFi tionalist stance, we have cut ourselves off from the rich complexity of how and why we take moral action or progress in moral commitment. An alternative, descriptive, model will involve the recognition of the complex of supports and constraints on moral life, the role of an active agent in navigating them, and the process of self-­transcendence and adoption of moral goals. In every chapter in this text, we see the interweaving of these supports, constraints, and 47 One can imagine lives centered on spiritual or religious values that in the right circumstances result in extensive moral action, or lives devoted to ethical rule-­following (rather than to abstract values) that might have a moral profile distinctly different from other moral exemplars (e.g. the exemplary FBI agent). 48 See Lapsley and Hardy (2017) and Lapsley (2020) for a parallel critique of moral development research as isolated within the “cognitive developmental approach to socialization.” Moral Formation 277 navigation. Central processes in this interweaving are personal, interpersonal, and cultural critique. These processes of critique are usually supported by a range of resources: values, master narratives, social influence, emotion, moral ecological influence, etc. These critiques can drive moral formation and we need to better understand the patterns in how they unfold. And it is these processes that allow us to continually critique our personal and societal ultimate values. 2. We cannot avoid grappling with normative claims in studying moral formation. The research program of Frimer, Walker, and colleagues makes a compelling case that a central move in moral commitment is from agency alone to agency in the service of communion. Their empirical description of the movement leads them to say people should make this transition, and that this transition should be valued as morally good – clearly making a normative claim based on, or at least in tandem with, an empirical pattern.49 Further, they claim that an unavoidable task in moral s psychology will be grappling with how normative moral value is embedded in our empirical descriptions of moral development: of theories of moral personhood must endorse not only goals for how individuals should (deontologically) reason right from wrong but also what they should (teleologically) value as being good from bad. The new challenge becomes the highly controversial task of articuro lating and defending an account of which values are preferable in sufficiently broad terms to avoid ethnocentrism. To be clear, our point is that this task is categorically unavoidable for any theory of moral psychology … [W]hich non-­neutral conception of the good is most appropriate remains important conceptual work for the field. [emphasis in the original]50 lP (Frimer & Walker, 2008, pp. 337–338) We agree with the necessity of this task. It is, at the very least, the puzzle at the heart of the moral exemplar approach: studying exemplars necessarily assumes there is a way to describe excellence on a moral dimension and to identify exemplars on that dimension. The first dimension of the TOI model, self-­transcendence, na centers the problem of determining the highest good among the many values for which committed individuals might transcend the self. Adding the dimension of conservation-­openness helps further open up the space of ultimate values and moral exemplars who might serve them. It is clear that moral inclusion/exclusion is a crucial indicator of for whom the self-­ transcendent commitment applies. Fi Understanding self-­transcendence as a process of transcending one’s relative ends to serve a higher good will help to conceptualize the normative question as one of moral action, about how one brings the normative into action (see Section 9.5.1.4). Even rule-­based morality involves selection of which rules are appropriate in what circumstances. It is difficult to imagine any adequate description of moral formation that does not address the puzzles associated with these three dimensions. 49 This should can be read as an instrumental should, that human development in the usual way involves this transition. But it has a flavor of a moral should, of the infinite. Colby and Damon (2015) make a similar claim that the field must grapple with the normative. 50 Note that here the process of evaluation is still limited to reason, and that the criterion seems to be the limited goal of “avoiding ethnocentrism.” Taking Moral Action Choosing ways of evaluating these puzzles will be a central interdisciplinary task in moral psychology.51 3. Moral formation likely occurs across multiple domains and on multiple dimensions. A significant obstacle in research on moral formation has been the desire to identify and map moral formation based upon a single domain or dimension. The fault for this cannot entirely be placed on what Lapsley and Hardy (2017) call the “cognitive developmental approach to socialization.” One can find it in almost all research programs in the area, even those not descended from the Kohlberg project. But complexity is unavoidable. Moral formation occurs with specific, concrete, commitments to a cause and at the abstract value level; the processes operate at implicit and explicit levels; there are multiple dimensions on which one can measure moral change and multiple aspects or levels of personality that can drive moral commitment. We have selected three dimensions among these (TOI: self-­ s transcendence, openness, and inclusion) that we hope will provide the right level of abstraction and the necessary variation to stretch our understanding of moral of formation. 4. An adequate understanding of moral formation must include the dense weave of evaluative, normative, and educative aspects as they guide the processes of self-­Transcendence. ro Moral formation is guided by an ongoing process of commitment to values, goals, or projects, and by the relations among these commitments. It is shaped by individual processes of evaluation of how well we are upholding the values or achieving the goals, and whether those goals are appropriate or even of ultimate concern. It lP is also embedded in a social matrix that schools us in those commitments and evaluations. Moral formation encompasses personality, reason, emotion, skills, moral ecology, and moral identity. It is an internal action of commitment, but one calling for expression, practice, and evaluation in moral action within specific domains of life and social contexts. Recognizing which aspects of moral formation na are occurring at what times and how they interweave will be crucial to understanding individuals’ moral life trajectories as they navigate their lives. Understanding this complexity in moral formation will require interdisciplinary rigor in investigation, rather than simple hand waving. Our critiques of the processes at the end of each section suggest fertile ground for this interdisciplinary investigation. Fi 9.5.2 Application We met the Munson family in the Introduction and we return to them here. They were seemingly living the good life of the upper middle class when they decided to take in foster children. Their religious backgrounds suggest that communal value commitments played a part in this decision. But it may have been a more self-­centered desire for a family as fulfillment of a community role. It is also possible that their religious commitments were their first priority and that these in turn lead to ­commitment that 51 This task is the door to philosophy and theology. If the task of choosing “which values are preferable” is indeed unavoidable, then this door is also unavoidable. Theologians can do this without necessarily being sectarian, as exemplified by Herdt’s (2019) expansive conclusion to her book on Bildung. Moral Formation 279 a psychologist might describe as communal (though actually rooted in a religious value dimension). The monk Thomas Merton’s initial commitments seemed focused on personal religious need in a close-­knit monastic community, but the social upheaval of his time, and the religious narratives in which he was embedded, offered him an opportunity to channel this into a profound concern for the oppressed. Thus, his journey of moral formation, as well as the Munsons’, is shaped and supported by the variety of contexts, influences, and processes we outline in this book. The Munson narrative is one of a slow, stepwise increase in commitment. First, they committed to some particular children, then, faced with physically disabled children, they redoubled their commitment to the children but also extended it to other children like them who were having trouble finding services to help them. Their work in this area led to volunteering at schools, serving on boards, and eventually founding a charitable organization to provide the needed services to children in the area. s Surely the levels of commitment and the actual goal of their actions changed over time. But if we were to interview them, it seems unlikely they would describe the of process as one of continuous rational evaluation of their commitments and planned increases in action based on the outcome of those reflections. However, they might well agree with a narrative of a journey in which they were drawn to do more of the good than they had started out with. This deepening of what came to be an ultimate ro concern is part and parcel of moral formation approaches across contemplative and religious traditions, we can find it in concepts of existential appropriation as well as in the education of the heart. This deepening of what concerns us ultimately, the moral good we consider our highest, comes with the task of evaluating and re-­evaluating lP not only our normative value system, but also the nature of our attachments to each of them. It is as much shaped by the nature of our evaluations, choices, and commitments as it is by our situation and culture. At each turn in the journey, the Munsons might have decided they had done enough. Then they would not have been confronted with the next situation that also had its calls for commitment or rejection. na"
9,9.5,"Discussion All human lives show moral formation, but not all lives are centered on morality; perhaps not even all highly moral lives are centered on morality.47 But one can learn to be (more or less) moral, even in adulthood. This journey from self-­centeredness to socially necessary moral commitment and possibly to moral exemplarity occurs under s multiple constraints and influences and comes in many flavors. This text is in part a catalogue of these influences and processes, and of the myriad ways that personality, moral identity, skills and knowledge, and moral ecology interactively influence and of are influenced by the processes of emotion, reason, and moral formation. 9.5.1 Conclusion ro 1. We should replace a concern for foundationalist criteria and bias with a concern for the role of personal, interpersonal, and cultural critique. For moral formation, critique and struggle on the journey is a better metaphor lP than foundations for a building. The acceptance in moral psychology of what Walker (2004) calls formalist, or foundationalist, rational models (like those of Kohlberg etc.) has led to framing the issues of moral formation in terms of increasing commitment to a foundational criterion.48 This approach is taken in part to escape from a simple relativism that would make us prisoners of socialization or instinct. For example, in Kohlberg, knowledge of and concern for justice is both na the philosophical foundation and the developmental goal. Bias is then framed as coming from any source other than conscious reasoning about justice. Emotional, social, or cultural influence, religion, personality characteristics, etc. are all seen as bias (Walker, 2004). On the contrary, each of these can be a source of support for moral action, and reason can be a source of bias. In the vain pursuit of a foundaFi tionalist stance, we have cut ourselves off from the rich complexity of how and why we take moral action or progress in moral commitment. An alternative, descriptive, model will involve the recognition of the complex of supports and constraints on moral life, the role of an active agent in navigating them, and the process of self-­transcendence and adoption of moral goals. In every chapter in this text, we see the interweaving of these supports, constraints, and 47 One can imagine lives centered on spiritual or religious values that in the right circumstances result in extensive moral action, or lives devoted to ethical rule-­following (rather than to abstract values) that might have a moral profile distinctly different from other moral exemplars (e.g. the exemplary FBI agent). 48 See Lapsley and Hardy (2017) and Lapsley (2020) for a parallel critique of moral development research as isolated within the “cognitive developmental approach to socialization.” Moral Formation 277 navigation. Central processes in this interweaving are personal, interpersonal, and cultural critique. These processes of critique are usually supported by a range of resources: values, master narratives, social influence, emotion, moral ecological influence, etc. These critiques can drive moral formation and we need to better understand the patterns in how they unfold. And it is these processes that allow us to continually critique our personal and societal ultimate values. 2. We cannot avoid grappling with normative claims in studying moral formation. The research program of Frimer, Walker, and colleagues makes a compelling case that a central move in moral commitment is from agency alone to agency in the service of communion. Their empirical description of the movement leads them to say people should make this transition, and that this transition should be valued as morally good – clearly making a normative claim based on, or at least in tandem with, an empirical pattern.49 Further, they claim that an unavoidable task in moral s psychology will be grappling with how normative moral value is embedded in our empirical descriptions of moral development: of theories of moral personhood must endorse not only goals for how individuals should (deontologically) reason right from wrong but also what they should (teleologically) value as being good from bad. The new challenge becomes the highly controversial task of articuro lating and defending an account of which values are preferable in sufficiently broad terms to avoid ethnocentrism. To be clear, our point is that this task is categorically unavoidable for any theory of moral psychology … [W]hich non-­neutral conception of the good is most appropriate remains important conceptual work for the field. [emphasis in the original]50 lP (Frimer & Walker, 2008, pp. 337–338) We agree with the necessity of this task. It is, at the very least, the puzzle at the heart of the moral exemplar approach: studying exemplars necessarily assumes there is a way to describe excellence on a moral dimension and to identify exemplars on that dimension. The first dimension of the TOI model, self-­transcendence, na centers the problem of determining the highest good among the many values for which committed individuals might transcend the self. Adding the dimension of conservation-­openness helps further open up the space of ultimate values and moral exemplars who might serve them. It is clear that moral inclusion/exclusion is a crucial indicator of for whom the self-­ transcendent commitment applies. Fi Understanding self-­transcendence as a process of transcending one’s relative ends to serve a higher good will help to conceptualize the normative question as one of moral action, about how one brings the normative into action (see Section 9.5.1.4). Even rule-­based morality involves selection of which rules are appropriate in what circumstances. It is difficult to imagine any adequate description of moral formation that does not address the puzzles associated with these three dimensions. 49 This should can be read as an instrumental should, that human development in the usual way involves this transition. But it has a flavor of a moral should, of the infinite. Colby and Damon (2015) make a similar claim that the field must grapple with the normative. 50 Note that here the process of evaluation is still limited to reason, and that the criterion seems to be the limited goal of “avoiding ethnocentrism.” Taking Moral Action Choosing ways of evaluating these puzzles will be a central interdisciplinary task in moral psychology.51 3. Moral formation likely occurs across multiple domains and on multiple dimensions. A significant obstacle in research on moral formation has been the desire to identify and map moral formation based upon a single domain or dimension. The fault for this cannot entirely be placed on what Lapsley and Hardy (2017) call the “cognitive developmental approach to socialization.” One can find it in almost all research programs in the area, even those not descended from the Kohlberg project. But complexity is unavoidable. Moral formation occurs with specific, concrete, commitments to a cause and at the abstract value level; the processes operate at implicit and explicit levels; there are multiple dimensions on which one can measure moral change and multiple aspects or levels of personality that can drive moral commitment. We have selected three dimensions among these (TOI: self-­ s transcendence, openness, and inclusion) that we hope will provide the right level of abstraction and the necessary variation to stretch our understanding of moral of formation. 4. An adequate understanding of moral formation must include the dense weave of evaluative, normative, and educative aspects as they guide the processes of self-­Transcendence. ro Moral formation is guided by an ongoing process of commitment to values, goals, or projects, and by the relations among these commitments. It is shaped by individual processes of evaluation of how well we are upholding the values or achieving the goals, and whether those goals are appropriate or even of ultimate concern. It lP is also embedded in a social matrix that schools us in those commitments and evaluations. Moral formation encompasses personality, reason, emotion, skills, moral ecology, and moral identity. It is an internal action of commitment, but one calling for expression, practice, and evaluation in moral action within specific domains of life and social contexts. Recognizing which aspects of moral formation na are occurring at what times and how they interweave will be crucial to understanding individuals’ moral life trajectories as they navigate their lives. Understanding this complexity in moral formation will require interdisciplinary rigor in investigation, rather than simple hand waving. Our critiques of the processes at the end of each section suggest fertile ground for this interdisciplinary investigation. Fi 9.5.2 Application We met the Munson family in the Introduction and we return to them here. They were seemingly living the good life of the upper middle class when they decided to take in foster children. Their religious backgrounds suggest that communal value commitments played a part in this decision. But it may have been a more self-­centered desire for a family as fulfillment of a community role. It is also possible that their religious commitments were their first priority and that these in turn lead to ­commitment that 51 This task is the door to philosophy and theology. If the task of choosing “which values are preferable” is indeed unavoidable, then this door is also unavoidable. Theologians can do this without necessarily being sectarian, as exemplified by Herdt’s (2019) expansive conclusion to her book on Bildung. Moral Formation 279 a psychologist might describe as communal (though actually rooted in a religious value dimension). The monk Thomas Merton’s initial commitments seemed focused on personal religious need in a close-­knit monastic community, but the social upheaval of his time, and the religious narratives in which he was embedded, offered him an opportunity to channel this into a profound concern for the oppressed. Thus, his journey of moral formation, as well as the Munsons’, is shaped and supported by the variety of contexts, influences, and processes we outline in this book. The Munson narrative is one of a slow, stepwise increase in commitment. First, they committed to some particular children, then, faced with physically disabled children, they redoubled their commitment to the children but also extended it to other children like them who were having trouble finding services to help them. Their work in this area led to volunteering at schools, serving on boards, and eventually founding a charitable organization to provide the needed services to children in the area. s Surely the levels of commitment and the actual goal of their actions changed over time. But if we were to interview them, it seems unlikely they would describe the of process as one of continuous rational evaluation of their commitments and planned increases in action based on the outcome of those reflections. However, they might well agree with a narrative of a journey in which they were drawn to do more of the good than they had started out with. This deepening of what came to be an ultimate ro concern is part and parcel of moral formation approaches across contemplative and religious traditions, we can find it in concepts of existential appropriation as well as in the education of the heart. This deepening of what concerns us ultimately, the moral good we consider our highest, comes with the task of evaluating and re-­evaluating lP not only our normative value system, but also the nature of our attachments to each of them. It is as much shaped by the nature of our evaluations, choices, and commitments as it is by our situation and culture. At each turn in the journey, the Munsons might have decided they had done enough. Then they would not have been confronted with the next situation that also had its calls for commitment or rejection. na 9.5.3 Open Questions The central task and puzzle of this chapter is to assemble the various aspects of moral formation in a way that is faithful to the wide variety of (im)moral trajectories. Only Fi then can we begin carefully to think about how to empirically describe them and how to theoretically explain them. We suggest here some open questions that this attempt offers: 1. Are there common psychological aspects to the commitments to the many different types of self-­transcending values and ultimate concerns? We have noted that most moral exemplars do not start out with a conscious commitment to “being good” but begin instead with specific commitments as the Munsons or Thomas Merton do in our application case. At this more concrete level, there may be thousands of ways to get on the path to moral formation. In fact, an existential viewpoint would suggest that we are already and always on that path, whether we want it or not. Still, at some higher abstract level this multitude may fit the self-­enhancement to self-­transcendence description. We have regularly remarked that some things that are taken to be ultimate can lead to terrorism, Taking Moral Action genocide, and other evils. Are the processes of commitment, evaluation, and schooling the same in all cases, good and evil? Are there any of these processes that might help us in distinguishing good vs. evil vs. indifferent commitments? What aspects of these processes and commitments constitute what is commonly called virtue? How are they distinguished from vice? And what might we learn from studying the negative trajectory of someone’s moral formation? 2. What is the relation of skill development to taking moral action? The study by Frimer et al. (2012) provides us with a way to frame this question. In their study of exemplars taken from the front pages of Time Magazine, they identify “agentic” and communal exemplars. Agentic exemplars are known for taking effective action, but not really for taking effective moral action. Do these two groups share skill sets, or are there some skills that are more associated with taking effective moral action? What might these moral skills be? Does developing these s moral skills influence moral formation or are these two different tasks? The monastic tradition we covered early in the chapter highlights some form of humility as of crucial in moral formation. There are empirical literatures we review in this chapter that identify the skills associated with a robust humility. 3. How might the traditional accounts of moral formation help us understand and explain psychological processes of moral action? ro Most psychological analyses of moral formation tend to fragment the processes they study, and scientific psychology is often drawn to those aspects that are easiest to measure or seem most objective. They concentrate on cognition, or emotional regulation, and there is little within them that compels a theoretical change of lP perspective, broadening of focus, or deepening of understanding. Nor do they grapple with the existential depth of the struggle with the human condition and the infinite. This is how we end up with a pile of pearls and no string to bind them together. We have presented several more holistic approaches to moral formation that are non-­scientific but nevertheless deeply empirically oriented because they na are based in long traditions of observation and critique of human moral action. These traditions see moral formation as both the self’s careful navigation of the moral world and an intentional reflection on and deepening of our commitments; as a longing search for wholeness and a willingness to let oneself and one’s goals be challenged by the social and normative world one encounters. If they are compliFi cated and paradoxical, it is likely because the phenomenon they have been closely observing and trying to guide is itself complicated, paradoxical, and full of variation. We are not proposing these traditions as alternative psychological theories. Rather, each proposes its approach as a practical “school” for formation that suggests opportunities for psychological research. See our comments at the end of each section for specific critiques that draw from this well of practical, empirical experience. Rigorous interdisciplinary inquiry may help identify ways that existing theoretical and empirical approaches in psychology are overlooking or ignoring important aspects of the broader process of moral formation. 4. How does moral ecology interact with moral formation? A theme throughout this text has been the applied question of how we can construct moral ecologies that support moral action. We now have some language to phrase that question in a way that may advance the conversation: How can we Moral Formation 281 construct moral ecologies that support effective individual, social, and cultural c­ ritique in a way that helps achieve appropriate SERE in moral commitments and action? There are many questions remaining within each of the terms in that sentence. And modifiers like “appropriate” are invitations – perhaps even demands – for interdisciplinary collaboration. Nevertheless, we hope this phrasing of the question opens the doors to conversations in service of moral action. 5. How is a SERE achieved and maintained in the face of ultimate commitments? In several other chapters (e.g. Chapters 3, 7, and 8) we mention the processes of social and cultural critique. This chapter has primarily focused on processes of personal critique (as does Chapter 5). And we have argued often that seeking a SERE is a useful description for these processes. This balance occurs across multiple dimensions (social, emotional, cognitive). We do not propose a model for how this happens. We are simply specifying the things one must bring into equilibrium. The s phrase reflective equilibrium is taken from philosophy (Rawls, 1971/1999) and suggests a balance among considerations. But clearly, if one is considering ultimate of concerns, equally weighting all the concerns is out of the question. How does one find a weighted balance in the face of the ultimate? So, perhaps it is achieving the appropriate tension instead. Maintaining this tension among our values, goals, or projects might be what allows the process of recognizing disfluency (see Chapter 6) ro when the tension among our moral commitments becomes too great. This recognition of disfluency helps one to break out of automatic processes and begin conscious, controlled reflection on why things are not working. This reflection may mean re-­evaluating a host of things, including one’s ultimate commitment (see the lP Chapter 5 for the complexity involved here). Thus, reflective equilibrium might be better expressed as the feeling of peace or clarity one achieves after the weighing and recalibration process. na"
9,9.6,"Further Readings These suggested readings are designed to lead the reader further into the literature that forms the main themes of this chapter. They combine some classic pieces and Fi recent work. Complete citations are provided in the references section. • McAdams (2013). “The psychological self as actor, agent, and author.” An understanding of change in the self at three different levels. • Bluck et al. (2005). “A tale of three functions: The self-­reported uses of autobiographical memory.” An empirical study to explore the uses of autobiographical narrative in both change and maintenance of the self. • Colby and Damon (1992). Some Do Care: Contemporary Lives of Moral Commitment. A classic study of moral exemplars in social service in the United States that includes discussion of change in moral commitments over time. • Applebaum (2012). Iron Curtain: The Crushing of Eastern Europe 1944–1956. A study of Soviet repression in East Germany, Hungary, and Poland. It shows the complexities of changing moral ecologies and their influence on moral commitment and ultimate value. Taking Moral Action • Gelfand (2021). “Cultural evolutionary mismatches in response to collective threat.” An overview of the idea of cultural tightness: a concept containing both strictness of norm following and narrowness of in-­group. This varies across both cultures and over time. • Herdt (2019). Forming Humanity: Redeeming the German Bildung Tradition. A comprehensive, complex, and subtle overview of the Bildung tradition from its classical sources to its integration in current theological and philosophical thought. • Walker and Frimer (2015). “Developmental trajectories of agency and communion in moral motivation.” Theoretical review of their research program that documents change from agentic commitments to agency in service of communion in adolescents, young adults, and moral exemplars. • Wrzus and Roberts (2017). “Processes of personality development in adulthood: The TESSERA framework.” A complex model of personality change that incorpos rates both implicit and intentional change. of"
